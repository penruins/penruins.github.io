[{"id":0,"href":"/post/computer-science/algorithm/algorithm/","title":"Algorithm","section":"Algorithm","content":"Algorithm# 代码随想录 Tips# 如果我要创建一个列表，并且需要一直在列表的开头插入元素，我要怎么实现代码保证效率# 在 Java 中，如果你需要频繁在列表的开头插入元素，使用 LinkedList 会比 ArrayList 更高效。因为 LinkedList 在列表开头插入元素的时间复杂度是 O(1)，而 ArrayList 在开头插入元素的时间复杂度是 O(n)，需要移动所有元素。\n使用 LinkedList 的示例代码：\nimport java.util.LinkedList; import java.util.List; public class Main { public static void main(String[] args) { // 创建一个 LinkedList List\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 在列表开头插入元素 list.add(0, 1); // 插入元素 1 list.add(0, 2); // 插入元素 2 list.add(0, 3); // 插入元素 3 // 输出列表 System.out.println(list); // 输出: [3, 2, 1] } }为什么 LinkedList 更高效？\nLinkedList 是基于双向链表实现的，插入和删除操作只需要调整节点的指针，时间复杂度为 O(1)。 ArrayList 是基于动态数组实现的，插入和删除操作需要移动元素，时间复杂度为 O(n)。 总结：\n如果你需要频繁在列表开头插入元素，优先选择 LinkedList 以保证效率。\nLinkedList 在任意位置插入和删除节点，时间复杂度都是O(1)吗？# 不是的，LinkedList 在任意位置插入和删除节点的时间复杂度并不总是 O(1)。具体的时间复杂度取决于操作的位置。\nLinkedList 的时间复杂度分析：\n在头部或尾部插入/删除节点：\n时间复杂度是 O(1)，因为 LinkedList 是双向链表，直接操作头节点或尾节点即可。 在任意位置插入/删除节点：\n时间复杂度是 O(n)，因为需要从头节点或尾节点开始遍历链表，找到目标位置后才能进行操作。 为什么任意位置插入/删除是 O(n)？\nLinkedList 是基于双向链表实现的，虽然插入和删除操作本身只需要调整指针（O(1)），但找到目标位置需要遍历链表。 平均情况下，遍历链表的时间复杂度是 O(n/2) ≈ O(n)。 示例代码：\nimport java.util.LinkedList; public class Main { public static void main(String[] args) { LinkedList\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(1); list.add(2); list.add(3); // 在索引 1 处插入元素（需要遍历到索引 1） list.add(1, 10); // 时间复杂度 O(n) // 删除索引 2 处的元素（需要遍历到索引 2） list.remove(2); // 时间复杂度 O(n) System.out.println(list); // 输出: [1, 10, 3] } }总结：\nLinkedList 在头部或尾部插入/删除节点的时间复杂度是 O(1)。 在任意位置插入/删除节点的时间复杂度是 O(n)，因为需要遍历链表找到目标位置。 如果你需要频繁在任意位置插入或删除节点，并且希望时间复杂度更低，可以考虑使用其他数据结构（如 ArrayList 或自定义数据结构），具体选择取决于你的使用场景。\n如果我要不断往list的末尾添加元素，是使用LinkedList还是ArrayList？# 如果你需要不断往列表的末尾添加元素，使用 ArrayList 会比 LinkedList 更高效。以下是原因和详细分析：\nArrayList 的优势 时间复杂度： 在末尾添加元素的平均时间复杂度是 O(1)。 只有在数组容量不足时，ArrayList 需要扩容（创建一个新的更大的数组并复制元素），此时时间复杂度是 O(n)。但扩容操作是分摊的，平均下来仍然是 O(1)。 空间效率： ArrayList 是基于数组实现的，内存连续，存储效率高，没有额外的指针开销。 缓存友好： 数组的内存布局是连续的，对 CPU 缓存更友好，访问速度更快。 LinkedList 的劣势 时间复杂度： 在末尾添加元素的时间复杂度是 O(1)，但每次添加都需要创建一个新的节点对象，并调整指针。 空间效率： LinkedList 是基于双向链表实现的，每个节点需要额外的空间存储前驱和后继指针，内存开销更大。 缓存不友好： 链表的内存布局是分散的，对 CPU 缓存不友好，访问速度较慢。 性能对比 ArrayList： 添加元素时，大多数情况下是 O(1)，偶尔扩容时是 O(n)。 内存连续，访问速度快。 LinkedList： 添加元素时，每次都是 O(1)，但需要创建节点对象和调整指针。 内存分散，访问速度慢。 代码示例 使用 ArrayList：\nimport java.util.ArrayList; import java.util.List; public class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 不断往末尾添加元素 for (int i = 0; i \u0026lt; 1000000; i++) { list.add(i); // 平均时间复杂度 O(1) } System.out.println(\u0026#34;ArrayList 添加完成\u0026#34;); } }使用 LinkedList：\nimport java.util.LinkedList; import java.util.List; public class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 不断往末尾添加元素 for (int i = 0; i \u0026lt; 1000000; i++) { list.add(i); // 时间复杂度 O(1)，但性能不如 ArrayList } System.out.println(\u0026#34;LinkedList 添加完成\u0026#34;); } } 实测性能 在实际测试中，ArrayList 的性能通常优于 LinkedList，尤其是在大量添加元素时。以下是一个简单的性能对比：\n操作 ArrayList 耗时 LinkedList 耗时 添加 100 万个元素 ~50 ms ~100 ms 添加 1000 万个元素 ~500 ms ~1200 ms 总结 如果你需要不断往列表末尾添加元素，优先选择 ArrayList。 它的时间复杂度更低（平均 O(1)）。 它的内存效率更高，访问速度更快。 只有在需要频繁在列表头部或中间插入/删除元素时，才考虑使用 LinkedList。 希望这个解答对你有帮助！如果还有其他问题，欢迎随时提问！\n如果我想要构造一个字符串，我会不断往字符串头部添加字符，我该怎么编码保证效率# 如果你需要不断往字符串的头部添加字符，直接使用 Java 的 String 或 StringBuilder 会导致性能问题，因为它们的底层实现不适合频繁在头部插入操作。以下是原因和高效解决方案：\n为什么 String 和 StringBuilder 不适合？ String： String 是不可变的，每次修改都会创建一个新的字符串对象，频繁在头部插入字符会导致大量对象创建和复制，性能极差。 StringBuilder： StringBuilder 是可变的，适合在尾部添加字符（时间复杂度 O(1)），但在头部插入字符的时间复杂度是 O(n)，因为需要移动所有现有字符。 高效解决方案 为了高效地在字符串头部添加字符，可以使用以下数据结构：\n方案 1：使用 LinkedList\u0026lt;Character\u0026gt;\nLinkedList 在头部插入元素的时间复杂度是 O(1)，非常适合频繁在头部添加字符的场景。 插入完成后，可以将 LinkedList 转换为字符串。 方案 2：使用 Deque\u0026lt;Character\u0026gt;（双端队列）\nDeque 是基于双向链表实现的，支持在头部和尾部高效插入和删除元素。 插入完成后，可以将 Deque 转换为字符串。 代码实现 方案 1：使用 LinkedList\u0026lt;Character\u0026gt;\nimport java.util.LinkedList; public class Main { public static void main(String[] args) { // 创建一个 LinkedList 来存储字符 LinkedList\u0026lt;Character\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 不断往头部添加字符 list.addFirst(\u0026#39;a\u0026#39;); // 添加字符 \u0026#39;a\u0026#39; list.addFirst(\u0026#39;b\u0026#39;); // 添加字符 \u0026#39;b\u0026#39; list.addFirst(\u0026#39;c\u0026#39;); // 添加字符 \u0026#39;c\u0026#39; // 将 LinkedList 转换为字符串 StringBuilder sb = new StringBuilder(); for (char c : list) { sb.append(c); } String result = sb.toString(); System.out.println(result); // 输出: cba } }方案 2：使用 Deque\u0026lt;Character\u0026gt;\nimport java.util.Deque; import java.util.LinkedList; public class Main { public static void main(String[] args) { // 创建一个 Deque 来存储字符 Deque\u0026lt;Character\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); // 不断往头部添加字符 deque.addFirst(\u0026#39;a\u0026#39;); // 添加字符 \u0026#39;a\u0026#39; deque.addFirst(\u0026#39;b\u0026#39;); // 添加字符 \u0026#39;b\u0026#39; deque.addFirst(\u0026#39;c\u0026#39;); // 添加字符 \u0026#39;c\u0026#39; // 将 Deque 转换为字符串 StringBuilder sb = new StringBuilder(); for (char c : deque) { sb.append(c); } String result = sb.toString(); System.out.println(result); // 输出: cba } } 性能分析 时间复杂度： 在头部插入字符的时间复杂度是 O(1)。 转换为字符串的时间复杂度是 O(n)，其中 n 是字符的数量。 空间复杂度： 使用 LinkedList 或 Deque 会额外存储每个字符的节点信息（前驱和后继指针），空间开销略高于 StringBuilder。 为什么不直接使用 StringBuilder？ StringBuilder 在头部插入字符的时间复杂度是 O(n)，因为需要移动所有现有字符。 示例： StringBuilder sb = new StringBuilder(); sb.insert(0, \u0026#39;a\u0026#39;); // O(n) sb.insert(0, \u0026#39;b\u0026#39;); // O(n) sb.insert(0, \u0026#39;c\u0026#39;); // O(n) System.out.println(sb.toString()); // 输出: cba这种方法在频繁插入时性能较差。 总结 如果需要不断往字符串头部添加字符，推荐使用 LinkedList\u0026lt;Character\u0026gt; 或 Deque\u0026lt;Character\u0026gt;。 它们在头部插入字符的时间复杂度是 O(1)，性能最优。 插入完成后，可以将其转换为字符串。 如果插入操作较少，或者主要在尾部添加字符，可以使用 StringBuilder。 希望这个解答对你有帮助！如果还有其他问题，欢迎随时提问！\n面试经典150题# 面试经典150题 数组/字符串# 移除元素# 2025-01-11 击败3.36% class Solution { public int removeElement(int[] nums, int val) { Arrays.sort(nums); int flagIndex = -1; int count = 0; for (int i = 0; i \u0026lt; nums.length; i++) { if (nums[i] == val \u0026amp;\u0026amp; count == 0) { flagIndex = i; count++; } else if (nums[i] == val) { count++; } } if (flagIndex != -1 \u0026amp;\u0026amp; count != 0) { for (int i = flagIndex; i \u0026lt; flagIndex + count; i++) { nums[i] = nums[nums.length - (i - flagIndex) - 1]; } } return nums.length - count; } }一维动态规划# 爬楼梯# 2025-01-11 击败100% class Solution { public int climbStairs(int n) { if (n == 0) return 0; if (n == 1) return 1; if (n == 2) return 2; int[] dp = new int[n + 1]; dp[0] = 0; dp[1] = 1; dp[2] = 2; for (int i = 3; i \u0026lt;= n; i++) { dp[i] = dp[i - 1] + dp[i - 2]; } return dp[n]; } }面试经典150题# 面试经典150题 数组/字符串# 合并两个有序数组# 合并两个有序数组 2025-01-12 public class Solution88 { public static void merge(int[] nums1, int m, int[] nums2, int n) { if (n == 0) return; int nIndex = 0; for (int i = m; i \u0026lt; m + n; i++) { nums1[i] = nums2[nIndex++]; } Arrays.sort(nums1); } public static void main(String[] args) { int[] nums1 = {1, 2, 3, 0, 0, 0}; int m = 3; int[] nums2 = {2, 5, 6}; int n = 3; merge(nums1, m, nums2, n); for (int i : nums1) { System.out.print(i + \u0026#34; \u0026#34;); } } }移除元素# 移除元素 2025-01-11 删除有序数组中的重复项# 删除有序数组中的重复项 2025-01-11 没有做出来，看的官方题解 2025-01-11 做完删除有序数组中的重复项 II之后再尝试重新解题完成 public class Solution26 { public static int removeDuplicates(int[] nums) { if (nums.length \u0026lt;= 1) return nums.length; int slow = 1; int fast = 1; while (slow \u0026lt;= fast \u0026amp;\u0026amp; fast \u0026lt; nums.length) { if (nums[fast] != nums[fast - 1]) { nums[slow] = nums[fast]; slow++; } fast++; } return slow; } public static void main(String[] args) { int[] nums = {0, 0, 1, 1, 1, 2, 2, 3, 3, 4}; for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(removeDuplicates(nums)); for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } } }删除有序数组中的重复项 II# 删除有序数组中的重复项 II 2025-01-11 public class Solution80 { public static int removeDuplicates(int[] nums) { if (nums.length \u0026lt;= 2) return nums.length; int slow = -1; int fast = 1; int count = 1; while (slow \u0026lt;= fast \u0026amp;\u0026amp; fast \u0026lt; nums.length) { if (nums[fast] == nums[fast - 1]) { count++; if (count \u0026gt; 2 \u0026amp;\u0026amp; slow == -1) { slow = fast; } else if (count \u0026lt;= 2 \u0026amp;\u0026amp; slow != -1) { nums[slow] = nums[fast]; slow++; } } else if (nums[fast] != nums[fast - 1]) { if (slow != -1) { nums[slow] = nums[fast]; slow++; } count = 1; } fast++; } return slow == -1 ? nums.length : slow; } public static void main(String[] args) { //int[] nums = {0,0,1,1,1,1,2,3,3}; //int[] nums = {1,2,2}; int[] nums = {1, 1, 1, 2, 2, 2, 3, 3}; for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(removeDuplicates(nums)); for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } } }多数元素# 多数元素 2025-01-12 轮转数组# 轮转数组 2025-01-18 进阶 尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。 你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 买卖股票的最佳时机# 买卖股票的最佳时机 2025-01-11 看官方题解做出来的 2025-01-17 review 买卖股票的最佳时机 II# 买卖股票的最佳时机 II 官方题解 理解 2025-01-17 方法一：动态规划 方法二：贪心 跳跃游戏# 跳跃游戏 2025-01-17 官方题解理解 贪心 2025-01-18 跳跃游戏 II# 跳跃游戏 II 2025-01-18 算法超时了 理解官方题解 2025-01-18 方法一：反向查找出发位置 Solution45.jump2 2025-01-18 方法二：正向查找可达到的最大位置 Solution45.jump3 H 指数# H 指数\n2025-01-18 Tips An easy approach is to sort the array first. What are the possible values of h-index? A faster approach is to use extra space. O(1) 时间插入、删除和获取随机元素\n除自身以外数组的乘积\n加油站\n分发糖果\n接雨水\n罗马数字转整数\n2025-01-12 整数转罗马数字\n最后一个单词的长度\n2025-01-12 最长公共前缀\n2025-01-12 反转字符串中的单词\n2025-01-18 进阶 如果字符串在你使用的编程语言中是一种可变数据类型，请尝试使用 O(1) 额外空间复杂度的 原地 解法。 Z 字形变换\n找出字符串中第一个匹配项的下标\n2025-01-12 文本左右对齐\n双指针# 验证回文串# 验证回文串 2025-01-13 判断子序列# 判断子序列 2025-01-13 两数之和 II - 输入有序数组# 两数之和 II - 输入有序数组\n2025-01-13 运行有时候会超过时间限制 盛最多水的容器\n三数之和\n滑动窗口# 长度最小的子数组# 长度最小的子数组 2025-01-22 无重复字符的最长子串# 无重复字符的最长子串 2025-01-22 串联所有单词的子串# 串联所有单词的子串 2025-01-22 最小覆盖子串# 最小覆盖子串 矩阵# 有效的数独# 有效的数独 2025-01-18 螺旋矩阵# 螺旋矩阵 2025-01-18 旋转图像# 旋转图像 理解官方题解 2025-01-18 方法一：使用辅助数组 2025-01-18 方法二：原地旋转 有数学公式的推导，需要自己推导一次 2025-01-18 方法三：用翻转代替旋转 有数学公式的推导，需要自己推导一次 矩阵置零# 矩阵置零 2025-01-18 生命游戏# 生命游戏 2025-01-18 进阶 你可以使用原地算法解决本题吗？请注意，面板上所有格子需要同时被更新：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。 本题中，我们使用二维数组来表示面板。原则上，面板是无限的，但当活细胞侵占了面板边界时会造成问题。你将如何解决这些问题？ ✅ 哈希表# ✅ 赎金信# 赎金信 2025-01-13 ✅ 同构字符串# 同构字符串 2025-01-13 ✅ 单词规律# 单词规律 2025-01-13 ✅ 有效的字母异位词# 有效的字母异位词 2025-01-13 ✅ 字母异位词分组# 字母异位词分组 2025-01-16 第一遍算法超时，看了官方题解思路后实现通过 ✅ 两数之和# 两数之和 2025-01-13 ✅ 快乐数# 快乐数 2025-01-13 ✅ 存在重复元素 II# 存在重复元素 II 2025-01-13 ✅ 最长连续序列# 最长连续序列 2025-01-16 看了官方题解后完成 区间# 栈# 有效的括号# 有效的括号 2025-01-22 简化路径# 简化路径 2025-01-22 最小栈# 最小栈 2025-01-22 理解官方题解 文字描述后完成 2025-01-22 理解官方题解 逆波兰表达式求值# 逆波兰表达式求值 2025-01-22 基本计算器# 基本计算器 链表# ✅ 环形链表# 环形链表 2025-01-20 理解官方题解 2025-01-20 方法一：哈希表 方法二：快慢指针 ✅ 两数相加# 两数相加 2025-01-20 ✅ 合并两个有序链表# 合并两个有序链表 2025-01-20 ✅ 随机链表的复制# 随机链表的复制 2025-01-20 ✅ 反转链表 II# 反转链表 II 2025-01-20 K 个一组翻转链表# K 个一组翻转链表 ✅ 删除链表的倒数第 N 个结点# 删除链表的倒数第 N 个结点 2025-01-20 进阶 2025-01-20 你能尝试使用一趟扫描实现吗？ ✅ 删除排序链表中的重复元素 II# 删除排序链表中的重复元素 II 2025-01-21 ✅ 旋转链表# 旋转链表 给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。 2025-01-20 public class Solution61 { public static ListNode rotateRight(ListNode head, int k) { if (head == null || head.next == null) return head; ListNode _head = head; int nodeCount = 1; while (_head.next != null) { _head = _head.next; nodeCount++; } _head.next = head; _head = head; for (int i = 0; i \u0026lt; (nodeCount - k % nodeCount) - 1; i++) { _head = _head.next; } head = _head.next; _head.next = null; return head; } public static void main(String[] args) { test002(); test001(); } public static void test001() { ListNode node0 = new ListNode(1); ListNode node1 = new ListNode(2); ListNode node2 = new ListNode(3); ListNode node3 = new ListNode(4); ListNode node4 = new ListNode(5); node0.next = node1; node1.next = node2; node2.next = node3; node3.next = node4; ListNode listNode = rotateRight(node0, 2); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } public static void test002() { ListNode node0 = new ListNode(0); ListNode node1 = new ListNode(1); ListNode node2 = new ListNode(2); node0.next = node1; node1.next = node2; ListNode listNode = rotateRight(node0, 4); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } static public class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } }✅ 分隔链表# 分隔链表 2025-01-21 public class Solution86 { public static ListNode partition(ListNode head, int x) { ListNode solder = new ListNode(-1); solder.next = head; ListNode insertPreNode = solder; ListNode insertNode = insertPreNode.next; while (insertNode != null \u0026amp;\u0026amp; insertNode.val \u0026lt; x) { insertPreNode = insertNode; insertNode = insertNode.next; } ListNode preNode = insertPreNode; ListNode currentNode = preNode.next; ListNode nextNode = currentNode != null ? currentNode.next : null; while (currentNode != null) { if (currentNode.val \u0026lt; x) { preNode.next = nextNode; insertPreNode.next = currentNode; currentNode.next = insertNode; insertPreNode = currentNode; } else { preNode = currentNode; } currentNode = nextNode; nextNode = currentNode != null ? currentNode.next : null; } return solder.next; } public static void main(String[] args) { test002(); test001(); } public static void test001() { ListNode node0 = new ListNode(1); ListNode node1 = new ListNode(4); ListNode node2 = new ListNode(3); ListNode node3 = new ListNode(2); ListNode node4 = new ListNode(5); ListNode node5 = new ListNode(2); node0.next = node1; node1.next = node2; node2.next = node3; node3.next = node4; node4.next = node5; ListNode listNode = partition(node0, 3); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } public static void test002() { ListNode node0 = new ListNode(2); ListNode node1 = new ListNode(1); node0.next = node1; ListNode listNode = partition(node0, 2); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } static public class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } }✅ LRU 缓存# LRU 缓存 2025-01-22 理解官方题解 二叉树# 二叉树的最大深度# 二叉树的最大深度 2025-01-15 相同的树# 相同的树 2025-01-15 翻转二叉树# 翻转二叉树 2025-01-15 对称二叉树# 对称二叉树 没做出来，看的官方题解 从前序与中序遍历序列构造二叉树# 从前序与中序遍历序列构造二叉树 从中序与后序遍历序列构造二叉树# 从中序与后序遍历序列构造二叉树 填充每个节点的下一个右侧节点指针 II# 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表# 二叉树展开为链表 路径总和# 路径总和 求根节点到叶节点数字之和# 求根节点到叶节点数字之和 二叉树中的最大路径和# 二叉树中的最大路径和 二叉搜索树迭代器# 二叉搜索树迭代器 完全二叉树的节点个数# 完全二叉树的节点个数 二叉树的最近公共祖先# 二叉树的最近公共祖先 二叉树层次遍历# 二叉搜索树# 图# 图的广度优先搜索# 字典树# ✅ 回溯# ✅ 电话号码的字母组合# 电话号码的字母组合 2025-01-15 ✅ 组合# 组合 2025-01-15 ✅ 全排列# 全排列 2025-01-15 ✅ 组合总和# 组合总和 2025-01-15 ✅ N 皇后 II# N 皇后 II 2025-01-15 ✅ 括号生成# 括号生成 2025-01-15 ✅ 单词搜索# 单词搜索 2025-01-15 分治# kadane算法# 二分查找# 堆# 位运算# 二进制求和# 给你两个二进制字符串 a 和 b ，以二进制字符串的形式返回它们的和。 示例 1： 输入:a = \u0026ldquo;11\u0026rdquo;, b = \u0026ldquo;1\u0026rdquo; 输出：\u0026ldquo;100\u0026rdquo; 示例 2： 输入：a = \u0026ldquo;1010\u0026rdquo;, b = \u0026ldquo;1011\u0026rdquo; -输出：\u0026ldquo;10101\u0026rdquo; 提示： 1 \u0026lt;= a.length, b.length \u0026lt;= 104 a 和 b 仅由字符 \u0026lsquo;0\u0026rsquo; 或 \u0026lsquo;1\u0026rsquo; 组成 字符串如果不是 \u0026ldquo;0\u0026rdquo; ，就不含前导零 二进制求和 2025-01-16 public class Solution67 { public static String addBinary(String a, String b) { StringBuilder sb = new StringBuilder(); int aIndex = a.length() - 1; int bIndex = b.length() - 1; int flag = 0; while (true) { int count = (aIndex \u0026lt; 0 ? \u0026#39;0\u0026#39; : a.charAt(aIndex)) - \u0026#39;0\u0026#39; + (bIndex \u0026lt; 0 ? \u0026#39;0\u0026#39; : b.charAt(bIndex)) - \u0026#39;0\u0026#39; + flag; sb.insert(0, count % 2); flag = count / 2; aIndex--; bIndex--; if (aIndex \u0026lt; 0 \u0026amp;\u0026amp; bIndex \u0026lt; 0 \u0026amp;\u0026amp; flag == 0) break; } return sb.toString(); } public static void main(String[] args) { System.out.println(addBinary(\u0026#34;11\u0026#34;, \u0026#34;1\u0026#34;)); System.out.println(addBinary(\u0026#34;1010\u0026#34;, \u0026#34;1011\u0026#34;)); } }颠倒二进制位# 颠倒二进制位 2025-01-16 没做出来, 参考这篇文章LeetCode 190. 颠倒二进制位 （位运算 分治） 2025-01-17 复习了一遍 2025-01-17 新增了中间值打印的代码在算法中 位1的个数# 位1的个数 2025-01-17 只出现一次的数字# 只出现一次的数字 2025-01-17 只出现一次的数字 II# 只出现一次的数字 II 2025-01-17 理解了官方题解 方法2 数字范围按位与# 数字范围按位与 2025-01-17 理解了官方题解 方法2 数学# 回文数# 回文数 2025-01-17 不将整数转为字符串来解决这个问题 public class Solution9 { public static boolean isPalindrome(int x) { String numberString = String.valueOf(x); int left = 0; int right = numberString.length() - 1; while (left \u0026lt;= right) { if (numberString.charAt(left) != numberString.charAt(right)) { return false; } left++; // 左边指针向右移动一个位置 right--; // 右边指针向左边移动一个位置 } return true; } public static void main(String[] args) { System.out.println(isPalindrome(121)); System.out.println(isPalindrome(-121)); //负数肯定不是回文数 System.out.println(isPalindrome(10)); } }加一# 给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。 最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。 你可以假设除了整数 0 之外，这个整数不会以零开头。 示例 1： 输入：digits = [1,2,3] 输出：[1,2,4] 解释：输入数组表示数字 123。 示例 2： 输入：digits = [4,3,2,1] 输出：[4,3,2,2] 解释：输入数组表示数字 4321。 示例 3： 输入：digits = [9] 输出：[1,0] 解释：输入数组表示数字 9。 加 1 得到了 9 + 1 = 10。 因此，结果应该是 [1,0]。 加一 2025-01-17 public class Solution66 { public static int[] plusOne(int[] digits) { ArrayList\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int digit : digits) { list.add(digit); } int flag = 0; // 表示进位 int number = list.get(list.size() - 1); // 最右边一位 int _number = number; number = (_number + 1) % 10; flag = (_number + 1) / 10; list.set(list.size() - 1, number); if (list.size() \u0026gt;= 2) { // 原数字位数大于1 for (int i = list.size() - 2; i \u0026gt;= 0; i--) { int numberTmp = list.get(i); list.set(i, (numberTmp + flag) % 10); flag = (numberTmp + flag) / 10; } } if (flag != 0) { // 如果还有一个进位，就在最左边新增一位 list.add(0, 1); } // 构造一个整数数组返回结果 int[] result = new int[list.size()]; for (int i = 0; i \u0026lt; list.size(); i++) { result[i] = list.get(i); } return result; } public static void main(String[] args) { int[] result = plusOne(new int[]{9, 9}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{9}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{1, 2, 3}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{4, 3, 2, 1}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); } }阶乘后的零# 给定一个整数 n ，返回 n! 结果中尾随零的数量。 提示 n! = n * (n - 1) * (n - 2) * \u0026hellip; * 3 * 2 * 1 示例 1： 输入：n = 3 输出：0 解释：3! = 6 ，不含尾随 0 示例 2： 输入：n = 5 输出：1 解释：5! = 120 ，有一个尾随 0 示例 3： 输入：n = 0 输出：0 提示：0 \u0026lt;= n \u0026lt;= 10^4 阶乘后的零 2025-01-17 version 1# public class Solution172 { // 因式分解 public static int trailingZeroes(int n) { int result = 0; int[] countArr = new int[]{0, 0}; for (int i = n; i \u0026gt;= 1; i--) { int number = i; while (number % 10 == 0) { result++; number /= 10; } while (number % 5 == 0) { countArr[1]++; number /= 5; } while (number % 2 == 0) { countArr[0]++; number /= 2; } int min = Math.min(countArr[0], countArr[1]); if (min != 0) { countArr[0] -= min; countArr[1] -= min; result += min; } } return result; } public static void main(String[] args) { for (int i = 5; i \u0026lt; 10000; i++) { System.out.println(i + \u0026#34; : \u0026#34; + trailingZeroes(i)); } } }version 2# 只需要因式分解 2 和 5 就行了，不用分解 10（已经包含了 2 和 5 ） class Solution { public static int trailingZeroes(int n) { int result = 0; int[] countArr = new int[]{0, 0}; for (int i = n; i \u0026gt;= 1; i--) { int number = i; while (number % 5 == 0) { countArr[1]++; number /= 5; } while (number % 2 == 0) { countArr[0]++; number /= 2; } int min = Math.min(countArr[0], countArr[1]); if (min != 0) { countArr[0] -= min; countArr[1] -= min; result += min; } } return result; } }x 的平方根# 给你一个非负整数 x ，计算并返回 x 的 算术平方根 由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 示例 1： 输入：x = 4 输出：2 示例 2： 输入：x = 8 输出：2 解释：8 的算术平方根是 2.82842\u0026hellip;, 由于返回类型是整数，小数部分将被舍去。 提示： 0 \u0026lt;= x \u0026lt;= 2^31 - 1 x 的平方根 2025-01-17 package com.penruins.leetcode; public class Solution69 { public static int mySqrt(int x) { long xLong = Long.valueOf(x).longValue(); if (xLong == 0) return 0; if (xLong == 1) return 1; for (long i = 1; i \u0026lt; xLong; i++) { if (i * i == xLong || (i * i \u0026lt; xLong \u0026amp;\u0026amp; (i + 1) * (i + 1) \u0026gt; xLong)) { return (int) i; } } return -1; } public static void main(String[] args) { System.out.println(mySqrt(2147483647)); System.out.println(2147483647); System.out.println(46340 * 46340); System.out.println(46341l * 46341l); // for (int i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { // System.out.println(i + \u0026#34; : \u0026#34; + mySqrt(i)); // } } }Pow(x, n)# 实现 pow(x, n) ，即计算 x 的整数 n 次幂函数（即，x^n ）。 示例 1： 输入：x = 2.00000, n = 10 输出：1024.00000 示例 2： 输入：x = 2.10000, n = 3 输出：9.26100 示例 3： 输入：x = 2.00000, n = -2 输出：0.25000 解释：2-2 = 1/22 = 1/4 = 0.25 提示： -100.0 \u0026lt; x \u0026lt; 100.0 -2^31 \u0026lt;= n \u0026lt;= 2^31-1 n 是一个整数 要么 x 不为零，要么 n \u0026gt; 0 -10^4 \u0026lt;= xn \u0026lt;= 10^4 Pow(x, n) 2025-01-17 超时了 2025-01-17 看懂了官方题解 直线上最多的点数# 直线上最多的点数 2025-01-17 看了官方题解，但还是不太理解 一维动态规划# 爬楼梯 2025-01-11 通过 多维动态规划# 排序 sort# 基础排序算法# 冒泡排序 Bubble Sort# 选择排序 Selection Sort# 插入排序 Insertion Sort# 高效排序算法# 快速排序 Quick Sort# com.penruins.JZOffer.sort.QuickSort 剑指Offer 12.3 归并排序 Merge Sort# 剑指Offer 12.4 迭代实现# 递归实现# 堆排序 Heap Sort# 希尔排序 Shell Sort# 特殊场景排序算法# 基数排序 Radix Sort# 计数排序 Counting Sort# com.penruins.JZOffer.sort.CountingSort 剑指Offer 12.2 桶排序 Bucket Sort# "},{"id":1,"href":"/post/others/about-me/","title":"about me","section":"Others","content":"about me# 家乡 云南昆明 骑行 Strava 电影 douban 观影记录 研究各种提升效率的小工具 vim 双拼 raspberry pi ios shortcut "},{"id":2,"href":"/post/computer-science/blog/blog/","title":"blog","section":"Blog","content":" Twikoo 网站评论系统 Markdown × 静态博客：图片智能压缩与高效写作发布流 谈一谈我的个人博客探索之路 wruby wruby is a single file, minimal site generator written in Ruby. (Not the ruby gem) plaintxt.org Minimalism in blog design, an experiment vitePress# Vite Press 一篇教你用VitePress + Github Pages搭建博客 hugo# "},{"id":3,"href":"/post/life/books/","title":"books","section":"Life","content":"2025# 2025-08# 亮剑 那不勒斯四部曲 2025-07# 台北人 好久没有读到这样的文字了，读起来不流畅。我选的那个版本在正文故事之后有好几篇对台北人的书评和分析，看这些的时候感觉自己更投入一些，才理解了这本书的深层含义 简读中国史 从中华文化的起源开始读历史应该是初中了吧，高中也都没有好好看教材。以现在的认知来看又对一些概念有了更深的理解，例如礼乐是什么，青铜文化传入到中国之后发展的独特性，礼乐崩坏指的是什么，分封制和郡县制，周秦之变，法家思想的极端，罢黜百家。 不止读书 里面提到的书可以慢慢看 读书的人 里面提到的书可以慢慢看 被讨厌的勇气 以对话的方式来论述阿德勒（个体心理学）的一些主要观点。我觉得人生是连续的刹那，这个观点很有意思 健身路线图 解构现代化 温铁军 开了个头读不下去了，概念太多，后面再来吧（2025-07-30） 2025-06# 看见 柴静发了视频讲看见书里的故事，就想着就把书拿来看了吧。看完书也把一些第一个10年的一些重要的新闻事件回顾了一下，文字中有对新闻事件的陈述，社会问题的思考，作者本人的思考。 超越百岁：长寿的科学与艺术 倦怠社会 里面提出的绩效社会对人心理的影响很有新意，但是读起来很不流畅，很晦涩，概念太多，没有得出结论的过程。 商业就是这样：不可不知的商业常识 2025-05# 天朝的崩溃：鸦片战争再研究 宋哥推荐我看的。作者对结论的推理非常严谨认真，尤其是在军事实力的对比上，严谨细致程度是之前读历史相关的书所没有接触到的。书中的主要结论在绪论中就表述很清楚了。我看书有时候总喜欢把绪论或者推荐序跳了直接看正文，这本书是和宋哥聊起来这本书的时候他说绪论是对整本书的总结，肯定要读，后面才补上的。 多谈谈问题 薄世宁医学通识讲义 讲了医学的发展历程，医学的核心概念，挺好的科普书 不被支配：为什么我们会被情感绑架 西西弗高速的一期提到了这本书，就找来看了看。远离自恋型人格障碍的人。 简读日本史 二手时间 2025-04# 东京八平米 找到工作之后读的第一本书，准备面试的时候一直在看技术书，读不动了，找了一本轻松一点的书来看看 印象深的是那个三四点开门的咖啡店，专门给赶早去做工的人做咖啡。老板还专门把自己的咖啡送给临终的老顾客。 Jenkins 2.x 实践指南 Git: Mastering Version Control 凤凰项目：一个IT运维的传奇故事 精通Scrapy网络爬虫 软件方法：业务建模和需求 2025-03# 高性能MySQL 从程序员到架构师 PostgreSQL实战 搞定系统设计：面试敲开大厂的门 大模型应用开发 动手做 AI Agent Redis 设计与实现 深入浅出 Spring Boot 3.x 大模型应用开发极简入门 2025-02# Java并发编程实战 黄仁勋：英伟达之芯 英伟达那么火，就找来看看了。讲了黄仁勋与英伟达一开始建立到人工智能爆发中间的故事，以及后面的故事。人工智能的部分除了显卡，还讲了辛顿（反向传播算法），李飞飞（图片标注集） 计算机网络 深入浅出HTTPS：从原理到实战 Python神经网络编程 Spring Cloud微服务：入门、实战与进阶 深入理解Java虚拟机 凤凰架构：构建可靠的大型分布式系统 2025-01# Java实战 Spring实战 美国困局：新右翼的兴起与挑战 置身事内：中国政府与经济发展 中国分税制改革的背景（第一次从这本书相对详细的了解具体是什么）；市场经济一开始政府对重点行业的扶持；分税制改革对中国房地产行业发展的影响。 树莓派开始：玩转Linux 看这本书主要是因为手上也有个树莓派，其次是可以以一个电脑的角度来输入命令行。看了多进程编程的代码，有了一些初步认识。复习了一些Linux的知识，例如进程间通信。 用地图看懂世界格局 这本书豆瓣评分不高，但还是读了。对所谓的世界格局也没有任何的知识，能读下去就读了呗 宏观经济学 人工智能入门实战：从校园到职场 剑指Offer 图解宏观经济学 2024-12# 改变未来的九大算法 古希腊文明的光芒 赵林 2023# 重来3：跳出疯狂的忙碌 书单# 那么作家约瑟夫·康拉德的《黑暗之心》则帮助我们看清了，我们对领导能力（即争取最高头衔）的严重曲解所带来的问题，或者说招致的罪恶。这部杰作为电影《现代启示录》提供了原型 《黑暗之心》围绕着帝国主义、殖民主义、种族关系以及人性的黑暗展开，主题并不难以理解。但它揭示的另外一层含义是官僚主义。该书中的“公司”（作者是用大写字母C来强调的）具有规则、程序和等级制度，有掌权者和争权夺势者，跟任何其他官僚体系并无差异。 《米德尔马契》 之所以你我能够享受稳定的生活，有一半应归功于那些不为人知、踏踏实实为了自己的理想而生活的先辈。 《世界是平的》 《一个青年艺术家的画像》则以戏剧性的夸张手法描述了宗教信仰向人文艺术的过渡。故事主人公斯蒂芬·迪达勒斯放弃天主教会的神职，因此放弃了获得圣餐变体的机会，他选择投身于文学的奇迹，引用书中的话则是，“把每日平凡的生活经历转化为永恒的发光的生命”，即凝结为不朽的艺术作品。 麦田里的守望者 莎士比亚的《麦克白》或者美国家喻户晓的《黑道家族》体现了人性中的野心 契诃夫或费里尼的作品呈现了社会的倦怠 以及美国作家拉尔夫·埃利森和印度作家阿兰达蒂·洛伊笔下的边缘人群 但丁教会了我爱与恨并非对立，两者相辅相成 英国小说家E.M.福斯特让我明白了自由心态常常是虚荣和无知的遮羞布 作家玛丽·盖茨基尔向我揭示了灵魂在肉体上的体现方式 在《婚变》这部小说中，杰弗里·尤金尼德斯讲述了20世纪80年代初从布朗大学毕业的3位学生的故事。 在他回答问题的时候，他已经全然忘记了这是一份学校试卷。他已经不是为了成绩在答题，而是在思考他自己及身边同龄人一直以来的困境。这是一种奇特的感觉。虽然笔下明明在引用蒂利希和海德格尔的话来阐述观点，但是在他脑海里浮现的却是自己和他的朋友们……在回答论文的问题时，米切尔不断地将自己的答案引向跟实际生活相关的内容。他在思考他的存在以及如何度过自己的一生。这是多么完美的结束大学生涯的方式。教育最终引领米切尔走进了生活。 她厌男，她是我女友 computer science# java# Spring实战（第6版） linux# 树莓派开始，玩转Linux 小说# 亮剑 沧浪之水 history# 简读中国史：世界史坐标下的中国 简读日本史 天朝的崩溃：鸦片战争再研究（修订版） economy# 置身事内 psychology# 被讨厌的勇气 不被支配：为什么我们会被情感绑架？ social# 看见 医学# 薄世宁医学通识讲义 书评# 读书的人 不止读书 方法论# 重来3：跳出疯狂的忙碌 "},{"id":4,"href":"/post/history/chinese-history/","title":"Chinese History","section":"History","content":" 中国文明并不是世界上最早出现的文明。以有文字和建筑能证明国家的出现而论，中国比苏美尔要晚近2000年，比埃及也要晚了1500年 但是中国后发先至。在西周时期，中国在人类历史上第一次建立起整饬的大一统封建制度，比欧洲早了近1800年。 接下来，中国又率先在世界上建立了大一统中央集权国家，同样比欧洲早了近2000年。 早在公元前3世纪，中国就实现了中央政权对基层社会的直接统治和严密控制，能够在全国范围内大规模调动资源 西欧中央集权国家和中国的中央集权的形成过程相当不同。欧洲是在议会、自治城市、行会等多种社会力量发育起来之后才出现中央集权国家的。因此，在欧洲的民族国家中，君主的专制权力是有限的，君主权力不仅受法律、议会的制约，也受到各社会阶层、利益团体的限制 欧洲的中央集权之路，还进行过多种探索和比较 英国之所以后来能超越西班牙，就是因为它的体制既比荷兰松散的城邦联合体更有凝聚力，同时又比西班牙的君权受到更大的约束 三代之治 周秦之变 分封制 和 郡县制 的区别 中世纪欧洲的政治体制和分封制的相似之处 议会制度 管理北京委员会 20世纪40年代土耳其政治民主化以后，数量庞大的底层民众开始显示力量，伊斯兰因素又堂而皇之地一步步彰显存在，到近些年达到高峰。 违背了科学的民主，最终会变得不民主！让专制体制下的臣民进行选举，他们只会选举出比较好的君主，而不是选出一个支持民主的公民；让宗教信徒进行选举，他们也只会选出宗教领袖，而不是选出一个具有科学精神的公民！ 拉丁美洲的民选政治也步入泥潭。 在贫富差距和社会动荡中焦虑不安的拉美民众很容易受到那些激进口号的影响，他们喜欢那些提出诱人目标和简单快速的解决方式的领导人，谁的气质和姿态最权威，最像“父亲”，谁的许诺最直接、最简单、最激进，就最容易上台。 比如委内瑞拉的查韦斯许诺要为穷人提供“超福利”（免费住房、免费汽油），因此迅速崛起于政治舞台。 上台之后，为了兑现承诺，查韦斯大力推行国有化，把所有行业都收归国有。 但赶走了有管理能力的外国投资者之后，委内瑞拉本国却没有成熟的企业家阶层接手，国有企业陷入效率低下和严重腐败当中，激进的国有化不久之后就导致各种物资短缺。堂堂的“石油富国”已经沦落到需要进口石油，超级市场没有食物，人们到垃圾箱去捡东西吃。 国家的经济崩溃了，穷人获得的福利也自然随之成为泡影。委内瑞拉的经济困境，反映的其实是政治上的不成熟。 清教文化，儒家文化 中国的历史、文化和地理，决定了它的大一统趋向 "},{"id":5,"href":"/post/computer-science/blog/hugo/","title":"Hugo","section":"Blog","content":" hugo website hugo-book alex-shpak/hugo-book Document Mermaid Document Hexo, Hugo, Vitepress，Vuepress博客框架比较 浅谈我为什么从 HEXO 迁移到 HUGO 在 Hugo 中配置 TOC 从一级标题开始显示# 要在 Hugo 中让侧边栏的目录(TOC)从一级标题(h1)开始显示，你可以通过以下几种方法实现：\n方法一：修改 config.toml# 在你的 Hugo 配置文件(通常是 config.toml 或 config.yaml)中添加或修改以下设置：\n[markup] [markup.tableOfContents] startLevel = 1 endLevel = 6或者对于 YAML 格式：\nmarkup: tableOfContents: startLevel: 1 endLevel: 6方法二：模板中指定# 如果你在模板中调用 TOC，可以这样指定：\n{{ .TableOfContents }}默认情况下，Hugo 会从二级标题(h2)开始显示 TOC。要修改这个行为，你需要使用方法一中的配置。\n方法三：使用自定义 CSS# 如果配置修改后仍然不符合预期，你可以添加自定义 CSS 来隐藏不需要的层级：\n/* 隐藏除一级标题外的其他层级 */ #TableOfContents ul ul { display: none; }方法四：使用 Goldmark 配置# 如果你使用的是 Goldmark 渲染器(默认)，确保配置正确：\n[markup.goldmark] [markup.goldmark.parser] [markup.goldmark.parser.attribute] block = true title = true注意事项# 确保你的内容中确实有一级标题(# 或 \u0026lt;h1\u0026gt;) 某些主题可能会覆盖默认的 TOC 行为，你可能需要检查主题文档 清除缓存(hugo --gc)有时能解决显示问题 如果你使用的是特定主题，可能需要查看该主题的文档，因为有些主题会提供自己的 TOC 配置选项。\n"},{"id":6,"href":"/post/life/%E6%96%B0%E7%9F%A5/","title":"新知","section":"Life","content":"新知# 如果有朋友有心在看这个page，需要提醒您一下，这个页面主要是我对我看的书，视频，电影的回忆，不会校正正确性，可能是不太准确的。\n2025-07-30# 青铜文明是从中亚传到中国的。牛，羊，小麦也是从中亚传过来的 （简读中国史） 从分封制到郡县制是为了加强皇帝的权利触及到最底层，加强中央集权（简读中国史） 法家思想推行到极致就变成了极端的功利主义，于人民于君主于推崇者都是输的结果（简读中国史） "},{"id":7,"href":"/post/computer-science/monitor/prometheus/","title":"prometheus","section":"Monitor","content":"prometheus# brew# 如果是使用 brew 安装的话，配置文件在这个位置 /opt/homebrew/etc/prometheus.yml\ngrafana# grafana dashboard springboot# SpringBoot + Prometheus + Grafana 实现自定义监控 database# x5y22r/druid-prometheus-monitor "},{"id":8,"href":"/post/computer-science/computer-science-recommend/","title":"推荐","section":"Computer Science","content":"Computer Science Java# concurrent java basic jvm mybatis mybatis plus spring spring boot spring boot validation unit test Tools# idea java utils xxl-job jackson blog hugo Artificial Intelligence# Artificail Intelligence Spring AI Spring AI Alibaba LangChain4j Qwen Code MoonshotAI/kimi-cli google-gemini/gemini-cli 火山方舟 提示工程指南 Operating System# Linux rasberry pi Mac Windows powershell IOS Tools# vim IdeaVim git Database# database mysql postgresql elasticsearch mongodb shardingsphere mycat druid basic# security networking crawler cloud 系统设计 CI/CD# docker orbStack gitlab jenkins maven nexus services# redis Front End# echarts vue Distributed System# distributed system spring cloud spring cloud alibaba sentinel github alex-shpak/hugo-book 这个博客就是用这个项目搭建的 hacker news 有很多关于计算机相关的文章，每天都会更新 资源下载相关 pingf/annie 可以用来下载B站视频 yt-dlp/yt-dlp 下载 youtube 视频 yutto-dev/bilili 下载 bilibili 视频(项目已经归档不再维护,目前还能用，可以使用yutto) yutto-dev/yutto 卡码笔记 代码随想录的网站，里面整理了一些计算机相关的知识点（非算法相关） cdk8s-zelda/IntelliJ-IDEA-Tutorial 介绍一些 idea 的使用技巧的 segment fault cdk8s/cdk8s-team-style 【从开公司到开发全平台产品】4.后端开发的思考、实践-UPUPMO 【从开公司到开发全平台产品】3.软件开发设计阶段的思考、实践-UPUPMO 自学计算机科学 websites# Plain Text Only# A List Of Text-Only \u0026amp; Minimalist News Sites (Updated 2025) 1MB Club 1MB Club is a growing collection of performance-focused web pages weighing less than 1 megabyte. 值得拥有的纯文本生产力 My productivity app is a never-ending .txt file Org Mode - Organize Your Life In Plain Text! Write plain text files Large Language Model(LLM)# 通义千问 Tools# wechatmp2markdown 微信公众号文章转Markdown Algorithms# TheAlgorithms/Java "},{"id":9,"href":"/post/computer-science/computer-science-learning-log/","title":"学习记录","section":"Computer Science","content":"学习记录# 2025-03-30 Sunday# 分区表的索引如何创建, 请以postgresql举例 postgresql中分区键会自动创建索引吗 kafka如何实现高吞吐量 不同消息队列消息写入方式对比 kafka如何保障顺序消费 Kafka的顺序消费能力与其他消息队列系统相比有何优势 kafka一个分区有多个消费者消费顺序是怎样的 kafka发送失败如何处理 Kafka突然宕机了消息会不会丢失 2025-01-17# 剑指Offer Book# 剑指Offer 第1章 面试的流程 1# 1.1 面试官谈面试 1 1.2 面试的三种形式 2 1.2.1 电话面试 2 1.2.2 共享桌面远程面试 3 1.2.3 现场面试 4 1.3 面试的三个环节 5 1.3.1 行为面试环节 5 应聘者的项目经验 6 应聘者掌握的技能 7 回答“为什么跳槽” 8 1.3.2 技术面试环节 10 扎实的基础知识 10 高质量的代码 11 清晰的思路 14 优化效率的能力 15 优秀的综合能力 16 1.3.3 应聘者提问环节 17 1.4 本章小结 18 第2章 面试需要的基础知识 20# 2.1 面试官谈基础知识 20 2.2 编程语言 22 2.2.1 C++ 22 面试题1：赋值运算符函数 24 经典的解法，适用于初级程序员 25 考虑异常安全性的解法，高级程序员必备 26 2.2.2 C# 27 面试题2：实现Singleton模式 31 不好的解法一：只适用于单线程 31 不好的解法二：可用于多线程但效率不高 32 可行的解法：同步锁前后两次判断 33 推荐的解法一：利用静态构造函数 34 推荐的解法二：按需创建实例 34 解法比较 35 2.3 数据结构 36 2.3.1 数组 36 面试题3：二维数组中的查找 38 2.3.2 字符串 42 面试题4：替换空格 44 O(n2)的解法，不足以拿到Offer 45 O(n)的解法，搞定Offer就靠它 46 2.3.3 链表 49 面试题5：从尾到头打印链表 51 2.3.4 树 53 面试题6：重建二叉树 55 2.3.5 栈和队列 58 面试题7：用两个栈实现队列 59 2.4 算法和数据操作 62 2.4.1 查找和排序 63 面试题8：旋转数组的最小数字 66 2.4.2 递归和循环 71 面试题9：斐波那契数列 73 效率很低的解法，面试官不会喜欢 73 面试官期待的实用解法 74 O(logn)但不够实用的解法 74 解法比较 75 2.4.3 位运算 77 面试题10：二进制中1的个数 78 可能引起死循环的解法 79 常规解法 79 能给面试官带来惊喜的解法 80 2.5 本章小结 82 第3章 高质量的代码 84# 3.1 面试官谈代码质量 84 3.2 代码的规范性 86 3.3 代码的完整性 87 从3方面确保代码的完整性 87 3种错误处理的方法 88 面试题11：数值的整数次方 90 自以为题目简单的解法 90 全面但不够高效的解法，离Offer已经很近了 90 全面又高效的解法，确保能拿到Offer 92 面试题12：打印1到最大的n位数 94 跳进面试官陷阱 94 在字符串上模拟数字加法 94 把问题转换成数字排列 97 面试题13：在O(1)时间删除链表结点 99 面试题14：调整数组顺序使奇数位于偶数前面 102 只完成基本功能的解法，仅适用于初级程序员 102 考虑可扩展性的解法，能秒杀Offer 104 3.4 代码的鲁棒性 106 面试题15：链表中倒数第k个结点 107 面试题16：反转链表 112 面试题17：合并两个排序的链表 114 面试题18：树的子结构 117 3.5 本章小结 121 第4章 解决面试题的思路 123# 4.1 面试官谈面试思路 123 面试题19：二叉树的镜像 125 4.2 画图让抽象问题形象化 125 面试题20：顺时针打印矩阵 127 4.3 举例让抽象问题具体化 131 面试题21：包含min函数的栈 132 面试题22：栈的压入、弹出序列 134 面试题23：从上往下打印二叉树 137 面试题24：二叉搜索树的后序遍历序列 140 面试题25：二叉树中和为某一值的路径 143 4.4 分解让复杂问题简单化 146 面试题26：复杂链表的复制 147 面试题27：二叉搜索树与双向链表 151 面试题28：字符串的排列 154 4.5 本章小结 158 第5章 优化时间和空间效率 160# 5.1 面试官谈效率 160 5.2 时间效率 162 面试题29：数组中出现次数超过一半的数字 163 基于Partition函数的O(n)算法 163 利用数组特点的O(n)算法 165 解法比较 166 面试题30：最小的k个数 167 O(n)的算法，只当可以修改输入数组时可用 167 O(nlogk)的算法，适合处理海量数据 168 解法比较 169 面试题31：连续子数组的最大和 171 举例分析数组的规律 171 应用动态规划法 173 面试题32：从1到n整数中1出现的次数 174 不考虑效率的解法，想拿Offer有点难 174 明显提高效率的解法，让面试官耳目一新 175 面试题33：把数组排成最小的数 177 5.3 时间效率与空间效率的平衡 181 面试题34：丑数 182 逐个判断整数是不是丑数的解法 182 创建数组保存已经找到的丑数的解法 183 面试题35：第一个只出现一次的字符 186 面试题36：数组中的逆序对 189 面试题37：两个链表的第一个公共结点 193 5.4 本章小结 196 第6章 面试中的各项能力 198# 6.1 面试官谈能力 198 6.2 沟通能力和学习能力 200 沟通能力 200 学习能力 200 善于学习、沟通的人也善于提问 201 6.3 知识迁移能力 203 面试题38：数字在排序数组中出现的次数 204 面试题39：二叉树的深度 207 重复遍历结点的解法，不足以打动面试官 209 只遍历结点一次的解法，正是面试官喜欢的 209 面试题40：数组中只出现一次的数字 211 面试题41：和为s的两个数字VS和为s的连续正数序列 214 面试题42：翻转单词顺序 VS左旋转字符串 218 6.4 抽象建模能力 222 面试题43：n个骰子的点数 223 基于递归求骰子点数，时间效率不够高 223 基于循环求骰子点数，时间性能好 224 面试题44：扑克牌的顺子 226 面试题45：圆圈中最后剩下的数字 228 经典的解法，用循环链表模拟圆圈 229 创新的解法，拿到Offer不在话下 230 6.5 发散思维能力 232 面试题46：求1+2+…+n 233 利用构造函数求解 234 利用虚函数求解 234 利用函数指针求解 235 利用模板类型求解 236 面试题47：不用加减乘除做加法 237 面试题48：不能被继承的类 239 常规的解法：把构造函数设为私有函数 239 新奇的解法：利用虚拟继承 240 6.6 本章小结 241 第7章 两个面试案例 243# 7.1 案例一：（面试题49）把字符串转换成整数 244 7.2 案例二：（面试题50）树中两个结点的最低公共祖先 252 第8章 英文版新增面试题 261# 8.1 数组 261 面试题51：数组中重复的数字 261 面试题52：构建乘积数组 263 8.2 字符串 265 面试题53：正则表达式匹配 265 面试题54：表示数值的字符串 267 面试题55：字符流中第一个不重复的字符 269 8.3 链表 270 面试题56：链表中环的入口结点 270 面试题57：删除链表中重复的结点 273 8.4 树 275 面试题58：二叉树的下一个结点 275 面试题59：对称的二叉树 277 面试题60：把二叉树打印成多行 278 面试题61：按之字形顺序打印二叉树 280 面试题62：序列化二叉树 283 面试题63：二叉搜索树的第k个结点 285 面试题64：数据流中的中位数 286 8.5 栈和队列 290 面试题65：滑动窗口的最大值 290 8.6 回溯法 294 面试题66：矩阵中的路径 294 面试题67：机器人的运动范围 296 2025-01-11# leetcode 刷题# 面试经典150题# 面试经典150题 数组/字符串# 合并两个有序数组 2025-01-12 移除元素 2025-01-11 删除有序数组中的重复项 2025-01-11 没有做出来，看的官方题解 2025-01-11 做完删除有序数组中的重复项 II之后再尝试重新解题完成 删除有序数组中的重复项 II 2025-01-11 多数元素 2025-01-12 轮转数组 2025-01-18 进阶 尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。 你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 买卖股票的最佳时机 2025-01-11 看官方题解做出来的 2025-01-17 review 买卖股票的最佳时机 II 官方题解 理解 2025-01-17 方法一：动态规划 方法二：贪心 跳跃游戏 2025-01-17 官方题解理解 贪心 2025-01-18 跳跃游戏 II 2025-01-18 算法超时了 理解官方题解 2025-01-18 方法一：反向查找出发位置 Solution45.jump2 2025-01-18 方法二：正向查找可达到的最大位置 Solution45.jump3 H 指数 2025-01-18 Tips An easy approach is to sort the array first. What are the possible values of h-index? A faster approach is to use extra space. O(1) 时间插入、删除和获取随机元素 除自身以外数组的乘积 加油站 分发糖果 接雨水 罗马数字转整数 2025-01-12 整数转罗马数字 最后一个单词的长度 2025-01-12 最长公共前缀 2025-01-12 反转字符串中的单词 2025-01-18 进阶 如果字符串在你使用的编程语言中是一种可变数据类型，请尝试使用 O(1) 额外空间复杂度的 原地 解法。 Z 字形变换 找出字符串中第一个匹配项的下标 2025-01-12 文本左右对齐 双指针# 验证回文串 2025-01-13 判断子序列 2025-01-13 两数之和 II - 输入有序数组 2025-01-13 运行有时候会超过时间限制 盛最多水的容器 三数之和 滑动窗口# 长度最小的子数组 2025-01-22 无重复字符的最长子串 2025-01-22 串联所有单词的子串 2025-01-22 最小覆盖子串 矩阵# 有效的数独 2025-01-18 螺旋矩阵 2025-01-18 旋转图像 理解官方题解 2025-01-18 方法一：使用辅助数组 2025-01-18 方法二：原地旋转 有数学公式的推导，需要自己推导一次 2025-01-18 方法三：用翻转代替旋转 有数学公式的推导，需要自己推导一次 矩阵置零 2025-01-18 生命游戏 2025-01-18 进阶 你可以使用原地算法解决本题吗？请注意，面板上所有格子需要同时被更新：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。 本题中，我们使用二维数组来表示面板。原则上，面板是无限的，但当活细胞侵占了面板边界时会造成问题。你将如何解决这些问题？ ✅ 哈希表# 赎金信 2025-01-13 同构字符串 2025-01-13 单词规律 2025-01-13 有效的字母异位词 2025-01-13 字母异位词分组 2025-01-16 第一遍算法超时，看了官方题解思路后实现通过 两数之和 2025-01-13 快乐数 2025-01-13 存在重复元素 II 2025-01-13 最长连续序列 2025-01-16 看了官方题解后完成 区间# 栈# 有效的括号 2025-01-22 简化路径 2025-01-22 最小栈 2025-01-22 理解官方题解 文字描述后完成 2025-01-22 理解官方题解 逆波兰表达式求值 2025-01-22 基本计算器 链表# 环形链表 2025-01-20 理解官方题解 2025-01-20 方法一：哈希表 方法二：快慢指针 两数相加 2025-01-20 合并两个有序链表 2025-01-20 随机链表的复制 2025-01-20 反转链表 II 2025-01-20 K 个一组翻转链表 删除链表的倒数第 N 个结点 2025-01-20 进阶 2025-01-20 你能尝试使用一趟扫描实现吗？ 删除排序链表中的重复元素 II 2025-01-21 旋转链表 2025-01-20 分隔链表 2025-01-21 LRU 缓存 2025-01-22 理解官方题解 二叉树# 二叉树的最大深度 2025-01-15 相同的树 2025-01-15 翻转二叉树 2025-01-15 对称二叉树 没做出来，看的官方题解 从前序与中序遍历序列构造二叉树 从中序与后序遍历序列构造二叉树 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表 路径总和 求根节点到叶节点数字之和 二叉树中的最大路径和 二叉搜索树迭代器 完全二叉树的节点个数 二叉树的最近公共祖先 二叉树层次遍历# 二叉搜索树# 图# 图的广度优先搜索# 字典树# ✅ 回溯# 电话号码的字母组合 2025-01-15 组合 2025-01-15 全排列 2025-01-15 组合总和 2025-01-15 N 皇后 II 2025-01-15 括号生成 2025-01-15 单词搜索 2025-01-15 分治# kadane算法# 二分查找# 堆# 位运算# 二进制求和 2025-01-16 颠倒二进制位 2025-01-16 没做出来, 参考这篇文章LeetCode 190. 颠倒二进制位 （位运算 分治） 2025-01-17 复习了一遍 2025-01-17 新增了中间值打印的代码在算法中 位1的个数 2025-01-17 只出现一次的数字 2025-01-17 只出现一次的数字 II 2025-01-17 理解了官方题解 方法2 数字范围按位与 2025-01-17 理解了官方题解 方法2 数学# 回文数 2025-01-17 不将整数转为字符串来解决这个问题 加一 2025-01-17 阶乘后的零 2025-01-17 x 的平方根 2025-01-17 Pow(x, n) 2025-01-17 超时了 2025-01-17 看懂了官方题解 直线上最多的点数 2025-01-17 看了官方题解，但还是不太理解 一维动态规划# 爬楼梯 2025-01-11 通过 多维动态规划# 2025-01-09# ✅ Spring实战 第6版 Book# 第1章 Spring 起步 1.1 什么是Spring 2025-01-09 1.2 初始化 spring 应用 2025-01-09 1.3 编写 Spring 应用 2025-01-09 1.4 俯瞰 Spring 风景线 2025-01-09 第2章 2.1 展现信息 2025-01-09 2.2 处理表单提交 2025-01-09 2.3 校验表单输入 2025-01-09 2.4 使用视图控制器 2025-01-09 2.5 选择视图模板库 2025-01-09 第3章 使用数据 3.1 2025-01-09 3.2 2025-01-11 3.3 2025-01-11 第4章 使用非关系型数据 4.1 2025-01-11 4.2 2025-01-11 第5章 保护Spring 5.1 2025-01-11 5.2 2025-01-11 5.3 2025-01-11 5.4 2025-01-11 5.5 2025-01-12 第6章 使用配置属性 6.1 2025-01-12 6.2 2025-01-12 6.3 2025-01-12 第7章 创建REST服务 7.1 2025-01-12 7.2 2025-01-12 7.3 2025-01-12 第8章 保护REST 8.1 2025-01-12 8.2 2025-01-12 8.3 2025-01-12 8.4 2025-01-12 第9章 发送异步消息 9.1 2025-01-13 9.2 2025-01-13 9.3 2025-01-13 第10章 Spring集成 10.1 2025-01-13 10.2 2025-01-13 10.3 2025-01-13 第11章 理解反应式编程 11.1 2025-01-13 11.2 2025-01-13 11.3 2025-01-13 第12章 开发反应式API 12.1 2025-01-13 12.2 2025-01-13 12.3 2025-01-13 12.4 2025-01-13 12.5 2025-01-13 第13章 反应式持久化数据 13.1 2025-01-14 13.2 2025-01-14 13.3 2025-01-14 第14章 使用RSocket 14.1 2025-01-14 14.2 2025-01-15 14.3 2025-01-15 第15章 部署Spring 15.1 2025-01-15 15.2 2025-01-15 15.3 2025-01-15 15.4 2025-01-15 第16章 管理Spring 16.1 2025-01-15 16.2 2025-01-15 16.3 2025-01-15 第17章 使用JMX监控Spring 17.1 2025-01-15 17.2 2025-01-15 17.3 2025-01-15 第18章 部署Spring 18.1 2025-01-15 18.2 2025-01-15 18.3 2025-01-15 18.4 2025-01-15 18.5 2025-01-15 JavaGuide 文档阅读# JavaGuide 必看 面试准备 Java 计算机基础 数据库 开发工具 常用框架 Spring\u0026amp;Spring Boot MyBatis常见面试题总结 2025-01-09 太过总结性，需要看一些更基础的文章 Netty常见面试题总结 系统设计 分布式 高性能 高可用 2025-01-08# 计算机教育中缺失的学期# 计算机教育中缺失的学期 阮一峰博客阅读# 阮一峰的网络日志 散文 观点与感想 算法与数学 开发者手册 理解计算机 JavaScript 计算机行业历史 周刊 创业 译文集 2025-01-05# spring 基础知识点 视频# B站大学终于把Spring做成动画片了，一周刷爆，2024最新版，学完即可面试，拿走不谢，学不会我退出IT圈！ 1 2025-01-05 Spring 是如何整合MyBatis管理Mapper接口的 2025-01-05 2 2025-01-06 3 2025-01-06 4 2025-01-06 5 2025-01-06 6 2025-01-06 7 2025-01-06 8 2025-01-06 9 2025-01-06 10 2025-01-06 11 (January 6, 2025 at 18:43:04 GMT+8) 12 (January 6, 2025 at 18:50:57 GMT+8) 13 (January 6, 2025 at 18:57:05 GMT+8) 14 (January 6, 2025 at 18:59:15 GMT+8) 15 2025-01-07 16 2025-01-07 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 100 2025-01-03# 代码随想录 视频# 代码随想录 数组# 链表# 哈希表# 字符串# 栈与队列# 二叉树# 1 理论基础 2025-01-09 2 递归遍历 (Leetcode 144, 145, 94) 2025-01-09 3 非递归遍历 2025-01-09 4 非递归遍历-中序 2025-01-11 5 层序遍历（广度优先搜索） 6 翻转二叉树 7 对称二叉树 8 二叉树的最大深度 9 二叉树的最小深度 10 完全二叉树节点的数量 11 平衡二叉树 12 二叉树的所有路径 13 左叶子之和 14 找左下角的值 15 路径总和 16 从中序和后序遍历序列构造二叉树 17 最大二叉树 18 合并二叉树 19 二叉搜索树中的搜索 (Leetcode 700) 2025-01-08 20 验证二叉搜索树 (Leetcode 98) 2025-01-08 21 二叉搜索树的最小绝对差 (Leetcode 530) 2025-01-08 22 二叉搜索树中的众数(Leetcode 501) 2025-01-09 23 二叉树的最近公共祖先(Leetcode 236) 2025-01-09 24 二叉搜索树的最近公共祖先 2025-01-09 25 二叉搜索树中的插入操作(Leetcode 701) 2025-01-09 26 删除二叉搜索树中的节点(Leetcode 450) 2025-01-09 27 修剪二叉搜索树 (Leetcode 669) 2025-01-09 28 将有序数组转换为二叉搜索树 (Leetcode 108) 2025-01-09 29 把二叉搜索树转换为累加树(Leetcode 538) 2025-01-09 ✅ 回溯法# 1 理论篇 2025-01-03 2 组合问题（对应力扣题目：77.组合） 2025-01-03 3 组合问题的剪枝操作（对应力扣题目：77.组合）2025-01-03 4 回溯算法如何剪枝？| LeetCode：216.组合总和III 2025-01-03 5 LeetCode：17.电话号码的字母组合 2025-01-03 6 组合总和（对应「leetcode」力扣题目：39.组合总和） 2025-01-03 7 LeetCode:40.组合总和II 2025-01-03 8 分割回文串 2025-01-04 9 复原IP地址 2025-01-04 10 子集 （Leetcode 78） 2025-01-04 11 子集2（Leetcode 90） 2025-01-04 12 递增子序列（Leetcode 491） 2025-01-04 13 全排列（Leetcode 46） 2025-01-04 14 全排列2（Leetcode 47）2025-01-04 15 N皇后（Leetcode 51） 2025-01-05 16 解数独（Leetcode 37） 2025-01-05 ✅ 贪心算法# 理论基础 2025-01-05 1 分发饼干 leetcode 455 2025-01-05 2 摆动序列 Leetcode 376 2025-01-05 3 最大子序和 2025-01-06 4 买卖股票最佳时机2 2025-01-06 5 跳跃游戏（Leetcode 55） 2025-01-06 6 跳跃游戏2 （Leetcode 45） 2025-01-06 这道题没听懂 7 K次取反后最大化的数组和 （Leetcode 1005） 2025-01-06 8 加油站（Leetcode 134） 2025-01-06 9 分发糖果（Leetcode 135） 2025-01-06 10 柠檬水找零（Leetcode 860） 2025-01-06 11 根据身高重建队列（Leetcode 406） 2025-01-06 12 用最少数量的箭引爆气球(Leetcode 452) 2025-01-06 13 无重叠区间(Leetcode 435) 2025-01-06 14 划分字母区间 (Leetcode 763) 2025-01-06 15 合并区间 （Leetcode 56） (January 7, 2025 at 15:18:40 GMT+8) 16 单调自增的数字（Leetcode 738）(January 7, 2025 at 15:41:59 GMT+8) 17 监督二叉树（Leetcode 968） (January 7, 2025 at 16:11:51 GMT+8) 动态规划# 1 理论基础 (January 7, 2025 at 16:34:49 GMT+8) 2 斐波那契数列 （Leetcode 509） (January 7, 2025 at 16:46:54 GMT+8) 3 爬楼梯（Leetcode 70） (January 7, 2025 at 16:57:46 GMT+8) 4 使用最小花费爬楼梯 (Leetcode 746) 2025-01-08 5 不同路径 2025-01-08 6 不同路径2 (Leetcode 63) 2025-01-08 7 整数拆分 (Leetcode 343) 2025-01-08 这道题没太听懂 8 不同的二叉搜索树（Leetcode 96） 9 0-1背包问题理论基础 10 0-1背包问题之滚动数组 11 分割等和子集 12 最后一块石头的重量2 13 目标和 14 一和零 15 完全背包理论基础 16 零钱兑换2 17 组合综合4 18 零钱兑换 19 完全平方数 20 单词拆分 21 打家劫舍 22 打家劫舍2 23 打家劫舍3 24 买卖股票的最佳时机1 25 买卖股票的最佳时机2 26 买卖股票的最佳时机3 27 买卖股票的最佳时机4 28 买卖股票的最佳时机含冷冻期 29 买卖股票的最佳时机含手续费 30 最长递增子序列 31 最长连续递增序列 32 最长重复子数组 33 最长公共子序列 34 不相交的线 35 最大子序和 36 判断子序列 37 不同的子序列 38 两个字符串的删除操作 39 编辑距离 40 回文子串 42 最长回文子序列 单调栈# 2024-11-14# What I Wish Someone Told Me About Postgres 介绍了 postgresql 相关的一些知识点，可以看一看 The WIRED Guide to Protecting Yourself From Government Surveillance How a stubborn computer scientist accidentally launched the deep learning boom 可以了解到 辛顿、黄仁勋、李飞飞 的工作是如何推动神经网络的发展的 "},{"id":10,"href":"/post/computer-science/algorithm/algorithm-practice-%E5%89%91%E6%8C%87-offer/","title":"algorithm practice 剑指 offer","section":"Algorithm","content":"algorithm practice 剑指 offer# 第1章 整数# 1.1 整数的基础知识# 面试题1：整数除法# 1.2 二进制# 面试题2：二进制加法# 面试题3：前n个数字二进制形式中1的个数# 简单计算每个整数的二进制形式中1的个数# 根据“i\u0026amp;（i-1）”计算i的二进制形式中1的个数# 根据“i/2”计算i的二进制形式中1的个数# 面试题4：只出现一次的数字# 面试题5：单词长度的最大乘积# 用哈希表记录字符串中出现的字符# 用整数的二进制数位记录字符串中出现的字符# 1.3 本章小结# 第2章 数组# 2.1 数组的基础知识# 2.2 双指针# 面试题6：排序数组中的两个数字之和# 面试题7：数组中和为0的3个数字# 面试题8：和大于或等于k的最短子数组# 面试题9：乘积小于k的子数组# 2.3 累加数组数字求子数组之和# 面试题10：和为k的子数组# 面试题11：0和1个数相同的子数组# 面试题12：左右两边子数组的和相等# 面试题13：二维子矩阵的数字之和# 2.4 本章小结# 第3章 字符串# 3.1 字符串的基础知识# 3.2 双指针# 面试题14：字符串中的变位词# 面试题15：字符串中的所有变位词# 面试题16：不含重复字符的最长子字符串# 需要多次遍历整个哈希表的解法# 避免多次遍历整个哈希表的解法# 面试题17：包含所有字符的最短字符串# 3.3 回文字符串# 面试题18：有效的回文# 面试题19：最多删除一个字符得到回文# 面试题20：回文子字符串的个数# 3.4 本章小结# 第4章 链表# 4.1 链表的基础知识# 4.2 哨兵节点# 用哨兵节点简化链表插入操作# 用哨兵节点简化链表删除操作# 4.3 双指针# 面试题21：删除倒数第k个节点# 面试题22：链表中环的入口节点# 需要知道环中节点数目的解法# 不需要知道环中节点数目的解法# 面试题23：两个链表的第1个重合节点# 4.4 反转链表# 面试题24：反转链表# 面试题25：链表中的数字相加# 面试题26：重排链表# 面试题27：回文链表# 4.5 双向链表和循环链表# 面试题28：展平多级双向链# 面试题29：排序的循环链表# 4.6 本章小结# 第5章 哈希表# 5.1 哈希表的基础知识# 5.2 哈希表的设计# 5.3 哈希表的应用# 5.4 本章小结# 第6章 栈# 6.1 栈的基础知识# 6.2 栈的应用# 面试题36：后缀表达式# 面试题37：小行星碰撞# 面试题38：每日温度# 面试题39：直方图最大矩形面积# 蛮力法# 分治法# 单调栈法# 面试题40：矩阵中的最大矩形# 6.3 本章小结# 第7章 队列# 7.1 队列的基础知识# 7.2 队列的应用# 面试题41：滑动窗口的平均值# 面试题42：最近请求次数# 7.3 二叉树的广度优先搜索 Solution0703001# 广度优先搜索# public List\u0026lt;Integer\u0026gt; bfs(TreeNode root) { Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); if (root != null) { queue.offer(root); } List\u0026lt;Integer\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); while (!queue.isEmpty()) { TreeNode node = queue.poll(); result.add(node.val); if (node.left != null) queue.offer(node.left); if (node.right != null) queue.offer(node.right); } return result; }面试题43：在完全二叉树中添加节点# // CBT Complete Binary Tree class CBTInserter { private Queue\u0026lt;TreeNode\u0026gt; queue; private TreeNode root; public CBTInserter(TreeNode root) { this.root = root; queue = new LinkedList\u0026lt;\u0026gt;(); while (queue.peek().left != null \u0026amp;\u0026amp; queue.peek().right != null) { TreeNode node = queue.poll(); queue.offer(node.left); queue.offer(node.right); } } public int insert(int v) { TreeNode parent = queue.peek(); TreeNode node = new TreeNode(v); if (parent.left == null) { parent.left = node; } else { parent.right = node; queue.poll(); queue.offer(parent.left); queue.offer(parent.right); } return parent.val; } public TreeNode get_root() { return this.root; } }面试题44：二叉树中每层的最大值# 用一个队列实现二叉树的广度优先搜索# public List\u0026lt;Integer\u0026gt; largestValues(TreeNode root) { int current = 0; int next = 0; Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); if (root != null) { queue.offer(root); current = 1; } List\u0026lt;Integer\u0026gt; result = new LinkedList\u0026lt;\u0026gt;(); int max = Integer.MIN_VALUE; while (!queue.isEmpty()) { TreeNode node = queue.poll(); current--; max = Math.max(max.node.val); if (node.left != null) { queue.offer(node.left); next++; } if (node.right != null) { queue.offer(node.right); next++; } if (current == 0) { result.add(max); max = Integer.MIN_VALUE; current = next; next = 0; } } return result; }用两个队列实现二叉树的广度优先搜索# public List\u0026lt;Integer\u0026gt; largestValues(TreeNode root) { Queue\u0026lt;TreeNode\u0026gt; queue1 = new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2 = new LinkedList\u0026lt;\u0026gt;(); if (root != null) { queue1.offer(root); } List\u0026lt;Integer\u0026gt; result = new LinkedList\u0026lt;\u0026gt;(); int max = Math.max(max, node.val); if (node.left != null) { queue2.offer(node.left); } if (node.right != null) { queue2.offer(node.right); } if (queue1.isEmpty()) { result.add(max); max = Integer.MIN_VALUE; queue1 = queue2; queue2 = new LinkedList\u0026lt;\u0026gt;(); } return result; }面试题45：二叉树最低层最左边的值# public int findBottomLeftValue(TreeNode root) { Queue\u0026lt;TreeNode\u0026gt; queue1 = new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2 = new LinkedList\u0026lt;\u0026gt;(); queue1.offer(root); int bottomLeft = root.val; while (!queue.isEmpty()) { TreeNode node = queue1.poll(); if (node.left != null) { queue2.offer(node.left); } if (node.right != null) { queue2.offer(node.right); } if (queue1.isEmpty()) { queue1 = queue2; queue2 = new LinkedList\u0026lt;\u0026gt;(); if (!queue1.isEmpty()) { bottomLeft = queue1.peek().val; } } } return bottomLeft; }面试题46：二叉树的右侧视图# public List\u0026lt;Integer\u0026gt; rightSideView(TreeNode root) { List\u0026lt;Integer\u0026gt; view = new LinkedList\u0026lt;\u0026gt;(); if (root == null) { return view; } Queue\u0026lt;TreeNode\u0026gt; queue1 = new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2 = new LinkedList\u0026lt;\u0026gt;(); queue1.offer(root); while (!queue1.isEmpty()) { TreeNode node = queue1.poll(); if (node.left != null) { queue2.offer(node.left); } if (node.right != null) { queue2.offer(node.right); } if (queue1.isEmpty()) { view.add(node.val); queue1 = queue2; queue2 = new LinkedList\u0026lt;\u0026gt;(); } } return view; }7.4 本章小结# 第8章 树# 8.1 树的基础知识# public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } }8.2 二叉树的深度优先搜索# 中序遍历# public List\u0026lt;Integer\u0026gt; inorderTraversal() { List\u0026lt;Integer\u0026gt; nodes = new LinkedList\u0026lt;\u0026gt;(); dfs(root, nodes); return nodes; } private void dfs(TreeNode root, List\u0026lt;Integer\u0026gt; nodes) { if (root != null) { dfs(root.left, nodes); nodes.add(root.val); dfs(root.right, nodes); } }迭代# // left -\u0026gt; current -\u0026gt; right public List\u0026lt;Integer\u0026gt; inorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; nodes = new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) { while (cur != null) { stack.push(cur); cur = cur.left; } cur = stack.pop(); nodes.add(cur.val); // current node cur = cur.right; } return nodes; }前序遍历# public List\u0026lt;Integer\u0026gt; preorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; nodes = new LinkedList\u0026lt;\u0026gt;(); dfs(root, nodes); return nodes; } private void dfs(TreeNode root, List\u0026lt;Integer\u0026gt; nodes) { if (root != null) { nodes.add(root.val); dfs(node.left, nodes); dfs(node.right, nodes); } }迭代# // current -\u0026gt; left -\u0026gt; right public List\u0026lt;Integer\u0026gt; preorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; result = new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); TreeNode cur = root; if (cur != null || !stack.isEmpty()) { while (cur != null) { result.add(cur.val); // current node stack.push(cur); cur = cur.left; } cur = stack.pop(); cur = cur.right; } return result; }后序遍历# 迭代# public List\u0026lt;Integer\u0026gt; postorderTraversal(TreeNode root) { List\u0026lt;Integer\u0026gt; result = new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); TreeNode cur = root; TreeNode prev = null; while (cur != null || !stack.isEmpty()) { while (cur != null) { stack.push(cur); cur = cur.left; } cur = stack.peek(); if (cur.right != null \u0026amp;\u0026amp; cur.right != prev) { } else { stack.pop(); result.add(cur.val); prev = cur; cur = null; } } return result; }3种遍历方法小结# 面试题47：二叉树剪枝# public TreeNode pruneTree(TreeNode root) { if (root == null) { return root; } root.left = pruneTree(root.left); root.right = pruneTree(root.right); if (root.left == null \u0026amp;\u0026amp; root.right == null \u0026amp;\u0026amp; root.val == 0) { return null; } return root; }面试题48：序列化和反序列化二叉树# 序列化# public String serialize(TreeNode root) { if (root == null) { return \u0026#34;#\u0026#34;; } String leftStr = serialize(root.left); String right = serialize(root.right); return String.valueOf(root.val) + \u0026#34;,\u0026#34; + leftStr + \u0026#34;,\u0026#34; + rightStr; }反序列化# public TreeNode deserialize(String data) { String[] nodeStrs = data.split(\u0026#34;,\u0026#34;); int[] i = {0}; return dfs(nodeStrs, i); } private TreeNode dfs(String[] strs, int[] i) { String str = strs[i[0]]; i[0]++; if (str.equals(\u0026#34;#\u0026#34;)) { return null; } TreeNode node = new TreeNode(Integer.valueOf(str)); node.left = dfs(strs, i); node.right = dfs(strs, i); return node; }面试题49：从根节点到叶节点的路径数字之和# public int sumNumbers(TreeNode root) { return dfs(root, 0); } private int dfs(TreeNode root, int path) { if (root == null) { return 0; } path = path * 10 + root.val; if (root.left == null \u0026amp;\u0026amp; root.right == null) { return path; } return dfs(root.left, path) + dfs(root.right, path); }面试题50：向下的路径节点值之和# public int pathSum(TreeNode root, int sum) { Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(0, 1); return dfs(root, sum, map, 0); } private int dfs(TreeNode root, int sum, Map\u0026lt;Integer, Integer\u0026gt; map, int path) { if (root == null) { return 0; } path += root.val; int count = map.getOrDefault(path - sum, 0); }面试题51：节点值之和最大的路径# 8.3 二叉搜索树# 面试题52：展平二叉搜索树# 面试题53：二叉搜索树的下一个节点# 时间复杂度O(n)的解法# 时间复杂度O(h)的解法# 面试题54：所有大于或等于节点的值之和# 面试题55：二叉搜索树迭代器# 面试题56：二叉搜索树种两个节点的值之和# 利用哈希表，空间复杂度为O（n）的解法# 应用双指针，空间复杂度为O（h）的解法# 8.4 TreeSet和TreeMap的应用# 面试题57：值和下标之差都在给定的范围内# 时间复杂度为O（nlogk）的解法# 时间复杂度为O（n）的解法# 面试题58：日程表# 8.5 本章小结# 第9章 堆# 9.1 堆的基础知识# 9.2 堆的应用# ✅ 面试题59：数据流的第k大数字 JZOffer59.java# ✅ 面试题60：出现频率最高的k个数字 JZOffer60.java# ✅ 面试题61：和最小的k个数对 JZOffer61.java# 使用最大堆# 使用最小堆# kSmallestPairs 9.3 本章小结# 第10章 前缀树# 10.1 前缀树的基础知识# ✅ 面试题62：实现前缀树 JZOffer62.java# 10.2 前缀树的应用# ✅ 面试题63：替换单词 JZOffer63.java# 面试题64：神奇的字典# 面试题65：最短的单词编码# 面试题66：单词之和# 面试题67：最大的异或# 10.3 本章小结# 第11章 二分查找# 11.1 二分查找的基础知识# ✅ 二分查找算法 com.penruins.JZOffer.BinarySearch.java# 11.2 在排序数组中二分查找# 面试题68：查找插入位置# 面试题69：山峰数组的顶部# 面试题70：排序数组中只出现一次的数字 com.penruins.JZOffer.JZOffer70.java# singleNonDuplicate 用异或运算的方式实现 面试题71：按权重生成随机数# 11.3 在数值范围内二分查找# 面试题72：求平方根# 面试题73：狒狒吃香蕉# 11.4 本章小结# 第12章 排序# 12.1 排序的基础知识# 面试题74：合并区间# 12.2 计数排序# 面试题75：数组相对排序# 12.3 快速排序# 快速排序算法 com.penruins.JZOffer.QuickSort# 面试题76：数组中第k大的数字# 12.4 归并排序# 面试题77：链表排序# 面试题78：合并排序链表# 利用最小堆选取值最小的节点# 按照归并排序的思路合并链表# 12.5 本章小结# 第13章 回溯法# 13.1 回溯法的基础知识# 13.2 集合的组合、排列# 13.3 回溯法解决其他类型问题# 13.4 本章小结# 第14章 动态规划# 14.1 动态规划的基础知识# 14.2 单序列问题# 14.3 双序列问题# 14.4 矩阵路径问题# 面试题98：路径的数目# 分析确定状态转移方程# 根据状态转移方程写递归代码# 递归代码# 优化空间效率# 面试题99：最小路径之和# 面试题100：三角形中最小路径之和# 14.5 背包问题# 0-1 背包问题 多重背包问题 完全背包问题 面试题101：分割等和子集# 分析确定状态转移方程# 根据状态转移方程写递归代码# 根据状态转移方程写迭代代码# 优化空间效率# 面试题102：加减的目标值# 面试题103：最小的硬币数目# 分析确定状态转移方程# 根据状态转移方程写代码# 另一种思路# 面试题104：排列的数目# int[] nums = new int[1 2 3]; i = 3; f(i) = f(i - nums[0]) + f(i - nums[1]) + f(i - nums[2]); f(0) = 1; f(1) = f(0) + f(-1) + f(-2) = 1; f(2) = f(1) + f(0) + f(-1) = 2; f(3) = f(2) + f(1) + f(0) = 4; f(2) {1,1} {2} f(1) {1} f(0) {}14.6 本章小结# 第15章 图 305# 15.1 图的基础知识 305# 15.2 图的搜索 307# 15.3 拓扑排序 333# 15.4 并查集 342# 15.5 本章小结 354# "},{"id":11,"href":"/post/life/bilibili/","title":"bilibili","section":"Life","content":"bilibili# movies# 木鱼水心 电影广角镜 world# Yooupi食途 星球研究所 世茹很如意 digital# 那岩KJMX TESTV官方频道 黄杨ME cycling# Contayu_Cycling 道长说车 club100 周四青年 艾慕葡萄 table tennis# -我是派派- computer science# TheCW PegasusWang 神州数码云基地 Koala聊开源 JavaEE之Spring框架 开源社KAIYUANSHE 美团技术团队 技术胖 代码随想录 张老师和杜老师编程课 photography# 影视飓风 music# 94不曈 bilibili-knowledge# 量子位 柴知道 other# M2档案 "},{"id":12,"href":"/post/life/cycling/","title":"cycling","section":"Life","content":"Cycling# 昆洛路-\u0026gt;彩云中路爬坡-\u0026gt;彩云北路# 8 2025-01-07 7 2024-12-19 6 2024-12-18 5 2024-12-17 4 2024-12-13 3 2024-12-10 2 2024-12-06 1 2024-11-29 骑行路线# 昆明# 环滇池 宝花路 爬至小亭子 梁王山上坡 西山后山爬坡 松花坝水库爬坡 昭通# 凤凰山 athlete# Tadej Pogacar# strava 2024-09-29 世锦赛冠军 2024-07-21 环法 stage 21 赛段冠军 2024-07-20 stage 20 赛段冠军 reference# pro cycling stats 自行车职业赛数据及积分排行查询 strava my_strava veloviewer 广州# 一口气把大学城所有环合上了 "},{"id":13,"href":"/post/sports/cycling/","title":"cycling","section":"Sports","content":" pro cycling stats 自行车职业赛数据及积分排行查询 videos# 【2025 Donostia San Sebastian Klasikoa（圣塞巴斯蒂安） "},{"id":14,"href":"/post/computer-science/database/database/","title":"database","section":"Database","content":"database# 索引 index# 什么是聚集索引、非聚集索引？# 聚集索引：数据行的物理存储顺序与索引的逻辑顺序一致 非聚集索引：数据行的物理存储顺序与索引的逻辑顺序不一致 为什么只能有一种聚集索引？# 因为数据物理的存储顺序只能有一种，因此只能有一种聚集索引 默认的聚集索引是什么？# 主键 什么是回表？# 当查询条件使用普通索引并且查询的列不包含在索引中，就需要查询完普通索引后再去查询聚集索引的树拿到完整的行数据 当底层建了abc的联合索引，底层会建a,ab, abc这3个索引么？# 不会，只创建一个联合索引树 联合索引（abc)，当查询ab, ac会走索引么？# ab 走索引 ac 只走 a 索引 order by 和 group by 如何创建索引？# order by 单列 直接创建 多列 创建联合索引, 索引顺序要和 order by 的顺序一致 不一致索引会失效 group by group by 实际上是先进行排序，再进行分组。所以遵循 order by 的索引机制 MySQL索引失效的20种场景# MySQL索引失效的20种场景 1 查询条件未使用索引列 SELECT * FROM users WHERE non_indexed_column = 'example' 2 查询条件对索引列使用了函数或表达式 SELECT * FROM users WHERE LEFT(name, 3) = 'Ali' 3 数据类型不一致引发隐式类型转换 SELECT * FROM users WHERE phone = 1234567890; -- phone 是 VARCHAR 4 联合索引使用时的范围查询阻断 SELECT * FROM users WHERE name = 'Alice' AND age \u0026gt; 30 AND city = 'New York' 5 如果 OR 条件中有字段未使用索引，会导致整体索引失效 SELECT * FROM users WHERE name = 'Alice' OR age = 30; 解决方法：拆分查询，用 UNION 替代 SELECT * FROM users WHERE name = 'Alice' UNION SELECT * FROM users WHERE age = 30; 6 LIKE 查询中使用前置通配符 % 时，无法利用索引 SELECT * FROM users WHERE name LIKE '%Alice'; 解决方法 替换为后置通配符 LIKE \u0026lsquo;Alice%\u0026rsquo; 使用全文索引 ALTER TABLE users ADD FULLTEXT(name); SELECT * FROM users WHERE MATCH(name) AGAINST('Alice'); 7 不等值操作符 != \u0026lt;\u0026gt; 通常会导致索引失效 SELECT * FROM users WHERE age != 30; 解决方法：改写为范围查询 SELECT * FROM users WHERE age \u0026lt; 30 OR age \u0026gt; 30; 8 IN 子句中参数过多时，索引可能失效 SELECT * FROM users WHERE id IN (1, 2, ..., 10000) 解决方法：分批查询或控制 IN 参数数量 SELECT * FROM users WHERE id BETWEEN 1 AND 5000 9 某些情况下对NULL值的查询可能导致索引失效 SELECT * FROM users WHERE email IS NULL; 解决方法：避免使用 NULL，改为特定占位值 10 ORDER BY 和 GROUP BY 不符合索引顺序 select * from users order by age, name; 索引顺序为(name,age) 解决方法：调整查询或索引顺序一致 11 索引列未覆盖查询字段 select age from users where name = 'Alice' 解决方法：创建覆盖索引 alter table users add index(name, age) 12 表统计信息过期 表的统计信息不准确时，MySQL优化器可能错误选择全表扫描 解决方法：定期更新统计信息 ANALYZE TABLE users 13 数据分布不均 select * from users where gender = 'M' -- gender 列 90% 的值相同 解决方法：优化查询字段或调整数据分布 14 子查询未优化 子查询结果集过大时，索引失效 SELECT * FROM users WHERE id IN (SELECT user_id FROM orders WHERE total \u0026gt; 100) 解决方法：改为 JOIN 查询 SELECT u.* FROM users u JOIN orders o ON u.id = o.user_id WHERE o.total \u0026gt; 100 15 锁机制干扰 间隙锁 描述：间隙锁可能阻止索引的高效使用 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE 解决方法：降低事务隔离级别至 Read Committed(读已提交) 可重复读加上间隙锁防止幻读 16 索引被动态调整 MySQL优化器动态调整索引，可能选择非最佳索引或直接全表扫描 SELECT * FROM users FORCE INDEX (idx_name) WHERE name = 'Alice' 17 聚合函数未走索引 使用聚合函数(如 COUNT, SUM) 时，索引可能无法被利用 SELECT COUNT(*) FROM users WHERE age \u0026gt; 30 解决方法：利用覆盖索引 ALTER TABLE users ADD INDEX(age) 18 使用了非等值JOIN select * from users u join orders o on u.id \u0026gt; o.user_id 优化连接条件，尽量使用等值连接 19 小表全表扫描替代索引扫描 对于非常小的表，MySQL优化器可能选择全表扫描而非索引 SELECT * FROM small_table WHERE id = 1; 解决方法：无需优化，小表全表扫描的代价通常可以忽略 20 分区表查询不走全局索引 分区表的查询条件不覆盖分区键时，全局索引可能无法生效 SELECT * FROM partitioned_users WHERE city = 'New York' 解决方法：在分区键上创建局部索引 分区表的索引如何创建# 分区# 分表和分区在物理存储上有什么区别？# 在数据库中一张表对应磁盘中的2个文件，拓展名为idb的文件和拓展名为frm的文件，idb文件存储表中的记录，frm存储表的结构信息 进行分表的话有几张表就有几个对应的文件，进行分区就只有一个frm文件和若干个idb文件，一个分区对应一个idb文件 分区能提升大表的读写性能就是因为根据分区规则仅仅扫描对应分区的磁盘文件，而不用进行全表扫描 一张表最多可以分多少个区？# 1024 事务# 数据隔离级别# 读未提交 Read Uncommitted 读已提交 Read Committed 脏读：同一个事务中，多次读取同一数据的结果不同 可重复读 Repeatable Read 幻读：同一个事务中，相同的查询条件读取到的数据条数不一样 串行化 Serializable MVCC# MVCC 的全称是什么？# Multi-Version Concurrency Control 多版本并发控制 MySQL的事务引擎仅仅使用行级锁吗？# 不是，它结合了行级锁+MVCC(多版本并发控制) MVCC适用于哪些隔离级别？# 适用于 REPEATED READ 和 READ COMMITTED 不适用于 READ UNCOMMITTED "},{"id":15,"href":"/post/computer-science/distributed-system/distributed-system/","title":"distributed system","section":"Distributed System","content":"distributed system# 微服务和分布式的比较# 微服务架构和分布式架构是现代软件系统中两种重要的设计模式 分布式架构 分布式架构是指将系统组件部署在不同的物理或虚拟节点上，通过网络协作完成任务。其核心目标是解决性能、可扩展性、容错性等问题，例如通过负载均衡、数据分片等技术提升系统吞吐能力 典型场景：分布式数据库（如Cassandra）、分布式计算（如Spark） 适合需要高性能、高可用性的场景，如大规模数据处理、高并发请求 微服务架构 微服务是一种将单体应用拆分为多个小型、独立服务的架构风格，每个服务围绕特定业务功能构建，通过轻量级通信（如HTTP/REST、gRPC）交互。核心目标是提升开发效率、灵活性和可维护性，解决业务复杂度问题 典型场景：电商平台（订单、库存等独立服务）。 适合业务复杂、需快速迭代的系统，尤其是多团队协作开发时 分布式是手段：通过物理分散提升系统能力 微服务是策略：通过逻辑拆分优化开发和维护 选择依据： 若需解决性能瓶颈，优先考虑分布式 若需应对业务复杂性，选择微服务 "},{"id":16,"href":"/post/computer-science/database/druid/","title":"druid","section":"Database","content":"druid# Spring Boot 整合 Druid 指南 SpringBoot——开启Druid监控统计功能(SQL监控、慢SQL记录、Spring监控、去广告) SpringBoot - 开启Druid监控统计功能教程（SQL监控、慢SQL记录、去广告） 这个有用，配置要全部加上，不能漏了 "},{"id":17,"href":"/post/computer-science/front-end/echarts/","title":"echarts","section":"Front End","content":"echarts# PPChart "},{"id":18,"href":"/post/computer-science/database/elasticsearch/","title":"elasticsearch","section":"Database","content":"ElasticSearch# 使用场景# 场景1 全文搜索Elasticsearch 凭借其强大、可扩展和快速的搜索功能，在全文搜索场景中表现出色。它允许用户以近乎实时的响应执行复杂的查询 场景2 实时分析Elasticsearch 能够实时执行分析，因此适用于跟踪实时数据（如用户活动、交易或传感器输出）的仪表板 场景3 机器学习通过在 X-Pack 中添加机器学习功能，Elasticsearch 可以自动检测数据中的异常、模式和趋势 场景4 地理数据应用程序Elasticsearch 通过地理空间索引和搜索功能支持地理数据。这对于需要管理和可视化地理信息的应用程序（如地图和基于位置的服务）非常有用 场景5 日志和事件数据分析组织使用 Elasticsearch 来聚合、监控和分析来自各种来源的日志和事件数据。它是 ELK 堆栈（Elasticsearch、Logstash、Kibana）的关键组件，用于管理系统和应用程序日志以识别问题和监控系统运行状况 场景6 安全信息和事件管理 （SIEM）Elasticsearch 可用作 SIEM 工具，帮助组织实时分析安全事件 "},{"id":19,"href":"/post/computer-science/github/","title":"github","section":"Computer Science","content":" 2025-08-12 移动端创建issue的时候要等issue的页面加载完成之后再返回到列表，如果没加载完就返回到列表，issue会丢失（列表显示不出来），但是issue的数量是已经累加了的 常用命令# # 查看远程仓库列表，需要指定 git fetch 哪一个远程仓库的时候会用到 # 因为可能有些仓库网络不通，直接 git fetch 会一直不响应 git remoteprofile# 官方文档 如果你新建一个和你的用户名一样名字的仓库，这个仓库的 Readme 就会展示在你的个人主页上 ref: 玩了一下 Github 个人首页的 Profile （使用 Action 自动更新） Github Action# GitHub Actions 入门教程 repository# torvalds/linux CesiumGS/cesium CesiumJS is a JavaScript library for creating 3D globes and 2D maps in a web browser without a plugin. It uses WebGL for hardware-accelerated graphics, and is cross-platform, cross-browser, and tuned for dynamic-data visualization. ohmyzsh/ohmyzsh Oh My Zsh is an open source, community-driven framework for managing your zsh configuration. duanluan/zutil 追求更快更全的 Java 工具类 文档 binarywang/Linux-Tutorial Java 程序员眼中的 Linux yihong0618 algorithm-practice# algorithm-practice dataStructure# com.penruins.dataStructure PriorityQueueDemo# demo1 PriorityQueue 默认为最小堆 如果 PriorityQueue 中没有元素了，则返回 null demo2 自定义一个比较器实现最大堆 follow# oldratlee graph(com.penruins.graph)# com.penruins.graph 广度优先搜索(com.penruins.graph.GraphSearch.bfs)# com.penruins.graph.GraphSearch.bfs 二维图的广度优先搜索 8个方向 从标志数组的打印可以看出来是广度优先搜索 "},{"id":20,"href":"/post/computer-science/big-data/hadoop/","title":"hadoop","section":"Big Data","content":"hadoop# Hadoop生态系统是一个由Apache基金会维护的开源软件集合，用于处理和分析大规模数据集。经过多年发展，Hadoop已从最初的HDFS和MapReduce两个核心组件扩展为一个包含众多工具和框架的完整生态系统 核心基础组件 HDFS (Hadoop Distributed File System) Hadoop的分布式文件系统，用于存储超大规模数据集 采用主从架构：NameNode(主节点)管理元数据，DataNode(从节点)存储实际数据块 特点：高容错性、高吞吐量、适合部署在廉价硬件上 YARN (Yet Another Resource Negotiator) Hadoop 2.0引入的资源管理和作业调度框架 包含ResourceManager(集群资源管理)和NodeManager(节点资源监控) 支持多种计算框架(MapReduce、Spark等)共享集群资源 MapReduce 分布式计算框架，采用\u0026quot;分而治之\u0026quot;思想 包含Map(数据分解)和Reduce(结果汇总)两个阶段 适合处理大规模离线批处理任务 数据存储组件 HBase 分布式列式NoSQL数据库，基于Google BigTable设计 构建在HDFS之上，提供实时读写能力 适合存储海量结构化数据 Hive 数据仓库工具，提供类SQL查询语言(HiveQL) 将SQL转换为MapReduce/Tez/Spark作业执行 适合数据汇总、即席查询和分析 Pig 高级数据流语言(Pig Latin)和执行框架 简化MapReduce编程，适合ETL流程 支持结构化/半结构化数据处理 数据采集与传输组件 Sqoop 关系型数据库与Hadoop间数据传输工具 支持从MySQL、Oracle等导入数据到HDFS/Hive/HBase 也支持将Hadoop数据导出到关系数据库 Flume 分布式日志收集系统 适合采集、聚合和移动大量日志数据到HDFS 包含Source(数据源)、Channel(传输通道)和Sink(目的地)三个组件 协调与管理组件 Zookeeper 分布式协调服务 提供统一命名服务、配置管理、集群同步等 解决分布式环境下的数据一致性问题 Oozie 工作流调度系统 用于编排Hadoop作业(MapReduce、Pig、Hive等) 支持定时和依赖触发 Ambari Hadoop集群管理工具 提供Web界面监控、配置和管理Hadoop集群 支持大多数Hadoop组件 高级计算框架 Spark 内存计算框架，比MapReduce快10-100倍 支持批处理、流处理、机器学习和图计算 可与HDFS、HBase等集成 Flink 流处理框架，支持事件时间和精确一次处理 适合实时数据分析场景 与Hadoop生态系统兼容 Mahout 机器学习算法库 提供聚类、分类、推荐等算法实现 可扩展至大规模数据集 其他重要组件 Kafka 分布式消息队列系统 高吞吐量、低延迟 常用于实时数据管道 Tez 优化后的MapReduce执行引擎 减少中间结果写入磁盘，提高性能 被Hive、Pig等采用 Avro 数据序列化系统 提供紧凑的二进制数据格式 支持RPC通信 "},{"id":21,"href":"/post/computer-science/big-data/hbase/","title":"hbase","section":"Big Data","content":"hbase# HBase 是一个面向列式存储的分布式数据库，其设计思想来源于 Google 的 BigTable 论文 HBase 底层存储基于 HDFS 实现，集群的管理基于 ZooKeeper 实现 HBase 良好的分布式架构设计为海量数据的快速存储、随机访问提供了可能，基于数据副本机制和分区机制可以轻松实现在线扩容、缩容和数据容灾，是大数据领域中 Key-Value 数据结构存储最常用的数据库方案 hbase vs elasticsearch# HBase是基于Hadoop生态的分布式列式数据库，源自Google BigTable设计，擅长海量结构化/半结构化数据的存储和高吞吐写入 Elasticsearch是基于Lucene的分布式搜索引擎，专注于全文检索、复杂查询和实时分析，采用文档型数据模型 数据模型与灵活性 HBase采用列式存储模型，数据按\u0026quot;行键(RowKey)+列族(Column Family)+列限定符(Qualifier)\u0026ldquo;组织，适合结构化或半结构化数据。虽然schema-free设计允许灵活添加列，但列族需要预先定义 Elasticsearch采用文档型模型，数据以JSON格式存储，天然支持非结构化数据。字段可以动态添加，无需预定义schema，更适合多变的数据结构 查询能力对比 HBase查询能力相对有限 主要支持基于RowKey的精确查询和范围扫描(Scan) 复杂查询需要借助二级索引或Phoenix等SQL层 无内置全文检索能力，需结合Solr等搜索引擎 Elasticsearch提供丰富的查询功能 支持全文搜索、模糊查询、分词查询、聚合分析等高级特性 提供强大的DSL查询语言和SQL接口 内置倒排索引，亿级数据下仍能保持秒级响应 典型场景：HBase适合\u0026quot;已知RowKey查明细\u0026rdquo;，ES适合\u0026quot;根据内容特征找文档\u0026quot; 性能与扩展性 写入性能 两者都基于LSM树结构，理论写入性能相当 实际场景中HBase写入更高效，因为ES需要构建倒排索引等额外开销 HBase单集群可支持每天TB级数据写入 查询性能 ES在复杂查询和全文检索方面性能显著优于HBase HBase在简单键值查询和范围扫描上延迟更低 扩展能力 HBase天生为海量数据设计，通过Region分裂实现水平扩展 ES通过分片(Shard)机制扩展，但数据量极大时可能需要业务层干预 存储成本与资源消耗 存储效率 HBase采用列式存储+压缩，存储效率更高，适合长期保存海量数据 ES因维护索引和副本，存储开销通常比HBase高30%-50% 资源消耗 ES的CPU和内存消耗更高（分词、索引构建等） HBase更注重I/O优化，适合资源受限环境 维护复杂度 HBase依赖完整的Hadoop生态(HDFS/ZooKeeper等)，组件多，运维复杂度高 Elasticsearch自成体系，部署和维护相对简单，但集群调优需要专业知识 实时性与一致性 HBase采用强一致性模型(基于2PC协议)，适合对一致性要求高的场景 Elasticsearch采用最终一致性，查询实时性更好但可能短暂不一致 典型应用场景推荐 适合选择HBase的场景 海量时序数据存储：如设备监控数据、日志流水(每日5G以上) 高吞吐写入：需要持续写入TB级结构化数据的场景 简单查询为主：已知主键的快速查询或固定模式的范围扫描 长期数据归档：需要低成本长期保存的历史数据 案例：某埋点系统每天100G数据通过Kafka写入HBase，稳定运行 适合选择Elasticsearch的场景 全文检索需求：如商品搜索、内容检索、日志分析 复杂查询分析：需要多条件组合、聚合统计的业务 实时数据分析：如应用监控、安全分析等需要秒级响应的场景 灵活的数据结构：字段频繁变化或无法预定义schema的情况 混合架构方案 对于同时需要海量存储和复杂查询的场景，可考虑ES+HBase组合架构 HBase作为主存储，保证数据持久性和高吞吐写入 ES作为索引层，提供丰富的查询能力 通过数据同步工具保持两者数据一致 百亿级数据架构案例：使用ES处理复杂查询，HBase保证可靠存储，两者协同工作 选型决策关键因素 数据规模：日增5GB以下ES更简单，TB级选HBase 查询复杂度：简单查询HBase足够，复杂搜索选ES 数据结构：固定结构用HBase，多变结构用ES 资源预算：资源有限优先HBase，可接受较高成本选ES 团队技能：熟悉Hadoop选HBase，无大数据经验ES更易上手 总结建议 Elasticsearch是搜索和复杂查询的首选，特别适合日志分析、内容检索等需要灵活查询的场景 HBase是海量数据存储的可靠选择，特别适合时序数据、用户行为记录等高吞吐写入场景 HBase与RDBMS的区别# 存储方式：HBase为列式存储，RDBMS为行式存储 扩展性：HBase支持水平扩展，RDBMS通常垂直扩展 事务：HBase仅支持单行事务，RDBMS支持多行复杂事务 HBase与Hive的区别# 用途：HBase是实时数据库，Hive是离线数据仓库 查询性能：HBase支持毫秒级查询，Hive依赖MapReduce，延迟高 数据存储结构# Region：表的水平分区，按RowKey范围划分 MemStore：写缓存，满时刷盘生成HFile HFile：底层存储文件，基于HDFS的列族数据块 hbase 的特点# 易扩展 海量存储 列式存储 高可靠性 稀疏性 模块组成# HBase 可以将数据存储在本地文件系统，也可以存储在 HDFS 文件系统。在生产环境中，HBase 一般运行在 HDFS 上，以 HDFS 作为基础的存储设施。HBase 通过 HBase Client 提供的 Java API 来访问 HBase 数据库，以完成数据的写入和读取。HBase 集群主由HMaster、Region Server 和 ZooKeeper 组成 HMaster 负责管理 RegionServer，实现其负载均衡 管理和分配 Region，比如在 Region split时分配新的 Region，在 RegionServer 退出时迁移其内的 Region 到其他 RegionServer上 管理namespace和table的元数据（实际存储在HDFS上） 权限控制（ACL） RegionServer 存放和管理本地 Region 读写HDFS，管理Table中的数据 Client 从 HMaster 中获取元数据，找到 RowKey 所在的 RegionServer 进行读写数据 ZooKeeper 存放整个 HBase集群的元数据以及集群的状态信息 实现HMaster主从节点的failover RowKey设计原则# 长度：建议≤16字节，避免内存和存储浪费 散列性：高位散列（如哈希前缀）防止热点问题 唯一性：必须保证RowKey唯一标识数据 应用场景# 适用场景 半结构化/非结构化数据（如日志、用户行为） 高并发实时读写（如电商订单、社交消息） HBase是根据谷歌的BigTable设计的。典型的应用场景就是不断插入新的信息（谷歌的情况下就是互联网上新生成的网页），而不怎么修改。比如现在Facebook的messenger就是用HBase实现的 Facebook Facebook用HBase存储在线消息，每天数据量近百亿，每月数据量250 ~ 300T， HBase读写比基本在1:1，吞吐量150w qps 小米 10+在线HBase集群，好几百台服务器，米聊历史数据，消息push系统等多个重要应用系统都建立在HBase基础之上 网易 哨兵监控系统，云信历史数据，日志归档数据等一系列重要应用底层都由HBase提供服务 写密集型应用，每天写入量巨大，而相对读数量较小的应用，比如IM的历史消息，游戏的日志等等 不需要复杂查询条件来查询数据的应用，HBase只支持基于rowkey的查询，对于HBase来说，单条记录或者小范围的查询是可以接受的，大范围的查询由于分布式的原因，可能在性能上有点影响，而对于像SQL的join等查询，HBase无法支持 对性能和可靠性要求非常高的应用，由于HBase本身没有单点故障，可用性非常高 数据量较大，而且增长量无法预估的应用，HBase支持在线扩展，即使在一段时间内数据量呈井喷式增长，也可以通过HBase横向扩展来满足功能 不适用场景 需要复杂事务或多表关联查询的业务 Reference# 什么是HBase？终于有人讲明白了 "},{"id":22,"href":"/post/life/hiking/","title":"hiking","section":"Life","content":"Hiking# "},{"id":23,"href":"/post/computer-science/big-data/hive/","title":"hive","section":"Big Data","content":"hive# Apache Hive是一个基于Hadoop的数据仓库基础设施，主要用于处理和分析存储在Hadoop分布式文件系统(HDFS)中的大规模数据集。它由Facebook开发并开源，旨在为大数据分析提供类SQL的查询能力，使得非程序员也能方便地进行海量数据处理 "},{"id":24,"href":"/post/computer-science/tools/idea/","title":"IDEA","section":"Tools","content":" document theme# Sepia Theme 这个颜色偏黄在比较亮的办公室用比较舒服 索引# 如果IDE一直对构建目录(例如target)进行索引，可以将这个目录设置为 Excluded，这样就不会对这个目录进行索引了 右键目录 Mark Directory as -\u0026gt; Excluded 通义灵码# Cursor平替，国产AI程序员终于支持IDEA！ Spring Debugger# 【IDEA】Spring 调试的天花板？Debug能力直接起飞 新版本功能# 2025.1# 【IDEA】全新版本IDEA，Java开发体验再优化，值不值得更新？ "},{"id":25,"href":"/post/computer-science/operating-system/ios/","title":"IOS","section":"Operating System","content":" 一日一技：iOS抓包最简单方案 Charles 有 iOS 版本，app store 上就能下载，使用下来还不错 Open-Source iOS Apps A collaborative list of open-source iOS, iPadOS, watchOS, tvOS and visionOS apps, your contribution is welcome 😄 dkhamsing/news IOS26# Liquid Glass 继续调整，iOS 26 Beta 近期更新值得关注的变化 APPS# 轻听英语 Kiwix 众山小笔记 微信输入法 很清爽，但是输入的体验不太好（自动补全不智能，这点还是搜狗输入法好用。。） Picsew 长截图工具 Net Shadowrocket Strides Charles Caenets - Jupyter Actions Shortcuts 的拓展 app，它封装了很多新的动作 文件传输 LocalSend Blip Blip 据说比 LocalSend 更稳定，而且支持互联网传输文件 Data Jar 2025-08-12 不知道为啥，icloud数据同步会报错，之前iPhone上的数据还同步到iPad那边了。app store 上好久没更新了。同步不了就当本地用了 HashPhotos a-Shell a-shell: A terminal for iOS, with multiple windows holzschu/a-Shell-commands GitHub 大陆的 App Store 已经下载不到了 下载好了之后可以不用 magic 就能使用，比web 的网络稳定性更好 可以查看action的执行情况 working copy 目前用下来最好的 git 客户端 现在在中国大陆的 app store 上架的app要备案，因为这个app的开发者是国外大哥，不要因为政策下架呀。。 Freeform 苹果原生的白板应用，很流畅，添加很多图片也不会卡顿。现在还没有创建文件夹的功能，希望尽快有这个功能，白板多了不好管理文件。2025-07-30 bark Finb/Bark Bark is a push notification tool app. It\u0026rsquo;s free, simple, and secure, leveraging APNs without draining device battery. document Bark-Java-SDK Day One Obsidian ios 端最好用的 markdown 编辑器，可以把笔记存到 obsidian 的云服务上，也可以存到 icloud上。我是配合 working copy push到github，然后配合github的action，自动构建更新我的博客（比如这段话我就是在手机上用obsidian编辑的） 实在受不了都 ios 18，apple notes还是那么极简，没有目录，不支持markdown，还是坚持不下来使用 IFTTT 3 个非常规 Day One 使用场景 触发你的智能生活：IFTTT 入门 RSS Inoreader Feedly "},{"id":26,"href":"/post/computer-science/job/","title":"job","section":"Computer Science","content":"job# 应届生的简历 "},{"id":27,"href":"/post/computer-science/distributed-system/message-queue/kafka/","title":"kafka","section":"Message Queue","content":"kafka# kafka vs rocketmq# Kafka 和 RocketMQ 之性能对比 kafka如何实现高吞吐量的？# 顺序读写 零拷贝 分区与并行处理 批量发送 数据压缩 页缓存 高效的日志存储(将消息分段、并建立索引文件、支持快速定位与消息读取) Kafka突然宕机了消息会不会丢失# 消息的持久化机制 消息会存储到日志文件中，宕机后不会丢失 副本机制 一个分区可以建立副本，确保数据不丢失 生产者确认机制 刷盘机制 同步刷盘, 每次写入消息就将写入到磁盘中, 但损失了效率 异步刷盘 kafka如何保障顺序消费# 分区内的顺序性 将分区键与业务ID进行绑定，保证相同业务的消息都发送到对应分区进行顺序消费 kafka重平衡的触发条件是什么？# 消费者组成员发生变化 消费者的加入、退出或崩溃 订阅主题分区数发生变化 主题分区增加或减少 订阅主题发生变化 使用正则表达式订阅主题时，新的主题被匹配 kafka发送失败如何处理# 同步发送模式 捕获异常 异步发送模式 在回调方法中捕获异常 重试机制 设置重试次数 错误分类处理 可恢复错误 网络超时 不可恢复错误 无效的主题 调整生产者配置 设置acks, 可以设置为all，确保所有副本都确认才返回成功 使用死信队列 将发送失败的消息加入到死信队列中，以便后续处理 kafka的分区分配策略有哪些？# RangeAssignor RoundRobinAssignor StickerAssignor CooperativeStickerAssignor kafka默认的分区策略是什么？# DefaultPartitioner 指定分区 基于key分配 轮询分配 "},{"id":28,"href":"/post/computer-science/llm/2025-03-30-7-kafka%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA%E6%9C%89%E5%A4%9A%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/","title":"kafka一个分区有多个消费者消费顺序是怎样的","section":"Computer Science","content":"kafka一个分区有多个消费者消费顺序是怎样的# 在 Kafka 中，一个分区（Partition）只能被同一个消费者组（Consumer Group）内的一个消费者（Consumer）消费，这是 Kafka 设计的基本原则。以下是详细分析：\n1. 单分区与消费者组的消费规则# 一个分区仅由一个消费者消费：\n在同一个消费者组内，每个分区会被分配给组内的唯一消费者。例如，如果一个 Topic 有 3 个分区，消费者组有 3 个消费者，则每个消费者负责一个分区，消息按分区顺序消费29。\n消费者数量 \u0026gt; 分区数：多余的消费者会处于空闲状态，无法消费任何分区的消息。 消费者数量 ≤ 分区数：每个消费者可能分配到一个或多个分区，但一个分区始终只对应一个消费者29。 分区内消息严格有序：\n单个分区内的消息按生产者写入的顺序存储和消费，消费者按偏移量（Offset）递增顺序处理消息1317。\n2. 多消费者消费同一分区的特殊情况# 不同消费者组：\n多个消费者组可以独立消费同一个分区的消息（每个组内仍遵循单消费者规则），但不同组之间的消费进度（Offset）互不影响。例如：\n消费者组 A 的 Consumer 1 消费分区 0； 消费者组 B 的 Consumer 1 也消费分区 029。 注意：这种场景下，消息会被重复消费，且各组消费顺序独立。 同一消费者组内多线程消费：\n若一个消费者启动多线程处理同一分区的消息，需自行保证线程间的顺序性（如单线程消费或业务层排序），否则可能乱序11。\n3. 分区分配策略的影响# Kafka 默认的分区分配策略（如 RangeAssignor 或 RoundRobinAssignor）会影响消费者与分区的对应关系，但不会改变单分区单消费者的核心规则13。例如：\nRangeAssignor：按分区范围顺序分配，可能导致分区分配不均。 RoundRobinAssignor：轮询分配，更均衡但可能打乱业务相关性13。 4. 总结与建议# 顺序性保障： 单分区内消息天然有序，但需确保消费者组内单线程消费17。 跨分区顺序需通过相同 Key 路由到同一分区实现局部有序117。 扩展性权衡：\n增加分区数可提升并行度，但需避免消费者数量不足导致负载不均。 若需多消费者并发处理同一分区的消息且保持顺序，需引入外部排序机制（如优先级队列）或改用单消费者多线程模式11。\n"},{"id":29,"href":"/post/computer-science/llm/2025-03-30-8-kafka%E5%8F%91%E9%80%81%E5%A4%B1%E8%B4%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/","title":"kafka发送失败如何处理","section":"Computer Science","content":"kafka发送失败如何处理# 当 Kafka 生产者发送消息失败时，可以通过以下方法进行排查和处理，结合错误类型和业务需求选择合适策略：\n一、常见失败原因及解决方案# 网络故障\n现象：生产者无法连接 Broker，或发送超时。 解决： 检查网络连通性（如防火墙、DNS 解析）。 增加生产者参数 retries（重试次数）和 retry.backoff.ms（重试间隔）114。 分区副本不可用\n现象：目标分区 Leader 副本宕机或正在重分配。 解决： 检查 Broker 和分区状态（如 kafka-topics.sh --describe）。 配置 acks=all 确保所有副本确认写入，避免数据丢失114。 主题不存在\n现象：发送到未创建的主题。 解决： 提前创建主题，或启用 auto.create.topics.enable=true（生产环境慎用）1。 消息大小超限\n现象：消息超过 max.request.size 或 Broker 限制。 解决： 增大 max.request.size 或拆分大消息114。 生产者配置错误\n现象：bootstrap.servers 配置错误或序列化器不匹配。 解决： 检查 bootstrap.servers 地址和序列化配置（如 StringSerializer）。 二、发送失败的处理策略# 同步发送模式\n调用 send().get() 阻塞等待发送结果，捕获异常后重试或记录日志222。 try { RecordMetadata metadata = producer.send(record).get(); } catch (Exception e) { // 重试或记录失败 } 异步发送模式\n通过回调（Callback）处理失败，例如重试或存入死信队列2。 producer.send(record, (metadata, exception) -\u0026gt; { if (exception != null) { // 异步处理失败 } }); 启用自动重试\n配置 retries=3（默认0）和 retry.backoff.ms=1000，应对瞬时错误（如网络抖动）2。 幂等性与事务\n设置 enable.idempotence=true 避免重复消息；事务消息需配置 transactional.id。 监控与报警\n监控生产者指标（如 record-error-rate），对持续失败触发报警。 三、高级优化建议# 调整批量参数\n增大 batch.size 和 linger.ms 提升吞吐，但可能增加延迟22。 压缩消息\n配置 compression.type=snappy/lz4 减少网络传输量22。 备份与容灾\n确保 replication.factor≥2，避免单点故障导致数据不可用114。 四、总结# 瞬时错误：通过重试和异步回调处理。 持久错误：检查配置、资源限制或 Broker 状态。 关键业务：结合同步发送、幂等性和事务保证可靠性12。 若问题持续，建议结合 Broker 日志（如 kafka-server.log）和生产者日志进一步定位。\n"},{"id":30,"href":"/post/computer-science/llm/2025-03-30-5-kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E9%9A%9C%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9/","title":"kafka如何保障顺序消费","section":"Computer Science","content":"kafka如何保障顺序消费# Kafka 通过其独特的分区机制和消费者组设计来保障消息的顺序消费，但需注意其仅能保证单分区内的顺序性，跨分区的全局顺序需额外设计。以下是具体实现方法和原理：\n一、单分区顺序性保障# 分区内消息严格有序\nKafka 的每个分区（Partition）是一个有序的、不可变的日志序列，消息按生产者发送的顺序追加到分区末尾，消费者按相同顺序读取11825。 关键设计：分区内的消息通过偏移量（Offset）标识顺序，消费者按 Offset 递增消费18。 生产者配置\n相同 Key 路由到同一分区：生产者通过消息 Key 的哈希值确定分区，相同 Key 的消息始终进入同一分区，确保业务相关的消息顺序12539。 // 示例：发送相同Key的消息到同一分区 ProducerRecord\u0026lt;String, String\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;topic\u0026#34;, \u0026#34;order-123\u0026#34;, \u0026#34;message\u0026#34;); producer.send(record); 限制并发请求：设置 max.in.flight.requests.per.connection=1，防止生产者因重试导致消息乱序3125。 消费者配置\n单线程消费：每个分区仅由一个消费者线程处理，避免并发消费破坏顺序18。 手动提交 Offset：确保消息处理完成后再提交 Offset，防止重复消费或漏消费。 二、全局顺序性实现（跨分区）# 单分区策略\n将 Topic 设置为单分区，所有消息集中到一个分区，但会牺牲吞吐量和扩展性242532。 适用场景：低吞吐但强顺序要求的场景（如金融交易流水）24。 基于 Key 的分区路由\n将需顺序处理的消息（如同一订单 ID）通过相同 Key 路由到固定分区，实现局部顺序139。 局限性：若 Key 分布不均，可能导致分区负载倾斜24。 应用层排序\n消费者拉取多分区消息后，通过优先级队列（如按时间戳或业务ID排序）实现全局顺序。 示例： PriorityQueue\u0026lt;ConsumerRecord\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(Comparator.comparing(ConsumerRecord::timestamp)); 三、高级配置与优化# 幂等生产者\n设置 enable.idempotence=true，避免重试导致消息重复或乱序，同时允许 max.in.flight.requests.per.connection\u0026gt;1 提升吞吐31。 消费者组与分区数平衡\n消费者组内实例数 ≤ 分区数，确保每个分区仅由一个消费者处理1838。 分区分配策略： RangeAssignor：按分区范围分配，适合分区数固定的场景38。 RoundRobin：轮询分配，均衡负载但可能打乱业务顺序38。 避免消费者重平衡\n消费者频繁加入/退出会触发分区重分配，可能导致短暂乱序。可通过 session.timeout.ms 调整心跳检测时间。 四、适用场景与权衡# 高吞吐 vs 顺序性：Kafka 默认优先保证吞吐，全局顺序需牺牲性能2431。 推荐方案： 局部顺序：Key 分区 + 单线程消费（如订单状态变更）139。 全局顺序：单分区或应用层排序（如日志时间序列）25。 总结# Kafka 的顺序消费能力依赖于合理配置生产者的分区策略、消费者的并发控制及业务逻辑设计。单分区顺序是原生支持的，而全局顺序需结合业务需求权衡性能与一致性182431。\n"},{"id":31,"href":"/post/computer-science/llm/2025-03-30-3-kafka%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F/","title":"kafka如何实现高吞吐量","section":"Computer Science","content":"kafka如何实现高吞吐量# Kafka 实现高吞吐量的核心机制基于其多层次的优化设计，包括存储、网络、并行处理和资源利用等方面。以下是关键实现原理及技术细节：\n1. 顺序写入与页缓存技术# 顺序写入磁盘：Kafka 将消息追加到分区日志文件末尾，避免随机磁盘寻址。顺序写入的吞吐量接近内存读写速度（可达数百MB/s），远高于随机写入11222。 页缓存（Page Cache）：消息首先写入操作系统的页缓存（内存），由操作系统异步刷盘。这减少了直接磁盘I/O的开销，同时利用内存加速读写11223。 2. 零拷贝（Zero-Copy）技术# sendfile 系统调用：消费者读取数据时，Kafka 通过 sendfile 直接将页缓存的数据发送到网卡，跳过用户态与内核态之间的数据拷贝，减少CPU消耗和上下文切换15153。 mmap 内存映射：生产者写入时通过内存映射文件（mmap）将磁盘文件映射到内存，避免数据复制1251。 3. 分区与并行处理# 分区机制：Topic 分为多个 Partition，每个 Partition 独立处理读写请求，支持水平扩展。分区数越多，并行度越高，吞吐量线性增长34。 消费者组：多个消费者并行消费不同分区，避免单点瓶颈。例如，6个分区的Topic可由6个消费者同时处理，提升整体消费速率。 4. 批量处理与压缩# 生产者批量发送：Producer 累积消息到批次（如100ms或1MB阈值）后一次性发送，减少网络和磁盘I/O次数1232。 消息压缩：支持 Snappy、GZIP 等压缩算法，减少网络传输数据量（尤其对文本数据压缩率可达80%）1222。 5. 高效的存储与索引# 稀疏索引：每个 Partition 的日志分段（Segment）附带索引文件，通过偏移量快速定位消息，避免全量扫描3223。 日志分段清理：定期删除过期数据或合并小文件，保持存储高效。 6. 网络与协议优化# 二进制协议：自定义紧凑的二进制通信协议，减少解析开销32。 长轮询与拉取模式：消费者主动拉取消息（Pull），根据处理能力控制流量，避免Broker过载。 总结# Kafka 的高吞吐量是多项技术协同作用的结果：\n存储层：顺序写入+页缓存+零拷贝最大化I/O效率； 架构层：分区+并行处理实现水平扩展； 传输层：批量+压缩+高效协议降低网络开销。 实际应用中，需根据业务调整分区数、批次大小和压缩算法等参数以进一步优化性能112。\n"},{"id":32,"href":"/post/computer-science/llm/2025-03-30-6-kafka%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B%E4%B8%8E%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%B3%BB%E7%BB%9F%E7%9B%B8%E6%AF%94%E6%9C%89%E4%BD%95%E4%BC%98%E5%8A%BF/","title":"Kafka的顺序消费能力与其他消息队列系统相比有何优势","section":"Computer Science","content":"Kafka的顺序消费能力与其他消息队列系统相比有何优势# Kafka 在顺序消费能力上与其他主流消息队列系统（如 RabbitMQ、RocketMQ）相比，具有独特的优势和适用场景。以下是详细对比分析：\n一、Kafka 顺序消费的核心优势# 分区内严格有序\nKafka 通过分区（Partition）机制天然保证同一分区内的消息顺序性，消息按写入顺序存储和消费，适用于高吞吐场景下的局部有序需求（如订单流水、日志流）1。 对比：RabbitMQ 默认不保证顺序，需通过单队列单消费者或复杂的分组逻辑实现；RocketMQ 虽支持队列内有序，但需依赖队列分配策略。 高性能与扩展性\nKafka 的分区设计允许水平扩展，通过增加分区数提升吞吐量，同时保持分区内顺序。例如，10个分区的 Topic 可支持10个消费者并行消费，每个消费者处理一个分区的有序消息128。 对比：RabbitMQ 单队列模式无法扩展，吞吐量受限；RocketMQ 虽支持多队列，但全局有序需牺牲队列数（单队列）47。 生产者控制灵活\n通过消息 Key 的哈希路由，Kafka 可将需顺序处理的消息（如相同订单ID）固定到同一分区，兼顾顺序性与并行能力28。 对比：RabbitMQ 需业务层实现分组逻辑；RocketMQ 类似但需显式配置 MessageQueueSelector47。 零拷贝与批量处理\nKafka 的零拷贝技术和批量发送机制减少 I/O 开销，在高吞吐场景下仍能保持低延迟的顺序消费129。 对比：RabbitMQ 的推送模型和内存优先策略在吞吐量上逊色1。 二、与其他消息队列的对比# 特性 Kafka RocketMQ RabbitMQ 顺序性保证 分区内有序，分区间无序 队列内有序，队列间无序 默认无序，需单队列单消费者 全局有序实现 单分区主题（牺牲吞吐）或 Key 分区 单队列主题或 Key 选择队列 单队列单消费者或消息分组 并行能力 高（多分区并行） 高（多队列并行） 低（单队列限制）40 适用场景 日志聚合、流处理、高吞吐局部有序 金融交易、分布式事务 低吞吐、简单顺序需求1 三、Kafka 的局限性# 全局有序成本高\n需将 Topic 设为单分区，严重限制吞吐量，仅适合低并发场景2847。 对比：RocketMQ 同样需单队列，但提供顺序消息 API 简化实现47。 消费者复杂度\n需手动管理 Offset 和分区分配，多线程消费时需避免破坏顺序（如使用阻塞队列排序）28。 对比：RabbitMQ 的简单队列模型更易实现单线程消费40。 延迟消息不支持\nKafka 原生不支持延迟消息，需业务层实现，而 RocketMQ 和 RabbitMQ 提供内置支持1。 四、总结与选型建议# 选择 Kafka：\n适合高吞吐、分区级顺序场景（如日志流、事件溯源），需利用分区和 Key 路由平衡顺序与性能129。 选择 RocketMQ：\n需兼顾顺序性、事务和高并发的金融场景（如订单状态变更）47。 选择 RabbitMQ：\n低吞吐、简单顺序需求（如任务队列），或需灵活路由的场景40。 Kafka 的顺序消费优势在于其分区机制与高吞吐设计的结合，而其他系统在特定场景（如事务、延迟）可能更适用。实际选型需综合业务需求和性能权衡1。\n"},{"id":33,"href":"/post/computer-science/llm/2025-03-30-9-kafka%E7%AA%81%E7%84%B6%E5%AE%95%E6%9C%BA%E4%BA%86%E6%B6%88%E6%81%AF%E4%BC%9A%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1/","title":"Kafka突然宕机了消息会不会丢失","section":"Computer Science","content":"Kafka突然宕机了消息会不会丢失# Kafka 在突然宕机时是否会导致消息丢失，取决于其副本机制、生产者配置、刷盘策略等多个因素。以下是具体分析：\n一、可能导致消息丢失的场景# 生产者未启用高可靠性配置\n若生产者设置 acks=0 或 acks=1，且消息未完全同步到副本时 Leader 宕机，消息会丢失： acks=0：生产者不等待 Broker 确认，直接发送下一条消息，宕机时丢失风险最高111。 acks=1：仅 Leader 写入本地日志即返回成功，若 Follower 未同步且 Leader 宕机，消息丢失1118。 Broker 刷盘策略为异步\nKafka 默认先将消息写入操作系统的 PageCache，异步刷盘。若服务器宕机，PageCache 中未刷盘的消息会丢失1118。 副本同步不足\n若 min.insync.replicas=1（默认），且仅 Leader 持有消息时宕机，即使设置 acks=all 也可能丢失消息1823。 二、避免消息丢失的配置# 生产者端\n设置 acks=all：确保所有 ISR（同步副本）均写入消息后才返回成功1118。 启用幂等性（enable.idempotence=true）和重试机制（retries\u0026gt;0），防止重复发送和网络抖动导致丢失143。 Broker 端\n提高 min.insync.replicas（如设置为 2），确保至少两个副本同步成功1823。 同步刷盘（log.flush.interval.messages=1），但会显著降低性能，仅适用于金融等高可靠性场景1118。 Topic 配置\n设置 replication.factor≥3，多副本冗余存储，即使一台 Broker 宕机，其他副本仍可提供服务23。 三、Kafka 的可靠性保障机制# ISR 机制 只有与 Leader 同步的副本（ISR）才能参与选举，避免数据不一致1823。 自动故障恢复 Leader 宕机后，Controller 会从 ISR 中选举新 Leader，继续提供服务23。 持久化设计 消息以追加日志（append-only）形式写入磁盘，即使消费者已消费，数据仍保留（可配置保留时间）。 四、总结# 可能丢失：若配置为 acks=0/1、异步刷盘或副本不足时，宕机会导致消息丢失。 不会丢失：若配置 acks=all、同步刷盘且 min.insync.replicas≥2，即使单台 Broker 宕机，消息仍可从其他副本恢复111823。 建议：根据业务重要性权衡性能与可靠性，金融级场景建议同步刷盘 + 多副本 + 事务支持（transactional.id）43。\n"},{"id":34,"href":"/post/life/life/","title":"life","section":"Life","content":" 什么是真正有效的驱蚊产品？ "},{"id":35,"href":"/post/computer-science/operating-system/linux/","title":"linux","section":"Operating System","content":"linux# resources# 鸟哥的Linux私房菜：基础学习篇 第四版 快乐的Linux命令行 telnet# # 确认某个ip, port 是否是联通的 # 在 centos 环境下，如果没有这个命令，需要通过 yum 先安装一下 yum install telnet telnet 192.168.1.100 8080ssh# tail# tail -f xxxxsed# sed命令详解 nmon# nmon 系统性能监控工具的使用 HomePage yazi# sxyazi/yazi 官方仓库 docs 【命令行必备】Yazi：最强文件管理器 TheCW "},{"id":36,"href":"/post/computer-science/operating-system/mac/","title":"mac","section":"Operating System","content":"mac# 如何像极客一样使用你的Mac？分享下我的Mac工作流 Setapp 车门焊死，你用的 app「平替」有哪些？ icloud# 文件APP不同步-iCloud云盘延迟同步解决方法 killall bird killall cloudd brew# 查看 brew 服务运行状态 brew services list mysql# 启动 brew services start mysql@8.0 使用命令行连接 mysql mysql -u root reference Macbook通过brew安装mysql8.0 mongodb# mongodb 安装 brew tap mongodb/brew brew update brew install mongodb-community@8.0 启动 mongodb brew services start mongodb-community@8.0 停止 mongodb brew services stop mongodb-community@8.0 mongodb 配置文件位置 vim /opt/homebrew/etc/mongod.conf 窗口管理# AltTab# 官网 相比起系统自带的 command + tab 它提供相同应用的窗口切换（例如浏览器打开了多个窗口，系统自带的是不能指定某一个窗口进行切换的） 可以设置UI的样式，用列表的方式来展示窗口，文字设置的小一点 Yabai# 用Mac不用它，你的Mac白买了 —— 平铺式窗口管理器yabai ffmpeg# 安装 brew install ffmpeg postgresql# Homebrew 安装 postgresql yazi# docs git# lazygit# jesseduffield/lazygit zen·工作环境搭建之git篇之Lazygit LazyGit 使用教程：简化 Git 操作的终端工具 yt-dlp# yt-dlp/yt-dlp 安装 brew install yt-dlp output-template yt-dlp -N 20 https://www.youtube.com/@xiaodaodalang --merge-output-format mp4 # 后台下载 nohup yt-dlp -N 20 https://www.youtube.com/@xiaodaodalang --merge-output-format mp4 \u0026amp; # 加上日期前缀 yt-dlp -N 20 -o \u0026#34;%(upload_date\u0026gt;%Y-%m-%d)s-%(title)s.%(ext)s\u0026#34; https://www.youtube.com/@xiaodaodalang --merge-output-format mp4player# Mac下最好的视频播放器 IINA orbstack# orbstack skechybar# skechybar install homerow# 模拟点击 Hammerspoon# 脚本工具 免费又强大的 macOS 自动化工具，Hammerspoon 可以让你少买很多 App HomePage arc# dia# folo# Folo: 你的一站式信息订阅平台（可同时订阅B站、油管、X等多个平台的博主） reference# 如何评价Orbstack（在Mac上低开销地运行容器和Linux）？ 登录虚拟机# orb -m ubuntu -u xiangliu disk# DaisyDisk Hidden space 隐藏空间 如何用命令弹出硬盘 查询硬盘挂载路径 df -h 取消挂载 diskutil unmount xxxxx transmit 文件传输工具 Raycast# 最强macOS生产力软件：Raycast AeroSpace# 我用AeroSpace替代了yabai+skhd Apple Music# 一日一技 | 如何用命令行将音乐转码到 iTunes Plus AAC battery# Powerflow：轻巧好用的 macOS 电源与充电状态监控神器 vladkens/macmon altente mac 上抓取应用的https的包# 在Mac上抓取应用的HTTPS流量，你需要使用网络分析工具，如Wireshark、Charles Proxy或MITMproxy。由于HTTPS加密了数据传输，直接抓包无法查看具体内容，因此通常需要设置一个代理服务器来进行中间人攻击（Man-in-the-Middle, MITM）来解密和检查HTTPS流量。\n以下是使用Charles Proxy作为例子来说明如何进行HTTPS流量的抓取：\n安装Charles Proxy:\n下载并安装Charles Proxy应用程序到你的Mac电脑上。 配置Charles SSL代理:\n打开Charles，前往Proxy -\u0026gt; SSL Proxying Settings。 在SSL Proxying标签中点击Enable SSL Proxying。 添加你想要监控的应用程序使用的域名端口对，例如对于大多数Web流量是443端口。 安装Charles的SSL证书:\n为了让Charles能够解密HTTPS流量，你需要信任它的SSL证书。 在Charles中前往Help -\u0026gt; SSL Proxying -\u0026gt; Install Charles Root Certificate。 按照提示完成证书安装，并确保系统信任此证书。 配置设备或应用以使用Charles代理:\n如果你想抓取的是Mac本地应用的流量，你需要配置该应用使用Charles作为HTTP/HTTPS代理。 对于某些应用程序，这可能需要更改系统的网络设置，或者在应用内部设置代理服务器地址为localhost或127.0.0.1，端口号通常是8888（默认的Charles监听端口）。 如果是移动设备上的应用，你需要设置设备的Wi-Fi连接使用手动HTTP代理指向运行Charles的Mac的局域网IP地址和端口。 开始抓包:\n现在你可以启动目标应用程序并开始与它交互，所有的HTTPS流量应该会通过Charles被截获，并且如果你正确设置了SSL代理，你应该能看到解密后的流量。 过滤和分析流量:\n使用Charles提供的过滤器和搜索功能来定位你感兴趣的特定请求和响应。 请注意，抓取和解密HTTPS流量可能涉及到隐私问题以及违反服务条款的风险。务必确保你有合法的权利去监视和分析这些流量。如果你是在测试自己的应用，确保遵循公司的政策和法律要求。如果你试图分析第三方应用的流量，请确保你有权这样做。\ncharles# Mac使用Charles进行HTTPS抓包 高颜值抓包工具Charles，实现Mac和IOS端抓取https请求 Configure Charles Root certificate on Mac 需要在keychains里信任证书 Charles Proxy for Mobile apps that use SSL Pinning 8 Ways to Bypass SSL Pinning in iOS tools# neofetch# mac 安装 brew install neofetch ubuntu 安装 sudo apt install neofetch mess# 我的Mac效率设置和软件（2024） 10款好用的Mac系统监控软件推荐 建模太阳磁场、运行本地大模型！为什么学生都爱用Macbook Air？ Lakr233/MobileTransfer MobileTransfer is an app operating on MobileBackup (idevicebackup2). It offers a way to backup and restore data on iOS devices. Lakr233/BBackupp Back up your iOS devices the way it\u0026rsquo;s meant to be done. questions# 2024-11-15 指纹识别及录入问题 M1 macbookPro 指纹不是识别及其慢就是识别不了，没有反应 电脑插电会有影响，不插电指纹功能是正常的 2025-02-08 Is there a way to download Screen Time data from iPhone or other Apple devices? Timing "},{"id":37,"href":"/post/computer-science/distributed-system/message-queue/message-queue/","title":"Message Queue","section":"Message Queue","content":"Message Queue# 消息队列如何选型？# 高吞吐量、大数据场景：Kafka 金融交易、高可靠场景：RocketMQ 支持事务消息和高可用性 易于使用、功能丰富：RabbitMQ 云原生、多租户场景：Pulsar 适合需要高扩展性和分层存储的场景 简单轻量、定制开发场景：NSQ 适合 Golang技术栈 "},{"id":38,"href":"/post/computer-science/database/mycat/","title":"mycat","section":"Database","content":"mycat# 那些年非常火的MyCAT是什么？ MyCat(看这一篇就够了） 应用场景 MySQL读写分离 分库分表 数据库路由器 整合数据源 当一个项目需要用到多种数据源如Oracle, MySQL, SQL Server, PostgreSQL时，可以利用Mycat进行整合，只需访问Mycat这一个数据源就行 逻辑库 schema 业务开发人员通常在实际应用中并不需要知道中间件的存在，只需要关注数据库，所以数据库中间件可以被当做一个或多个数据库集群构成的逻辑库 逻辑表 table 既然有逻辑库，就会有逻辑表。在分布式数据库中，对于应用来说，读写数据的表就是逻辑表。逻辑表可以分布在一个或多个分片库中，也可以不分片 Mycat的原理最重要的一个动词是拦截，它拦截用户发送过来的SQL语句 Mycat 如何实现高可用# 基于keepalived的MyCat高可用技术 Keepalived通过VRRP协议实现虚拟IP(VIP)的自动漂移，当主节点故障时，VIP会自动切换到备用节点，实现MyCat服务的高可用 HAProxy+Keepalived实现高可用与负载均衡 HAProxy实现MyCat多节点的负载均衡 Keepalived实现HAProxy自身的高可用 同时解决了MyCat的负载均衡器的高可用问题 "},{"id":39,"href":"/post/computer-science/database/mysql/","title":"mysql","section":"Database","content":"mysql# MySQL知识体系的三驾马车 MySQL是怎样跑起来的读书笔记 #13 binlog# redo log 和 binlog日志# redo log 重做日志 Redo log是InnoDB存储引擎特有的物理日志，主要保证事务的持久性和崩溃恢复能力(crash-safe)。当MySQL实例意外宕机时，InnoDB可以通过redo log恢复已提交但未写入数据文件的事务，确保数据不会丢失 Redo log采用\u0026quot;预写日志(WAL, Write-Ahead Logging)\u0026ldquo;机制：在数据页修改前，先记录日志到redo log buffer，再根据策略刷盘到redo log文件 刷盘策略 通过innodb_flush_log_at_trx_commit 参数控制 0：每秒刷盘一次，事务提交时不刷盘(可能丢失1秒数据) 1：每次事务提交都刷盘(默认，最安全) 2：写入OS缓存，不立即刷盘(仅MySQL崩溃安全，服务器宕机可能丢失数据) bin log 二进制日志 Binlog是MySQL Server层维护的逻辑日志，记录所有引起数据变更的SQL语句或行变更 主要用于 主从复制：从库通过重放主库的binlog实现数据同步 时间点恢复：结合全量备份和binlog可实现任意时间点的数据恢复 数据归档：记录数据库所有变更历史 三种格式 STATEMENT：记录SQL原文(默认)，可能因函数(如NOW())导致主从不一致 ROW：记录行数据变更(最安全)，但日志量大 MIXED：混合模式，根据语句自动选择格式 刷盘控制 通过 sync_binlog 参数控制 0：由系统决定刷盘时机 1：每次事务提交都刷盘(最安全) N：每N个事务刷盘一次(平衡性能与安全性) 两阶段提交：保证日志一致性 Prepare阶段：写入redo log并标记为prepare状态 写入binlog Commit阶段：将redo log标记为commit状态 读写分离# SpringBoot+Mybatis-Plus实现mysql读写分离方案 在 Spring Boot 中优雅地实现读写分离 【读写分离】SpringBoot整合多数据源实现读写分离（一） Reference# MySQL 架构原理 "},{"id":40,"href":"/post/tools/obsidian/","title":"obsidian","section":"Tools","content":" website 中文论坛 Web Clipper obsidian新版本的Base和weread插件一起打造你的专属图书馆 weread-obsidian-plugin "},{"id":41,"href":"/post/life/learning-others-log/","title":"other learning","section":"Life","content":"other learning# 经济学原理# 经济学原理 1 微观部分 什么是经济学 2 什么是经济学 3 像经济学家一样思考 1 4 像经济学家一样思考 2 5 经济相互依存性和贸易的好处 1 6 经济相互依存性和贸易的好处 2 7 供给与需求 1 8 供给与需求 2 9 供给与需求 3 10 弹性及其应用 1 11 弹性及其应用 2 12 弹性及其应用 3 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 2025-01-04# 清华韩秀云精品课（第一季，64集）# 清华韩秀云精品课（第一季，64集） ✅ 第一期：国外宏观经济形势# 1 美国央行大放水 2025-01-04 2 负债率的欧洲和日本 2025-01-04 3 政府发钱刺激经济 2025-01-04 ✅ 第二期：通胀来了，该如何配置资产# 4 通胀来了怎么办 2025-01-05 5 如何配置你的资产？2025-01-05 6 投资房产考虑什么？2025-01-05 7 投资黄金有必要吗？2025-01-06 8 炒股要注意什么？2025-01-06 ✅ 第三期：我国宏观政策走向# 9 政府救市与共同富裕 2025-01-06 10 2022年政策与行业机会 2025-01-07 ✅ 第四期：黄金# 11 黄金的前世今生 2025-01-07 12 美元和黄金挂钩与脱钩 2025-01-07 13 黄金的避险功能 2025-01-08 14 全世界的金库在哪里 2025-01-08 15 投资黄金该注意什么 2025-01-08 ✅ 第五期：石油# 16 石油的前世今生 2025-01-09 17 洛克菲勒与标准石油 2025-01-09 18 美国石油反垄断 2025-01-09 19 油价为何总在波动 2025-01-11 20 欧佩克的转变 2025-01-11 21 石油的用途 2025-01-11 22 油价为何是负的 2025-01-12 23 什么是石油期货的 2025-01-12 ✅ 第六期：楼市# 24 房价的成长史的 2025-01-12 25 楼市中看不见的手的 2025-01-13 26 市场决定资源配置的 2025-01-13 27 买房要选稀缺的 2025-01-13 28 买住宅怎么选 2025-01-15 29 买商铺和写字楼 2025-01-15 30 买房看机会成本 2025-01-15 31 买房要注意几件事 2025-01-16 32 买房还是租房好 2025-01-16 33 政府何为要调控楼市 2025-01-16 34 楼市调控还会继续吗？ 2025-01-17 35 房地产税会退出吗？ 2025-01-17 36 房地产税推出后，房价会下跌吗？ 2025-01-17 37 买房防止变成资产 2025-01-19 38 警惕房地产泡沫 2025-01-19 39 全球楼市涨跌互见 2025-01-19 第七期：股市# 40 炒股要懂经济学 2025-01-20 41 股票是如何诞生的？ 2025-01-20 42 东印度公司的第一张股票 2025-01-20 43 英美为什么发股票 2025-01-21 44 荷兰证券交易所的诞生 2025-01-21 45 纽约证券交易所的由来 2025-01-21 46 道琼斯指数的故事 2025-01-21 47 股票价格与股价指数 2025-01-21 48 股市的投资理念 2025-01-21 49 炒股应该注意什么？2025-02-09 50 参与股市的几种方式 2025-02-09 51 郁金香泡沫 2025-02-09 52 密西西比泡沫 2025-02-10 53 南海泡沫 2025-02-10 54 美国1929年股灾 2025-02-10 55 中国2007年股市暴涨 2025-02-11 56 中国2015年股灾 2025-02-11 57 教你判断股市趋势 2025-02-11 第八期：汇市# 58 汇率的基本知识 2025-02-13 59 人民币汇率 2025-02-13 60 美元的霸权 2025-02-13 61 欧元的诞生 2025-02-15 62 人民币国际化 2025-02-15 "},{"id":42,"href":"/post/life/podcast/","title":"podcast","section":"Life","content":"podcast# 小宇宙# 码农姐妹 经济新闻每日速递 纵横说 "},{"id":43,"href":"/post/life/politics/","title":"politics","section":"Life","content":"politics# 茶党# \u0026ldquo;茶党\u0026rdquo;（Tea Party）通常指的是美国的一个政治运动，这个运动始于2009年，主要由保守派共和党支持者组成，强调减少政府开支、降低税收、限制政府权力以及遵守美国宪法。茶党的名字来源于1773年的波士顿茶叶事件，这是一个反对英国殖民统治和高税收的历史事件，象征着对政府过度干预的抗议。\n茶党成员经常组织示威活动，尤其是在经济政策和财政责任方面。他们在2010年的中期选举中对美国政治产生了显著影响，支持了多位共和党候选人的当选，这些候选人随后在美国国会中代表了更加保守的立场。\n随着时间的发展，茶党的影响力有所减弱，但它仍然是美国政治中一个重要的保守力量。如果你有关于茶党的更具体问题，欢迎继续提问。\n茶党和共和党建制派的区别是什么# 茶党和共和党建制派是美国共和党内两个不同的政治派别，它们在政治立场、策略和目标上存在一些显著差异：\n政治立场：\n茶党：茶党通常被视为共和党内的激进派，强调极端保守的经济政策，比如大幅减税、削减政府开支、反对政府干预市场、减少债务和赤字。此外，茶党成员往往强烈反对奥巴马政府时期的医疗保健改革（即“奥巴马医改”）等政策。 共和党建制派：相比之下，建制派共和党人虽然也支持保守政策，但他们的立场相对温和，愿意与民主党合作以实现政治目标。建制派更倾向于维护共和党的传统利益，包括与大企业和精英阶层的关系。 策略和方法：\n茶党：茶党成员倾向于采取更为激进的策略，包括组织大规模抗议活动、支持极端保守的候选人、反对妥协。他们通常认为现有的政治体系已经腐败，需要彻底改革。 共和党建制派：建制派共和党人更倾向于通过传统政治渠道实现目标，如立法谈判、建立联盟和政治筹款。他们更注重保持共和党的整体稳定和长期利益。 目标：\n茶党：茶党的目标是推动共和党向更加保守的方向发展，减少政府规模和干预，保护个人自由和财产权。 共和党建制派：建制派的目标是保持共和党的主流地位，通过务实的政治策略赢得选举，维护共和党的长期利益和权力。 支持者基础：\n茶党：茶党的支持者通常是中下层中产阶级，他们对经济困境和政府过度干预感到不满，希望通过政治行动表达自己的诉求。 共和党建制派：建制派的支持者更多来自大企业和精英阶层，他们希望通过共和党的政策维护自身的经济利益。 总结来说，茶党和共和党建制派在政治立场、策略和目标上存在明显的差异，茶党更激进、更强调基层动员，而建制派则更温和、更注重政治稳定和长期利益。\n"},{"id":44,"href":"/post/computer-science/database/postgresql/","title":"postgresql","section":"Database","content":"postgresql# "},{"id":45,"href":"/post/computer-science/llm/2025-03-30-2-postgresql%E4%B8%AD%E5%88%86%E5%8C%BA%E9%94%AE%E4%BC%9A%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E5%90%97/","title":"postgresql中分区键会自动创建索引吗","section":"Computer Science","content":"postgresql中分区键会自动创建索引吗# 在PostgreSQL中，分区键不会自动创建索引。以下是详细说明和相关建议：\n1. 分区键与索引的关系# PostgreSQL的分区表机制本身不会自动为分区键创建索引。分区键仅用于数据路由（决定数据存储在哪个分区），但不会自动优化基于该列的查询性能1。 如果需要对分区键进行高效查询（尤其是范围查询或等值查询），必须手动创建索引。例如： -- 在分区表上显式创建分区键索引 CREATE INDEX idx_logdate ON log_history (logdate); -- 自动在所有子分区上创建相同索引从PostgreSQL 11开始，在父表上创建的索引会自动传播到所有子分区16。 2. 为什么需要手动创建索引？# 分区剪枝（Partition Pruning）依赖分区键：虽然查询时PostgreSQL会根据分区键过滤不需要的分区，但如果查询条件还包含其他非分区键列，仍需额外索引来加速126。 唯一约束的限制：若要在分区表上创建主键或唯一约束，必须包含分区键列，否则无法保证全局唯一性16。例如： -- 正确做法：包含分区键 ALTER TABLE sales ADD PRIMARY KEY (order_id, sale_date); -- sale_date是分区键 3. 自动索引传播的特性# 从PostgreSQL 11开始，在父表上创建的索引（包括唯一索引）会自动在所有子分区上创建相同结构的索引16。 但需注意： 并发创建索引（CONCURRENTLY）：无法直接在父表上并发创建索引，需逐个分区操作29。 索引类型一致性：所有分区的索引必须与父表索引类型相同（如B-tree、Hash等）。 4. 最佳实践建议# 显式为高频查询的分区键创建索引，即使它已用于分区剪枝126。 结合查询模式设计索引：若查询常使用分区键 + 其他列，可创建复合索引。 定期监控索引使用情况：删除未使用的索引以减少维护开销。 总结# PostgreSQL的分区键本身不会自动创建索引，需手动添加。合理设计分区键和索引（尤其是包含分区键的复合索引）能显著提升查询性能116。\n"},{"id":46,"href":"/post/computer-science/distributed-system/message-queue/rabbitmq/","title":"rabbitmq","section":"Message Queue","content":"rabbitmq# main# RabbitMQ RabbitMQ Tutorials Hello World Work Queues Distributing tasks among workers 一个生产者，多个消费者 Publish/Subscribe Sending messages to many consumers at once 一个消息，每个消费者都能接收到 Routing 多个消费者订阅同一个生产者的消息, 通过路由键，选择性消费 Topics 通过匹配的方式来选择性接收 RPC rabbitmq有哪几种模式# 简单模式（Simple Mode） 描述：一个生产者（Producer）和一个消费者（Consumer），消息直接发送到队列中，不需要交换机（Exchange）。 特点：消息只能被一个消费者处理，适合简单的点对点通信。 应用场景：简单的任务队列，如日志收集。 工作队列模式（Work Queue Mode） 描述：一个生产者和多个消费者，消息分发到多个消费者，但每个消息只能被一个消费者处理。 特点：默认采用轮询机制分发消息，支持手动确认（ack）以确保消息处理成功。 应用场景：任务分发，如多个消费者处理不同的任务。 发布/订阅模式（Publish/Subscribe Mode） 描述：生产者将消息发送到交换机（Exchange），交换机将消息广播到所有绑定的队列，每个队列可以有多个消费者。 特点：使用 fanout 类型的交换机，消息会被所有消费者接收。 应用场景：消息广播，如通知多个系统或用户。 路由模式（Routing Mode） 描述：生产者将消息发送到交换机，交换机根据路由键（Routing Key）将消息分发到匹配的队列。 特点：使用 direct 类型的交换机，支持精确的路由规则。 应用场景：根据特定规则分发消息，如按日志级别分类。 主题模式（Topics Mode） 描述：类似于路由模式，但支持更灵活的路由规则，使用通配符（如 * 和 #）匹配路由键。 特点：使用 topic 类型的交换机，支持复杂的路由逻辑。 应用场景：需要灵活匹配和过滤消息的场景，如多维度消息分发。 RPC 模式（Remote Procedure Call Mode） 描述：生产者发送消息后，等待消费者处理并返回结果，类似于远程过程调用。 特点：通过回调队列实现请求和响应的匹配。 应用场景：需要同步返回结果的场景，如远程调用。 发布确认模式（Publisher Confirms Mode） 描述：生产者在发送消息后，等待 RabbitMQ 的确认，确保消息被成功接收。 特点：提高消息的可靠性，避免消息丢失。 应用场景：需要高可靠性的消息传递，如金融交易。 Header 模式（Headers Mode） 描述：根据消息的头部信息（Headers）进行路由，而不是依赖路由键。 特点：使用 headers 类型的交换机，支持复杂的匹配规则。 应用场景：需要根据消息属性进行路由的场景。 rabbitmq有哪些类型的路由键# 在 RabbitMQ 中，路由键（Routing Key） 是用于决定消息如何被路由到队列的关键字。路由键的具体使用方式取决于 交换机类型，不同类型的交换机对路由键的处理方式不同。以下是 RabbitMQ 中常见的交换机类型及其对应的路由键使用方式：\n直连交换机（Direct Exchange） 路由键规则：路由键必须与 绑定键（Binding Key） 完全匹配。 特点：消息会被精确地路由到绑定键与路由键完全匹配的队列。 示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。 主题交换机（Topic Exchange） 路由键规则：路由键支持通配符匹配。 * 匹配一个单词（如 quick.orange.rabbit 匹配 quick.orange.*）。 # 匹配零个或多个单词（如 lazy.# 匹配 lazy.orange.rabbit 和 lazy.dog）。 特点：支持灵活的路由规则，适用于复杂的消息分发场景。 示例：路由键 quick.orange.rabbit 会匹配绑定键 quick.orange.* 和 *.rabbit 的队列。 扇出交换机（Fanout Exchange） 路由键规则：忽略路由键。 特点：将消息广播到所有绑定到该交换机的队列，路由键对消息路由没有影响。 示例：无论路由键是什么，消息都会被发送到所有绑定队列。 头交换机（Headers Exchange） 路由键规则：不使用路由键，而是根据消息的 头部属性（Headers） 进行匹配。 特点：通过键值对匹配消息和队列，适用于需要基于消息属性进行路由的场景。 示例：如果队列绑定规则要求消息头部包含 type=error，则只有满足该条件的消息会被路由到该队列。 总结 直连交换机：完全匹配路由键和绑定键。 主题交换机：支持通配符匹配，灵活性高。 扇出交换机：忽略路由键，广播消息。 头交换机：基于消息头部属性匹配，不使用路由键。 核心组件# Broker（服务器） 负责接收和分发消息的应用，RabbitMQ Server 就是 Message Broker。 Virtual Host（虚拟主机） 用于逻辑隔离，类似于网络中的 namespace 概念。多个用户可以共享同一个 RabbitMQ Server，但每个用户在自己的 vhost 中创建 exchange、queue 等。 Connection（连接） 生产者（Producer）和消费者（Consumer）与 Broker 之间的 TCP 连接。 Channel（信道） 在 Connection 内部建立的逻辑连接，用于执行 AMQP 操作。每个线程通常对应一个 Channel，以减少 TCP 连接的开销。 Exchange（交换机） 消息到达 Broker 的第一站，根据分发规则将消息路由到队列。常见的类型包括 direct、topic 和 fanout。 Queue（队列） 消息最终被送到队列中，等待消费者取走。 Binding（绑定） 交换机和队列之间的虚拟连接，binding 中可以包含 routing key，用于消息的分发依据。 Message（消息） 由生产者发送并通过交换机路由到队列的数据单元，通常由头部（元数据）和正文（负载数据）组成。 Producer（生产者） 创建并发布消息的应用程序，负责将消息发送到 RabbitMQ。 Consumer（消费者） 从队列中获取并处理消息的应用程序。 AMQP（高级消息队列协议） RabbitMQ 使用的通信协议，确保不同系统间的互操作性。 这些组件共同构成了 RabbitMQ 的核心架构，使其能够高效地处理消息传递任务。\nRabbit可以实现高吞吐量吗# 是的，RabbitMQ 可以实现高吞吐量，但其性能表现取决于具体的配置和使用场景。以下是一些关键点和优化策略，可以帮助 RabbitMQ 实现更高的吞吐量： RabbitMQ 的吞吐量表现 RabbitMQ 的吞吐量通常在 万级到十万级消息每秒，虽然相比 Kafka 和 RocketMQ（十万级到百万级）稍低，但在大多数场景下已经足够高效。 其性能受多种因素影响，包括硬件配置、网络带宽、消息大小、持久化设置等。 优化 RabbitMQ 吞吐量的策略 使用 Direct Exchange** Direct Exchange 的吞吐率比 Topic Exchange 快约 2 倍，因为它不需要复杂的路由匹配。 2. 自动确认（Auto ACK） 自动确认比手动确认的吞吐率快约 2 倍，因为减少了确认操作的开销。但自动确认可能会丢失消息，需根据业务需求权衡。 3. 批量消费与确认 在高吞吐量场景下，建议使用 channel.Qos 设置预取数量（prefetchCount），结合缓冲区处理和批量确认（channel.Ack 的 multiple 参数），以减少单条确认的开销。 4. 惰性队列（Lazy Queue） 惰性队列将消息直接存储到磁盘，避免了内存过载和间歇性的 page-out 操作，适合处理大量消息堆积的场景。 5. 集群和镜像模式 镜像模式（Mirror Mode）可以保证数据的高可靠性，同时通过多节点分担负载提高吞吐量。 6. 优化硬件和网络 使用高性能的硬件（如 SSD）和充足的网络带宽，可以显著提升 RabbitMQ 的吞吐量。 7. 消息大小和持久化 较小的消息大小和合理的持久化设置（如仅在必要时启用）可以提高吞吐量。 RabbitMQ 的吞吐量虽然不及 Kafka 和 RocketMQ，但在 低延迟 和 灵活性 方面表现更优，适合需要复杂路由和消息顺序性保证的场景。 4. 实际应用建议# 如果业务场景对吞吐量要求极高（如日志收集、大数据处理），可以考虑 Kafka 或 RocketMQ。 如果业务场景更注重低延迟、灵活路由和易用性，RabbitMQ 是一个不错的选择，并通过上述优化策略提升其吞吐量。 集群模式# 主备模式（Warren 模式） 描述：主备模式是一种简单的高可用方案，通常用于并发量和数据量不高的场景。主节点提供读写服务，而备节点仅作为备份，不提供读写服务。当主节点宕机时，备节点会自动切换为主节点，继续提供服务。 特点： - 主节点提供读写，备节点仅备份。 - 配置简单，适合中小规模应用。 应用场景：中小型系统，对高可用性要求不高的场景。 镜像模式（Mirror 模式） 描述：镜像模式是 RabbitMQ 最常用的集群模式，确保数据的高可靠性。在这种模式下，队列中的消息会在多个节点之间同步，即使某个节点宕机，数据也不会丢失。 特点： - 消息和元数据在所有节点间同步。 - 通常需要 2-3 个节点来实现数据同步，保证 100% 数据不丢失。 - 适合对数据可靠性要求高的场景。 应用场景：互联网大厂、金融系统等对数据可靠性要求极高的场景。 多活模式（Federation 模式） 描述：多活模式用于实现异地数据复制，适合跨地域的 RabbitMQ 集群。通过 Federation 插件，可以在不同数据中心之间复制消息，实现高可用性和负载均衡。 特点： - 支持跨地域的消息复制。 - 配置复杂，但可以实现高可用性和负载均衡。 - 适合需要异地灾备和多中心部署的场景。 应用场景：跨地域的分布式系统，如全球化的电商平台。 远程模式（Shovel 模式） 描述：远程模式用于将消息从本地集群复制到远程集群，适合处理高负载场景。通过 Shovel 插件，可以将部分消息路由到远程集群进行处理。 特点： - 支持异步消息复制。 - 配置较为复杂，适合处理高负载场景。 - 目前已较少使用，多被多活模式替代。 应用场景：早期的高负载处理场景。 默认集群模式（普通集群模式） 描述：默认集群模式下，RabbitMQ 仅同步元数据（如队列、交换机、绑定关系等），而不会同步队列中的消息内容。消息仅存储在创建队列的节点上，其他节点只保存元数据和指向该节点的指针。 特点： - 消息不复制，节省存储空间。 - 节点故障时，消息可能丢失。 - 适合对消息可靠性要求不高的场景。 应用场景：测试环境或对消息可靠性要求较低的场景。 RabbitMQ的集群模式在实际项目中如何选型# 中小规模系统，对高可用性要求不高 推荐模式：主备模式（Warren 模式） 特点： - 配置简单，易于维护。 - 主节点提供读写服务，备节点作为备份。 - 当主节点宕机时，备节点自动切换为主节点。 适用场景： - 中小型系统，消息量不大。 - 对高可用性要求不高，允许短暂的服务中断。 对数据可靠性要求高，需要消息不丢失 推荐模式：镜像模式（Mirror 模式） 特点： - 消息和元数据在所有节点间同步，保证数据不丢失。 - 通常需要 2-3 个节点来实现数据同步。 - 适合对数据可靠性要求极高的场景。 适用场景： - 金融、支付等对数据可靠性要求高的系统。 - 互联网大厂的核心业务系统。 跨地域部署，需要异地灾备和多中心高可用 推荐模式：多活模式（Federation 模式） 特点： - 支持跨地域的消息复制，实现异地灾备。 - 配置复杂，但可以实现高可用性和负载均衡。 - 适合需要异地灾备和多中心部署的场景。 适用场景： - 全球化的电商平台或分布式系统。 - 需要跨地域高可用的业务。 高负载场景，需要分担消息处理压力 推荐模式：远程模式（Shovel 模式） 特点： - 将部分消息路由到远程集群进行处理，分担负载。 - 配置较为复杂，目前已较少使用，多被多活模式替代。 适用场景： - 早期的高负载处理场景。 - 需要分担消息处理压力的系统。 测试环境或对消息可靠性要求较低 推荐模式：默认集群模式（普通集群模式） 特点： - 仅同步元数据（如队列、交换机、绑定关系等），消息不复制。 - 节点故障时，消息可能丢失。 - 配置简单，适合测试环境或对消息可靠性要求较低的场景。 适用场景： 开发测试环境。 对消息可靠性要求较低的业务。 需要灵活的路由和消息分发 推荐模式：镜像模式 + 多活模式 特点： - 结合镜像模式的高可靠性和多活模式的跨地域能力。 - 实现灵活的路由和消息分发，同时保证数据可靠性。 适用场景： - 复杂的分布式系统，需要灵活的消息路由和高可靠性。 需要高吞吐量和低延迟 推荐模式：镜像模式 + 优化配置 特点： - 通过镜像模式保证数据可靠性，同时优化配置（如 Direct Exchange、自动确认、批量处理等）提升吞吐量。 - 适合对吞吐量和延迟要求较高的场景。 适用场景： - 高并发的消息处理系统，如实时交易系统。 rabbitmq可以像kafka一样把消费者平均分配到所有broker上吗# RabbitMQ 和 Kafka 在消费者分配机制上有显著差异，RabbitMQ 并不能像 Kafka 一样将消费者平均分配到所有 Broker 上。以下是两者的具体对比： RabbitMQ 的消费者分配机制 在 RabbitMQ 中，消费者是直接绑定到队列的，而队列是创建在特定的 Broker 上的。因此，消费者的分配取决于队列的分布： 队列分布：一个队列只能存在于一个 Broker 上，即使是在集群模式下，队列也不会自动分布在多个 Broker 上。 消费者分配：消费者连接到队列所在的 Broker，因此消费者的分布取决于队列的位置。如果一个队列在一个 Broker 上，那么所有消费该队列的消费者都会连接到这个 Broker。 镜像队列：为了提高可用性，RabbitMQ 支持镜像队列（Mirrored Queue），将队列复制到多个 Broker 上。但这只是数据的冗余备份，消费者的连接仍然集中在主队列所在的 Broker 上。 Kafka 的消费者分配机制 在 Kafka 中，消费者是基于分区（Partition）进行分配的，而分区可以分布在多个 Broker 上： 分区分布：一个主题（Topic）可以分为多个分区，每个分区可以分布在不同的 Broker 上。 消费者分配：消费者组中的消费者会分配到不同的分区，从而实现负载均衡。Kafka 会自动将分区均匀地分配给消费者组中的消费者。 动态扩展：Kafka 支持动态增加分区和消费者，从而实现横向扩展。 RabbitMQ 与 Kafka 的对比\n特性 RabbitMQ Kafka 消费者分配 消费者绑定到队列，队列位于单个 Broker 上 消费者分配到分区，分区分布在多个 Broker 上 负载均衡 需要手动配置镜像队列或多队列实现负载均衡 自动将分区均匀分配给消费者组 扩展性 扩展性有限，依赖于队列的分布 支持动态增加分区和消费者，扩展性强 适用场景 适合低延迟、复杂路由的场景 适合高吞吐量、流数据处理的场景 如何实现 RabbitMQ 的负载均衡 虽然 RabbitMQ 不能像 Kafka 那样自动将消费者分配到所有 Broker 上，但可以通过以下方式实现负载均衡： 多队列策略：为同一个主题创建多个队列，并将消费者分布到不同的队列上。 镜像队列：使用镜像队列提高可用性，但消费者的连接仍然集中在主队列所在的 Broker 上。 客户端负载均衡：在客户端实现逻辑，将消费者均匀地分配到不同的 Broker 上。 rabbitmq 为什么不能保证消息的顺序性# 多个消费者并发消费同一个队列 问题：当多个消费者同时消费同一个队列时，RabbitMQ 会将消息分发给不同的消费者。由于每个消费者的处理速度不同，可能会导致消息的消费顺序与发送顺序不一致。 示例：如果消息 A、B、C 按顺序进入队列，消费者 1 拿到消息 A，消费者 2 拿到消息 B，但消费者 2 处理速度更快，导致消息 B 先于消息 A 被处理。 消费者内部多线程处理 问题：即使一个队列只有一个消费者，如果消费者内部使用多线程处理消息，不同线程的执行顺序也可能导致消息的消费顺序错乱。 示例：消费者内部将消息 A 和 B 分配给不同的线程处理，线程 2 先处理消息 B，线程 1 后处理消息 A，导致顺序错乱。 网络延迟或重试机制 问题：消息在传输过程中可能因网络延迟或消费者处理失败而触发重试机制，导致消息的到达顺序与发送顺序不一致。 复杂的交换器和队列配置 问题：使用复杂的交换器配置（如 Topic Exchange）可能会将消息路由到不同的队列中，这些队列的消费顺序无法保证。 RabbitMQ 的设计机制 RabbitMQ 的设计目标是高吞吐量和高可用性，而不是严格的消息顺序性。它通过并发消费和负载均衡来提高性能，但这也会导致消息顺序的不可控。 如果需要保证消息顺序性，可以通过以下方式解决： 单一消费者模式：一个队列只绑定一个消费者。 消息分区策略：将相关消息路由到同一个队列，确保顺序性。 消费者内部排序：在消费者端使用内存队列对消息进行排序。 如果只有一个生产者一个消费者，消费者是单线程的，能保证消息的顺序性吗# 是的，如果只有一个生产者、一个消费者，并且消费者是单线程的，RabbitMQ 可以保证消息的顺序性。以下是具体原因和机制： 生产者发送顺序 生产者将消息顺序发送到 RabbitMQ 的队列中。RabbitMQ 的队列是先进先出（FIFO）的，因此消息会按照发送顺序存储在队列中。 消费者单线程消费 消费者是单线程的，意味着它一次只处理一条消息，处理完一条消息后才会从队列中取出下一条消息。这种方式确保了消息按照队列中的顺序被消费。 队列的 FIFO 特性 RabbitMQ 的队列本身是 FIFO 数据结构，只要消费者是单线程的，消息就会按照进入队列的顺序被处理。 注意事项 网络延迟：虽然生产者和消费者是单线程的，但在极端情况下（如网络延迟或重试机制），可能会导致消息到达队列的顺序与发送顺序不一致。这种情况非常罕见，但在高要求场景下仍需注意。 消费者内部逻辑：如果消费者在处理消息时引入了异步操作（如多线程或异步回调），可能会破坏消息的顺序性。 "},{"id":47,"href":"/post/computer-science/operating-system/raspberrypi/","title":"raspberry pi","section":"Operating System","content":"raspberry pi# reference# 树莓派文档 clash# reference 为什么全局代理后， CMD 依然 Ping 不通 Google？ 树莓派 Clash 透明代理(TProxy) 在 Raspberry Pi 上运行 Clash 作为透明代理 解决 Clash Meta 中TUN模式无法上网的问题：正确配置DNS设置 解决 树莓派ping: baidu.com: 域名解析暂时失败 树莓派安装clash，实现科学上网 在 Raspberry Pi 上运行 Clash 作为透明代理 http://yacd.haishan.me yt-dlp# 使用这个工具，可以下载 youtube 视频\n后台下载命令 nohup yt-dlp -N 20 {{video_url}} --merge-output-format mp4 \u0026amp; 实时查看后台下载进度 tail -f nohup.out 停止下载 查询后台进程号 ps -aux | grep yt-dlp 杀死进程 kill -9 {{进程号}} tomcat# 树莓派安装Tomcat wget https://archive.apache.org/dist/tomcat/tomcat-9/v9.0.36/bin/apache-tomcat-9.0.36.tar.gz tar zxvf apache-tomcat-9.0.36.tar.gz cd ~/apache-tomcat-9.0.36/bin sudo ./startup.shdd# dd 命令是一个非常强大的工具，可以用来复制和转换文件。通过创建一个临时文件并测量其读写速度，可以测试存储介质的性能。\n打开终端：您可以通过SSH连接到您的树莓派，或者直接在树莓派上打开终端。\n测试写入速度：\n创建一个 1GB 的临时文件，并测量写入速度： sudo dd if=/dev/zero of=testfile bs=1M count=1024 conv=fdatasync 解释： if=/dev/zero：从 /dev/zero 读取数据（这是一个无限的零流）。 of=testfile：将数据写入名为 testfile 的文件。 bs=1M：每次读写 1MB 的数据块。 count=1024：写入 1024 个 1MB 的数据块，总共 1GB。 conv=fdatasync：确保所有数据都写入磁盘后再结束命令。 测试读取速度：\n读取刚刚创建的文件，并测量读取速度： sudo dd if=testfile of=/dev/null bs=1M 解释： if=testfile：从 testfile 文件读取数据。 of=/dev/null：将数据写入 /dev/null（丢弃数据）。 bs=1M：每次读取 1MB 的数据块。 删除测试文件：\n测试完成后，删除 testfile 以释放空间： sudo rm testfile iwlist# sudo iwlist wlan0 scan sudo iwlist wlan0 scan | grep SSID定时任务# 查看当前的定时任务 crontab -l 编辑定时任务 crontab -e 外网登录# 如何从外网登录访问树莓派Raspberry Pi holer Wisdom wisdom-projects/holer 方式一：使用公开的holer映射或者开通holer服务，通过holer客户端软件经holer服务器实现公网访问 方式二：使用holer服务端软件搭建holer服务，通过holer客户端软件经自己服务器实现公网访问， Holer端口映射软件使用教程 cpolar# cpolar 3.3 将隧道配置为后台服务 Cpolar快速入门教程：树莓派系列 后台管理页面 http://localhost:9200 zsh: corrupt history file /home/me/.zsh_history# 怎样修复zsh历史记录错误：zsh: corrupt history file /home/me/.zsh_history cd ~ mv .zsh_history .zsh_history_bad strings -eS .zsh_history_bad \u0026gt; .zsh_history fc -R .zsh_history"},{"id":48,"href":"/post/computer-science/redis/","title":"redis","section":"Computer Science","content":"redis# redis基本数据类型, 使用场景# 5大基本类型 String 字符串 常用场景： 缓存：存储用户信息、配置信息等。 计数器：如文章阅读量、点赞数等。 分布式锁：通过 SETNX 命令实现。 Hash 哈希 常用场景： 存储用户信息：如用户 ID 作为 key，用户属性（姓名、年龄等）作为 field-value 对。 存储商品信息：如商品 ID 作为 key，商品详情（价格、库存等）作为 field-value 对。 List 列表 常用场景： 消息队列：通过 LPUSH 和 RPOP 实现简单的消息队列。 最新消息列表：如微博的时间线、朋友圈动态等。 Set 集合 常用场景： 标签系统：如文章标签、用户兴趣标签等。 去重：如统计独立 IP 访问量。 Sorted Set 有序集合 常用场景： 排行榜：如游戏积分排行榜、热搜榜等。 延迟队列：通过分数存储时间戳，按时间顺序处理任务。 什么是缓存击穿 缓存穿透 缓存雪崩# 缓存击穿 Cache Breakdown 热点数据过期的同时有大量的请求访问该热点数据，导致数据库负载突然增加 解决办法 使用互斥锁，同时只能一个线程读取数据库中的数据后保存到缓存中，其他线程等待读取缓存中的值 缓存穿透 Cache Penetration 查询的数据在缓存和数据库中都不存在 解决办法 缓存空值 布隆过滤器 参数校验 简单动态字符串# 链表# 字典# 跳跃表# 整数集合# 压缩列表# 对象# 数据库# redis 集群# redis 的集群模式有哪些？# 主从模式 主节点负责写操作，从节点负责读操作，实现读写分离 哨兵模式 在主从复制的基础上，增加了自动故障转移功能。哨兵节点监控主从节点的状态，当主节点故障时，自动选举从节点为主节点 cluster模式 通过数据分片（Sharding）实现分布式存储，支持自动故障转移和负载均衡 redis 数据如何进行分片？# 槽位计算：通过 CRC16(key) % 16384 计算键（key）所属的槽位 槽位分配：每个节点负责维护一部分槽位，槽位分布均匀，支持动态扩容和缩容 数据路由：客户端请求时，先计算 key 的槽位，然后根据槽位找到对应的节点 分片的实现方案有哪些？# 客户端分片 Redis-rb Predis 代理分片（客户端与Redis节点之间增加代理层 Twemproxy） 增加了系统的复杂性和延迟 主从# Reference 《Redis设计与实现》 第15章 复制 在Redis中，用户可以通过执行SLAVEOF命令或者设置slaveof选项，让一个服务器去复制（replicate）另一个服务器，我们称呼被复制的服务器为主服务器（master），而对主服务器进行复制的服务器则被称为从服务器（slave） 进行复制中的主从服务器双方的数据库将保存相同的数据，概念上将这种现象称作“数据库状态一致”，或者简称“一致”。 旧版复制功能的实现# 同步 sync 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 步骤 1）从服务器向主服务器发送SYNC命令。 2）收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令。 3）当主服务器的BGSAVE命令执行完毕时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。 4）主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。 命令传播 command propagate 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器的数据库重新回到一致状态 旧版复制功能的缺陷# 在Redis中，从服务器对主服务器的复制可以分为以下两种情况 初次复制：从服务器以前没有复制过任何主服务器，或者从服务器当前要复制的主服务器和上一次复制的主服务器不同 对于初次复制来说，旧版复制功能能够很好地完成任务 断线后重复制：处于命令传播阶段的主从服务器因为网络原因而中断了复制，但从服务器通过自动重连接重新连上了主服务器，并继续复制主服务器 对于断线后重复制来说，旧版复制功能虽然也能让主从服务器重新回到一致状态，但效率却非常低 SYNC命令是一个非常耗费资源的操作 1）主服务器需要执行BGSAVE命令来生成RDB文件，这个生成操作会耗费主服务器大量的CPU、内存和磁盘I/O资源。 2）主服务器需要将自己生成的RDB文件发送给从服务器，这个发送操作会耗费主从服务器大量的网络资源（带宽和流量），并对主服务器响应命令请求的时间产生影响。 3）接收到RDB文件的从服务器需要载入主服务器发来的RDB文件，并且在载入期间，从服务器会因为阻塞而没办法处理命令请求。 因为SYNC命令是一个如此耗费资源的操作，所以Redis有必要保证在真正有需要时才执行SYNC命令。 新版复制功能的实现# 为了解决旧版复制功能在处理断线重复制情况时的低效问题，Redis从2.8版本开始，使用PSYNC命令代替SYNC命令来执行复制时的同步操作 PSYNC命令具有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式 其中完整重同步用于处理初次复制情况：完整重同步的执行步骤和SYNC命令的执行步骤基本一样，它们都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步 而部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态 部分重同步的实现# 部分重同步功能由以下三个部分构成： 主服务器的复制偏移量（replication offset）和从服务器的复制偏移量 执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量 主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量的值加上N 从服务器每次收到主服务器传播来的N个字节的数据时，就将自己的复制偏移量的值加上N 通过对比主从服务器的复制偏移量，程序可以很容易地知道主从服务器是否处于一致状态 如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同的 相反，如果主从服务器两者的偏移量并不相同，那么说明主从服务器并未处于一致状态 主服务器的复制积压缓冲区（replication backlog） 复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB 和普通先进先出队列随着元素的增加和减少而动态调整长度不同，固定长度先进先出队列的长度是固定的，当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列 当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面 主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量 当从服务器重新连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作 如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作 相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作 根据需要调整复制积压缓冲区的大小 Redis为复制积压缓冲区设置的默认大小为1MB，如果主服务器需要执行大量写命令，又或者主从服务器断线后重连接所需的时间比较长，那么这个大小也许并不合适 如果复制积压缓冲区的大小设置得不恰当，那么PSYNC命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要 如果复制积压缓冲区的大小设置得不恰当，那么PSYNC命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要 其中second为从服务器断线后重新连接上主服务器所需的平均时间（以秒计算） 而write_size_per_second则是主服务器平均每秒产生的写命令数据量（协议格式的写命令的长度总和） 例如，如果主服务器平均每秒产生1 MB的写数据，而从服务器断线之后平均要5秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于5MB。 为了安全起见，可以将复制积压缓冲区的大小设为2secondwrite_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理 服务器的运行ID（run ID） 每个Redis服务器，不论主服务器还是从服务，都会有自己的运行ID 运行ID在服务器启动时自动生成，由40个随机的十六进制字符组成 当从服务器对主服务器进行初次复制时，主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来 当从服务器断线并重新连上一个主服务器时，从服务器将向当前连接的主服务器发送之前保存的运行ID 如果从服务器保存的运行ID和当前连接的主服务器的运行ID相同，那么说明从服务器断线之前复制的就是当前连接的这个主服务器，主服务器可以继续尝试执行部分重同步操作 相反地，如果从服务器保存的运行ID和当前连接的主服务器的运行ID并不相同，那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器，主服务器将对从服务器执行完整重同步操作 PSYNC 命令的实现# 复制的实现# 心跳检测# Sentinel# Sentinel（哨岗、哨兵）是Redis的高可用性（high availability）解决方案：由一个或多个Sentinel实例（instance）组成的Sentinel系统（system）可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求 集群# Redis集群是Redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供复制和故障转移功能 节点# 一个Redis集群通常由多个节点（node）组成，在刚开始的时候，每个节点都是相互独立的，它们都处于一个只包含自己的集群当中，要组建一个真正可工作的集群，我们必须将各个独立的节点连接起来，构成一个包含多个节点的集群 槽指派# Redis集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽（slot），数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点可以处理0个或最多16384个槽 当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok）；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态（fail） 在集群中执行命令# 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己 如果键所在的槽正好就指派给了当前节点，那么节点直接执行这个命令 如果键所在的槽并没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令 重新分片# Redis集群的重新分片操作可以将任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点），并且相关槽所属的键值对也会从源节点被移动到目标节点。 重新分片操作可以在线（online）进行，在重新分片的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求 ASK错误# 复制与故障转移# Redis集群中的节点分为主节点（master）和从节点（slave），其中主节点用于处理槽，而从节点则用于复制某个主节点，并在被复制的主节点下线时，代替下线主节点继续处理命令请求 消息# 集群中的各个节点通过发送和接收消息（message）来进行通信，我们称发送消息的节点为发送者（sender），接收消息的节点为接收者（receiver） 节点发送的消息主要有以下五种 MEET PING PONG FAIL PUBLISH "},{"id":49,"href":"/post/computer-science/security/","title":"security","section":"Computer Science","content":"security# man-in-the-middle attack 中间人攻击# SSL Pinning is a technique we use on the client side to avoid a man-in-the-middle attack by validating the server certificates. The developers embed (or pin) a list of trustful certificates in the client application during development and use them to compare against the server certificates during runtime.\nIf there is a mismatch between the server and the local copy of certificates, the connection will be disrupted, and no further user data will be sent to that server. This enforcement ensures that user devices communicate only with dedicated, trustful servers.\nSSL Pinning prevents a man-in-the-middle attack, which means an attacker can not intercept the traffic and modify the data. If an attacker can not intercept the traffic, the application automatically prevents many server-side vulnerabilities. Because an attacker can not perform API-level test cases, implementing SSL is very important.\nSSL pinning# reference Charles Proxy for Mobile apps that use SSL Pinning 8 Ways to Bypass SSL Pinning in iOS "},{"id":50,"href":"/post/computer-science/distributed-system/sentinel/","title":"Sentinel","section":"Distributed System","content":"Sentinel# 性能压测# “引入Sentinel带来的性能损耗非常小，只有在业务单机量级超过25万QPS的时候才会有一些显著的影响（5%～10%左右），单机QPS不太大的时候损耗几乎可以忽略不计。”这是Sentinel官方文档中的一句话，本节将通过基准测试验证这句话。 SPI在Sentinel中的应用# SPI机制在阿里巴巴集团开源的项目中被广泛使用，如Dubbo，RocketMQ与Sentinel都使用了SPI机制 除了Dubbo外，RocketMQ与Sentinel使用的都是Java提供的SPI机制 Dubbo使用的是自实现的一套SPI——Dubbo SPI，与Java SPI的配置方式不同，Dubbo SPI使用Key-Value方式配置，目的是实现自适应扩展机制 Java SPI实现原理与适用场景 SPI（Service Provider Interface，服务提供者接口）是一种服务发现机制，是Java的一个内置标准，可以保障不同的开发者实现某个特定的服务 SPI的本质是将接口实现类的全限定名配置在文件中，由服务加载器读取配置文件、加载实现类并创建实例。使用SPI机制能够实现运行时从配置文件中读取接口的实现类并创建实例 ServiceLoader.load() SPI机制的适用场景 适合适用策略模式、责任链模式的场景都可以使用SPI机制 Java SPI在Sentinel中的应用 我们可以直接替换Sentinel提供的默认SlotChainBuilder，使用自定义的SlotChainBuilder为资源构造自己的ProcessorSlotChain，以实现修改ProcessorSlot排列顺序、增加或移除ProcessorSlot的功能 责任链模式在Sentinel中的应用# 我们将Sentinel提供的所有ProcessorSlot分为两类 一类是负责完成资源指标数据统计的ProcessorSlot 一类是实现限流、熔断等流量控制功能的ProcessorSlot Sentinel使用责任链模式将注册的所有ProcessorSlot按照一定的顺序串成一个单向链表 实现资源指标数据统计的ProcessorSlot必须在实现流量控制功能的ProcessorSlot的前面，原因很简单，限流、熔断降级等都需要依赖资源的实时指标数据做判断 Reference# 实战Alibaba Sentinel：深度解析微服务高并发流量治理 "},{"id":51,"href":"/post/computer-science/database/shardingsphere/","title":"shardingsphere","section":"Database","content":"shardingsphere# 官网 概览# 什么是 shardingsphere# Apache ShardingSphere 是一款分布式的数据库生态系统， 可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力对原有数据库进行增强 Apache ShardingSphere 设计哲学为 Database Plus，旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。 它站在数据库的上层视角，关注它们之间的协作多于数据库自身 ShardingSphere-JDBC ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务 ShardingSphere-Proxy ShardingSphere-Proxy 定位为透明化的数据库代理端，通过实现数据库二进制协议，对异构语言提供支持 ShardingSphere-JDBC# ShardingSphere-Proxy# 启动手册 二进制发布包 使用 docker 构建 GraalVM Native Image(Alpha) 高性能数据库集群# 第一种：读写分离# 主库负责处理事务性的增删改操作，从库负责处理查询操作 能够有效的避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善 读写分离是根据SQL语义的分析，将读操作和写操作分别路由至主库与从库 两种方式 一主多从 多主多从 第二种：数据库分片# 传统的将数据集中存储至单一节点的解决方案，在性能、可用性和运维成本这三方面已经难于满足海量数据的场景 性能 由于关系型数据库大多采用 B+ 树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降； 同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈 可用性 从可用性的方面来讲，服务化的无状态性，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。 而单一的数据节点，或者简单的主从架构，已经越来越难以承担。数据库的可用性，已成为整个系统的关键。 运维成本 从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，对于 DBA 的运维压力就会增大。 数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围 在传统的关系型数据库无法满足互联网场景需要的情况下，将数据存储至原生支持分布式的 NoSQL 的尝试越来越多。 但 NoSQL 对 SQL 的不兼容性以及生态圈的不完善，使得它们在与关系型数据库的博弈中始终无法完成致命一击，而关系型数据库的地位却依然不可撼动 什么是数据分片？ 按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。 数据分片的有效手段是对关系型数据库进行分库和分表。 分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。 除此之外，分库还能够用于有效的分散对数据库单点的访问量； 分表虽然无法缓解数据库压力，但却能够提供尽量将分布式事务转化为本地事务的可能，一旦涉及到跨库的更新操作，分布式事务往往会使问题变得复杂。 使用多主多从的分片方式，可以有效的避免数据单点，从而提升数据架构的可用性。 读写分离分散了数据库读写操作的压力，但是没有分散存储的压力，为了满足业务数据存储的需求，就需要将存储分散到多台数据库服务器上 数据分片的有效手段是对关系型数据库进行分库和分表 数据分片的拆分方式 垂直分片 水平分片 垂直分片# 什么是垂直分片？ 按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务 而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库 垂直分片的问题 垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。 专库专用 例如将商城库拆分为订单库、用户库、库存库 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理 垂直分表适合将表中某些不常用的列，或者是占了大量空间的列拆分出去 水平分片# 什么是水平分片 水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分 例如：根据主键分片，偶数主键的记录放入 0 库（或表），奇数主键的记录放入 1 库（或表） 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是数据分片的标准解决方案 水平分表 单表切分为多表之后，新的表即使在同一个数据库服务器中，也可能带来可观的性能提升，如果性能能够满足业务要求，可以不拆分到多台数据库服务器，毕竟业务分库也会引入很多复杂性 水平分库 如果单表拆分为多表后，单台服务器依然无法满足性能要求，那就需要将多个表分散在不同的数据库服务器中 数据分片的挑战# 面对如此散乱的分片之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。 他们需要知道数据需要从哪个具体的数据库的子表中获取 另一个挑战则是，能够正确的运行在单节点数据库中的 SQL，在分片之后的数据库中并不一定能够正确运行。 例如，分表导致表名称的修改，或者分页、排序、聚合分组等操作的不正确处理。 跨库事务也是分布式的数据库集群要面对的棘手事情 合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。 在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。 而基于 XA 的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。 目标# 尽量透明化分库分表所带来的影响，让使用方尽量像使用一个数据库一样使用水平分片之后的数据库集群，是 Apache ShardingSphere 数据分片模块的主要设计目标 CAP理论中的C在实践中是不可能完美实现的，在数据复制的过程中，节点N1和节点N2的数据并不一致（强一致性）。即使无法做到强一致性，但应用可以采用合适的方式达到最终一致性 基本可用 软引用 最终一致性 阿里巴巴Java开发手册 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表 如果预计3年后的数据量根本达不到这个级别，请不要在创建表时就分库分表 读写分离和数据分片具体的视线方式有两种 程序代码封装 在代码中抽象一个数据访问层（中间层封装），实现读写操作分离和数据库服务器连接的管理 Apache ShardingSphere ShardingSphere-JDBC 程序代码封装 ShardingSphere-Proxy 中间件封装 中间件封装 独立一套系统处理，实现读写操作分离和数据库服务器连接的管理。对于业务服务器来说，访问中间件和访问数据库没有区别，在业务服务器看来，中间件就是一个数据库服务器 MyCat 主从同步原理# slave会从master读取binlog来进行数据同步 1 master将数据改变记录到bin log中 2 当 slave 上执行 start slave 命令之后，slave会创建一个IO连接用来连接master，请求master中的binlog 3 当 slave 连接 master 时，master 会创建一个 log dump 线程，用于发送 bin log 的内容。在读取 binlog 的内容的操作中，会对主节点中的binlog加锁，当读取完成并发送给从服务器后解锁 4 IO 线程接收主节点 binlog dump 进程发来的更新之后，保存到中继日志 relay log 中 5 slave 的 SQL 线程，读取 relay log 日志，并解析成具体操作，从而实现主从操作一直，最终数据一致 MyCat与ShardingSphere深度对比# 如果是从传统单体结构迁移，且只需要基本的分库分表功能，MyCat可能更合适 如果是新建的云原生系统或微服务架构，ShardingSphere是更好的选择 考虑到技术演进和社区支持，新项目建议优先考虑ShardingSphere 某些场景可以组合使用-用ShardingSphere-JDBC处理应用内分片，用MyCat/ShardingShpere-Proxy处理遗留系统访问 分布式事务# 在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。 几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生 关系型数据库虽然对本地事务提供了完美的 ACID 原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。 如何让数据库在分布式场景下满足 ACID 的特性或找寻相应的替代方案，是分布式事务的重点工作 挑战# 强一致的事务与柔性事务的 API 和功能并不完全相同，在它们之间并不能做到自由的透明切换。 在开发决策阶段，就不得不在强一致的事务和柔性事务之间抉择，使得设计和开发成本被大幅增加 基于 XA 的强一致事务使用相对简单，但是无法很好的应对互联网的高并发或复杂系统的长事务场景； 柔性事务则需要开发者对应用进行改造，接入成本非常高，并且需要开发者自行实现资源锁定和反向补偿 原理介绍# ShardingSphere 对外提供 begin/commit/rollback 传统事务接口，通过 LOCAL，XA，BASE 三种模式提供了分布式事务的能力 LOCAL事务# LOCAL 模式基于 ShardingSphere 代理的数据库 begin/commit/rolllback 的接口实现， 对于一条逻辑 SQL，ShardingSphere 通过 begin 指令在每个被代理的数据库开启事务，并执行实际 SQL，并执行 commit/rollback。 由于每个数据节点各自管理自己的事务，它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 在性能方面无任何损耗，但在强一致性以及最终一致性方面不能够保证。 XA事务# XA 事务采用的是 X/OPEN 组织所定义的 DTP 模型 所抽象的 AP（应用程序）, TM（事务管理器）和 RM（资源管理器） 概念来保证分布式事务的强一致性。 其中 TM 与 RM 间采用 XA 的协议进行双向通信，通过两阶段提交实现。 与传统的本地事务相比，XA 事务增加了准备阶段，数据库除了被动接受提交指令外，还可以反向通知调用方事务是否可以被提交。 TM 可以收集所有分支事务的准备结果，并于最后进行原子提交，以保证事务的强一致性 XA 事务建立在 ShardingSphere 代理的数据库 xa start/end/prepare/commit/rollback/recover 的接口上 对于一条逻辑 SQL，ShardingSphere 通过 xa begin 指令在每个被代理的数据库开启事务，内部集成 TM，用于协调各分支事务，并执行 xa commit/rollback 基于 XA 协议实现的分布式事务，由于在执行的过程中需要对所需资源进行锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将会对并发场景下的性能产生一定的影响 BASE事务# 如果将实现了 ACID 的事务要素的事务称为刚性事务的话，那么基于 BASE 事务要素的事务则称为柔性事务 BASE 是基本可用、柔性状态和最终一致性这三个要素的缩写 基本可用（Basically Available）保证分布式事务参与方不一定同时在线 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉 最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性 在 ACID 事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。 通过放宽对强一致性要求，来换取系统吞吐量的提升 基于 ACID 的强一致性事务和基于 BASE 的最终一致性事务都不是银弹，只有在最适合的场景中才能发挥它们的最大长处。 Apache ShardingSphere 集成了 SEATA 作为柔性事务的使用方案 应用场景# 在单机应用场景中，依赖数据库提供的事务即可满足业务上对事务 ACID 的需求。但是在分布式场景下，传统数据库解决方案缺乏对全局事务的管控能力，用户在使用过程中可能遇到多个数据库节点上出现数据不一致的问题 ShardingSphere 分布式事务，为用户屏蔽了分布式事务处理的复杂性，提供了灵活多样的分布式事务解决方案，用户可以根据自己的业务场景在 LOCAL，XA，BASE 三种模式中，选择适合自己的分布式事务解决方案 ShardingSphere LOCAL 事务使用场景 对于 LOCAL 事务，在分布式环境下，不保证各个数据库节点之间数据的一致性和隔离性，需要业务方自行处理可能出现的不一致问题。适用于用户希望自行处理分布式环境下数据一致性问题的业务场景 ShardingSphere XA 事务使用场景 对于 XA 事务，提供了分布式环境下，对数据强一致性的保证。但是由于存在同步阻塞问题，对性能会有一定影响。适用于对数据一致性要求非常高且对并发性能要求不是很高的业务场景 ShardingSphere BASE 事务使用场景 对于 BASE 事务，提供了分布式环境下，对数据最终一致性的保证。由于在整个事务过程中，不会像 XA 事务那样全程锁定资源，所以性能较好。适用于对并发性能要求很高并且允许出现短暂数据不一致的业务场景 YMAL配置# YMAL配置 读写分离# 核心概念# 核心概念 主库 添加、更新以及删除数据操作所使用的数据库，目前仅支持单主库 从库 查询数据操作所使用的数据库，可支持多从库 主从同步 将主库的数据异步的同步到从库的操作。 由于主从同步的异步性，从库与主库的数据会短时间内不一致 负载均衡策略 通过负载均衡策略将查询请求疏导至不同从库 使用限制 不处理主库和从库的数据同步 不处理主库和从库的数据同步延迟导致的数据不一致 不支持主库多写 不处理主从库间的事务一致性。主从模型中，事务中的数据读写均用主库。 数据库网关# 背景 随着数据库碎片化趋势的不可逆转，多种类型数据库的共存已渐成常态。使用一种 SQL 方言访问异构数据库的场景在不断增加 挑战 多样化的数据库的存在，使访问数据库的 SQL 方言难于标准化，工程师需要针对不同种类的数据库使用不同的方言，缺乏统一化的查询平台 将不同类型的数据库方言自动翻译为后端数据库所使用的方言，让工程师可以使用任意一种数据库方言访问所有的后端异构数据库，可以极大的降低开发和维护成本 目标 SQL 方言的自动翻译，是 Apache ShardingSphere 数据库网关希望达成的主要目标 应用场景 随着业务场景的多元化，企业内部的数据库产品也呈现多元化的趋势，业务应用与不同数据库产品的对接也变得异常复杂，ShardingSphere 数据库网关可以屏蔽业务应用与底层多元化数据库之间连接，同时为不同的业务场景提供统一的访问协议和语法体系，能够帮助企业快速打造统一的数据访问平台。 使用限制 Apache ShardingSphere 的 SQL 方言翻译处于实验阶段 目前仅支持 MySQL/PostgreSQL 的方言自动翻译，工程师可以使用 MySQL 的方言和协议，访问 PostgreSQL 数据库，反之亦然 流量治理# 数据迁移# 挑战 在迁移过程中，不应该对正在运行的业务造成影响。尽可能减少迁移时数据不可用的时间窗口，是数据迁移的第一个挑战 其次，数据迁移不应该对现有的数据造成影响，如何保证数据的正确性，是数据迁移的第二个挑战 应用场景 假如一个应用系统在使用传统单体数据库，单表数据量达到了1亿并且还在快速增长，单体数据库负载持续在高位，成为系统瓶颈。一旦数据库成为瓶颈，对应用服务器扩容是无效的，需要对数据库进行扩容 数据加密# 数据脱敏# 影子库# 背景 在基于微服务的分布式应用架构下，业务需要多个服务是通过一系列的服务、中间件的调用来完成，所以单个服务的压力测试已无法代表真实场景。 在测试环境中，如果重新搭建一整套与生产环境类似的压测环境，成本过高，并且往往无法模拟线上环境的复杂度以及流量。 因此，业内通常选择全链路压测的方式，即在生产环境进行压测，这样所获得的测试结果能够准确地反应系统真实容量和性能水平 可观察性# 如何观测集群的运行状态，使运维人员可以快速掌握当前系统现状，并进行进一步的维护工作，是分布式系统的全新挑战 登录到具体服务器的点对点运维方式，无法适用于面向大量分布式服务器的场景 通过对系统可观察性数据的遥测是分布式系统推荐的运维方式。 Tracing（链路跟踪）、 Metrics（指标监控）和 Logging （日志）是系统运行状况的可观察性数据重要的获取手段 APM（应用性能监控） 是通过对系统可观察性数据进行采集、存储和分析，进行系统的性能监控与诊断，主要功能包括性能指标监控、调用链分析，应用拓扑图等 Apache ShardingSphere 并不负责如何采集、存储以及展示应用性能监控的相关数据，而是为应用监控系统提供必要的指标数据 换句话说，Apache ShardingSphere 仅负责产生具有价值的数据，并通过标准协议或插件化的方式递交给相关系统 Tracing 用于获取 SQL 解析与 SQL 执行的链路跟踪信息。Apache ShardingSphere 默认提供了对 OpenTelemetry，SkyWalking 的支持，也支持用户通过插件化的方式开发自定义的 Tracing 组件 使用 OpenTelemetry OpenTelemetry 在 2019 年由 OpenTracing 和 OpenCencus 合并而来。 使用这种方式，只需要在 agent 配置文件中，根据 OpenTelemetry SDK 自动配置说明 ，填写合适的配置即可。可以导出数据到 Jaeger，Zipkin 使用 SkyWalking 需要在 agent 配置中配置启用对应插件，并且需要同时配置使用 SkyWalking 的 apm-toolkit 工具 使用 SkyWalking 的内置自动探针 Apache ShardingSphere 团队与 Apache SkyWalking 团队共同合作，在 SkyWalking 中实现了 Apache ShardingSphere 自动探针，可以将相关的应用性能数据自动发送到 SkyWalking 中。注意这种方式的自动探针不能与 Apache ShardingSphere 插件探针同时使用 Metrics 则用于收集和展示整个集群的统计指标。Apache ShardingSphere 默认提供了对 Prometheus 的支持 联邦查询# 背景 当用户使用数据分片对海量数据进行水平拆分时，虽然能够有效解决数据库性能瓶颈，但业务上也因此带来了一些新的问题。 例如以下场景：跨节点关联查询、子查询、分页、排序、聚合查询。在进行业务实现时需要注意查询 SQL 的使用范围，尽量避免跨数据库实例查询，这使得业务层面的功能受到了数据库的限制 ShardingSphere的分布式事务功能具体是如何实现的？# XA事务（强一致性）# 实现原理 基于XA协议的两阶段提交(2PC) 使用ShardingSphere的XATransactionManager作为事务管理器 工作流程 准备阶段 事务协调器向所有参与者发送prepare请求 各参与者执行事务但不提交，记录undo/redo日志 参与者返回准备就绪或失败响应 提交/回滚阶段 如果所有参与者都准备就绪，发送commit请求 如果任一参与者准备失败，发送rollback请求 参与者根据指令完成最终操作 Seata事务（柔性事务/AT模式）# 整合Seata的AT(Automatic Transaction)模式 基于全局锁+分支事务的补偿机制 工作流程 第一阶段 业务SQL被Seata拦截解析 RM生成undo log记录修改前数据 执行业务SQL并提交本地事务 向TC注册分支事务并报告状态 第二阶段 成功时：异步删除undo log 失败时：基于 undo log 进行补偿回滚 BASE事务（Saga模式）# 基于Saga模式的长事务解决方案 每个子事务都有对应的补偿操作 最终一致性模型 执行模式 正向流程：按顺序执行所有子事务 补偿流程：出现失败时，逆序执行补偿操作 生产实践建议# 金融核心系统：优先考虑XA事务 普通交易系统：推荐Seata AT模式 跨系统长流程：考虑Saga模式 Reference# 官方文档 这个很好，优先看这个 shardingsphere分库分表示例（逻辑表，真实表，绑定表，广播表，单表），分页性能测试 ShardingSphere学习（超详细） 为什么几乎所有的开源数据库中间件都是国内公司开源的？并且几乎都停止了更新？ - 张亮的回答 - 知乎 "},{"id":52,"href":"/post/computer-science/distributed-system/spring-cloud/","title":"Spring Cloud","section":"Distributed System","content":"Spring Cloud# 服务注册与发现# Eureka# Netflix 开源的服务注册中心，采用 AP 架构（高可用性），通过心跳机制检测服务状态 包含 Eureka Server（注册中心）和 Eureka Client（服务提供者/消费者） 注：Eureka 2.x 已停止维护，建议新项目使用 Nacos Nacos# Spring Cloud Alibaba 的核心组件，兼具服务注册中心和配置中心功能，支持 CP/AP 模式切换 提供动态服务发现、健康检查、配置管理等功能，适用于云原生场景 服务调用与负载均衡# Feign# 声明式的 REST 客户端，通过动态代理简化服务间 HTTP 调用，整合了 Ribbon 实现负载均衡 Ribbon# 客户端负载均衡组件，支持轮询、随机、权重等算法，需配合 Eureka/Nacos 使用 注：Ribbon 已进入维护阶段，Spring Cloud LoadBalancer 是新一代替代方案 Dubbo# Spring Cloud Alibaba 支持的 RPC 框架，适用于高性能服务调用，替代 Feign+Ribbon 的组合 服务容错与熔断# Hystrix# Netflix 开源的熔断器，通过熔断、降级、隔离机制防止服务雪崩 注：Hystrix 已停止维护，推荐使用 Sentinel Sentinel# Alibaba 开源的流量控制组件，支持熔断、限流、系统自适应保护，提供实时监控 服务网关# Zuul# Netflix 的 API 网关，负责路由、过滤、负载均衡，但性能较低 注：Zuul 1.x 已停止维护，Zuul 2.x 未集成到 Spring Cloud Spring Cloud Gateway# 基于 Reactor 的高性能网关，支持动态路由、限流、集成 Sentinel 配置中心# Spring Cloud Config# 集中化管理配置，支持 Git、本地存储等，但需配合 Bus 实现动态刷新 Nacos Config# 与 Nacos 注册中心无缝集成，支持配置动态更新和版本管理 消息总线与事件驱动# Spring Cloud Bus# 通过消息队列（如 RabbitMQ、Kafka）广播配置变更，实现配置热更新 Spring Cloud Stream# 统一消息中间件抽象层，支持 Kafka、RocketMQ 等 分布式链路追踪# Sleuth + Zipkin# 追踪微服务调用链路，生成请求依赖图，便于故障排查 SkyWalking# 更强大的 APM 工具，支持分布式追踪、性能监控 分布式事务# Seata# Alibaba 开源的分布式事务解决方案，支持 AT、TCC、SAGA 模式 其他组件# Spring Cloud Security# OAuth2、JWT 等安全认证 Spring Cloud OpenFeign# Feign 的增强版，支持 Spring MVC 注解 Reference# "},{"id":53,"href":"/post/computer-science/distributed-system/spring-cloud-alibaba/","title":"Spring Cloud Alibaba","section":"Distributed System","content":"Spring Cloud Alibaba# Spring Cloud Alibaba Spring Cloud VS Spring Cloud Alibaba# 现在学spring cloud alibaba 还是spring cloud? 以下是 Spring Cloud 和 Spring Cloud Alibaba 的详细对比，从技术定位、核心组件、适用场景等维度综合分析，并结合实际应用场景提供选型建议：\n功能 Spring Cloud Spring Cloud Alibaba 优势对比 服务注册与发现 Eureka（AP，已停更） Nacos（AP/CP 双模，高性能） Nacos 支持动态配置管理，性能提升 50%+ 配置中心 Config Server（基于 Git） Nacos Config（可视化界面） Nacos 支持实时推送和多环境配置 流量控制与熔断 Hystrix（维护模式） Sentinel（动态规则、实时监控） Sentinel 支持精细化流量控制和系统保护 分布式事务 无官方方案（依赖第三方） Seata（原生集成 AT/TCC 模式） Seata 简化分布式事务开发 消息队列 无（依赖 RabbitMQ） RocketMQ（高吞吐、事务消息） RocketMQ 适合高并发和削峰填谷场景 "},{"id":54,"href":"/post/computer-science/database/sql/","title":"SQL","section":"Database","content":"sql# 2502 设计内存分配器# ✅ 175 组合两个表# 175. 组合两个表 需要展示的字段 姓 LastName 名 FirstName 城市 City 州 State 如果 personId 的地址不再 Address 表中，则报告为 null 使用左连接 select FirstName, LastName, City, State from Person left join on Person.PersonId = Address.PersonId;176 第二高的薪水# 176. 第二高的薪水 Create table If Not Exists Employee ( id int, salary int ); Truncate table Employee; insert into Employee (id, salary) values (\u0026#39;1\u0026#39;, \u0026#39;100\u0026#39;); insert into Employee (id, salary) values (\u0026#39;2\u0026#39;, \u0026#39;200\u0026#39;); insert into Employee (id, salary) values (\u0026#39;3\u0026#39;, \u0026#39;300\u0026#39;); insert into Employee (id, salary) values (\u0026#39;4\u0026#39;, \u0026#39;400\u0026#39;); insert into Employee (id, salary) values (\u0026#39;5\u0026#39;, \u0026#39;500\u0026#39;); insert into Employee (id, salary) values (\u0026#39;6\u0026#39;, \u0026#39;600\u0026#39;); insert into Employee (id, salary) values (\u0026#39;7\u0026#39;, \u0026#39;700\u0026#39;);Employee 表： +-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | salary | int | +-------------+------+ id 是这个表的主键。 表的每一行包含员工的工资信息。select distinct Salary as SecondHighestSalary from Employee order by Salary desc limit 1 offset 1然而，如果没有第 2 高的薪资，即表里可能只有一条记录，这个解答会被评测为 \u0026lsquo;Wrong Answer\u0026rsquo; 。为了克服这个问题，我们可以将其作为临时表。\nSELECT (SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1 OFFSET 1) AS SecondHighestSalary ;177 第N高的薪水# 177 第N高的薪水 create function getNthHighestSalary(N int) returns int begin declare M int; set M = N - 1; return (select distinct salary from Employee order by salary desc limit M, 1); end 178 分数排名# 178 分数排名 Create table If Not Exists Scores ( id int, score DECIMAL(3, 2) ); Truncate table Scores; insert into Scores (id, score) values (\u0026#39;1\u0026#39;, \u0026#39;3.5\u0026#39;); insert into Scores (id, score) values (\u0026#39;2\u0026#39;, \u0026#39;3.65\u0026#39;); insert into Scores (id, score) values (\u0026#39;3\u0026#39;, \u0026#39;4.0\u0026#39;); insert into Scores (id, score) values (\u0026#39;4\u0026#39;, \u0026#39;3.85\u0026#39;); insert into Scores (id, score) values (\u0026#39;5\u0026#39;, \u0026#39;4.0\u0026#39;); insert into Scores (id, score) values (\u0026#39;6\u0026#39;, \u0026#39;3.65\u0026#39;);表: Scores +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | score | decimal | +-------------+---------+ id 是该表的主键（有不同值的列）。 该表的每一行都包含了一场比赛的分数。Score 是一个有两位小数点的浮点值。方法 1：DENSE_RANK# select s.score, dense_rank() over ( order by S.score desc ) as \u0026#39;rank\u0026#39; from Scores S;窗口函数# 方法 2: 使用 COUNT(DISTINCT \u0026hellip;) 的相关子查询# select S1.score, (select count(distinct S2.score) from Scores S2 where S2.score \u0026gt;= S1.score) as \u0026#39;rank\u0026#39; from Scores S1 order by S1.score desc;方法 3：使用 INNER JOIN 和 COUNT(DISTINCT\u0026hellip;)# select S.score, count(distinct T.score) as \u0026#39;rank\u0026#39; from Scores S inner join Scores T on S.score \u0026lt;= T.score group by S.id, S.socre order by S.score desc;数据库表自身进行内连接的结果是什么# 数据库表自身进行内连接（Self-Join）的结果是将表中的每一行与同一表中的其他行进行匹配，基于指定的连接条件。如果连接条件满足，则返回匹配的行组合。\n具体说明：\n连接条件：通常使用主键、外键或其他相关列作为连接条件。 结果：返回满足条件的行组合，未匹配的行将被排除。 示例：\n假设有一个表 Employees：\nEmployeeID Name ManagerID 1 Alice 3 2 Bob 3 3 Charlie NULL 4 David 2 执行以下自连接查询：\nSELECT e1.Name AS Employee, e2.Name AS Manager FROM Employees e1 INNER JOIN Employees e2 ON e1.ManagerID = e2.EmployeeID;结果：\nEmployee Manager Alice Charlie Bob Charlie David Bob 解释：\nAlice 和 Bob 的 ManagerID 为 3，与 Charlie 的 EmployeeID 匹配。 David 的 ManagerID 为 2，与 Bob 的 EmployeeID 匹配。 Charlie 没有 ManagerID，因此不参与匹配。 总结：\n自连接的结果是表中满足连接条件的行组合，常用于处理层次结构或递归关系的数据。\n180 连续出现的数字# 180 连续出现的数字 Create table If Not Exists Logs ( id int, num int ); Truncate table Logs; insert into Logs (id, num) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;4\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;5\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;6\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;7\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;8\u0026#39;, \u0026#39;2\u0026#39;);表：Logs +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | num | varchar | +-------------+---------+ 在 SQL 中，id 是该表的主键。 id 是一个自增列。select distinct l1.Num as ConsecutiveNums from Logs l1, Logs l2, Logs l3 where l1.Id = l2.Id - 1 and l2.Id = l3.Id - 1 and l1.Num = l2.Num and l2.Num = l3.Num and l1.Num = l3.Num;✅ 181 超过经理收入的员工# 181 超过经理收入的员工 Create table If Not Exists Employee2 ( id int, name varchar(255), salary int, managerId int ); Truncate table Employee2; insert into Employee2 (id, name, salary, managerId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;3\u0026#39;); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;4\u0026#39;); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, NULL); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, NULL);表：Employee +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | name | varchar | | salary | int | | managerId | int | +-------------+---------+ id 是该表的主键（具有唯一值的列）。 该表的每一行都表示雇员的ID、姓名、工资和经理的ID。select e1.name as \u0026#39;Employee\u0026#39; from Employee e1 inner join Employee e2 on e1.managerId = e2.Id where e1.salary \u0026gt; e2.salary;182 查找重复的电子邮箱# 182 查找重复的电子邮箱 Create table If Not Exists Person ( id int, email varchar(255) ); Truncate table Person; insert into Person (id, email) values (\u0026#39;1\u0026#39;, \u0026#39;a@b.com\u0026#39;); insert into Person (id, email) values (\u0026#39;2\u0026#39;, \u0026#39;c@d.com\u0026#39;); insert into Person (id, email) values (\u0026#39;3\u0026#39;, \u0026#39;a@b.com\u0026#39;);方法一：使用 GROUP BY 和临时表# select Email from (select Email, count(Email) as num from Person group by Email) as statistics where num \u0026gt; 1;方法二：使用 GROUP BY 和 HAVING 条件# select Email from Person group by Email having count(Email) \u0026gt; 1;✅ 183 从不订购的客户# 183 从不订购的客户 Create table If Not Exists Customers ( id int, name varchar(255) ); Create table If Not Exists Orders ( id int, customerId int ); Truncate table Customers; insert into Customers (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;); insert into Customers (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;); insert into Customers (id, name) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;); insert into Customers (id, name) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;); Truncate table Orders; insert into Orders (id, customerId) values (\u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;); insert into Orders (id, customerId) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;);-- 实现方法1 select c.name as Customers from Customers c left join Orders o on c.id = o.customerId where o.id is null; -- 实现方法2 select name as \u0026#39;Customers\u0026#39; from Customers where id not in (select distinct(customerId) from Orders);✅ 184 部门工资最高的员工# 184 部门工资最高的员工 Create table If Not Exists Employee3 ( id int, name varchar(255), salary int, departmentId int ); Create table If Not Exists Department ( id int, name varchar(255) ); Truncate table Employee3; insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;2\u0026#39;, \u0026#39;Jim\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;3\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;4\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;5\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); Truncate table Department; insert into Department (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;IT\u0026#39;); insert into Department (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Sales\u0026#39;);select Department.name as \u0026#39;Department\u0026#39;, Employee.name as \u0026#39;Employee\u0026#39;, Salary from Employee join Department on Employee.DepartmentId = Department.Id where (Employee.DepartmentId, Salary) in (select DepartmentId, max(Salary) from Employee group by DepartmentId) ;185 部门工资前三高的所有员工# 185 部门工资前三高的所有员工 drop table Employee; Create table If Not Exists Employee ( id int, name varchar(255), salary int, departmentId int ); drop table Department; Create table If Not Exists Department ( id int, name varchar(255) ); Truncate table Employee; insert into Employee (id, name, salary, departmentId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;5\u0026#39;, \u0026#39;Janet\u0026#39;, \u0026#39;69000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;6\u0026#39;, \u0026#39;Randy\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;7\u0026#39;, \u0026#39;Will\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;1\u0026#39;); Truncate table Department; insert into Department (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;IT\u0026#39;); insert into Department (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Sales\u0026#39;);196 删除重复的电子邮箱# 196 删除重复的电子邮箱 delete p1 from Person p1, Person p2 where p1.Email = p2.Email and p1.Id \u0026gt; p2.Id;197 上升的温度# 197 上升的温度 select a.id from Weather a, Weather b where datediff(a.recordDate, b.recordDate) = 1 and a.Temperature \u0026gt; b.Temperature;262 行程和用户# 511 游戏玩法分析 I# 511 游戏玩法分析 I 方法 1：分组并提取最小值# select player_id, min(event_date) as first_login from Activity group by player_id;方法 2：窗口函数# rank()# select X.player_id, X.event_date as first_login from (select A.player_id, A.event_date rank() over ( partition by A.player_id group by A.event_date ) as rnk from Activity A) X where X.rnk = 1;first_value()# --- 必须使用 distinct SELECT DISTINCT A.player_id, FIRST_VALUE(A.event_date) OVER ( PARTITION BY A.player_id ORDER BY A.event_date ) AS first_login FROM Activity A;512 游戏玩法分析 II# 534 游戏玩法分析 III# 550 游戏玩法分析 IV# 550. 游戏玩法分析 IV select player_id, date_add(min(event_date), interval 1 day) as second_date from Activity group by player_id在sql中，from后面用逗号写了多张表，这样属于什么连接# 在 SQL 中，如果在 FROM 子句中使用逗号分隔多张表，例如：\nFROM table1, table2这属于 隐式连接（Implicit Join），也称为 笛卡尔连接（Cartesian Join）或 交叉连接（Cross Join）。它的行为是将两张表的所有行进行组合，生成一个笛卡尔积。\n隐式连接的特点：\n没有明确的连接条件：\n如果没有在 WHERE 子句中指定连接条件，结果将是两张表的笛卡尔积。 例如，table1 有 3 行，table2 有 4 行，结果将返回 (3 \\times 4 = 12) 行。 连接条件需要在 WHERE 子句中指定：\n如果需要特定的连接逻辑（如内连接），必须在 WHERE 子句中明确写出连接条件。 例如： FROM table1, table2 WHERE table1.id = table2.table1_id; 可读性较差：\n隐式连接的语法不够直观，尤其是在涉及多张表或复杂连接条件时，容易出错或难以维护。 示例：\n假设有两张表：\ntable1:\nid name 1 Alice 2 Bob table2:\nid table1_id value 1 1 100 2 2 200 3 1 300 隐式连接（无 WHERE 条件）： SELECT * FROM table1, table2;结果（笛卡尔积）：\nid name id table1_id value 1 Alice 1 1 100 1 Alice 2 2 200 1 Alice 3 1 300 2 Bob 1 1 100 2 Bob 2 2 200 2 Bob 3 1 300 隐式连接（带 WHERE 条件）： SELECT * FROM table1, table2 WHERE table1.id = table2.table1_id;结果（内连接效果）：\nid name id table1_id value 1 Alice 1 1 100 1 Alice 3 1 300 2 Bob 2 2 200 显式连接 vs 隐式连接：\n显式连接（推荐）：\n使用 JOIN 关键字（如 INNER JOIN、LEFT JOIN 等）。 连接条件写在 ON 子句中。 语法清晰，易于维护。 示例： SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.table1_id; 隐式连接（不推荐）：\n使用逗号分隔表。 连接条件写在 WHERE 子句中。 可读性差，容易出错。 总结：\n在 FROM 子句中使用逗号分隔多张表属于 隐式连接。如果没有指定 WHERE 条件，结果将是笛卡尔积；如果指定了 WHERE 条件，可以实现类似内连接的效果。但出于可读性和可维护性的考虑，建议使用显式连接（JOIN）。\n569 员工薪水中位数# 570 至少有5名直接下属的经理# 571 给定数字的频率查询中位数# 574 当选者# 577 员工奖金# 578 查询回答率最高的问题# 579 查询员工的累计薪水# 580 统计各专业学生人数# 584 寻找用户推荐人# 585 2016年的投资# 586 订单最多的客户# 595 大的国家# 596 超过 5 名学生的课# 597 好友申请 I：总体通过率# 601 体育馆的人流量# 602 好友申请 II ：谁有最多的好友# 603 连续空余座位# 607 销售员# 608 树节点# 610 判断三角形# 612 平面上的最近距离# 613 直线上的最近距离# 614 二级关注者# 615 平均工资：部门与公司比较# 618 学生地理信息报告# 619 只出现一次的最大数字# 620 有趣的电影# 626 换座位# 627 变更性别# 1045 买下所有产品的客户# 1050 合作过至少三次的演员和导演# 1068 产品销售分析 I# 1069 产品销售分析 II# mac2025 mysql# leetcode# "},{"id":55,"href":"/post/sports/table-tennis/","title":"table tennis","section":"Sports","content":" 张继科（日）原片 "},{"id":56,"href":"/post/computer-science/front-end/vue/","title":"vue","section":"Front End","content":"vue# vuejs.org 文档 vue2 教程 Vue 2.0 在 2023 年 12 月 31 日停止更新 vue3 教程 快速上手# 安装 node.js 使用 brew 安装 brew install node 检查 node 是否安装成功 node -v npm -v 创建 vue 项目 npm create vue@latest cd my-vue-project 修改镜像源 reference npm、yarn、pnpm 最新国内镜像源设置和常见问题解决 npm install npm run dev Local http://localhost:5173 Vue DevTools http://localhost:5173/__devtools__/ reference 如何在 macOS 上安装 Node.js "},{"id":57,"href":"/post/computer-science/llm/2025-03-30-4-%E4%B8%8D%E5%90%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%B6%88%E6%81%AF%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94/","title":"不同消息队列消息写入方式对比","section":"Computer Science","content":"不同消息队列消息写入方式对比# 以下是主流消息队列（Kafka、RocketMQ、RabbitMQ、Pulsar、ActiveMQ）在消息写入方式上的对比，结合性能、可靠性和适用场景进行综合分析：\n1. Kafka# 写入方式： 顺序追加写入：消息以追加（Append-only）方式写入分区日志文件，利用磁盘顺序I/O的高性能特性11528。 批量发送：生产者（Producer）将消息累积到批次（如1MB或100ms阈值）后批量发送，减少网络和磁盘I/O次数28。 异步刷盘：默认异步刷盘（依赖页缓存），通过参数可配置同步刷盘（牺牲性能换可靠性）28。 特点： 高吞吐（10万级/秒），适合日志、大数据场景115。 不支持延迟消息，仅保证分区内有序1628。 2. RocketMQ# 写入方式： 顺序写+索引：消息追加到CommitLog文件（顺序写），同时构建索引文件（ConsumeQueue）加速查询42。 同步/异步刷盘：支持同步刷盘（强一致性）和异步刷盘（高性能）4243。 事务消息：通过“半消息”机制实现分布式事务，先暂存消息，本地事务提交后再确认写入42。 特点： 兼顾高吞吐（10万级/秒）和功能完备性（延迟消息、事务支持）1628。 适合电商、金融等业务场景142。 3. RabbitMQ# 写入方式： 内存+磁盘混合：默认优先写入内存，通过持久化队列（Durable Queue）将消息同步到磁盘128。 Exchange路由：消息通过Exchange根据路由规则（Direct/Topic/Fanout）分发到队列116。 特点： 实时性高（微秒级延迟），但吞吐量较低（万级/秒）28。 支持复杂路由和消息确认机制，适合中小规模业务116。 4. Pulsar# 写入方式： 分层存储：消息先写入Broker的内存层，再异步持久化到BookKeeper集群（计算与存储分离）116。 分片（Segment）存储：Topic分区划分为Segment，分散存储提高扩展性1。 特点： 支持秒级延迟消息和多租户，适合云原生和异地容灾场景116。 吞吐量接近Kafka，但架构更复杂1。 5. ActiveMQ# 写入方式： 内存/KahaDB/JDBC：默认KahaDB（基于日志的存储），支持JDBC持久化到数据库。 同步刷盘可选：通过配置选择是否同步刷盘。 特点： 功能全面但吞吐量最低（万级/秒），适合传统企业应用28。 社区活跃度低，逐渐被替代28。 对比总结# 特性 Kafka RocketMQ RabbitMQ Pulsar ActiveMQ 写入性能 最高（顺序I/O+批量） 高（顺序写+索引） 低（内存优先） 高（分层存储） 最低 可靠性 异步刷盘可能丢数据 支持同步刷盘 依赖持久化配置 高（BookKeeper） 依赖配置 延迟消息 不支持 支持 支持（插件） 支持秒级 支持 适用场景 日志/大数据 电商/金融 中小规模业务 云原生/异地容灾 传统企业应用 参考资料：115162842\n"},{"id":58,"href":"/post/computer-science/llm/2025-03-30-1-%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E7%B4%A2%E5%BC%95%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA-%E8%AF%B7%E4%BB%A5postgresql%E4%B8%BE%E4%BE%8B/","title":"分区表的索引如何创建，请以postgresql举例","section":"Computer Science","content":"分区表的索引如何创建，请以postgresql举例# PostgreSQL分区表索引创建指南# PostgreSQL中分区表索引的创建方法与普通表有所不同，需要特别注意分区表的特性。以下是详细的创建方法和示例：\n一、基本索引创建方法# 1. 自动分区索引（PostgreSQL 11+）# 从PostgreSQL 11开始，可以直接在父表上创建索引，系统会自动为所有子分区创建对应的索引1247。\n-- 创建分区表 CREATE TABLE sales ( id SERIAL PRIMARY KEY, product VARCHAR, sale_date DATE ) PARTITION BY RANGE (sale_date); -- 创建子分区 CREATE TABLE sales_2021_01_01 PARTITION OF sales FOR VALUES FROM (\u0026#39;2021-01-01\u0026#39;) TO (\u0026#39;2021-01-02\u0026#39;); CREATE TABLE sales_2021_01_02 PARTITION OF sales FOR VALUES FROM (\u0026#39;2021-01-02\u0026#39;) TO (\u0026#39;2021-01-03\u0026#39;); -- 在父表上创建索引，会自动应用到所有分区 CREATE INDEX idx_product ON sales (product);2. 手动创建分区索引（PostgreSQL 10及以下）# 在PostgreSQL 10及以下版本，需要为每个分区单独创建索引：\n-- 为每个分区单独创建索引 CREATE INDEX sales_2021_01_01_product_idx ON sales_2021_01_01 (product); CREATE INDEX sales_2021_01_02_product_idx ON sales_2021_01_02 (product);二、特殊索引类型# 1. 唯一索引和主键# PostgreSQL 11+支持在分区表上创建唯一约束和主键，但必须包含分区键47：\n-- 创建包含分区键的唯一索引 CREATE TABLE rtable(c1 INT, c2 VARCHAR(10)) PARTITION BY RANGE(c1); ALTER TABLE rtable ADD CONSTRAINT pk_rtable PRIMARY KEY(c1);2. 局部索引(Partial Index)# 可以只为满足特定条件的行创建索引，节省空间并提高查询效率25：\n-- 只为活跃客户创建索引 CREATE INDEX idx_customer_inactive ON customer(active) WHERE active = 0;3. 全局索引(Global Index)# PostgreSQL支持全局索引，可以跨分区查询而不需要包含分区键2743：\n-- 创建全局索引 CREATE INDEX idx_global ON employees(email) GLOBAL;三、在线创建索引的注意事项# PostgreSQL不支持直接在分区表上并发创建索引(CONCURRENTLY)，但可以通过以下方法实现类似效果17：\n在每个分区上并发创建索引 在父表上以非并发方式创建索引 -- 错误方法（会报错） CREATE INDEX CONCURRENTLY idx_product ON sales (product); -- 正确方法 -- 1. 在每个分区上并发创建索引 CREATE INDEX CONCURRENTLY sales_2021_01_01_product_idx ON sales_2021_01_01 (product); CREATE INDEX CONCURRENTLY sales_2021_01_02_product_idx ON sales_2021_01_02 (product); -- 2. 在父表上创建索引 CREATE INDEX idx_product ON sales (product);四、索引类型选择# PostgreSQL支持多种索引类型，应根据查询需求选择合适的类型4041：\nB-tree：默认索引类型，适合范围查询和等值查询 Hash：只支持等值查询，但性能更好 GIN：适合全文搜索和数组查询 GiST：适合空间数据和复杂数据类型 BRIN：适合大型有序数据集，占用空间小 -- 创建GIN索引示例 CREATE INDEX idx_gin ON documents USING gin (content gin_trgm_ops);五、最佳实践建议# 索引应包含查询条件中的常用列1 对于分区表，考虑查询是否使用分区键来决定索引类型27 定期分析索引使用情况，删除不必要的索引 对于大型分区表，考虑使用BRIN索引减少空间占用40 唯一约束必须包含分区键列47 通过合理设计分区表索引，可以显著提高PostgreSQL数据库的查询性能和管理效率。\n"},{"id":59,"href":"/post/computer-science/algorithm/%E5%89%91%E6%8C%87offer%E8%BF%99%E6%9C%AC%E4%B9%A6%E4%B8%AD%E6%AF%8F%E4%B8%80%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98%E5%AF%B9%E5%BA%94leetcode%E7%9A%84%E9%A2%98%E7%9B%AE/","title":"剑指offer题目对应","section":"Algorithm","content":"剑指offer这本书中每一道面试题对应leetcode的题目# 《剑指Offer》是一本经典的编程面试书籍，其中包含了许多高质量的编程题目。很多题目与LeetCode上的题目有对应关系。以下是一些《剑指Offer》中的题目及其在LeetCode上的对应题目：\n1. 数组中重复的数字# 剑指Offer题目：找出数组中重复的数字。 LeetCode对应题目：287. 寻找重复数 2. 二维数组中的查找# 剑指Offer题目：在一个二维数组中查找某个数是否存在。 LeetCode对应题目：240. 搜索二维矩阵 II 3. 替换空格# 剑指Offer题目：将字符串中的空格替换为\u0026quot;%20\u0026quot;。 LeetCode对应题目：剑指 Offer 05. 替换空格 4. 从尾到头打印链表# 剑指Offer题目：从尾到头打印链表。 LeetCode对应题目：剑指 Offer 06. 从尾到头打印链表 5. 重建二叉树# 剑指Offer题目：根据前序遍历和中序遍历的结果重建二叉树。 LeetCode对应题目 ：105. 从前序与中序遍历序列构造二叉树 6. 二叉树的下一个节点# 剑指Offer题目：给定二叉树中的一个节点，找到中序遍历的下一个节点。 LeetCode对应题目：剑指 Offer 08. 二叉树的下一个节点 7. 用两个栈实现队列# 剑指Offer题目：用两个栈实现队列。 LeetCode对应题目：232. 用栈实现队列 8. 斐波那契数列# 剑指Offer题目：求斐波那契数列的第n项。 LeetCode对应题目：509. 斐波那契数 9. 旋转数组的最小数字# 剑指Offer题目：在一个旋转数组中查找最小的数字。 LeetCode对应题目：153. 寻找旋转排序数组中的最小值 10. 矩阵中的路径# 剑指Offer题目：在矩阵中查找是否存在某条路径。 LeetCode对应题目：79. 单词搜索 11. 机器人的运动范围# 剑指Offer题目：计算机器人能够到达的格子数。 LeetCode对应题目：剑指 Offer 13. 机器人的运动范围 12. 剪绳子# 剑指Offer题目：将绳子剪成若干段，使得乘积最大。 LeetCode对应题目：343. 整数拆分 13. 二进制中1的个数# 剑指Offer题目：统计一个整数的二进制表示中1的个数。 LeetCode对应题目：191. 位1的个数 14. 数值的整数次方# 剑指Offer题目：实现函数计算数值的整数次方。 LeetCode对应题目：50. Pow(x, n) 15. 打印从1到最大的n位数# 剑指Offer题目：打印从1到最大的n位数。 LeetCode对应题目：剑指 Offer 17. 打印从1到最大的n位数 16. 删除链表的节点# 剑指Offer题目：在O(1)时间内删除链表节点。 LeetCode对应题目：237. 删除链表中的节点 17. 正则表达式匹配# 剑指Offer题目：实现正则表达式匹配。 LeetCode对应题目：10. 正则表达式匹配 18. 表示数值的字符串# 剑指Offer题目：判断字符串是否表示数值。 LeetCode对应题目：剑指 Offer 20. 表示数值的字符串 19. 调整数组顺序使奇数位于偶数前面# 剑指Offer题目：调整数组顺序，使奇数位于偶数前面。 LeetCode对应题目：905. 按奇偶排序数组 20. 链表中倒数第k个节点# 剑指Offer题目：找到链表中倒数第k个节点。 LeetCode对应题目：剑指 Offer 22. 链表中倒数第k个节点 21. 反转链表# 剑指Offer题目：反转链表。 LeetCode对应题目：206. 反转链表 22. 合并两个排序的链表# 剑指Offer题目：合并两个排序的链表。 LeetCode对应题目：21. 合并两个有序链表 23. 树的子结构# 剑指Offer题目：判断一棵树是否是另一棵树的子结构。 LeetCode对应题目：剑指 Offer 26. 树的子结构 24. 二叉树的镜像# 剑指Offer题目：求二叉树的镜像。 LeetCode对应题目：226. 翻转二叉树 25. 对称的二叉树# 剑指Offer题目：判断一棵二叉树是否是对称的。 LeetCode对应题目：101. 对称二叉树 26. 顺时针打印矩阵# 剑指Offer题目：顺时针打印矩阵。 LeetCode对应题目：54. 螺旋矩阵 27. 包含min函数的栈# 剑指Offer题目：实现一个包含min函数的栈。 LeetCode对应题目：155. 最小栈 28. 栈的压入、弹出序列# 剑指Offer题目：判断一个序列是否是栈的弹出序列。 LeetCode对应题目：946. 验证栈序列 29. 从上到下打印二叉树# 剑指Offer题目：从上到下打印二叉树。 LeetCode对应题目：102. 二叉树的层序遍历 30. 二叉搜索树的后序遍历序列# 剑指Offer题目：判断一个序列是否是二叉搜索树的后序遍历序列。 LeetCode对应题目 ：剑指 Offer 33. 二叉搜索树的后序遍历序列 31. 二叉树中和为某一值的路径# 剑指Offer题目：找到二叉树中路径和等于某个值的路径。 LeetCode对应题目：113. 路径总和 II 32. 复杂链表的复制# 剑指Offer题目：复制复杂链表。 LeetCode对应题目：138. 复制带随机指针的链表 33. 二叉搜索树与双向链表# 剑指Offer题目：将二叉搜索树转换为双向链表。 LeetCode对应题目 ：426. 将二叉搜索树转化为排序的双向链表 34. 序列化二叉树# 剑指Offer题目：实现二叉树的序列化和反序列化。 LeetCode对应题目：297. 二叉树的序列化与反序列化 35. 字符串的排列# 剑指Offer题目：输出字符串的所有排列。 LeetCode对应题目：剑指 Offer 38. 字符串的排列 36. 数组中出现次数超过一半的数字# 剑指Offer题目：找到数组中出现次数超过一半的数字。 LeetCode对应题目：169. 多数元素 37. 最小的k个数# 剑指Offer题目：找到数组中最小的k个数。 LeetCode对应题目：剑指 Offer 40. 最小的k个数 38. 连续子数组的最大和# 剑指Offer题目：找到连续子数组的最大和。 LeetCode对应题目：53. 最大子数组和 39. 1～n整数中1出现的次数# 剑指Offer题目：统计1～n整数中1出现的次数。 LeetCode对应题目：233. 数字 1 的个数 40. 数字序列中某一位的数字# 剑指Offer题目：找到数字序列中某一位的数字。 LeetCode对应题目：400. 第 N 位数字 41. 把数组排成最小的数# 剑指Offer题目：把数组排成最小的数。 LeetCode对应题目：剑指 Offer 45. 把数组排成最小的数 42. 把数字翻译成字符串# 剑指Offer题目：把数字翻译成字符串。 LeetCode对应题目：91. 解码方法 43. 礼物的最大价值# 剑指Offer题目：在矩阵中寻找礼物的最大价值。 LeetCode对应题目：剑指 Offer 47. 礼物的最大价值 44. 最长不含重复字符的子字符串# 剑指Offer题目：找到最长不含重复字符的子字符串。 LeetCode对应题目：3. 无重复字符的最长子串 45. 丑数# 剑指Offer题目：找到第n个丑数。 LeetCode对应题目：264. 丑数 II 46. 第一个只出现一次的字符# 剑指Offer题目：找到第一个只出现一次的字符。 LeetCode对应题目：387. 字符串中的第一个唯一字符 47. 数组中的逆序对# 剑指Offer题目：统计数组中的逆序对。 LeetCode对应题目：剑指 Offer 51. 数组中的逆序对 48. 两个链表的第一个公共节点# 剑指Offer题目：找到两个链表的第一个公共节点。 LeetCode对应题目：160. 相交链表 49. 在排序数组中查找数字# 剑指Offer题目：在排序数组中查找某个数字出现的次数。 LeetCode对应题目 ：剑指 Offer 53 - I. 在排序数组中查找数字 I 50. 0～n-1中缺失的数字# 剑指Offer题目：找到0～n-1中缺失的数字。 LeetCode对应题目：268. 丢失的数字 51. 二叉搜索树的第k大节点# 剑指Offer题目：找到二叉搜索树的第k大节点。 LeetCode对应题目：剑指 Offer 54. 二叉搜索树的第k大节点 52. 二叉树的深度# 剑指Offer题目：求二叉树的深度。 LeetCode对应题目：104. 二叉树的最大深度 53. 平衡二叉树# 剑指Offer题目：判断一棵二叉树是否是平衡二叉树。 LeetCode对应题目：110. 平衡二叉树 54. 数组中数字出现的次数# 剑指Offer题目：找到数组中只出现一次的两个数字。 LeetCode对应题目：260. 只出现一次的数字 III 55. 数组中唯一只出现一次的数字# 剑指Offer题目：找到数组中唯一只出现一次的数字。 LeetCode对应题目：137. 只出现一次的数字 II 56. 和为s的两个数字# 剑指Offer题目：找到数组中两个数字，使得它们的和等于s。 LeetCode对应题目：剑指 Offer 57. 和为s的两个数字 57. 和为s的连续正数序列# 剑指Offer题目：找到所有和为s的连续正数序列。 LeetCode对应题目 ：剑指 Offer 57 - II. 和为s的连续正数序列 58. 翻转单词顺序# 剑指Offer题目：翻转句子中单词的顺序。 LeetCode对应题目：151. 反转字符串中的单词 59. 左旋转字符串# 剑指Offer题目：左旋转字符串。 LeetCode对应题目：剑指 Offer 58 - II. 左旋转字符串 60. 滑动窗口的最大值# 剑指Offer题目：找到滑动窗口中的最大值。 LeetCode对应题目：239. 滑动窗口最大值 61. 扑克牌中的顺子# 剑指Offer题目：判断扑克牌是否是顺子。 LeetCode对应题目：剑指 Offer 61. 扑克牌中的顺子 62. 圆圈中最后剩下的数字# 剑指Offer题目：圆圈中最后剩下的数字（约瑟夫环问题）。 LeetCode对应题目 ：剑指 Offer 62. 圆圈中最后剩下的数字 63. 股票的最大利润# 剑指Offer题目：计算股票的最大利润。 LeetCode对应题目：121. 买卖股票的最佳时机 64. 求1+2+…+n# 剑指Offer题目：求1+2+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 LeetCode对应题目：剑指 Offer 64. 求1+2+…+n 65. 不用加减乘除做加法# 剑指Offer题目：不用加减乘除做加法。 LeetCode对应题目：371. 两整数之和 66. 构建乘积数组# 剑指Offer题目：构建乘积数组。 LeetCode对应题目：238. 除自身以外数组的乘积 67. 把字符串转换成整数# 剑指Offer题目：把字符串转换成整数。 LeetCode对应题目：8. 字符串转换整数 (atoi) 68. 树中两个节点的最低公共祖先# 剑指Offer题目：找到树中两个节点的最低公共祖先。 LeetCode对应题目：236. 二叉树的最近公共祖先 以上是《剑指Offer》中部分题目与LeetCode上对应题目的对照表。由于LeetCode的题目库不断更新，可能会有新的题目与《剑指Offer》中的题目对应。建议在准备面试时，结合两本书的题目进行练习。\n"},{"id":60,"href":"/post/computer-science/algorithm/%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%85%B8150%E9%A2%98/","title":"面试经典 150 题","section":"Algorithm","content":"面试经典 150 题# 数组 / 字符串# ✅ 88 合并两个有序数组# ✅ 27 移除元素# ✅ 26 删除有序数组中的重复项# ✅ 80 删除有序数组中的重复项 II# ✅ 169 多数元素# ✅ 189 轮转数组# ✅ 121 买卖股票的最佳时机# 122 买卖股票的最佳时机 II# ✅ 55 跳跃游戏# ✅ 45 跳跃游戏 II# ✅ 274 H 指数# O(1) 时间插入、删除和获取随机元素# 除自身以外数组的乘积# 加油站# 分发糖果# 接雨水# ✅ 13 罗马数字转整数# 整数转罗马数字# ✅ 58 最后一个单词的长度# ✅ 14 最长公共前缀# ✅ 151 反转字符串中的单词# Z 字形变换# ✅ 28 找出字符串中第一个匹配项的下标# 文本左右对齐# 双指针# ✅ 125 验证回文串# ✅ 392 判断子序列# ✅ 167 两数之和 II - 输入有序数组# 盛最多水的容器# 三数之和# 滑动窗口# ✅ 长度最小的子数组# ✅ 无重复字符的最长子串# ✅ 串联所有单词的子串# 最小覆盖子串# 矩阵# ✅ 有效的数独# ✅ 螺旋矩阵# 旋转图像# ✅ 矩阵置零# ✅ 生命游戏# 哈希表# ✅ 383 赎金信# ✅ 205 同构字符串# ✅ 290 单词规律# ✅ 242 有效的字母异位词# ✅ 49 字母异位词分组# ✅ 1 两数之和# ✅ 202 快乐数# ✅ 219 存在重复元素 II# ✅ 128 最长连续序列# 区间# 汇总区间# 合并区间# 插入区间# 用最少数量的箭引爆气球# # 栈# ✅ 20 有效的括号# ✅ 71 简化路径# ✅ 155 最小栈# ✅ 150 逆波兰表达式求值# 基本计算器# 链表# ✅ 141 环形链表# ✅ 2 两数相加# ✅ 21 合并两个有序链表# ✅ 138 随机链表的复制# ✅ 92 反转链表 II# K 个一组翻转链表# ✅ 19 删除链表的倒数第 N 个结点# ✅ 82 删除排序链表中的重复元素 II# ✅ 61 旋转链表# ✅ 86 分隔链表# ✅ 146 LRU 缓存# 二叉树# ✅ 104 二叉树的最大深度# 104. 二叉树的最大深度 ✅ 100 相同的树# 100. 相同的树 ✅ 226 翻转二叉树# 226. 翻转二叉树 ✅ 101 对称二叉树# 101. 对称二叉树 ✅ 105 从前序与中序遍历序列构造二叉树# 105. 从前序与中序遍历序列构造二叉树 ✅ 106 从中序与后序遍历序列构造二叉树# 106. 从中序与后序遍历序列构造二叉树 ✅ 117 填充每个节点的下一个右侧节点指针 II# 117. 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表# ✅ 路径总和# 求根节点到叶节点数字之和# 二叉树中的最大路径和# 二叉搜索树迭代器# 完全二叉树的节点个数# 二叉树的最近公共祖先# 二叉树层次遍历# ✅ 199 二叉树的右视图# 199.二叉树的右视图 ✅ 637 二叉树的层平均值# 637. 二叉树的层平均值 ✅ 二叉树的层序遍历# ✅ 二叉树的锯齿形层序遍历# 103.二叉树的锯齿形层序遍历 ✅ 二叉搜索树# ✅ 二叉搜索树的最小绝对差# ✅ 二叉搜索树中第 K 小的元素# 验证二叉搜索树# 图# ✅ 200 岛屿数量# 200.岛屿数量 被围绕的区域# 克隆图# 除法求值# 课程表# 课程表 II# 图的广度优先搜索# 909 蛇梯棋# 909 蛇梯棋 官方题解\nclass Solution { public int snakesAndLadders(int[][] board) { int n = board.length; boolean[] vis = new boolean[n * n + 1]; // 广度优先使用队列 Queue\u0026lt;int[]\u0026gt; queue = new LinkedList\u0026lt;int[]\u0026gt;(); // int[0] cell的序号 // int[1] 到达这个cell所需要的步数 queue.offer(new int[]{1, 0}); while (!queue.isEmpty()) { int[] p = queue.poll(); // 遍历6个可能下棋的位置 for (int i = 1; i \u0026lt;= 6; ++i) { int nxt = p[0] + i; if (nxt \u0026gt; n * n) { // 超出边界 break; } int[] rc = id2rc(nxt, n); // 得到下一步的行列 if (board[rc[0]][rc[1]] \u0026gt; 0) { // 存在蛇或梯子 nxt = board[rc[0]][rc[1]]; } if (nxt == n * n) { // 到达终点 return p[1] + 1; } if (!vis[nxt]) { vis[nxt] = true; queue.offer(new int[]{nxt, p[1] + 1}); // 扩展新状态 } } } return -1; } public int[] id2rc(int id, int n) { int r = (id - 1) / n, c = (id - 1) % n; if (r % 2 == 1) { c = n - 1 - c; } return new int[]{n - 1 - r, c}; } }最小基因变化# 最小基因变化 方法一：广度优先搜索# 官方题解\nclass Solution { public int minMutation(String start, String end, String[] bank) { Set\u0026lt;String\u0026gt; cnt = new HashSet\u0026lt;String\u0026gt;(); Set\u0026lt;String\u0026gt; visited = new HashSet\u0026lt;String\u0026gt;(); char[] keys = {\u0026#39;A\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;T\u0026#39;}; for (String w : bank) { cnt.add(w); } if (start.equals(end)) { return 0; } if (!cnt.contains(end)) { return -1; } Queue\u0026lt;String\u0026gt; queue = new ArrayDeque\u0026lt;String\u0026gt;(); queue.offer(start); visited.add(start); int step = 1; while (!queue.isEmpty()) { int sz = queue.size(); for (int i = 0; i \u0026lt; sz; i++) { String curr = queue.poll(); for (int j = 0; j \u0026lt; 8; j++) { for (int k = 0; k \u0026lt; 4; k++) { // 24种变异 if (keys[k] != curr.charAt(j)) { StringBuffer sb = new StringBuffer(curr); sb.setCharAt(j, keys[k]); String next = sb.toString(); if (!visited.contains(next) /*没有遍历过*/ \u0026amp;\u0026amp; cnt.contains(next) /*在基因库中*/) { if (next.equals(end)) { return step; } // 在基因库中，但不是目标值 queue.offer(next); visited.add(next); } } } } } step++; } return -1; } }方法二：预处理优化# 官方题解\nclass Solution { public int minMutation(String start, String end, String[] bank) { int m = start.length(); int n = bank.length; List\u0026lt;Integer\u0026gt;[] adj = new List[n]; for (int i = 0; i \u0026lt; n; i++) { adj[i] = new ArrayList\u0026lt;Integer\u0026gt;(); } int endIndex = -1; for (int i = 0; i \u0026lt; n; i++) { // 记录目标基因序列在基因库中的下标 if (end.equals(bank[i])) { endIndex = i; } for (int j = i + 1; j \u0026lt; n; j++) { int mutations = 0; for (int k = 0; k \u0026lt; m; k++) { if (bank[i].charAt(k) != bank[j].charAt(k)) { mutations++; } if (mutations \u0026gt; 1) { break; } } // 记录基因库中每个基因序列可以进行的有效基因变异 if (mutations == 1) { adj[i].add(j); adj[j].add(i); } } } // 目标基因序列不再基因库中 if (endIndex == -1) { return -1; } Queue\u0026lt;Integer\u0026gt; queue = new ArrayDeque\u0026lt;Integer\u0026gt;(); boolean[] visited = new boolean[n]; int step = 1; for (int i = 0; i \u0026lt; n; i++) { int mutations = 0; for (int k = 0; k \u0026lt; m; k++) { if (start.charAt(k) != bank[i].charAt(k)) { mutations++; } if (mutations \u0026gt; 1) { break; } } // 如果执行到这里，说明初始基因序列可以通过一次有效变异为当前遍历的基因库序列 // 队列记录的是一次有效变异可变的基因序列下标（在基因库中的下标） if (mutations == 1) { queue.offer(i); visited[i] = true; } } while (!queue.isEmpty()) { int sz = queue.size(); for (int i = 0; i \u0026lt; sz; i++) { int curr = queue.poll(); if (curr == endIndex) { return step; } for (int next : adj[curr]) { if (visited[next]) { continue; } visited[next] = true; queue.offer(next); } } step++; } return -1; } }单词接龙# ✅ 字典树# ✅ 208 实现 Trie (前缀树)# 208 实现 Trie (前缀树) ✅ 211 添加与搜索单词 - 数据结构设计# 211 添加与搜索单词 - 数据结构设计 ✅ 212 单词搜索 II# 212 单词搜索 II ✅ 回溯# ✅ 电话号码的字母组合# ✅ 组合# ✅ 全排列# ✅ 组合总和# ✅ N 皇后 II# ✅ 括号生成# ✅ 单词搜索# 分治# ✅ 108 将有序数组转换为二叉搜索树# 108 将有序数组转换为二叉搜索树 148 排序链表# 148 排序链表 建立四叉树# 合并 K 个升序链表# Kadane 算法# 最大子数组和# 环形子数组的最大和# 二分查找# 搜索插入位置# 搜索二维矩阵# 寻找峰值# 搜索旋转排序数组# 在排序数组中查找元素的第一个和最后一个位置# 寻找旋转排序数组中的最小值# 寻找两个正序数组的中位数# 堆# 数组中的第K个最大元素# IPO# 查找和最小的 K 对数字# 数据流的中位数# 位运算# 二进制求和# 颠倒二进制位# 位1的个数# 只出现一次的数字# 只出现一次的数字 II# 数字范围按位与# 数学# ✅ 9 回文数# ✅ 66 加一# ✅ 172 阶乘后的零# ✅ 69 x 的平方根# 50 Pow(x, n)# 149 直线上最多的点数# 一维动态规划# ✅ 爬楼梯# 打家劫舍# 单词拆分# 零钱兑换# 最长递增子序列# 多维动态规划# 三角形最小路径和# 最小路径和# 不同路径 II# 最长回文子串# 交错字符串# 编辑距离# 买卖股票的最佳时机 III# 买卖股票的最佳时机 IV# 最大正方形# "},{"id":61,"href":"/post/life/goal/","title":"goal","section":"Life","content":"goal# 2025-01-12# 过年前完成(1月24日内) 面试经典150题(一天完成5道题, 应该完成70道题左右) Spring实战 第6版 Book (读完这本书) 清华韩秀云精品课（第一季，64集）(大概应该看到56集) 美国困局：“新右翼” 的兴起与挑战 (读完这本书) OAuth 2 in Action Microservices Security in Action API Security in Action ActiveMQ in Action RabbitMQ in Depth（Manning，2017年） Alvaro Videla和Jason J.W. Williams合著的RabbitMQ in Action（Manning，2012年） Kafka in Action （Manning，2017年） Enterprise Integration Patterns（Addison-Wesley，2003年） Functional Programming in Java（Manning，2017年） Grokking Functional Programming（Manning，2021年） "},{"id":62,"href":"/post/life/coffee/","title":"coffee","section":"Life","content":"coffee# 咖啡碎碎念#1 一次探店2家上海“天花板”咖啡馆？！喝到一半老板直接开始上课？#上海VLOG（上） 科普丨意式咖啡傻傻分不清？10分钟带你全部看懂 马克西姆咖啡机 马克西姆使用评测（上）3000+价位段最值得入手半自动意式咖啡机一体机 马克西姆咖啡机评测（下）使用成本低是最好的入手理由 马克西姆咖啡机用了一年，总结出5个使用技巧 马克西姆半自动家用咖啡机，如何调试和定量出品，掌握核心2点，控制好粉重和粉液比 "},{"id":63,"href":"/post/computer-science/database/mongodb/","title":"Penruins","section":"Database","content":"mongodb# "},{"id":64,"href":"/post/blog/2025/2025-03-31-shardingsphere-prometheus-%E9%85%8D%E7%BD%AE/","title":"2025 03 31 Shardingsphere Prometheus 配置","section":"Posts","content":"2025-03-31-Shardingsphere-prometheus-配置# 把 shardingsphere proxy 搭建好之后，想要把监测数据放到 grafana里面进行监测，但是按照找到的资料来配置好像都不太行，自己研究了一下启动脚本，现在可以正常获取到指标数据了，所以花点时间把这个问题记录一下\n下载了官网提供的 shardingsphere-proxy 的包之后，里面其实已经包含了 agent 相关的 jar 包以及插件相关的 jar 包，其实不需要再下载一个 shardingsphere-agent\n我们需要配置一下agent.yaml里面的内容，文件的位置在 apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/agent/conf/agent.yaml，现在只需要配置 prometheus，所以如下所示\nplugins: metrics: Prometheus: host: \u0026#34;localhost\u0026#34; port: 9000 props: jvm-information-collector-enabled: \u0026#34;true\u0026#34;在 prometheus 的配置文件中需要加上 9000 的指标接口（如果是使用 brew 安装的话，配置文件在这个位置 /opt/homebrew/etc/prometheus.yml）\nscrape_configs: - job_name: \u0026#39;shardingsphere\u0026#39; static_configs: - targets: [\u0026#39;localhost:9000\u0026#39;]网上查到的这篇文章 Apache ShardingSphere Agent 可观察性实用指南 提到需要修改脚本文件，其实是不用修改的，只需要夹一个参数 --agent 就可以\n需要注意的是运行的目录需要在 shardingsphere-proxy 的根目录下，因此命令如下所示\nsh bin/start.sh 5555 --agent查看日志 vim logs/stdout.log 打印的应该如下所示\nMar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-metrics-prometheus-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-tracing-opentelemetry-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-metrics-core-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-plugin-core-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-logging-file-5.5.2.jar [INFO ] 2025-03-31 18:07:38.772 [main] o.a.s.d.p.c.l.PipelineContextManagerLifecycleListener - mode type is not Cluster, mode type=\u0026#39;Standalone\u0026#39;, ignore [INFO ] 2025-03-31 18:07:38.786 [main] o.a.s.p.v.ShardingSphereProxyVersion - Database type is `MySQL`, version is `8.0.41`, database name is `sharding_db` [INFO ] 2025-03-31 18:07:38.786 [main] o.a.s.p.frontend.ssl.ProxySSLContext - Proxy frontend SSL/TLS is not enabled. [INFO ] 2025-03-31 18:07:38.836 [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy Standalone mode started successfully这个时候需要查询一下数据库，agent才会把服务启起来\n[INFO ] 2025-03-31 18:08:14.258 [nioEventLoopGroup-3-1] o.a.s.a.c.p.PluginLifecycleServiceManager - Start plugin: Prometheus [INFO ] 2025-03-31 18:08:14.290 [nioEventLoopGroup-3-1] o.a.s.a.p.m.p.PrometheusPluginLifecycleService - Prometheus metrics HTTP server `localhost:9000` start success.日志如上打印之后，agent就真正启动了。访问 http://localhost:9000/metrics 可以看到返回了指标数据\nReference# 可观察性的使用 官方文档 Apache ShardingSphere Agent 可观察性实用指南 "},{"id":65,"href":"/post/blog/2025/2025-08-07-%E5%B9%BF%E5%B7%9E%E7%94%9F%E6%B4%BB/","title":"2025 08 07 广州生活","section":"Posts","content":"2025-08-07 广州生活# 华南植物园 交通方式：6号线坐到植物园站 感觉温室很值得逛，有好几个温室馆(热带雨林植物室、高山/极地植物室、沙漠植物室、奇异植物室) 二沙岛 骑车不错，可以在草坪上露营，在桥的地下有一个健身打乒乓球🏓的，有很多乒乓球桌，打球的人也很多。星海音乐厅就在二沙岛上 好像新的地铁通车有一站可以直接到二沙岛 鱼珠码头 自行车电动车也可以上船，刷地铁的码就行（车刷一次，人刷一次） 如果要去大学城或者去生物岛骑车，就要到鱼珠码头去坐车（不然从海珠区那边绕过去太远了。。。。如果体力好也可以这么做） 生物岛 骑车绕圈，路况很好 陈家祠 里面的木雕，象牙雕，屋顶上的雕像都很有特色。相比起广东省博物馆，陈家祠更值得去 广州动物园 水獭🦦，卡皮巴拉，蛇🐍有很多种类 大熊猫馆有几只大熊猫🐼，里面有空调（果然国宝的待遇就是不一样） 小熊猫在高高的树上，要仔细找一找才看得到 去的那天天气太热了，动物们都懒羊羊的在睡觉 如果坐5号线到动物园站，是从南门进，从南到北逛动物园，最后还要绕回南门坐地铁。 白云山 天气凉快一点可以考虑去 广州美术馆 交通 如果是坐5号线出发的话，坐到珠江新城后转3号线坐一站到广州塔，然后走一小段路就到美术馆了 美术馆不需要预约，直接去就行了 海鸥岛 有点远，看看后面计划一下怎么去 永庆坊 流花湖公园 越秀公园 如果是逛完南越王古墓博物馆去越秀公园, 博物馆出大门往右边走第一个十字路口过到街对面（博物馆的街对面）, 就有一个越秀公园的入口可以进入。这个入口离羊雕像很近，爬一段楼梯就到了。 公园里有几个湖；里面的路有些起伏，一会儿上坡一会儿下坡；走路散步还是很舒服的；遇到了很多小猫 图书馆 黄埔区图书馆 大沙馆 经常去这个图书馆自习，周三闭馆，1楼的自习区开放到晚上21点，其他区域到18点 黄埔区图书馆 香雪馆 大沙馆更豪华，有很多座位下面都有插座 一楼有介绍黄埔区的展览陈列，拍了一些黄埔区行政区划相关的图片 广州市图书馆 人真的太多了。。。位置就在广东省博物馆的旁边 层数很多，书的种类也很多。在二楼停留了一会儿，就兰花养殖的书就有好几排书架 博物馆 广东省博物馆 需要在博物馆的公众号提前预约，晚上22点放票。但当天去的时候好像不预约也行，但是需要买票。 有一部分的展品和陈家祠是重合的（木雕，象牙雕，祠堂相关的文物），种类没有陈家祠的丰富 广东革命历史博物馆 南越王古墓博物馆 2025-08-16 进馆需要10元的门票，可在微信小程序上买票（进馆好像不限流，我当天早上买的票，下午去的）。但是到古墓下面需要预约，这个不需要钱，但不好预约到 博物馆主要是逛几个主题展，以及在古墓的上方有一圈栈道，可以走走一圈看看下面是什么样子（下去需要预约）；有一个炮台可以走上去看看，上面有一颗很大的树，有几个大炮的金属制的模型 其他 南越是秦朝灭亡之后建立，在汉武帝的时候被征服由汉朝中央管辖。也就是说，这是一段公元前的历史。好像滇国也是在汉武帝的时候被征服的 广州十三行博物馆 中山大学生物博物馆 广州迪士普音响博物馆 周边城市 香港 澳门 北海 长沙 海口 上海 杭州 武汉 上饶 岳阳 九江 南昌 骑行# 科学城体育公园 广州休闲骑行路线推荐｜广州科学城体育公园 "},{"id":66,"href":"/post/blog/2025/2025-08-26-ssh-%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/","title":"2025 08 26 SSH 端口转发","section":"Posts","content":"2025-08-26 ssh 进行端口转发# 如果你的网络连接是这样的：你当前的电脑是 Network-Node-1, 可以通过 ssh 连接服务器 Server-1, Server-1 可以通过 ssh 连接 Server-2, 和 Server-3，Server-2 和 Server-3 也是相互联通的。但是 Network-Node-1 不能直接连接 Server-2 和 Server-3。\n如果在 Server-2 或者 Server-3 上部署了一些服务(例如数据库)，你会如何连接这些服务呢？\n这个时候最好的方法就是使用端口转发\n在 ~/.ssh/config 中进行配置\nHost test HostName Server-1 User myuser Port 22 LocalForward 18001 Server-2:22 # Server-2 ssh LocalForward 18002 Server-3:22 # Server-3 ssh LocalForward 18003 Server-2:3306 # mysql文件保存之后执行 ssh test, 接下来输入密码就会通过 ssh 连接到 Server-1, 这个时候你所看到的和普通的 ssh 连接没有什么区别，但实际上它进行了端口转发。保留当前这个窗口不关闭，使用 ip 为 localhost，端口为 18001 和 18002, 可以在 Network-1 直接连接 Server-2 和 Server-3, 同时也可以通过 localhost:3306 连接在 Server-2 上部署的 mysql 服务\n"},{"id":67,"href":"/post/blog/2025/2025-10-09-nginx-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"2025 10 09 Nginx 使用技巧","section":"Posts","content":"不知道 nginx 的配置文件在哪里# find / -name \u0026#34;*nginx*\u0026#34;基本操作# 启动 ./nginx 停止运行 ./nginx -s stop "},{"id":68,"href":"/post/blog/2025/2025-10-27-spring-ai-%E5%AD%A6%E4%B9%A0/","title":"2025 10 27 Spring Ai 学习","section":"Posts","content":"Spring AI 学习 (2025-10-27)# 项目地址 penruins/spring-ai-demo test# curl -X POST \u0026#39;http://localhost:8080/chat/test/1\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;question\u0026#34;: \u0026#34;云南省的省会是哪里?\u0026#34;}\u0026#39;reference# Spring AI 进阶之路01：三步将 AI 整合进 Spring Boot ThomasVitale/llm-apps-java-spring-ai Samples showing how to build Java applications powered by Generative AI and Large Language Models (LLMs) using Spring AI. 零基础入门Spring AI "},{"id":69,"href":"/post/blog/2025/2025-10-29-idea-proxy/","title":"2025 10 29 Idea Proxy","section":"Posts","content":"idea 过代理抓包# 最近在研究 spring AI，对框架如何调用模型的接口构造参数比较感兴趣，就想在运行程序的时候抓包看一下调用接口的参数。在 IntelliJ Idea 中运行的程序需要单独配置代理（我用的抓包工具是 Charles），这篇文章把我配置的笔记整理一下\n在 charles 中导出证书文件 .cer 或者 .pem 拓展名\n然后执行如下命令，将证书导入到 java 的证书中\n\u0026#34;$JAVA_HOME\\bin\\keytool.exe -import -file $CHARLES_CERTIFICATE_PATH -keystore $JAVA_HOME\\security\\cacerts -alias charles_cert # 命令执行会要求输入密码，请记住这个密码 $CHARLES_CERT_PASSWORD在 idea 项目的配置中加上如下的 jvm 参数\n-Djavax.net.ssl.trustStore=\u0026#34;$JAVA_HOME\\security\\cacerts\u0026#34; -Djavax.net.ssl.trustStorePassword=\u0026#34;$CHARLES_CERT_PASSWORD\u0026#34; -DproxySet=true -DproxyHost=127.0.0.1 -DproxyPort=8887reference# How do I hook up Charles with IntelliJ? "},{"id":70,"href":"/post/computer-science/cloud/","title":"Cloud","section":"Computer Science","content":"cloud\n"},{"id":71,"href":"/post/computer-science/micro-service/nacos/","title":"Nacos","section":"Micro Service","content":"关于 Nacos 配置更新后避免 HikariCP 连接断开的问题# 解决方案# 使用 @RefreshScope(proxyMode = ScopedProxyMode.NO) 排除数据源# @Configuration @RefreshScope(proxyMode = ScopedProxyMode.NO) public class DataSourceConfig { // 数据源配置 }自定义 RefreshScope 排除数据源相关配置# @Bean public RefreshScope refreshScope() { RefreshScope scope = new RefreshScope(); scope.setExcludeNames(new String[]{\u0026#34;dataSource\u0026#34;, \u0026#34;hikariDataSource\u0026#34;}); return scope; }在 bootstrap.yml 中排除特定配置的刷新# spring: cloud: nacos: config: refresh-enabled: true refreshable-data-sources: none # 不刷新数据源配置使用 @RefreshScope 但不刷新数据源# @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource.hikari\u0026#34;) @RefreshScope(proxyMode = ScopedProxyMode.NO) public HikariDataSource dataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); }最佳实践# 分离配置：将数据库配置和其他频繁变动的配置分开，放在不同的配置文件中 版本控制：对数据库配置的修改应该通过版本控制和应用重启来完成，而不是热更新 监控：即使解决了这个问题，也应该监控数据库连接池状态 注意事项# 这些解决方案可能会因 Spring Boot/Cloud 版本不同而有所差异 在生产环境实施前应在测试环境充分验证 如果确实需要动态修改数据库配置，建议使用更优雅的方式如多数据源切换 "},{"id":72,"href":"/post/life/blog-recommend/","title":"Blog Recommend","section":"Life","content":"Blog Recommend# 当然我在扯淡 王垠 yihong0618 阮一峰的网络日志 每周都会更新 科技爱好者周刊 编程随想的博客 云风的 BLOG 羡辙杂俎 AnthonyFu一个托尼 Hank\u0026rsquo;s Blog obsidian-weread-plugin 的作者 郭宇 ninghao.net Thomas Vitale Software Engineer | Java | Cloud Native | Developer Experience plantegg Honesty Blog 信鑫 Blog "},{"id":73,"href":"/post/life/video-recommend/","title":"Video Recommend","section":"Life","content":"Video Recommend# 2025-03-30 投资是怎样赚钱的？ "},{"id":74,"href":"/post/others/economy/","title":"Economy","section":"Others","content":"2025 反内卷# 本轮反内卷法治化与市场化结合，上一轮去产能主要以行政主导模式 #财经-2025-16 上一轮去产能，中央设定产能淘汰硬指标（如钢铁去产能1.5亿吨），纳入地方政府考核体系，通过“一刀切”关停、限产实现快速出清。 本轮“反内卷”政策，具有一系列明确的法律约束，即新修订的《反不正当竞争法》明确禁止“低于成本价倾销”，建立公平竞争审查制度。 同时，更为注重市场引导：通过产能置换指标交易（如水泥行业每新增1吨产能需退出1.5吨旧产能）、行业协会自律倡议（如光伏企业集体减产30%）实现渐进式出清。 同时，上一轮去产能主要为国企主导实施。国有企业承担80%钢铁去产能任务，政策执行刚性强。本轮行业“反内卷”，新兴行业（如光伏、汽车等）民企占比超70%，政策更依赖行业自发协调（如中汽协倡议统一供应商账期）而非行政命令。 同时，面对的行业也不一样。本轮“反内卷”所对应的是部分先进制造业。由于部分先进制造业出海，前期按照全球需求进行产能布局，外需回落或暂时的贸易壁垒才加剧了供需错配压力。 本轮行业“反内卷”面临总需求疲软，通货紧缩的宏观背景；上一轮去产能时，需求端支撑，价格传导顺畅。 对一些工业和制造业行业而言，“反内卷”也势必将导致一定程度的“去产能”。但不意味着以“去产能”为核心目的来推动“反内卷”，更不适合刚性的以产量和投资下降等产能去化指标来衡量“反内卷”效果。由于本轮调整的行业范围与性质较上一轮更为复杂，“反内卷”必须坚持以纠正市场失灵，建立公平竞争的市场秩序为最终目标的改革思路，而不能变成新一轮的行政性“去产能”。本轮行业反内卷的核心是提质，走高质量发展道路，而非简单的“去产能”。 什么是适度宽松的货币政策？# 通货膨胀为什么有利于企业提高利润？# 通货膨胀在一定条件下可能对企业利润产生积极影响，主要原因如下：\n1. 价格上涨带动收入增长# 产品提价能力：通货膨胀推高整体价格水平时，企业可能将成本上涨（如原材料、人工）转嫁给消费者，提高产品售价。若需求弹性较小（消费者对价格不敏感），销售收入增长会快于成本增长，从而扩大利润空间。 名义收入增加：即使实际销量不变，价格上涨会直接推高企业的名义收入，在财务报表上体现为利润上升。 2. 债务实际价值下降# 减轻债务负担：企业若持有固定利率债务，通货膨胀会降低债务的实际价值（未来偿还的货币购买力下降）。例如，企业借入100万元，通胀率为10%时，第二年这笔债务的实际价值相当于约90万元，变相减少企业负担。 杠杆效应：资产价值随通胀上升，而负债名义值不变，可能改善企业资产负债表，增强融资能力。 3. 库存收益（存货利润）# 前期低成本库存增值：持有大量原材料或成品库存的企业，在通胀期间可按更高价格出售库存，形成“存货利润”。例如，以低价购入的原材料在生产后以高价卖出，利润被放大。 会计利润提升：在先进先出（FIFO）会计方法下，早期低成本库存被先计入成本，当期收入按高价匹配，利润虚增（但需注意税务影响）。 4. 刺激消费与投资需求# 提前消费：若消费者预期未来价格继续上涨，可能提前购买商品，短期提振企业销量。 资产升值预期：通胀环境下，企业持有的不动产、设备等资产名义价值上升，可能通过资产重估或抵押贷款获得额外收益。 5. 工资调整滞后# 人工成本暂时偏低：工资调整通常滞后于物价上涨，短期内企业用工成本实际下降，利润率扩大（但长期可能引发员工不满或劳动力流失）。 需注意的风险与限制：# 成本传导不畅：若市场竞争激烈或需求疲软，企业无法完全转嫁成本，利润反而受压。 恶性通胀破坏经济：持续高通胀会导致消费者购买力锐减、供应链混乱，最终损害企业长期经营。 利率上升压力：央行可能加息抑制通胀，增加企业融资成本。 总结：# 通货膨胀对企业利润的促进作用主要体现在价格传导能力、债务稀释和库存收益等方面，但高度依赖行业特性、市场结构和通胀程度。合理利用通胀环境可提升短期利润，但企业需警惕长期经济失衡风险。\nmess# 沿海地区高歌猛进的人工智能、大模型、具身智能、物联网、工业互联网等等，必将给内地相对传统的产业进一步赋能，带来进一步的效率提升 "},{"id":75,"href":"/post/blog/2025/2025-%E5%B9%BF%E5%B7%9E-%E6%89%BE%E5%B7%A5%E4%BD%9C/","title":"2025 广州 找工作","section":"Posts","content":"2025 广州 找工作# 面试记录# 2025-03-21 网易游戏商城-充值 第一面 未通过# 在生产环境下如何给一张表添加索引？ 数据库的ACID有了解吗？ kafka如何保证消息的有序性？ redis的集群模式有哪些？ 2025-03-19 探迹科技-后台开发python 技术复试 通过# 开发的模块的QPS是多少？ Netty的线程模式是怎样的？(简历中提到了使用了Netty作为tcp连接的框架) 如果商城中有10亿个商品，每天的活跃用户平均有1000w，每个用户平均每天会浏览10个商品，如何在数据库中保存浏览记录？ 你的职业规划是怎样的？ 反问 为什么要是属于python作为后台开发的语言？ 2025-03-12 探迹科技-后台开发python 技术初面 通过# 开发的模块的QPS是多少？ 有一个很长的整数数组，给定一个整数total，返回2个下标，使得下标对应的两个元素相加等于total，要怎么实现？ HashMap 底层的数据结构是怎样的？ HashMap 是线程安全的吗？如何保证它线程安全？ 主从数据库是如何进行数据同步的？ 有没有关注什么新技术？ "},{"id":76,"href":"/post/life/article/","title":"article","section":"Life","content":" 2025-03-31-Shardingsphere-prometheus-配置 2025-广州-找工作 2025-03-29 教育到底怎么了？ 2025-03-16 能找到工作吗？ "},{"id":77,"href":"/post/science/biology/","title":"biology","section":"Science","content":"线粒体# 线粒体的任务很简单：把我们吃下去的糖和脂肪，转化为细胞可以使用的能量分子，ATP。没有它，人的心跳会停、呼吸会断，连神经之间的信息传导都无法完成。它是生命体内最基础，却最不可或缺的“动力单元”。 不同于细胞中大多数基因都储存在细胞核里，线粒体有一套独立的小型基因组，叫线粒体DNA（mtDNA）。更特别的是，这套遗传信息几乎完全来自母亲。 线粒体病# PGT（胚胎植入前遗传学检测） 通过筛选胚胎中mtDNA突变比例较低者进行移植，相当于在一组不确定选项中，谨慎地挑出那个最可能避开疾病的“好签”； 该方法前提 女性体内必须存在多个突变水平较低的胚胎可供选择。对于mtDNA突变比例极高的女性来说，PGT往往无解，她们体内根本没有“可选项”。 PNT（原核移植） 则是在受精刚完成的原核阶段，将父母的细胞核移植进一枚去核的健康捐赠卵子中，从源头更换线粒体，完成一次细胞层级的“偷天换日”。 科学家将受精卵中的细胞核DNA转移到一枚健康女性捐赠的、已去核的卵子中，保留父母遗传信息，更换线粒体“供能系统”。这就产生了所谓的“三亲婴儿”，孩子的细胞核来自父母，而线粒体DNA来自第三方女性捐赠者。 争议 伦理争议的焦点并不仅仅在于“这是不是改造”，更在于“它会不会成为一个滑坡起点”。一旦社会接受了“为了避免疾病可以更换DNA”，是否也会接受“为了提高素质可以优化DNA”？当修改线粒体成为合法选项，是否也会让“定制婴儿”的概念顺势潜入现实？尤其是在资源分配不平等的世界中，技术本身中立，使用它的人却未必如此。 现实中，各国对这项技术的态度明显分化。英国在2015年成为全球首个立法批准线粒体捐赠治疗的国家，并设置了严格的个案审批机制。澳大利亚、乌克兰等国也在特定框架内尝试推进。而美国则态度保守，至今不允许在临床中使用会遗传改变的胚胎技术，相关研究只能停留在实验室层面。 "},{"id":78,"href":"/post/computer-science/crawler/","title":"crawler","section":"Computer Science","content":"crawler# 针对豆瓣反爬问题的讨论 从豆瓣的反爬说说自建代理池 "},{"id":79,"href":"/post/computer-science/ci-cd/docker/","title":"docker","section":"CI/CD","content":"# centos 操作系统环境下 # docker 启动 systemctl start docker # docker 重启 systemctl restart docker # docker 停止 systemctl stop docker # docker 运行状态 systemctl status docker # 进入容器中 docker exec -it \u0026lt;container-name\u0026gt; /bin/bash # 查看本地镜像 docker images # 当前有哪些容器在运行 docker ps # docker 中有哪些容器，包括在运行以及已停止的 docker ps -a如何开启 debug 模式# # 编辑文件 sudo vim /etc/systemd/system/docker.service.d/debug.conf # 添加或修改以下内容 [Service] ExecStart= ExecStart=/usr/bin/dockerd --debug # 重新加载 systemd 配置并重启 Docker sudo systemctl daemon-reload sudo systemctl restart docker"},{"id":80,"href":"/post/others/f1/","title":"F1","section":"Others","content":" Chester117 合集·F1分钟小知识 我亲手搓了一条F1轮胎 "},{"id":81,"href":"/post/computer-science/ci-cd/gitlab/","title":"Gitlab","section":"CI/CD","content":" Gitlab 安装和配置 "},{"id":82,"href":"/post/books/computer-science/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/","title":"Java并发编程实战","section":"Computer Science","content":" Java并发编程实战 第1章 简介# 1.1 并发简史# 1.2 线程的优势# 1.3 线程带来的风险# 1.4 线程无处不在# 开发线程安全的类比开发非线程安全的类要更加谨慎和细致 每个Java应用程序都会使用线程 当JVM启动时，它将为JVM的内部任务（例如，垃圾收集、终结操作等）创建后台线程，并创建一个主线程来运行main方法。 AWT（Abstract Window Toolkit，抽象窗口工具库）和Swing的用户界面框架将创建线程来管理用户界面事件。 Timer将创建线程来执行延迟任务。 一些组件框架，例如Servlet和RMI，都会创建线程池并调用这些线程中的方法。 当某个框架在应用程序中引入并发性时，通常不可能将并发性仅局限于框架代码，因为框架本身会回调（Callback）应用程序的代码，而这些代码将访问应用程序的状态。 对线程安全性的需求也不能局限于被调用的代码，而是要延伸到需要访问这些代码所访问的程序状态的所有代码路径。因此，对线程安全性的需求将在程序中蔓延开来。 第2章 线程安全性# 要编写线程安全的代码，其核心在于要对状态访问操作进行管理，特别是对共享的（Shared）和可变的（Mutable）状态的访问。 “共享”意味着变量可以由多个线程同时访问，而“可变”则意味着变量的值在其生命周期内可以发生变化。 一个对象是否需要是线程安全的，取决于它是否被多个线程访问 当多个线程访问某个状态变量并且其中有一个线程执行写入操作时，必须采用同步机制来协同这些线程对变量的访问。 Java中的主要同步机制是关键字synchronized，它提供了一种独占的加锁方式，但“同步”这个术语还包括volatile类型的变量，显式锁（Explicit Lock）以及原子变量。 2.1 什么是线程安全性# 在线程安全性的定义中，最核心的概念就是正确性。如果对线程安全性的定义是模糊的，那么就是因为缺乏对正确性的清晰定义。 正确性的含义是，某个类的行为与其规范完全一致。在良好的规范中通常会定义各种不变性条件（Invariant）来约束对象的状态，以及定义各种后验条件（Postcondition）来描述对象操作的结果。 线程安全性：当多个线程访问某个类时，这个类始终都能表现出正确的行为，那么就称这个类是线程安全的。 当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 在线程安全类中封装了必要的同步机制，因此客户端无须进一步采取同步措施。 无状态对象一定是线程安全的 大多数Servlet都是无状态的，从而极大地降低了在实现Servlet线程安全性时的复杂性。只有当Servlet在处理请求时需要保存一些信息，线程安全性才会成为一个问题。 2.2 原子性# 在并发编程中，这种由于不恰当的执行时序而出现不正确的结果是一种非常重要的情况，它有一个正式的名字：竞态条件（Race Condition） 2.2.1 竞态条件# 当某个计算的正确性取决于多个线程的交替执行时序时，那么就会发生竞态条件。换句话说，就是正确的结果要取决于运气 “先检查后执行”：首先观察到某个条件为真（例如文件X不存在），然后根据这个观察结果采用相应的动作（创建文件X），但事实上，在你观察到这个结果以及开始创建文件之间，观察结果可能变得无效（另一个线程在这期间创建了文件X），从而导致各种问题（未预期的异常、数据被覆盖、文件被破坏等）。 2.2.2 示例：延迟初始化中的竞态条件# 延迟初始化的目的是将对象的初始化操作推迟到实际被使用时才进行，同时要确保只被初始化一次。 假定线程A和线程B同时执行getInstance。A看到instance为空，因而创建一个新的ExpensiveObject实例。B同样需要判断instance是否为空。此时的instance是否为空，要取决于不可预测的时序，包括线程的调度方式，以及A需要花多长时间来初始化ExpensiveObject并设置instance。如果当B检查时，instance为空，那么在两次调用getInstance时可能会得到不同的结果，即使getInstance通常被认为是返回相同的实例。 2.2.3 复合操作# 要避免竞态条件问题，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或之后读取和修改状态，而不是在修改状态的过程中。 假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。 原子操作是指，对于访问同一个状态的所有操作（包括该操作本身）来说，这个操作是一个以原子方式执行的操作。 在java.util.concurrent.atomic包中包含了一些原子变量类，用于实现在数值和对象引用上的原子状态转换。通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问操作都是原子的。 当在无状态的类中添加一个状态时，如果该状态完全由线程安全的对象来管理，那么这个类仍然是线程安全的 当状态变量的数量由一个变为多个时，并不会像状态变量数量由零个变为一个那样简单 在实际情况中，应尽可能地使用现有的线程安全对象（例如AtomicLong）来管理类的状态。与非线程安全的对象相比，判断线程安全对象的可能状态及其状态转换情况要更为容易，从而也更容易维护和验证线程安全性。 2.3 加锁机制# 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。 2.3.1 内置锁# Java提供了一种内置的锁机制来支持原子性：同步代码块（Synchronized Block）。 以关键字synchronized来修饰的方法就是一种横跨整个方法体的同步代码块，其中该同步代码块的锁就是方法调用所在的对象。静态的synchronized方法以Class对象作为锁。 每个Java对象都可以用做一个实现同步的锁，这些锁被称为内置锁（Intrinsic Lock）或监视器锁（Monitor Lock） 2.3.2 重入# 当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞 由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。“重入”意味着获取锁的操作的粒度是“线程”，而不是“调用” 重入的一种实现方法是，为每个锁关联一个获取计数值和一个所有者线程。 当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1。如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。 2.4 用锁来保护状态# 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，在这种情况下，我们称状态变量是由这个锁保护的。 之所以每个对象都有一个内置锁，只是为了免去显式地创建锁对象。 每个共享的和可变的变量都应该只由一个锁来保护，从而使维护人员知道是哪一个锁。 一种常见的加锁约定是，将所有的可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径进行同步，使得在该对象上不会发生并发访问。 并非所有数据都需要锁的保护，只有被多个线程同时访问的可变数据才需要通过锁来保护。 2.5 活跃性与性能# 不良并发（Poor Concurrency）应用程序：可同时调用的数量，不仅受到可用处理资源的限制，还受到应用程序本身结构的限制。 当实现某个同步策略时，一定不要盲目地为了性能而牺牲简单性（这可能会破坏安全性）。 无论是执行计算密集的操作，还是在执行某个可能阻塞的操作，如果持有锁的时间过长，那么都会带来活跃性或性能问题。 当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。 第3章 对象的共享# 同步还有另一个重要的方面：内存可见性（Memory Visibility）。我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态，而且希望确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 3.1 可见性# 在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。 3.1.1 失效数据# 3.1.2　非原子的64位操作# 当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性（out-of-thin-air safety） 最低安全性适用于绝大多数变量，但是存在一个例外：非volatile类型的64位数值变量（double和long，请参见3.1.4节）。Java内存模型要求，变量的读取操作和写入操作都必须是原子操作，但对于非volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位￼。因此，即使不考虑失效数据问题，在多线程程序中使用共享且可变的long和double等类型的变量也是不安全的，除非用关键字volatile来声明它们，或者用锁保护起来。 3.1.3　加锁与可见性# 加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。 3.1.4　Volatile变量# Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。 在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制。 在当前大多数处理器架构上，读取volatile变量的开销只比读取非volatile变量的开销略高一些。 我们并不建议过度依赖volatile变量提供的可见性。如果在代码中依赖volatile变量来控制状态的可见性，通常比使用锁的代码更脆弱，也更难以理解。 仅当volatile变量能简化代码的实现以及对同步策略的验证时，才应该使用它们。 如果在验证正确性时需要对可见性进行复杂的判断，那么就不要使用volatile变量。 volatile的语义不足以确保递增操作（count++）的原子性，除非你能确保只有一个线程对变量执行写操作。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。 当且仅当满足以下所有条件时，才应该使用volatile变量 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁。 调试小提示：对于服务器应用程序，无论在开发阶段还是在测试阶段，当启动JVM时一定都要指定-server命令行选项。server模式的JVM将比client模式的JVM进行更多的优化，例如将循环中未被修改的变量提升到循环外部，因此在开发环境（client模式的JVM）中能正确运行的代码，可能会在部署环境（server模式的JVM）中运行失败。例如，如果在程序清单3-4中“忘记”把asleep变量声明为volatile类型，那么server模式的JVM会将asleep的判断条件提升到循环体外部（这将导致一个无限循环），但client模式的JVM不会这么做。在解决开发环境中出现无限循环问题时，解决这个问题的开销远小于解决在应用环境出现无限循环的开销。 3.2 发布与逸出# “发布（Publish）”一个对象的意思是指，使对象能够在当前作用域之外的代码中使用。 将一个指向该对象的引用保存到其他代码可以访问的地方，或者在某一个非私有的方法中返回该引用，或者将引用传递到其他类的方法中。在许多情况中，我们要确保对象及其内部状态不被发布。而在某些情况下，我们又需要发布某个对象，但如果在发布时要确保线程安全性，则可能需要同步。发布内部状态可能会破坏封装性，并使得程序难以维持不变性条件。例如，如果在对象构造完成之前就发布该对象，就会破坏线程安全性。当某个不应该发布的对象被发布时，这种情况就被称为逸出（Escape）。 发布对象的最简单方法是将对象的引用保存到一个公有的静态变量中，以便任何类和线程都能看见该对象 一般来说，如果一个已经发布的对象能够通过非私有的变量引用和方法调用到达其他的对象，那么这些对象也都会被发布。 当某个对象逸出后，你必须假设有某个类或线程可能会误用该对象。这正是需要使用封装的最主要原因：封装能够使得对程序的正确性进行分析变得可能，并使得无意中破坏设计约束条件变得更难。 安全的对象构造过程 不要在构造过程中使this引用逸出 在构造过程中使this引用逸出的一个常见错误是，在构造函数中启动一个线程。当对象在其构造函数中创建一个线程时，无论是显式创建（通过将它传给构造函数）还是隐式创建（由于Thread或Runnable是该对象的一个内部类），this引用都会被新创建的线程共享。在对象尚未完全构造之前，新的线程就可以看见它。 在构造函数中创建线程并没有错误，但最好不要立即启动它，而是通过一个start或initialize方法来启动 在构造函数中调用一个可改写的实例方法时（既不是私有方法，也不是终结方法），同样会导致this引用在构造过程中逸出。 如果想在构造函数中注册一个事件监听器或启动线程，那么可以使用一个私有的构造函数和一个公共的工厂方法（Factory Method），从而避免不正确的构造过程 3.3 线程封闭# Swing应用程序的许多并发错误都是由于错误地在另一个线程中使用了这些被封闭的对象。 线程封闭是在程序设计中的一个考虑因素，必须在程序中实现。 3.3.1 Ad-hoc线程封闭# 在volatile变量上存在一种特殊的线程封闭。只要你能确保只有单个线程对共享的volatile变量执行写入操作，那么就可以安全地在这些共享的volatile变量上执行“读取-修改-写入”的操作。在这种情况下，相当于将修改操作封闭在单个线程中以防止发生竞态条件，并且volatile变量的可见性保证还确保了其他线程能看到最新的值。 由于Ad-hoc线程封闭技术的脆弱性，因此在程序中尽量少用它，在可能的情况下，应该使用更强的线程封闭技术（例如，栈封闭或ThreadLocal类）。 3.3.2 栈封闭# 栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。 由于任何方法都无法获得对基本类型的引用，因此Java语言的这种语义就确保了基本类型的局部变量始终封闭在线程内。 3.3.3 ThreadLocal 类# ThreadLocal对象通常用于防止对可变的单实例变量（Singleton）或全局变量进行共享。 假设你需要将一个单线程应用程序移植到多线程环境中，通过将共享的全局变量转换为ThreadLocal对象（如果全局变量的语义允许），可以维持线程安全性。 3.4 不变性# 如果某个对象在被创建后其状态就不能被修改，那么这个对象就称为不可变对象。 不可变对象一定是线程安全的 虽然在Java语言规范和Java内存模型中都没有给出不可变性的正式定义，但不可变性并不等于将对象中所有的域都声明为final类型，即使对象中所有的域都是final类型的，这个对象也仍然是可变的，因为在final类型的域中可以保存对可变对象的引用。 当满足以下条件时，对象才是不可变的： 对象创建以后其状态就不能修改。 对象的所有域都是final类型。 对象是正确创建的（在对象的创建期间，this引用没有逸出）。 3.4.1 Final域# 关键字final可以视为C++中const机制的一种受限版本，用于构造不可变性对象。final类型的域是不能修改的（但如果final域所引用的对象是可变的，那么这些被引用的对象是可以修改的）。 即使对象是可变的，通过将对象的某些域声明为final类型，仍然可以简化对状态的判断，因此限制对象的可变性也就相当于限制了该对象可能的状态集合。 正如“除非需要更高的可见性，否则应将所有的域都声明为私有域”[EJ Item 12]是一个良好的编程习惯，“除非需要某个域是可变的，否则应将其声明为final域”也是一个良好的编程习惯。 3.4.2 示例：使用volatile类型来发布不可变对象# 通过使用包含多个状态变量的容器对象来维持不变性条件，并使用一个volatile类型的引用来确保可见性，使得Volatile Cached Factorizer在没有显式地使用锁的情况下仍然是线程安全的 3.5 安全发布# 3.5.1 不正确的发布：正确的对象被破坏# 你不能指望一个尚未被完全创建的对象拥有完整性。某个观察该对象的线程将看到对象处于不一致的状态，然后看到对象的状态突然发生变化，即使线程在对象发布后还没有修改过它。 3.5.2 不可变对象与初始化安全性# 我们已经知道，即使某个对象的引用对其他线程是可见的，也并不意味着对象状态对于使用该对象的线程来说一定是可见的。为了确保对象状态能呈现出一致的视图，就必须使用同步。 任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。 在没有额外同步的情况下，也可以安全地访问final类型的域。然而，如果final类型的域所指向的是可变对象，那么在访问这些域所指向的对象的状态时仍然需要同步。 3.5.3 安全发布的常用模式# 可变对象必须通过安全的方式来发布，这通常意味着在发布和使用该对象的线程时都必须使用同步。 要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见 在静态初始化函数中初始化一个对象引用。 将对象的引用保存到volatile类型的域或者AtomicReferance对象中。 将对象的引用保存到某个正确构造对象的final类型域中。 将对象的引用保存到一个由锁保护的域中。 在线程安全容器内部的同步意味着，在将对象放入到某个容器，例如Vector或synchronizedList时，将满足上述最后一条需求。如果线程A将对象X放入一个线程安全的容器，随后线程B读取这个对象，那么可以确保B看到A设置的X状态，即便在这段读/写X的应用程序代码中没有包含显式的同步。 线程安全库中的容器类提供了以下的安全发布保证 通过将一个键或者值放入Hashtable、synchronizedMap或者ConcurrentMap中，可以安全地将它发布给任何从这些容器中访问它的线程（无论是直接访问还是通过迭代器访问）。 通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、synchronizedList或synchronizedSet中，可以将该元素安全地发布到任何从这些容器中访问该元素的线程。 通过将某个元素放入BlockingQueue或者ConcurrentLinkedQueue中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。 要发布一个静态构造的对象，最简单和最安全的方式是使用静态的初始化器 public static Holder holder=new Holder（42） 静态初始化器由JVM在类的初始化阶段执行。由于在JVM内部存在着同步机制，因此通过这种方式初始化的任何对象都可以被安全地发布 3.5.4 事实不可变对象# 如果对象在发布后不会被修改，那么对于其他在没有额外同步的情况下安全地访问这些对象的线程来说，安全发布是足够的。 如果对象从技术上来看是可变的，但其状态在发布后不会再改变，那么把这种对象称为“事实不可变对象（Effectively Immutable Object）” 通过使用事实不可变对象，不仅可以简化开发过程，而且还能由于减少了同步而提高性能。 例如，Date本身是可变的￼，但如果将它作为不可变对象来使用，那么在多个线程之间共享Date对象时，就可以省去对锁的使用 3.5.5 可变对象# 如果对象在构造后可以修改，那么安全发布只能确保“发布当时”状态的可见性。对于可变对象，不仅在发布对象时需要使用同步，而且在每次对象访问时同样需要使用同步来确保后续修改操作的可见性。 在并发程序中使用和共享对象时，可以使用一些实用的策略，包括： 线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。 3.5.6 安全地共享对象# 第4章 对象的组合# 4.1 设计线程安全的类# 4.2 实例封闭# 4.3 线程安全性的委托# 4.4 在现有的线程安全类中添加功能# 4.5 将同步策略文档化# 第5章 基础构建模块# 5.1 同步容器类# 5.2 并发容器# 5.3 阻塞队列和生产者-消费者模式# 5.4 阻塞方法与中断方法# 5.5 同步工具类# 5.6 构建高效且可伸缩的结果缓存# 第6章 任务执行# 6.1 在线程中执行任务# 6.2 Executor框架# 6.3 找出可利用的并行性# 第7章 取消与关闭# 7.1 任务取消# 7.2 停止基于线程的服务# 7.3 处理非正常的线程终止# 7.4 JVM关闭# 第8章 线程池的使用# 8.1 在任务与执行策略之间的隐性耦合# 8.2 设置线程池的大小# 8.3 配置ThreadPoolExecutor# 8.4 扩展ThreadPoolExecutor# 8.5 递归算法的并行化# 第9章 图形用户界面应用程序# 9.1 为什么GUI是单线程的# 9.2 短时间的GUI任务# 9.3 长时间的GUI任务# 9.4 共享数据模型# 9.5 其他形式的单线程子系统# 第10章 避免活跃性危险# 10.1 死锁# 10.2 死锁的避免与诊断# 10.3 其他活跃性危险# 第11章 性能与可伸缩性# 11.1 对性能的思考# 11.2 Amdahl定律# 11.3 线程引入的开销# 11.4 减少锁的竞争# 11.5 示例：比较Map的性能# 11.6 减少上下文切换的开销# 第12章 并发程序的测试# 12.1 正确性测试# 12.2 性能测试# 12.3 避免性能测试的陷阱# 12.4 其他的测试方法# 第13章 显式锁# 13.1 Lock与ReentrantLock# 13.2 性能考虑因素# 13.3 公平性# 13.4 在synchronized和ReentrantLock之间进行选择# 13.5 读-写锁# 第14章 构建自定义的同步工具# 14.1 状态依赖性的管理# 14.2 使用条件队列# 14.3 显式的Condition对象# 14.4 Synchronizer剖析# 14.5 AbstractQueuedSynchronizer# 14.6 java.util.concurrent同步器类中的AQS# 第15章 原子变量与非阻塞同步机制# 15.1 锁的劣势# 15.2 硬件对并发的支持# 15.3 原子变量类# 15.4 非阻塞算法# 第16章 Java内存模型# 16.1 什么是内存模型，为什么需要它# 16.2 发布# 16.3 初始化过程中的安全性# "},{"id":83,"href":"/post/computer-science/ci-cd/jenkins/","title":"Jenkins","section":"CI/CD","content":"Jenkins# docs docker macOS macOS Installer for Jenkins LTS Install the latest LTS version: brew install jenkins-lts Start the Jenkins service: brew services start jenkins-lts Restart the Jenkins service: brew services restart jenkins-lts Update the Jenkins version: brew upgrade jenkins-lts Using Jenkins jenkins-zh/jenkins-client-java Java实现的对Jenkins操作 password# jenkins publish over SSH中SSH sever密码存放位置 记录 从jenkins配置文件中解密密码 reference# 在Jenkins中拉取GitHub上的代码包（超详细) jenkins配置全局凭据 结合gitlab jenkins部署github项目 "},{"id":84,"href":"/post/life/law/","title":"law","section":"Life","content":" 最高法举行《最高人民法院关于审理劳动争议案件适用法律问题的解释（二）》新闻发布会 01新劳动争议司法解释回应竞业等热点问题 "},{"id":85,"href":"/post/computer-science/ci-cd/maven/","title":"maven","section":"CI/CD","content":"# 加上多线程的参数 -T 可以加快构建速度 数量就设置为CPU的核心数就行了 # 这个参数要和实际并行构建的任务综合考虑，如果同时构建的任务太多，那么这个参数不宜设置为CPU的核心数 # 如果经常是单个任务进行构建，那么可以直接配置为CPU的核心数 mvn clean package -T {CPU.CORE_NUMS} -Dmaven.test.skip=true -P prodplugin# 从Maven中的命令行参数跳过exec-Maven插件 reference# 利用码云gitee搭建个人maven仓库 "},{"id":86,"href":"/post/computer-science/micro-service/micro-service/","title":"micro service","section":"Micro Service","content":"监控# SkyWalking 极简入门 "},{"id":87,"href":"/post/life/my-history/","title":"my history","section":"Life","content":"2025# 2025-08 南越王古墓博物馆、越秀公园 2025-08-16 📖《亮剑》看完了 2025-08-15 广州市美术馆 2025-08-09 📖《优秀的绵羊》 2025-08-05 📖《简读中国史：世界史坐标下的中国》 2025-08-03 2025-07 广东省博物馆、广州市图书馆、有珠云南菜 #oado 2025-07-26 环法第19赛段，波加查本来可以争取赛段冠军的但是最后他没有进攻，温格高也没有进攻，最后阿伦斯曼几秒钟的优势拿到了第二个冠军，哎 #oado 2025-07-25 点都德 #oado 2025-07-24 奥体中心绕圈 #oado 2025-07-19 广州动物园 #oado 2025-07-05 📖《看见》 2025-07-05 2025-06 📖《简读日本史》 2025-06-25 2025-05 🚴🏻二沙岛 #oado 2025-05-25 陈家祠 #oado 2025-05-18 📖《天朝的崩溃：鸦片战争再研究》 2025-05-16 🚴🏻生物岛 #oado 2025-05-15 大学舍友来昆明找我，和他们逛了一天昆明 2025-05-02 2025-04 香雪大行车店修车，顺便去黄埔香雪图书馆看了看 #oado 2025-04-20 北京路，沙面岛 #oado 2025-04-12 开始上班了 2025-04-10 📖《东京八平米》 2025-04-09 2025-03 🚴🏻环海珠区，要累死 2025-03-01 2025-02 出发去广州 #oado 2025-02-19 2025-01 📖《置身事内：中国政府与经济发展》 2025-01-29 📖《美国困局》 2025-01-19 🚗卧云山环线练车 #oado 2025-01-10 "},{"id":88,"href":"/post/computer-science/ci-cd/nexus/","title":"Nexus","section":"CI/CD","content":"Nexus# docker sonatype/nexus3 install docker run -d -p 8081:8081 --name nexus sonatype/nexus3 "},{"id":89,"href":"/post/computer-science/ci-cd/orbstack/","title":"OrbStack","section":"CI/CD","content":" OrbStack OrbStack is the fast, light, and easy way to run Docker containers and Linux. Develop at lightspeed with our Docker Desktop alternative. "},{"id":90,"href":"/post/computer-science/operating-system/powershell/","title":"powershell","section":"Operating System","content":" fleschutz/PowerShell Mega Collection of PowerShell Scripts 一句话完成繁琐操作：你可以试试的 8 个 Windows 命令行工具 systeminfo 列出当前电脑的ip Get-CimInstance -Class Win32_NetworkAdapterConfiguration -Filter IPEnabled=$true | Select-Object -ExpandProperty IPAddress 定时任务# windows用任务计划定时执行powershell脚本 字符问题# win10下,cmd,power shell设置默认编码为‘UTF-8’? - 马甲的回答 "},{"id":91,"href":"/post/computer-science/python/","title":"Python","section":"Computer Science","content":"Python# yutto# "},{"id":92,"href":"/post/books/computer-science/python%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","title":"Python神经网络编程","section":"Computer Science","content":"第1章 神经网络如何工作# "},{"id":93,"href":"/post/computer-science/reddison/","title":"reddison","section":"Computer Science","content":"什么情况下使用 redistemplate 什么时候使用 reddison# 在 Java 项目中，选择 RedisTemplate（Spring Data Redis）还是 Redisson 取决于具体需求场景。以下是两者的对比和适用场景分析：\n1. RedisTemplate（Spring Data Redis）# 定位：Spring 生态提供的轻量级 Redis 操作工具，封装了 Jedis/Lettuce。 适用场景：\n简单的 CRUD 操作：读写字符串、Hash、List 等基础数据结构。 与 Spring 生态深度集成：需要无缝配合 @Cacheable、Spring Session 等功能。 无需复杂分布式特性：例如仅需缓存数据、计数器等基础功能。 特点：\n支持 JSON、JDK 序列化等多种序列化方式。 提供简单的发布/订阅、事务支持。 不支持分布式锁、信号量等高级功能（需自行基于 SETNX 实现）。 示例场景：\n// 存储字符串 redisTemplate.opsForValue().set(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); // 存储Hash redisTemplate.opsForHash().put(\u0026#34;user:1\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;Alice\u0026#34;); 2. Redisson# 定位：分布式服务框架，提供丰富的分布式数据结构和高阶功能。 适用场景：\n需要分布式协调：如分布式锁（RLock）、信号量（RSemaphore）、延迟队列（RDelayedQueue）。 复杂分布式业务：跨 JVM 共享对象、分布式任务调度（如 RExecutorService）。 高性能分布式缓存：支持本地缓存联动（RLocalCachedMap）。 特点：\n提供 java.util.concurrent 风格的 API（如 RMap、RList）。 内置看门狗机制避免锁死，支持锁自动续期。 支持 Redis 集群、哨兵、云托管等多种部署模式。 示例场景：\n// 分布式锁 RLock lock = redisson.getLock(\u0026#34;orderLock\u0026#34;); lock.lock(10, TimeUnit.SECONDS); // 自动释放避免死锁 try { // 处理订单 } finally { lock.unlock(); } // 分布式Map RMap\u0026lt;String, Object\u0026gt; map = redisson.getMap(\u0026#34;userMap\u0026#34;); map.put(\u0026#34;user1\u0026#34;, new User()); 3. 对比总结# 需求 RedisTemplate Redisson 简单数据读写（String/Hash） ✅ 更轻量 ✅ 但稍重 分布式锁/信号量 ❌ 需手动实现 ✅ 内置完善支持 与 Spring Cache 集成 ✅ 原生支持 ✅ 需额外配置 跨 JVM 共享复杂对象 ❌ 序列化受限 ✅ 透明化操作 延迟队列、BloomFilter ❌ 不支持 ✅ 直接提供 4. 如何选择？# 选 RedisTemplate 如果：\n项目已深度集成 Spring，仅需基础 Redis 操作。\n不想引入额外依赖，保持轻量级。\n选 Redisson 如果：\n需要分布式锁、限流等高级功能。\n业务涉及跨服务共享对象或复杂协调逻辑。\n追求更直观的分布式数据结构（如 RList 替代手动序列化）。\n5. 混合使用# 两者可以共存，例如：\n用 RedisTemplate 处理简单缓存。 用 Redisson 实现分布式锁和队列。 需注意避免序列化冲突（建议统一配置序列化方式）。 "},{"id":94,"href":"/post/books/computer-science/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","title":"Redis设计与实现","section":"Computer Science","content":"第2章 简单动态字符串# 第3章 链表# 第4章 字典# 第5章 跳跃表# 第6章 整数集合# 第7章 压缩列表# 第8章 对象# Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象） 对象的类型 字符串对象 REDIS_STRING 列表对象 REDIS_LIST 哈希对象 REDIS_HASH 集合对象 REDIS_SET 有序集合对象 REDIS_ZSET 对于Redis数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种 当我们称呼一个数据库键为“字符串键”时，我们指的是“这个数据库键所对应的值为字符串对象” 当我们称呼一个键为“列表键”时，我们指的是“这个数据库键所对应的值为列表对象” TYPE命令的实现方式也与此类似，当我们对一个数据库键执行TYPE命令时，命令返回的结果为数据库键对应的值对象的类型，而不是键对象的类型 因为键的类型始终为字符串 "},{"id":95,"href":"/post/books/computer-science/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E4%B8%8E%E8%BF%9B%E9%98%B6/","title":"Spring Cloud微服务：入门、实战与进阶","section":"Computer Science","content":"1.3 什么是Spring Cloud# Eureka 服务注册中心，用于服务管理 Ribbon 基于客户端的负载均衡组件 Hystrix 容错框架，能够防止服务的雪崩效应 Feign Web服务客户端，能够简化HTTP接口的调用 Zuul API网关，提供路由转发、请求过滤等功能 Config 分布式配置管理 Sleuth 服务跟踪 Stream 构建消息驱动的微服务应用程序的框架 Bus 消息代理的集群消息总线。 第3章　Eureka注册中心# Spring Cloud Eureka是一个基于REST的服务，并且提供了基于Java的客户端组件，能够非常方便地将服务注册到Spring Cloud Eureka中进行统一管理。 服务治理是微服务架构中必不可少的一部分，阿里开源的Dubbo框架就是针对服务治理的。服务治理必须要有一个注册中心，除了用Eureka作为注册中心外，我们还可以使用Consul、Etcd、Zookeeper等来作为服务的注册中心。 用过Dubbo的读者应该清楚，Dubbo中也有几种注册中心，比如基于Zookeeper、基于Redis等，不过用得最多的还是Zookeeper方式。至于使用哪种方式都是可以的，注册中心无非就是管理所有服务的信息和状态。 程序也是一样，当你需要调用某一个服务的时候，你会先去Eureka中去拉取服务列表，查看你调用的服务在不在其中，在的话就拿到服务地址、端口等信息，然后调用。 为什么Eureka比Zookeeper更适合作为注册中心呢？ 主要是因为Eureka是基于AP原则构建的，而ZooKeeper是基于CP原则构建的。在分布式系统领域有个著名的CAP定理，即C为数据一致性；A为服务可用性；P为服务对网络分区故障的容错性。这三个特性在任何分布式系统中都不能同时满足，最多同时满足两个。 Zookeeper有一个Leader，而且在这个Leader无法使用的时候通过Paxos(ZAB)算法选举出一个新的Leader。这个Leader的任务就是保证写数据的时候只向这个Leader写入，Leader会同步信息到其他节点。通过这个操作就可以保证数据的一致性。 总而言之，想要保证AP就要用Eureka，想要保证CP就要用Zookeeper。Dubbo中大部分都是基于Zookeeper作为注册中心的。Spring Cloud中当然首选Eureka。 第4章　客户端负载均衡Ribbon# 目前主流的负载方案分为两种：一种是集中式负载均衡，在消费者和服务提供方中间使用独立的代理方式进行负载，有硬件的（比如F5），也有软件的（比如Nginx）。另一种则是客户端自己做负载均衡，根据自己的请求情况做负载，Ribbon就属于客户端自己做负载。 Ribbon作为一款客户端负载均衡框架，默认的负载策略是轮询，同时也提供了很多其他的策略，能够让用户根据自身的业务需求进行选择。 第6章　Hystrix服务容错处理# 在微服务架构中存在多个可直接调用的服务，这些服务若在调用时出现故障会导致连锁效应，也就是可能会让整个系统变得不可用，这种情况我们称之为服务雪崩效应。 Hystrix是Netflix针对微服务分布式系统采用的熔断保护中间件，相当于电路中的保险丝。 "},{"id":96,"href":"/post/computer-science/vim/","title":"vim","section":"Computer Science","content":" 大家來學VIM（一個歷久彌新的編輯器） Just Vim It nvim# neovim.io 直接用brew安装就行 brew install neovim 第一步肯定是要把插件管理工具安装一下 junegunn/vim-plug 直接运行文档中linux的安装命令 indent# How can I make (Neo)Vim wrap lines in respect to indentation? 这个可以解决缩进换行的问题，很棒！ clipboard 剪贴板# 直接在配置文件中添加这两行，就可以了\nvnoremap y \u0026#34;+y set clipboard+=unnamedplusquickfix# VIM学习笔记 QuickFix LazyVim# lazyvim org 用 neovim 写 markdown 是一种什么样的体验(含技巧) markdown# theCW 不影响听课的高效率记笔记方法：Vim + Markdown - 教学与配置 iamcco/markdown-preview.nvim My neovim markdown setup in 2024 tadmccorkle/markdown.nvim cnshsliu/smp.nvim MeanderingProgrammer/render-markdown.nvim 这个插件可以直接在 neovim 中直接 render markdown 文件 但是安装只提供了 lua 的安装方式 outline.nvim# hedyhli/outline.nvim 这个插件太优秀了！ 解决 outline 左箭头和下箭头乱码的问题\nsymbol_folding = { autofold_depth = false, markers = { \u0026#39;\u0026gt;\u0026#39;, \u0026#39;∨\u0026#39; }, } Vim Markdown Folding?\n直接在配置文件中加上下面这段\nfunction! MarkdownLevel() if getline(v:lnum) =~ \u0026#39;^# .*$\u0026#39; return \u0026#34;\u0026gt;1\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^## .*$\u0026#39; return \u0026#34;\u0026gt;2\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^### .*$\u0026#39; return \u0026#34;\u0026gt;3\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^#### .*$\u0026#39; return \u0026#34;\u0026gt;4\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^##### .*$\u0026#39; return \u0026#34;\u0026gt;5\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^###### .*$\u0026#39; return \u0026#34;\u0026gt;6\u0026#34; endif return \u0026#34;=\u0026#34; endfunction au BufEnter *.md setlocal foldexpr=MarkdownLevel() au BufEnter *.md setlocal foldmethod=expr 搜索插件# fzf# note 只能搜索文件，不能进行全文搜索 安装fzf brew install fzf 安装 fzf 的vim的插件 junegunn/fzf.vim Reference FZF：终端下的文件查找器【猛男必备233333】 telescope# nvim-telescope/telescope.nvim 支持全文搜索需要额外安装这个插件 BurntSushi/ripgrep 搜索结果换行的配置，vimscript 版本\nlua \u0026lt;\u0026lt;EOF require(\u0026#34;telescope\u0026#34;).setup { defaults = { wrap_results = true, }, pickers = { oldfiles = { initial_mode = \u0026#34;normal\u0026#34; } } } EOF美化# Looking for airline replacement famiu/feline.nvim buffer# akinsho/bufferline.nvim 需要安装一个字体，不然图标显示不出来很丑 ryanoasis/nerd-fonts brew install font-hack-nerd-font ap/vim-buftabline 这个 repository 里面讲了一些和 buffer 有关的只是和维护者对 buffer 的一些思考 dropbar.nvim# cellular.automation# vimscript# VimScript 五分钟入门（翻译） lua# theCW 用Lua重新配置Neovim，我一周就干了个这。｜ Neovim Vlog[0] Lua实战：加强Neovim｜Neovim Vlog[1] theCW的lua 配置 从 VimScipt 切换至 Lua "},{"id":97,"href":"/post/computer-science/operating-system/windows/","title":"windows","section":"Operating System","content":"AutoHotkey# AutoHotkey others# 一日一技 | 重启试试不是长久之计，两条命令帮你排查意外关机成因 在 Windows 上用 WSL 开发的操作体验指北 "},{"id":98,"href":"/post/books/computer-science/%E4%B8%80%E6%9C%AC%E4%B9%A6%E8%AE%B2%E9%80%8F-elasticsearch%E5%8E%9F%E7%90%86%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/","title":"一本书讲透 ElasticSearch：原理、进阶与工程实践","section":"Computer Science","content":"第1章 Elastic Stack全景# 首先，Elasticsearch支持各类应用、网站等的全文搜索，包括淘宝、京东等电商平台的搜索，360手机助手、豌豆荚等应用市场平台的搜索，以及腾讯文档、石墨文档等平台的全文检索服务。 许多知名企业，如58集团、唯品会、日志易、国投瑞银等，都使用Elasticsearch来快速分析和处理大量的日志数据，从而对业务运行状况进行实时的监控和故障排查。 许多知名企业的商业智能系统，如睿思BI、百度数据可视化Sugar BI、永洪BI等，都借助Elasticsearch的高效、实时的数据分析和可视化能力，帮助企业更好地理解市场趋势、优化决策过程。 ClickHouse ClickHouse是一款由俄罗斯搜索引擎Yandex开发并开源的列式存储数据库，专为**OLAP（在线分析处理）**场景设计。ClickHouse具有高速查询分析的能力，支持实时添加数据和修改结构，并且能够实现高度数据压缩比，从而有效节省存储空间。此外，ClickHouse支持SQL查询，易于使用和集成。 第2章 Elasticsearch基础知识# 倒排索引 一本C语言图书末页的索引结构。这种结构揭示了核心关键词与页码之间的对应关系。这种关系模式可以视为倒排索引的实际例证。在此结构中，我们可以根据关键词快速找到包含这个关键词的内容的页码。这与倒排索引在接收关键词输入后能够迅速定位包含该关键词的文档的性质是一致的。借由这种类比，我们可以更为直观地理解倒排索引在数据查询中的关键作用。 数据索引化 数据索引化指的是数据在写入搜索引擎（本书中主要指Elasticsearch）的过程中，扫描文档中的每一个词项，结合分词器和词典对必要的词项建立倒排索引，同时指明该词项在文章中出现的次数和位置。 全文检索的前提是待检索的数据已经索引化，当用户查询时能根据建立的倒排索引进行查找。 全文检索的特点如下 只处理文本，不处理语义。 结果列表有相关度排序。 支持高亮显示结果数据。 原始的文本被切分为单个单词、短语或特殊标记后进行存储。 给定词与它的变体（如近义词）会被折叠为一个词，如electrification和ectric、mice和mouse、“土豆”和“马铃薯”、“西红柿”和“番茄”等，每组词均被视为同一个词。 2.2 Elasticsearch的核心概念# 集群 Elasticsearch集群常用于处理大规模数据集，目的是实现容错和高可用。Elasticsearch集群需要一个唯一标识的集群名称来防止不必要的节点加入。集群大小从单个节点到数千个节点不等，具体大小取决于实际业务场景。 节点 节点是指一个Elasticsearch实例，更确切地说，它是一个Elasticsearch进程。节点可以部署到物理机或者虚拟机上。每当Elasticsearch启动时，节点就会开始运行。每个节点都有唯一标识的名称，在部署多节点集群环境的时候我们要注意不要写错节点名称。 索引 索引可以看作数据库中的一个表，它包含了一组具有相似结构的文档 在Elasticsearch中，数据以JSON格式的文档存储在索引内。 每个索引具有唯一的名称，以便在执行搜索、更新和删除操作时进行引用。 索引的名称可以由用户自定义，但必须全部小写。 分片 在了解分片是什么之前，让我们谈谈为什么需要分片。假设你有一个包含超大规模文档的索引，有总计1TB的数据。当前集群中有两个节点，每个节点有512GB的空间可用于存储数据。显然，整个索引无法存储在任何一个节点上，因此有必要以某种方式拆分索引的数据，否则会导致数据存储不完整。在这种情况下，索引的大小超过了单个节点的硬件限制，分片就派上用场了。分片通过将索引分成更小的部分来解决这个问题。 当处理涉及多个数据分片的查询时，Elasticsearch会将查询请求分发到各个相关的分片，并将它们的结果集进行聚合。 副本 分片可以被复制，被复制的分片称为“主分片”，如图2-3中的主分片1～4；主分片的复制版本称为“副本分片”或简称为“副本”，如图2-3中的副本1～4 创建索引时需要指定主分片，且主分片数一经指定就不支持动态更新了。而副本同样需要在创建索引时指定，每个分片可以有0或多个副本，副本数支持动态更新。 当某主分片所在的数据节点不可用时，会导致主分片丢失现象，若短时间内不对此采取补救措施，集群会将该分片对应的副本提升为新的主分片。 文档 关系型数据库将数据以行或元组为单位存储在数据库表中，而Elasticsearch将数据以文档为单位存储在索引中。 作为Elasticsearch的基本存储单元，文档是指存储在Elasticsearch索引中的JSON对象。文档中的数据由键值对构成。键是字段的名称，值是不同数据类型的字段。不同的数据类型包含但不限于字符串类型、数字类型、布尔类型、对象类型等。 字段 字段是Elasticsearch中最小的单个数据单元，类似于关系型数据库表中的字段。一般实战项目前期的设计环节都是根据业务需求拆分、定义字段，并且敲定字段类型。在上面航空类索引的示例中，“FlightNum”是字段，其含义为“航班号”，字段类型为keyword。 与关系型数据库不同的是，Elasticsearch的一个字段可以设定两种或两种以上的数据类型，通过定义multi-field来灵活地满足复杂的业务需求。 映射 不少初学者对映射(Mapping)这个概念会感觉不好理解。映射类似于关系型数据库中的Schema，可以近似地理解为**“表结构”**。 我们拿到一个业务需求后，往往会将业务细分会几个索引。每个索引都需要一个相对固定的表结构，包含但不限于字段名称、字段类型、是否需要分词、是否需要索引、是否需要存储、是否需要多字段类型等。这些都是设计映射时要考虑的问题。 分词 在英文文本中，空格就是切分语句或短语的“屏障”。但中文文本中则没有了这道“屏障”，于是分词就变得就不那么简单，需要由专门的分词算法构建的分词器来实现。 第3章 Elasticsearch集群部署# 什么是堆内存\nJava中的堆是JVM所管理的最大的一块内存空间，主要用于存放各种类的实例对象。在Java中，堆被划分成两个不同的区域：新生代(Young)和老年代(Old)。新生代又被划分为3个区域：Eden、From Survivor、To Survivor。 这样划分的目的是使JVM更好地管理堆内存中的对象，包括内存的分配以及回收。 堆内存的作用是什么\n堆内存的唯一目的就是创建对象实例，所有的对象实例和数组都要在堆上分配。 堆内存如何配置\n默认情况下，Elasticsearch JVM使用的堆内存最小和最大值均为4 GB（8.X版本以上） 在转移到生产环境时，配置足够容量的堆大小以确保Elasticsearch功能和性能是必要的。 Elasticsearch将通过对Xms（最小堆大小）和Xmx（最大堆大小）的设置来分配jvm.options中指定的整个堆。 堆内存的值取决于服务器上可用的内存大小。Elasticsearch堆内存设置对其性能表现来说十分关键。建议将堆大小配置为服务器可用内存的50%，上限为32GB，且预留足够的内存给操作系统以提升缓存效率。合理调整堆内存大小可减轻垃圾回收工作的压力，优化查询速度和索引效率。请务必进行监控并根据实际需求来调整堆内存大小。 为什么堆内存不能超过物理机内存的一半\n堆对Elasticsearch来说绝对重要，它用于许多内存数据结构的快速操作。但还有另外一个非常重要的内存使用者——Lucene。 Lucene旨在利用底层操作系统来缓存内存中的数据结构。Lucene段存储在单个文件中。因为段一旦形成就不会改变，所以它们非常容易进行缓存，并且，底层操作系统会将热段保留在内存中以便更快地进行访问。这些段包括倒排索引（用于全文搜索）和正排索引（用于聚合）。 Lucene的性能依赖于与操作系统的这种交互。如果把所有可用的内存都给Elasticsearch堆，那么Lucene就不会有任何剩余的内存，这会严重影响其性能。针对内存的分配，通常的建议是将可用内存的一半分配给Elasticsearch堆，而保留剩下的一半。这种操作的核心在于平衡Elasticsearch堆和Lucene。剩余的内存看起来空闲，但其实并非如此，因为Lucene会利用这些“空闲”内存来提高搜索和索引的性能。这种内存分配策略确保了Elasticsearch与Lucene之间的高效协作，进而能够提升整体系统性能。 如果实际业务不需要在字符串字段上做聚合操作（开启text类型的fielddata），则可以考虑进一步降低堆大小。堆较小，就可以从Elasticsearch（更快的GC）和Lucene（更多内存缓存）中获得更好的性能。 Elasticsearch集群节点角色划分\n节点类型 主节点：负责集群管理和元数据维护，确保集群正常运行。 数据节点：负责存储、检索和处理数据，提供搜索和聚合功能。 协调节点：处理客户端请求，协调数据节点工作，优化分布式搜索。 ingest节点：即预处理节点，负责数据预处理，如过滤、转换等，准备好数据再将其索引到数据节点。 在Elasticsearch 8.X版本中，节点类型升级为节点角色。节点角色分得很细，包括数据节点角色、主节点角色、ingest节点角色、热节点角色等。 在Elasticsearch集群中，每个启动的Elasticsearch进程都可以叫作一个节点。以Elasticsearch 8.X版本集群为例，如果我们不手动设置节点角色，则默认节点角色为cdfhilmrstw 主节点 专用候选主节点(dedicated master-eligible node) 仅投票主节点(voting-only master-eligible node) 关于集群主节点配置，要强调一点：高可用性集群需要至少3个符合主节点资格的节点，其中至少两个不是仅投票节点。这样即使其中一个节点发生故障，该集群也能够选举出一个主节点。 数据节点 内容数据节点 热数据节点 热数据节点的用途主要是保存最近、最常访问的热数据，即经常被访问和更新的数据 温数据节点 冷数据节点 冷冻数据节点 ingest节点 这类节点通常执行由预处理管道组成的预处理任务 仅协调节点 这类节点的作用类似于智能负载均衡器，负责路由分发请求、聚拢（或叫作收集，可理解为分发的反过程）搜索或聚合结果 远程节点 这类节点用于跨集群检索或跨集群复制 机器学习节点 机器学习节点是一类特殊类型的节点，它专门用于运行机器学习功能。它们负责运行数据分析任务，如异常检测、预测和回归等。这类节点的功能是收费的，Elasticsearch开源版本并不提供。 转换节点 转换节点是一个特殊类型的节点，负责执行数据转换任务。数据转换是指将数据从一种格式或结构转换为另一种格式或结构的过程。在Elasticsearch中，这通常涉及对原始数据创建新的索引，并对新索引中的数据进行汇总、分组或其他转换操作，以便更有效地进行分析和查询。 Nginx+Elasticsearch Coordinate+Elasticsearch Master+Elasticsearch Node应该如何安装配置呢？可以只安装一个节点，然后拷贝并更改其他节点角色吗？\n先划分节点角色。节点不多的话可以一个个手动部署（部署好一个以后，可以在其他部署中进行拷贝，再修改角色、IP等）；节点非常多的话可以借助Ansible等脚本工具快速部署。 在Elasticsearch部署上，节点角色分为m、d、i等多种，它们在部署上各有什么优势？更推荐哪种？\nm代表主节点master，d代表数据节点data，i代表数据预处理节点ingest。不同节点角色有不同的应用场景，建议根据集群规模进行综合考虑。 请问在写入海量数据时，应该连接什么角色的节点，是专用协调节点还是数据节点？\n这要看节点规模和节点角色划分。如果已经有了独立协调节点，则连接独立协调节点。如果没有，则连接硬件配置较高的节点。 在进行节点角色的配置时，data_hot、data_warm、data_cold等角色和早期版本中自定义的attr属性有区别吗？\n新版本具有新特性，所以有区别。新的方式配置更为简洁，并且可读性强、用户体验优。 Elasticsearch的角色data、data_content、data_hot、data_warm、data_cold之间有什么区别？\n这涉及冷热集群架构的数据节点的分层处理机制。对于早期版本冷热集群架构中手动配置节点属性的部分，Elasticsearch 8.X版本做了精细切分，使得数据的冷热集群管理更为高效。尤其在默认迁移自动实现机制之后，早期版本的分片分配策略手动配置（如下方代码所示）变得不再必要。 Elasticsearch 8.X的data_content角色是什么？它和协调节点有什么区别？\n它们是两种完全不同的节点。data_content属于数据节点，是永久存储数据的地方。而协调节点是用来请求路由分发、结果汇聚处理的。 Elasticsearch集群核心配置解读\n开发模式和生产模式 默认情况下，Elasticsearch工作在开发模式(development mode)下。在该模式下，如果配置错误，则警告信息会写入日志文件，但节点依然是能启动的。而在生产模式(production mode)下，一旦出现配置错误，节点就无法正常启动了。这本质上是一种保护机制。 开发模式和生产模式的界限在于：当修改network.host的默认值之后，默认的开发模式会升级为生产模式。通俗地讲，如果开发者个人搭建集群，则推荐使用开发模式；如果企业级开发环境，务必使用生产模式。 Linux前置配置 修改文件描述符数目 首先，Elasticsearch在节点和HTTP客户端之间进行通信使用了大量的套接字，而套接字需要足够的文件描述符支持。 其次，在许多Linux发行版本中，每个进程默认有1024个文件描述符，这对Elasticsearch节点来说实在是太低了，何况该节点要处理数以百计的索引，所以要调大这个默认值。 修改最大映射数量 Elasticsearch对各种文件混合使用了niofs（非阻塞文件系统）和mmapfs（内存映射文件系统），以实现对各种文件的优化处理。为了保证系统的顺畅运行，需要合理配置最大映射数量(MMP)，以便有足够的虚拟内存可用于内存映射的文件。 path.data配置注意事项：\n不要修改data路径下的任何文件，手动修改会有数据损坏或丢失的风险。 不要尝试对数据目录进行备份，因为Elasticsearch不支持文件备份后的恢复操作。 使用快照snapshot命令对集群进行备份，使用restore命令进行恢复。 不要对数据路径进行病毒扫描，病毒扫描可能会阻止Elasticsearch工作，甚至修改数据目录内容。 在Elasticsearch系统中，为了保证数据安全，不同节点间的通信和数据传输通常采用HTTPS的加密协议。这样的设计能有效防止数据在传输过程中被窃取或篡改。同样，Elasticsearch与Kibana之间的互动也使用了HTTPS，以确保数据在交互过程中的安全性。\n第4章 Elasticsearch索引# 4.1 索引的定义# 索引是具有相同结构的文档的集合，由唯一索引名称标定。\n实战场景1：将采集的不同业务类型的数据存储到不同的索引。\n微博业务对应的索引weibo_index 新闻业务对应的索引news_index 博客业务对应的索引blog_index 以上3个索引包含的字段个数、字段名称、字段类型可能不完全一致。 实战场景2：按日期切分存储日志索引\n2025年1月的日志对应logs_202501 2025年3月的日志对应logs_202503 索引设置\n静态设置(static index settings)，只允许在创建索引时或者针对已关闭的索引进行设置。 设置主分片大小的参数是index.number_of_shards，只在创建索引时生效，不支持动态修改。默认主分片大小为1，且每个索引的分片数量上限默认为1024。此限制是一个安全限制，可防止索引分片数过多导致集群不稳定。 动态设置(dynamic index settings)，可以借助更新设置(update settings)的方式进行动态更新，更新后立即生效。 设置副本数参数为index.number_of_replicas，可以动态修改。 设置刷新频率参数为index.refresh_interval，可以动态修改。默认刷新频率参数值为1s，即每秒刷新一次。这1s决定了Elasticsearch是近实时的搜索引擎，而非准实时搜索引擎。如果业务层面对实时性的要求不高，可以考虑将该值调大。因为如果采用1s，则每秒都会生成一个新的分段，会影响写入性能。 max_result_window是Elasticsearch中的一个设置参数，用于控制搜索结果的最大窗口的大小。默认情况下，max_result_window的值为10000。这意味着在分页搜索时最多可以返回10000条数据。如果每页可显示10条数据，那么最多可以翻到1000页。 增大max_result_window的值可能会对Elasticsearch集群的性能产生影响，尤其是在处理大量数据时。因此，在根据实际需求调整此参数时，要权衡性能和查询范围之间的关系。如果需要遍历大量数据，则建议使用scroll API或search_after参数，以更高效地进行处理。 4.3 索引别名# 场景1：面对PB级别的增量数据，对外提供服务的是基于日期切分的n个不同索引，每次检索都要指定数十个甚至数百个索引，非常麻烦。 场景2：线上提供服务的某个索引设计不合理，比如某字段分词定义不准确，那么如何保证对外提供服务不停止，也就是在不更改业务代码的前提下更换索引？ "},{"id":99,"href":"/post/books/%E4%BA%AE%E5%89%91/","title":"亮剑","section":"Books","content":" 秦人不暇自哀而后人哀之，后人哀之而不鉴之，亦使后人而复哀后人也 ‘孩子，将来你出息了，可别忘了穷乡亲，别忘了你也是穷人家的孩子。’ 你老丈人好吗？这老先生可不简单，别看是一介书生，很有战略眼光，他这一点拨，我有点醍醐灌顶的感觉。什么？老先生成了右派啦？乱弹琴，怎么他妈的到处是右派？ 老K# "},{"id":100,"href":"/post/books/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E7%AC%AC%E4%B8%89%E7%89%88/","title":"宏观经济学 第三版","section":"Books","content":"宏观经济学 第三版# 第1章 经济学原理的实践# 第2章 经济科学：运用数据和模型理解世界# 第3章 优化：竭力做到最好# 第4章 需求，供给与均衡# 第5章 国家财富：定义和测算宏观经济总量# 第6章 总收入# 第7章 经济增长# 第8章 为什么很多地区仍然不发达？# 第9章 就业与失业# 第10章 信贷市场# 信贷：我们把包括企业家、购房者和学生在内的借款主体称为债务人，他们所借入的资金被称为信贷\n借款当然不是免费的，借款人需要支付利息。借款的初始金额被称为本金。利率是借款者在偿还本金之外，需要（在满一年时）为每1美元贷款支付的额外费用。也可以说，利率就是一笔1美元贷款的年度成本。\n如果你借了1年期利率为i的L美元，1年后你要偿还本金L美元加上i×L美元的利息。为了和实际利率区分开来，我们把利率i称为名义利率。\n实际利率=名义利率-通货膨胀率\n实际GDP=名义GDP-通货膨胀率 几乎所有的贷款都是以名义利率发放的 我现在理解了韩秀云说的贷款买房比全款买房更好，因为实际利率会随着通货膨胀越来越低，甚至可能低于越来的本金 通货膨胀率指的是整体经济中物价上涨的速度。\n其他条件不变时，通货膨胀率越高，企业销售的商品和服务价格就会越高，在给定的名义利率下偿还贷款就会越容易。 信贷需求曲线：信贷需求量与实际利率之间的关系\n政府所感知到的商业机会变化、家庭偏好或预期的变化、政府政策的变化，会使得信贷需求曲线左移或右移 实际利率：人们因存钱而得到的回报，因为今天存的1美元，在一年后的购买力是1+r美元，其中r是实际利率\n换句话说，实际利率是当前消费的机会成本，也就是你基于未来的购买力而放弃的东西。因此，较高的实际利率会增加当前消费的机会成本，鼓励更高水平的储蓄。 真实市场中，为了补偿出借人，具有不同违约风险的借款者需面对不同的实际利率。 信贷供给曲线：信贷供给量与实际利率之间的关系\n信贷供给曲线的移动则源于实际利率不变的情况下，追求优化的经济主体储蓄动机的变化（家庭储蓄动机的变化、企业储蓄动机的变化） 人们为什么要储蓄？\n为退休储蓄 为孩子存钱 为一些可预见的大额支出而存钱 投资个人事业而存钱 以备不时之需 信贷市场：借款者从储蓄者那里获取资金的市场，有时也被称为可贷资金市场\n信贷市场均衡：信贷供给曲线与信贷需求曲线的交点所对应的实际利率和信贷量 交点决定了市场中的信贷总量(Q*)和均衡实际利率(r*)。在均衡实际利率下，信贷需求量等于信贷供给量。实际利率高于均衡水平将导致超额的信贷供给，这通常会给实际利率带来下行压力。实际利率低于均衡水平将导致超额的信贷需求，给实际利率带来上行压力。 信贷市场的作用：通过使储蓄者把多余的钱出借给借款者，信贷市场改善了经济中的资源配置\n金融资本：金融资本存在多种不同的形式，包括信贷（也被称为债务）和股权。\n当一个储蓄者将其存款变成信贷时，他就把自己的储蓄借给了另一个人，换来的是连本带息偿还贷款的承诺。 当一个储蓄者把自己的存款变成股权时，他就利用其储蓄变成了一家公司的股东，这意味着他获得了公司的所有权和对公司未来利润的索取权。这些利润会以股息的形式支付给公司股东。 独角兽：越来越多科技初创公司的市值超过10亿美元。在向公众发行股票之前估值超过这一门槛的公司被称为独角兽。\n第11章 货币体系# 第12章 短期波动# 第13章 逆周期宏观经济政策# 第14章 宏观经济学和国际贸易# 第15章 开放经济的宏观经济学# "},{"id":101,"href":"/post/blog/2025/2025-03-29-%E6%95%99%E8%82%B2%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E4%BA%86/","title":"教育到底怎么了 2025-03-29","section":"Posts","content":"教育到底怎么了 2025-03-29# 我们的价值在哪里？\n刚刚走过来图书馆的时候，听了一个新的播客（无界有声）「毕业即失业，教育到底怎么了」。听完之后感触还是很深的，尤其是在现在工作不好找的情况下，真的是很有体会。\n首先是播客里面提到的一个老生常谈的话题，我们接受的教育学到的东西在我们进入职场时有用吗？或者说社会需要什么你知道吗？我一直都觉得理论知识是很重要的，这决定了你能实践的深度和广度，对我而言我接受的教育并不是完全没有用的。但是第二个问题，我确实没有思考过。即使是上一家公司在降本增效的时候，同事调侃说领导要让我们思考「我们的价值在哪里？」「我们能为公司带来什么价值？」的时候我觉得这只是在PUA。现在我觉得这个问题是很有意义的，如果我们是一个普通人，我们需要在这个社会上生存，我们就需要去思考这个问题，尤其是在现在竞争这么激烈的情况下。如果你所在的行业真的就已经卷到不能再待下去了，更需要思考这个问题。你需要调整你自己，去学习新的技能，以市场为指导。\n现在学历是真的越来越不值钱了，你要培养你自己全方面的能力，而不是去内卷。上一份工作关系好的同事X一直推荐我买一个咖啡机，我平时每天都喝咖啡自己买一个咖啡机既省钱，又有做咖啡的乐趣多好；还有我渐渐地不怎么骑车了。工作都把我蹂躏成什么样子了，我没有思考的时间，对其他事情也渐渐地没有了兴趣，对我的爱好（骑行、乒乓球）也越来越不上心了。最主要的，我作为一个程序员，在高强度的工作压力下也没有很多的积累，也造成了我这次找工作焦虑的主要原因（我想如果我入职的岗位是纯粹做技术的，我这次应该就没有那么焦虑了吧）\n我不应该抱着学习地心态来面对社会和职场，我要想我有什么价值。读到这句话我想到最直接的就是我学习计算机，我想着要有一个环境我才能去了解掌握到高并发的知识，才能学习到AI相关的知识。不，我要努力为自己创造这样的条件，培养这些能力，让培养出来的这些能力成为我的通行劵。应该要放弃学习心态来面对社会和职场。\n不要通过学校和分数来评判你的成功和失败，你要具体分析你每一次的表现，在你能承受的范围内，再进步一点。就像这次找工作面试一样，不要去那么在意是通过了还是没有通过，去总结每次面试你的收获是什么，你有什么可以改进的地方，这样的心态才是好的。好的心态真的很重要。\n"},{"id":102,"href":"/post/computer-science/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"系统设计","section":"Computer Science","content":"系统设计# 数据持久化# 冷热分离# 冷热分离之 OTS 表格存储实战 数据架构：数据冷热分离实践思考 数据架构：概念与冷热分离 查询分离# 分表分库# 服务发现# 事务处理# 本地事务# 全局事务# 共享事务# 分布式事务# 缓存# 客户端缓存# 系统是否真的需要缓存？# 软件开发中引入缓存的负面作用要明显大于硬件缓存带来的负面作用 从开发角度来说 你要考虑缓存的失效、更新、一致性等问题（硬件缓存也有这些问题，只是不需要由你去考虑，主流的ISA也都没有提供任何直接操作缓存的指令） 从运维角度来说 缓存会掩盖一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上 从安全角度来说 缓存可能会泄漏某些保密数据，也是容易受到攻击的薄弱点 引入缓存的理由 为缓解CPU压力而引入缓存 譬如把方法运行结果存储起来、把原本要实时计算的内容提前算好、对一些公用的数据进行复用，这可以节省CPU算力，顺带提升响应性能 为缓解I/O压力而引入缓存 譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问， 将原本对单点部件（如数据库）的读写访问变为对可扩缩部件（如缓存中间件）的访问，顺带提升响应性能 服务端缓存# 读缓存# 写缓存# 负载均衡# 流量治理# 服务容错# 流量控制# 可观测性# 时间日志# 链路追踪# 聚合度量# 架构安全性# 认证# 授权# 凭证# 保密# 传输# 分布式共识# Reference# 凤凰架构 构建可靠的大型分布式系统 搞定系统设计 面试敲开大厂的门 "},{"id":103,"href":"/post/books/%E8%8B%B1%E4%BC%9F%E8%BE%BE-%E9%BB%84%E4%BB%81%E5%8B%8B%E4%B9%8B%E8%8A%AF/","title":"英伟达-黄仁勋之芯","section":"Books","content":"黄仁勋-英伟达之芯# 第1章 求学生涯# 第2章 职涯早期# 第3章 从餐厅起步的Nvidia# 第4章 英伟达遭遇绝境# 第5章 咸鱼翻身# 第6章 新机器时代曙光初现# 第7章 死亡竞赛# 第8章 游戏玩家拯救英伟达# 第9章 光速之道# 第10章 同频共振# 第11章 范式转变的时刻# 第12章 千载难逢的机会# 第13章 由机器引领的时代# 克里泽夫斯基：辛顿在多伦多大学时的学生 因为无法解释神经网络的计算过程，学术界不认可这种方法 辛顿给苏茨克弗和克里泽夫斯基布置了一项艰巨的任务：利用英伟达的GPU训练计算机学会图像识别 卡坦扎罗 2011年加入英伟达 cuDNN cuda deep neural network 矩阵乘法 优秀的神经网络软件应该注重速度而不是精度 马克思与黄仁勋的分歧 马斯克认为，先进的人工智能可能带来灭绝级威胁。这一观点得到了包括辛顿和苏茨克弗在内的大批技术专家的认同，他们还是最初那篇关于AlexNet的论文的合著者。然而黄仁勋完全不这么认为。他竟觉得人工智能毫无风险，真是令我吃惊。 第14章 AI行业的佼佼者# 2016年，英伟达的股价飙升了224%，这让黄仁勋重获荣光，再度跻身亿万富翁行列。不过，在当年的标准普尔500指数中，表现最抢眼的股票并非英伟达，而是其长期竞争对手AMD，其股价涨幅高达309%。黄仁勋并不甘心位居次席。 Omniverse 第15章 AI工厂# 乌斯科雷特把这套学习机制命名为“自注意力” 第16章 全球最具价值的半导体企业# 在2018年的GTC大会上，黄仁勋指出，在短短5年内，英伟达的GPU处理速度提升了25倍，这一成绩远超摩尔定律的预测。接着，他展示了一张图，这张图显示在2012年的显卡上需要一周的时间才能训练出AlexNet，而在他推出的新款计算机DGX-2上则仅需18分钟就能完成训练。 2020年7月，英伟达的市值终于超越了英特尔。没过多久，英伟达的市值又超越了AMD。 第17章 这个时代最重要的科技公司# 第18章 人类需要更多智慧# 第19章 更多电力更大算力# 第20章 地球上最重要的股票# 第21章 向理性本身发起挑战# 第22章 深不见底的恐惧# 第23章 思考机器# "},{"id":104,"href":"/post/computer-science/%E8%BF%90%E7%BB%B4/","title":"运维","section":"Computer Science","content":"查询# # 查找文件 find ./ -name \u0026#34;elastic\u0026#34; # 端口查询 ### 查询 sudo netstat -tulnp | grep :443 sudo lsof -i :443 ### 杀死 kill -9 内存# # 服务器内存占用率 free -h磁盘# # 磁盘占用 df -h"}]