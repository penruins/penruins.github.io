[{"id":0,"href":"/post/others/about-me/","title":"about me","section":"Others","content":" about me # 家乡 云南昆明 骑行 Strava 电影 douban 观影记录 研究各种提升效率的小工具 vim 双拼 raspberry pi ios shortcut "},{"id":1,"href":"/post/life/books/","title":"books","section":"Life","content":" 2025-07 # 台北人 好久没有读到这样的文字了，读起来不流畅。我选的那个版本在正文故事之后有好几篇对台北人的书评和分析，看这些的时候感觉自己更投入一些，才理解了这本书的深层含义 简读中国史 从中华文化的起源开始读历史应该是初中了吧，高中也都没有好好看教材。以现在的认知来看又对一些概念有了更深的理解，例如礼乐是什么，青铜文化传入到中国之后发展的独特性，礼乐崩坏指的是什么，分封制和郡县制，周秦之变，法家思想的极端，罢黜百家。 不止读书 里面提到的书可以慢慢看 读书的人 里面提到的书可以慢慢看 被讨厌的勇气 以对话的方式来论述阿德勒（个体心理学）的一些主要观点。我觉得人生是连续的刹那，这个观点很有意思 健身路线图 解构现代化 温铁军 开了个头读不下去了，概念太多，后面再来吧（2025-07-30） 2025-06 # 看见 柴静发了视频讲看见书里的故事，就想着就把书拿来看了吧。看完书也把一些第一个10年的一些重要的新闻事件回顾了一下，文字中有对新闻事件的陈述，社会问题的思考，作者本人的思考。 超越百岁：长寿的科学与艺术 倦怠社会 里面提出的绩效社会对人心理的影响很有新意，但是读起来很不流畅，很晦涩，概念太多，没有得出结论的过程。 商业就是这样：不可不知的商业常识 2025-05 # 天朝的崩溃：鸦片战争再研究 宋哥推荐我看的。作者对结论的推理非常严谨认真，尤其是在军事实力的对比上，严谨细致程度是之前读历史相关的书所没有接触到的。书中的主要结论在绪论中就表述很清楚了。我看书有时候总喜欢把绪论或者推荐序跳了直接看正文，这本书是和宋哥聊起来这本书的时候他说绪论是对整本书的总结，肯定要读，后面才补上的。 多谈谈问题 薄世宁医学通识讲义 讲了医学的发展历程，医学的核心概念，挺好的科普书 不被支配：为什么我们会被情感绑架 西西弗高速的一期提到了这本书，就找来看了看。远离自恋型人格障碍的人。 简读日本史 二手时间 2025-04 # 东京八平米 找到工作之后读的第一本书，准备面试的时候一直在看技术书，读不动了，找了一本轻松一点的书来看看 印象深的是那个三四点开门的咖啡店，专门给赶早去做工的人做咖啡。老板还专门把自己的咖啡送给临终的老顾客。 Jenkins 2.x 实践指南 Git: Mastering Version Control 凤凰项目：一个IT运维的传奇故事 精通Scrapy网络爬虫 软件方法：业务建模和需求 2025-03 # 高性能MySQL 从程序员到架构师 PostgreSQL实战 搞定系统设计：面试敲开大厂的门 大模型应用开发 动手做 AI Agent Redis 设计与实现 深入浅出 Spring Boot 3.x 大模型应用开发极简入门 2025-02 # Java并发编程实战 黄仁勋：英伟达之芯 英伟达那么火，就找来看看了。讲了黄仁勋与英伟达一开始建立到人工智能爆发中间的故事，以及后面的故事。人工智能的部分除了显卡，还讲了辛顿（反向传播算法），李飞飞（图片标注集） 计算机网络 深入浅出HTTPS：从原理到实战 Python神经网络编程 Spring Cloud微服务：入门、实战与进阶 深入理解Java虚拟机 凤凰架构：构建可靠的大型分布式系统 2025-01 # Java实战 Spring实战 美国困局：新右翼的兴起与挑战 置身事内：中国政府与经济发展 中国分税制改革的背景（第一次从这本书相对详细的了解具体是什么）；市场经济一开始政府对重点行业的扶持；分税制改革对中国房地产行业发展的影响。 树莓派开始：玩转Linux 看这本书主要是因为手上也有个树莓派，其次是可以以一个电脑的角度来输入命令行。看了多进程编程的代码，有了一些初步认识。复习了一些Linux的知识，例如进程间通信。 用地图看懂世界格局 这本书豆瓣评分不高，但还是读了。对所谓的世界格局也没有任何的知识，能读下去就读了呗 宏观经济学 人工智能入门实战：从校园到职场 剑指Offer 图解宏观经济学 2024-12 # 改变未来的九大算法 古希腊文明的光芒 赵林 2023 # 重来3：跳出疯狂的忙碌 书单 # 那么作家约瑟夫·康拉德的《黑暗之心》则帮助我们看清了，我们对领导能力（即争取最高头衔）的严重曲解所带来的问题，或者说招致的罪恶。这部杰作为电影《现代启示录》提供了原型 《黑暗之心》围绕着帝国主义、殖民主义、种族关系以及人性的黑暗展开，主题并不难以理解。但它揭示的另外一层含义是官僚主义。该书中的“公司”（作者是用大写字母C来强调的）具有规则、程序和等级制度，有掌权者和争权夺势者，跟任何其他官僚体系并无差异。 《米德尔马契》 之所以你我能够享受稳定的生活，有一半应归功于那些不为人知、踏踏实实为了自己的理想而生活的先辈。 《世界是平的》 《一个青年艺术家的画像》则以戏剧性的夸张手法描述了宗教信仰向人文艺术的过渡。故事主人公斯蒂芬·迪达勒斯放弃天主教会的神职，因此放弃了获得圣餐变体的机会，他选择投身于文学的奇迹，引用书中的话则是，“把每日平凡的生活经历转化为永恒的发光的生命”，即凝结为不朽的艺术作品。 麦田里的守望者 莎士比亚的《麦克白》或者美国家喻户晓的《黑道家族》体现了人性中的野心 契诃夫或费里尼的作品呈现了社会的倦怠 以及美国作家拉尔夫·埃利森和印度作家阿兰达蒂·洛伊笔下的边缘人群 但丁教会了我爱与恨并非对立，两者相辅相成 英国小说家E.M.福斯特让我明白了自由心态常常是虚荣和无知的遮羞布 作家玛丽·盖茨基尔向我揭示了灵魂在肉体上的体现方式 在《婚变》这部小说中，杰弗里·尤金尼德斯讲述了20世纪80年代初从布朗大学毕业的3位学生的故事。 在他回答问题的时候，他已经全然忘记了这是一份学校试卷。他已经不是为了成绩在答题，而是在思考他自己及身边同龄人一直以来的困境。这是一种奇特的感觉。虽然笔下明明在引用蒂利希和海德格尔的话来阐述观点，但是在他脑海里浮现的却是自己和他的朋友们……在回答论文的问题时，米切尔不断地将自己的答案引向跟实际生活相关的内容。他在思考他的存在以及如何度过自己的一生。这是多么完美的结束大学生涯的方式。教育最终引领米切尔走进了生活。 "},{"id":2,"href":"/post/history/chinese-history/","title":"Chinese History","section":"History","content":" 中国文明并不是世界上最早出现的文明。以有文字和建筑能证明国家的出现而论，中国比苏美尔要晚近2000年，比埃及也要晚了1500年 但是中国后发先至。在西周时期，中国在人类历史上第一次建立起整饬的大一统封建制度，比欧洲早了近1800年。 接下来，中国又率先在世界上建立了大一统中央集权国家，同样比欧洲早了近2000年。 早在公元前3世纪，中国就实现了中央政权对基层社会的直接统治和严密控制，能够在全国范围内大规模调动资源 西欧中央集权国家和中国的中央集权的形成过程相当不同。欧洲是在议会、自治城市、行会等多种社会力量发育起来之后才出现中央集权国家的。因此，在欧洲的民族国家中，君主的专制权力是有限的，君主权力不仅受法律、议会的制约，也受到各社会阶层、利益团体的限制 欧洲的中央集权之路，还进行过多种探索和比较 英国之所以后来能超越西班牙，就是因为它的体制既比荷兰松散的城邦联合体更有凝聚力，同时又比西班牙的君权受到更大的约束 三代之治 周秦之变 分封制 和 郡县制 的区别 中世纪欧洲的政治体制和分封制的相似之处 议会制度 管理北京委员会 20世纪40年代土耳其政治民主化以后，数量庞大的底层民众开始显示力量，伊斯兰因素又堂而皇之地一步步彰显存在，到近些年达到高峰。 违背了科学的民主，最终会变得不民主！让专制体制下的臣民进行选举，他们只会选举出比较好的君主，而不是选出一个支持民主的公民；让宗教信徒进行选举，他们也只会选出宗教领袖，而不是选出一个具有科学精神的公民！ 拉丁美洲的民选政治也步入泥潭。 在贫富差距和社会动荡中焦虑不安的拉美民众很容易受到那些激进口号的影响，他们喜欢那些提出诱人目标和简单快速的解决方式的领导人，谁的气质和姿态最权威，最像“父亲”，谁的许诺最直接、最简单、最激进，就最容易上台。 比如委内瑞拉的查韦斯许诺要为穷人提供“超福利”（免费住房、免费汽油），因此迅速崛起于政治舞台。 上台之后，为了兑现承诺，查韦斯大力推行国有化，把所有行业都收归国有。 但赶走了有管理能力的外国投资者之后，委内瑞拉本国却没有成熟的企业家阶层接手，国有企业陷入效率低下和严重腐败当中，激进的国有化不久之后就导致各种物资短缺。堂堂的“石油富国”已经沦落到需要进口石油，超级市场没有食物，人们到垃圾箱去捡东西吃。 国家的经济崩溃了，穷人获得的福利也自然随之成为泡影。委内瑞拉的经济困境，反映的其实是政治上的不成熟。 清教文化，儒家文化 中国的历史、文化和地理，决定了它的大一统趋向 "},{"id":3,"href":"/post/computer-science/computer-science/","title":"computer science","section":"Computer Science","content":" computer science # main # github # yihong0618 阮一峰的网络日志 nacos # nacos 官方文档 配置更新监听 Spring中动态监听Nacos配置更新 依赖里面没有 NacosConfigManager 这个类，是因为必须使用 spring cloud alibaba ? Nacos 融合 Spring，成为注册配置中心 Nacos 融合 Spring Cloud，成为注册配置中心 这个是最新的文档 2.x 的文档 事件驱动 最后配置变更是通过 spring 的框架的事件监听来实现的 @Autowired private Environment environment; @EventListener public void handleEnvironmentChange(EnvironmentChangeEvent event) { // TODO String key = event.getKeys().get(xxxx); String value = environment.getProperty(key) } 博客搭建 # Built with Sphinx using a theme provided by Read the Docs. e.g. "},{"id":4,"href":"/post/computer-science/java/java-basic/","title":"java basic","section":"Java","content":" java basic # mess # 八大数据类型 # byte char boolean short int long float double transient 关键字的作用是什么？ # 在一个类中如果变量被 transient 关键字修饰，在对类的对象进行序列化的时候就会忽略这个变量 什么是深拷贝？什么是浅拷贝？ # 深拷贝：递归地复制对象及其所有嵌套的子对象，生成一个完全独立的新对象。两个对象之间不共享引用 浅拷贝：创建一个新的对象，但只复制对象的最外层属性的引用 String # equals与 == 区别 # equals 比较的是两个字符串的内容是否是相等的 == 比较的是两个变量指向的引用是否是相等的 StringBuilder StringBuffer区别 # StringBuilder 线程不安全 StringBuffer 线程安全 StringBuffer 是怎么保证线程安全的？ # 对字符串操作的方法都通过 synchronized 关键字修饰，保证线程安全 StringBuffer 和 StringBuilder 字符串在底层是以什么数据结构保存的 # 两个类都继承子 AbstractStringBuilder 均使用 char[] value 保存字符串数据 HashMap # HashMap底层的数据结构是怎样的？ # java 1.8 之前 数组 + 链表 java 1.8 之后 数组 + 链表/红黑树 HashMap 是否线程安全，如何保证线程安全 # 不是线程安全的 如何保证线程安全 Collections.synchronizedMap() ConcurrentHashMap 读写锁 ReadWriteLock 局部使用 HashMap 初始化写，后续只读 HashMap get 时间复杂度 # 最好的情况是O(1) 若发生哈希碰撞，对应到桶之后还需要查询链表或红黑树，时间复杂度下降到O(N)或O(logN) HashMap 和 Hashtable 有什么区别？ # 线程安全性 HashMap是线程不安全的，HashTable是线程安全的 对空值的支持 HashMap的key和value都支持空值，HashTable不支持key或value为空值 List # Collection 和 Collections 有什么区别？ # Collection 是集合类的一个接口 Collections 是集合的一个工具类 LinkedList 删除时间复杂度 # 删除头和尾的时间复杂度为O(1)，因为在LinkedList中维护了头和尾2个指针 其他位置的时间复杂度为O(n) 函数式编程 # java的函数式编程包含哪些内容？ # java的函数式编程的概念中将只包含一个方法的接口称为函数式接口，可以通过Lambda表达式简化匿名类的定义 提供流操作了API，可以将集合的迭代操作变为链式操作，提供了并行处理集合的方法 提供了Optional类用来处理空指针的情况 I/O # 网络io分为哪几种 # 网络 I/O 模型主要分为以下五种：\n阻塞 I/O（Blocking I/O, BIO） 特点：用户线程在发起 I/O 操作后，如果数据未准备好，会一直阻塞等待，直到数据就绪并完成拷贝。 优点：实现简单，适合连接数少、并发度低的场景。 缺点：每个连接需要一个线程处理，线程开销大，不适合高并发场景。 非阻塞 I/O（Non-blocking I/O, NIO） 特点：用户线程发起 I/O 操作后，如果数据未准备好，会立即返回错误码，线程通过轮询不断检查数据是否就绪。 优点：一个线程可以处理多个连接，减少了线程阻塞。 缺点：频繁的系统调用和轮询会导致 CPU 资源浪费。 I/O 多路复用（I/O Multiplexing） 特点：使用单个线程监听多个文件描述符（如 socket），当某个描述符就绪时，通知用户线程进行处理。常见的实现有 select、poll 和 epoll。 优点：适合高并发场景，减少线程数量和系统开销。 缺点：数据拷贝阶段仍然是阻塞的，且实现复杂度较高。 信号驱动 I/O（Signal-driven I/O） 特点：用户线程发起 I/O 操作后，内核通过信号通知用户线程数据已就绪。 优点：避免了轮询，减少 CPU 资源浪费。 缺点：信号处理复杂，且信号队列可能溢出。 异步 I/O（Asynchronous I/O, AIO） 特点：用户线程发起 I/O 操作后立即返回，内核在数据准备和拷贝完成后通知用户线程。 优点：完全非阻塞，适合高性能场景。 缺点：实现复杂，且并非所有系统都支持。 Reference\n所以当发生一次网络请求时，将会按顺序经历“等待数据从远程主机到达缓冲区”和“将数据从缓冲区复制到应用程序地址空间”两个阶段\n根据实现这两个阶段的不同方法，人们把网络I/O模型总结为两类、五种模型：两类是指同步I/O与异步I/O，五种是指在同步I/O中又划分出阻塞I/O、非阻塞I/O、多路复用I/O、信号驱动I/O四种细分模型以及异步I/O模型\n异步I/O(Asynchronous I/O)：比如你在美团外卖订了个盒饭，付款之后你自己该干嘛干嘛，饭送到时骑手自然会打电话通知你。异步I/O中数据到达缓冲区后，不需要由调用进程主动进行从缓冲区复制数据的操作，而是复制完成后由操作系统向线程发送信号，所以它一定是非阻塞的。\n阻塞I/O(Blocking I/O)：你去饭堂打饭，发现饭还没做好，只能等待（线程休眠），直到饭做好，这就是被阻塞了。阻塞I/O是最直观的I/O模型，逻辑清晰，也比较节省CPU资源，但缺点是线程休眠所带来的上下文切换，这是一种需要切换到内核态的重负载操作，不应当频繁进行。\n非阻塞I/O(Non-Blocking I/O)：你去饭堂，发现饭还没做好，你就回去了，然后每隔3分钟来一次饭堂看饭是否做好，一直重复，直到饭做好。非阻塞I/O能够避免线程休眠，对于一些很快就能返回结果的请求，非阻塞I/O可以节省切换上下文切换的消耗，但是对于较长时间才能返回的请求，非阻塞I/O反而白白浪费了CPU资源，所以目前并不太常用。\n多路复用I/O(Multiplexing I/O)：多路复用I/O本质上是阻塞I/O的一种，但是它的好处是可以在同一条阻塞线程上处理多个不同端口的监听。仍以去食堂打饭为例，比如你代表整个宿舍去饭堂打饭，去到饭堂，发现饭还没做好，还是继续等待，其中某个舍友的饭好了，你就马上把那份饭送回去，然后继续等待其他舍友的饭做好。多路复用I/O是目前高并发网络应用的主流，它还可以细分为select、epoll、kqueue等不同实现，这里就不再展开了。\n信号驱动I/O(Signal-Driven I/O)：你去到饭堂，发现饭还没做好，但你跟厨师很熟，跟他说饭做好了叫你，然后你就回去了，等收到厨师通知后，你再去饭堂把饭拿回宿舍。这里厨师的通知就是那个“信号”，信号驱动I/O与异步I/O的区别是“从缓冲区获取数据”这个步骤的处理，前者收到的通知是可以开始进行复制操作了，即要你自己从饭堂拿回宿舍，在复制完成之前线程处于阻塞状态，所以它仍属于同步I/O操作，而后者收到的通知是复制操作已经完成，即外卖小哥已经把饭送到了。\n显然，异步I/O模型是最方便的，但前提是系统支持异步操作。异步I/O受限于操作系统，Windows NT内核早在3.5以后，就通过IOCP实现了真正的异步I/O模型。而Linux系统是在Linux Kernel 2.6才首次引入，目前还不算很完善，因此在Linux系统下实现高并发网络编程时仍以多路复用I/O模型模式为主。\n《凤凰架构》 7.2.2 网络I/O 模型\nJava支持的IO模型 # 阻塞 I/O（Blocking I/O, BIO） 特点：线程在发起 I/O 操作后会被阻塞，直到数据准备就绪并完成拷贝。 实现：Java 的传统 I/O 模型，位于 java.io 包下，如 FileInputStream、FileOutputStream 等。 适用场景：适合连接数较少、并发度低的场景。 缺点：每个连接需要一个线程处理，线程开销大，不适合高并发。 非阻塞 I/O（Non-blocking I/O, NIO） 特点：线程在发起 I/O 操作后不会被阻塞，可以立即返回并继续执行其他任务。 实现：Java 1.4 引入的新 I/O 模型，位于 java.nio 包下，如 ByteBuffer、FileChannel、SocketChannel 等。 适用场景：适合高并发场景，一个线程可以处理多个连接。 缺点：需要复杂的调度和管理。 异步 I/O（Asynchronous I/O, AIO） 特点：线程发起 I/O 操作后立即返回，内核在数据准备和拷贝完成后通知线程。 实现：Java 7 引入的异步 I/O 模型，位于 java.nio.channels 包下，如 AsynchronousFileChannel、AsynchronousSocketChannel 等。 适用场景：适合高性能、高并发的场景。 缺点：实现复杂，且并非所有系统都支持。 stream 结构 # "},{"id":5,"href":"/post/life/%E6%91%98%E6%8A%84%E5%88%86%E4%BA%AB/","title":"摘抄分享","section":"Life","content":" 摘抄分享 # 2025 # 2025-08-06 # 宋志平指出，像水泥、钢铁、光伏等产品，没有太大的价格弹性，降价是没用的，一家企业降了价，其他企业也降，需求还是那些。因此，要想产销平衡，必须限产。但限产后，价格上来了，企业又有了扩产能的冲动。限产量和限产能还得同时进行，才能保住价格。 #财经-2025-16\n地方政府热衷于扶持同质化产业，一是增值税是地方财政收入的主要税种；二是扭曲的政绩观，地方政府往往盯着中央的产业政策目录，却没有基于比较优势、因地制宜地发展本地产业。 #财经-2025-16\n黄少卿认为，财税关系的调整是关键，唯有如此，才能改变对地方政府的激励机制。如果地方政府的财政收入转为以物业税为主，将极大地激励地方政府改善营商环境、治安环境，加大知识产权保护。此外，地方政府的经济决策权和干预权，很多时候是通过地方立法和设立行政审批权等方式自我赋予的，建议中央可以对各地的行政审批事项进行逐一审核。 #财经-2025-16\n接受较低的实际GDP增长目标，削减过剩产能将导致实际GDP增长放缓。设定较低的实际GDP增长目标也将消除继续加大制造业和基础设施投资的动机。最后是提振国内消费。 #财经-2025-16\n摩根士丹利预计，2025年中国低通胀压力还会持续，2026年大概率也会如此，但2027年有更大可能是中国经济整体走出低通胀的第一年。未来12个月到18个月，中国低通胀压力将逐渐改善。 #财经-2025-16\n“现在有一种坏现象，价格战比的是谁的配置低，成本不断往下降。这样是坚决不行的，比如刹车系统，单个零件可能只差个几百块钱，但是在关键时候就是能不能保命的区别。卷价格是低层次的，质量才是最核心的。”一汽解放董事长、党委书记李胜感叹道。 #财经-2025-16\n“内卷”(Involution)源于人类学家克利福德·格尔茨的研究，原指一种社会发展模式停滞的状态：即所有人都付出更多努力，但整体收益却没提高，甚至下降。正常竞争的特点是：竞争能推动整体进步（企业持续创新→行业技术升级），个体在竞争中成长（通过学习提升能力）；而内卷的特点是：竞争只导致内耗（压价格→全行业利润下降），在竞争中被消耗。 #财经-2025-16 #内卷\n2025-08-05 # 我一般不习惯为了多元化而吹嘘“多元性”的价值，但是我不得不承认多元背景在公立大学课堂上的贡献和美妙之处。在我教授的一门研讨课上，有位女生来自巴基斯坦，有位来自孟加拉国，有位是坐轮椅的黑人，还有一位是以色列人，学生群体的多样性彻底影响了我们对东方文化的学术讨论。在这种氛围下，你无法对“他者”的概念进行简单的抽象和草率的分析。 #优秀的绵羊\n如果一所精英大学邀请我去发表新生入学演讲，我会告诉这些年轻人：你们或许确实很聪明，也很努力，但你们能来到这里，最主要的原因在于，你们很走运。你们或许的确通过竞争打败了自己的同龄对手，但事实上，你们的对手中有90％在比赛开始之前就已经出局了。 #优秀的绵羊\n很多人发现，精英学校的学生大都有一种优越感：因为他们的SAT分数比普通人高，所以他们自然就应该享有一些他人享受不到的特权。而事实上，真正的逻辑应当是：他们的SAT分数之所以比别人高，是因为他们本来得到的就比别人多。 #优秀的绵羊\n你无法通过沉思来同情不同背景的人，更不用说了解他们了。要想真正了解与自己背景不同的人，你只能实际进入他们的世界：不是去进行所谓的“奉献”，更不是请人喝杯咖啡，或带着屈尊俯就的态度去向下层人民嘘寒问暖一番。你如果要做到把对方当成与你平等的人，就得去了解他们本来的样子。 #优秀的绵羊\n我知道，很多人都夸你很聪明，但其实你并没有那么聪明；你只是在某些地方比别人聪明一些，而且只是比你周围的那群人聪明一些而已。名校之外还有很多聪明人，他们之所以没进名校，可能就是因为他们在这个世界上的阶层地位。很多不“聪明”的人其实很聪明。 #优秀的绵羊\n正如约翰·罗斯金告诉一位年轻精英人士的那样：“用大脑去尽力抢占一切并不比用拳头抢占更高尚。没错，这个社会总是要有分工的，有人要干活，有人要管理，但管理者并不应该拿走所有的利益。” #优秀的绵羊\n密涅瓦的猫头鹰总在黄昏起飞\n一位在波莫纳学院招生办公室工作的学生告诉我，她在面试中最喜欢的申请人是那些在高中阶段有过失败经历的人，她认为这样的人很有趣，但遗憾的是，这样的学生从来不会被录取。有人建议，在递交申请资料时，除了列出自己的成绩以外，申请者们还应当提交一份“失败履历”。 #优秀的绵羊\n要想在某一领域做到真正优秀，你必须学会专一，集中精力，听从自己的直觉，而不是去在意自己的履历是否丰富多彩。 #优秀的绵羊\n凯特琳·弗拉纳根曾说过，那些进入名校的人，大都接受过足够的教育，知道该如何保持政治正确，但他们所受的教育不足以让他们“认为精英大学的理念令人反感”。 #优秀的绵羊\n2025-08-04 # 一个人之所以有意思是因为他大量阅读，习惯思考，放慢脚步，投入深度对话，并为自己创建了一个丰满的内心世界。 #优秀的绵羊\n真正意义上的拥有自信本来就不会太在意考试成绩。真正的拥有自信是不管他人试图给你灌输什么理念，自己都始终坚信“我”的价值远远超过成绩，真正的拥有自信是自己决定什么是成功。 #优秀的绵羊\n我们会羡慕有人从名校退学并创业，成为下一个马克·扎克伯格，但不能理解有人完成大学学业仅仅是为了成为一名社会工作者。 #优秀的绵羊\n我现在已经从哈佛大学毕业，在一家独立运营的书店工作，生活有保障，但是我的经历跟你所描述的情况几乎一致：当我告诉周边的人我目前的工作，而且在短期之内并没有进一步深造或者上法学院的打算，也没有兴趣将来成为一名律师或者政治家时，我所得到的反馈是不理解，甚至愤怒。就在昨晚，我和父亲之间再次上演口舌战，他声讨我浪费了哈佛大学的文凭。他认为学习农耕，服务社区，给予自己时间思考，以及治愈长期严格分类和滞后的社交生活所造成的情感创伤是自私和懒惰的表现，远不及直接“出卖自己”创造价值。 #优秀的绵羊\n当你所从事的工作直接匹配你最强大的能力时，你的幸福感就油然而生，转化成快乐和自主。 #优秀的绵羊\n地位这个词则较为复杂，你永远不可能感到满足。从本质上来讲，地位就代表攀比与竞争，它不仅不会给你带来快乐，而且还时刻让你不快乐。 #优秀的绵羊\n就上大学期间如何提高自己这一问题，我在此提几个建议。同父母的交流频率不超过一周一次，最好是一个月一次。无须告诉父母任何有关论文或考试的成绩，甚至在校期间的任何情况，同时，也不要期望求助于父母。如果父母涉足你的选课或者大学生活的细节，那么你要委婉地拒绝。如果父母不接受你的拒绝，那么你得大声地告诉他们，大学是完全属于你的，不是他们的。 #优秀的绵羊\n你是否考虑过做一些无法在Facebook上炫耀的，不能为个人简历加分的事情？是否考虑过自由地漫游，或者“隐居”并享受阅读？是否考虑过跟一群朋友或需要合租的陌生人同住一个屋檐下，然后找份兼职来养活自己？你也许认为此举没有收获，但你至少会遇见你本来根本不可能遇见的人。 #优秀的绵羊\n广交人脉的最好办法就是随波逐流、人云亦云，不必为原则承担风险，或者根本不需要原则。生活在某种体制下，你既不需要信奉该体制，也无须质疑它。你只需要成为他人希望看到的守业者，最终你将像康拉德笔下的那位负责人一样，成为内心空洞的人。 #优秀的绵羊\n我们也许对政治不感兴趣，但是政治偏偏乐于影响每个人的生活。远离政治并不能消除政治无所不在的影响力。 #优秀的绵羊\n布朗大学的一位教授告诉我，年轻人有拯救世界的意愿，但是这种意愿背后的认知往往是，通过这些过程最终为自己争得某种社会地位 #优秀的绵羊\n就如另一位人文专业学生所言：“我每天被迫去思考人类历史上最难的问题”，这是你能给自己提供的关于如何说话和思考的最好训练。 #优秀的绵羊\n没有任何计时器可以量化我们从伍尔夫那里得到的收获，也没有尺子可以丈量狄更斯所带给我们的价值。我们需要的是故事，而不是公式。 #优秀的绵羊\n引用哲学家丽贝卡·戈尔茨坦的原话：“我信仰小说。我信奉它具有巨大的力量，能生动地呈现世界对我们每个人来说有多么不同。”艺术淡化了自我中心意识，教会了我们要有同情心，提高了我们的情商，或许艺术真的可以造就更好的我们。 #优秀的绵羊\n外交战略家查尔斯·希尔称，文学使用不受框架和方法论限制的语言，因有极大的自由度和灵活性而能够充分表达世界是如何真正运作的。 #优秀的绵羊 #文学的意义\n我甚至不是建议必须读人文专业。我只是建议，你们应该尽可能抓住大学里的各种机会，去尝试和体验那些与你所选专业不同的领域，尤其是人文领域所能带给你的那种独特经验。 #优秀的绵羊 #人文\n现代社会的种种问题，不仅在于官僚主义，还在于我们的领导者是一群过于专业化的精英，他们不仅是官僚系统里的懦夫，而且不能突破自己的专业背景思考问题。 #优秀的绵羊\n虽然刘易斯承认，教授的指导以学术为主，但是任何一种学习和成长必须是建立在感情之上的，因此学生更愿意寻求自己高度信任的教授的帮助。 #优秀的绵羊\n在求学的时候，我逐渐归纳出如何判断老师教学质量的一个规律。如果某位教授从来不透露一些与个人相关的信息，比如自己的孩子或者同事的趣闻轶事，那么我敢断定，从他身上学生将学不到太多东西。我并不是要求老师交代一切，而是希望老师能够让学生感受到他的真实存在。 #优秀的绵羊\n就像心理学家所说的“微小差异的自恋”，即人们为了感觉自己比那些与他们极其相似的人更优越而做出的无意义区分。 #优秀的绵羊\n2025-08-03 # 长夜才开始，黑暗中请记得太阳的模样，沉默中不要为魔鬼歌唱。\n一个人口几乎占人类三分之一的大帝国，不顾时势，安于现状，人为地隔绝于世并因此竭力以天朝尽善尽美的幻想自欺。这样一个帝国注定最后要在一场殊死的决斗中被打垮：在这场决斗中，陈腐世界的代表是激于道义，而最现代的社会的代表却是为了获得贱买贵卖的特权——这真是任何诗人想也不敢想的一种奇异的对联式悲歌。 #简读中国史\n资本主义在欧洲的发展，是人类历史的一个特殊现象，这一特殊现象的产生依赖于欧洲小国林立的特殊条件。无独有偶的是，在欧亚大陆另一端的日本，也因为诸侯林立，可以在危机面前做出多种选择，从而使正确的选择脱颖而出。 #简读中国史\n阿根廷著名诗人埃斯特万·埃切瓦利亚(Esteban Echeverría)曾写道：“我们是独立的，但我们是不自由的；西班牙的军队不再压迫我们，但她的传统却压得我们喘不过气来。” #简读中国史\n这些田园风味的农村公社不管初看起来怎样无害于人，却始终是东方专制制度的牢固基础；它们使人的头脑局限在极小的范围内，成为迷信的驯服工具，成为传统规则的奴隶，表现不出任何伟大和任何历史首创精神。 #马克思恩格斯全集\n历史中的资产阶级时期负有为新世界创造物质基础的使命：一方面要造成以全人类互相依赖为基础的世界交往，以及进行这种交往的工具，另方面要发展人的生产力，把物质生产变成在科学的帮助下对自然力的统治。资产阶级的工业和商业正为新世界创造这些物质条件，正像地质变革为地球创造了表层一样。 #马克思恩格斯全集\n阅读是大脑的运动，运动是身体的阅读\n如果要出人头地，出类拔萃，那么就要完全配合并服从这个系统。我看到身边不少朋友，为了成绩和简历，不惜牺牲自己的健康、友情、爱情、个人探索、课余活动等。而这些牺牲恰恰又是构建一个人内心和灵魂的基石。 #优秀的绵羊\n想象一下，一只悠闲的鸭子在湖面上逍遥自在地游过，水面之上的平静掩盖了水面之下鸭掌的疯狂拨动。 #优秀的绵羊\n当回头去看这些人的成长之路，我们会发现，这些人已经非常习惯于经受磨炼，因为只有克服种种困难才能出人头地，才让人觉得有安全感，才让人觉得自己有价值 #优秀的绵羊\n作家迈克尔·刘易斯写道，当三文鱼洄游时，“数量多了就会产生安全感”。 #优秀的绵羊\n这一切就使得人对风险极力回避。当你的生活中没有被给予犯错空间的时候，你唯一能做的就是不给错误任何机会。这是精英教育会阻碍个人学习的一大原因。 #优秀的绵羊\n由于学生都不愿意去上一门自己没有把握取得优秀成绩的课程，因此大家无法拓展并超越自己已经熟悉的领域。 #优秀的绵羊\n我们也可以说这是一种典型的中产阶层幻想：生活是可以预测的，只要步步为营取得好成绩，就能保证将来的稳定和舒适。 #优秀的绵羊\n家庭派送出一位孩子，孩子一直认为自己是独立、自由的，但其实不过是走上了一条完成父母使命的道路。 #优秀的绵羊\n赞美代替不了温暖，父母迫切希望灌输给孩子的浮夸自信代替不了自我效能感。 #优秀的绵羊\n她的女儿当下被哈佛录取，并不能证明她育儿方式的成功。她们当然会上哈佛，因为这就是哈佛所认可的培养方式，而这恰恰反映了整个教育系统的弊端。 #优秀的绵羊\n社会学家米切尔·L.史蒂文斯曾说：“富裕家庭的生活方式就是围绕如何培养可以量化的美德。”在这里，“可以量化的美德”无非就是大学申请表上能够体现出来的那些东西。总而言之，我们不仅在为应试而教育，而且为应试而活。 #优秀的绵羊\n就如同电影《黑天鹅》里的主人公为了达到完美的表演效果而不惜失去理智，仿佛生活在幻想之中。 #优秀的绵羊\n学生之所以会参加体育、艺术或者展现领导能力的活动，并不是因为对这些精神的追求，而是因为这是通向名校的必经之路。这些活动原本是有意义的，但是现在被简化成一种手段：体育竞技讲究的是体能训练，音乐不过表现为技术上的娴熟，服务他人则等同于做慈善，展现领导能力无非就是追求权力。 #优秀的绵羊\n米切尔·L.史蒂文斯在《创造一个阶层》一书中写道：“私人升学顾问就是教会学生如何包装自己，满足招生官的胃口。最终我们教会学生的，是去追求一个可以包装的自我，或者最起码是去追求一个可以包装的自我幻觉。” #优秀的绵羊\n这是个历史遗留问题，它的根源在于美国高等教育源自两个体系：传统英式的高等教育体系和以学术研究为导向的德式高等教育体系。因此，美国的高等教育从初始就是分裂的。 #优秀的绵羊\n如今高校之所以还存在专业分类，实质上是因为两种理念即深度教育和广度教育之间的一种妥协。这种妥协不仅存在于专业与非专业之间，而且存在于各专业类别与本专业之间。 #优秀的绵羊\n大学生修双学位的趋势越来越明显，部分原因是高校选修课系统相对于传统专业系统的无逻辑和无秩序性，鼓励了学生利用学分的灵活性来获取最大化收益。专业课程已经成为课程中唯一对学生有意义的部分，所以他们宁愿多学习专业课。 #优秀的绵羊\n所以，在入校之际，学生会听到一两次激动人心、鼓励他们思考人生的演讲；而到毕业之际，学生会重温一两次类似的鼓励他们思考人生的演讲。在这四年间，学生埋头钻研由一群专注细分领域的教授提供的课程，立志成为一名专才。 #优秀的绵羊\n从小接受赞美式教育的学生，自信心来源于完美主义，因此他们不具备接受批评的能力。 #优秀的绵羊\n问题在于，参与的事情越多，能做好的事情就越少，并且可能最后什么事情都做不好。 #优秀的绵羊\n然而，因为SAT分数往往跟家庭背景有较大的相关性，所以实际上，高校把更多的钱分配给了并不需要经济资助的学生，同时忽视了真正需要经济援助的家庭。学生可能为了争取被名校录取而不择手段，大学也是如此。 #优秀的绵羊\n高校运作商业化产生的最严重影响是学校对学生的重新定位。学生是“消费者”，因此学校需要迎合而非挑战他们。作为消费者，学生占有主动权。 #优秀的绵羊\n用刘易斯的话来说，那就是：“因为没有更远大的理想来引导本科教育，大学教育的决策往往是出于满足学生的直接需求而制定的。”这也就不难理解，为什么学校都在不断地集资，修建各种高端的宿舍、体育馆、学生中心等，即使负债累累也在所不惜。这种扩建工程在20世纪90年代和21世纪初发展得最为明显，也难怪学费一直在飞速增长。学校即使失去人文教育，也不能没有高端的设施。 #优秀的绵羊\n罗斯·多塞特如此评价他的母校：“哈佛依然是世界上最棒的高等学府之一”，但是“它不会主动教育你，也不会很有深度地引导或者影响你，甚至挑战你”。 #优秀的绵羊\n追究大学的使命是什么，无异于追问生命的目的、社会存在的意义以及人存在的意义是什么。 #优秀的绵羊\n之所以我们要去探究大学的目的是什么，就是因为我们要保证自己至少还能够成为一个完整的人 #优秀的绵羊\n大学承担的责任首先是教学生如何思考。虽然这听起来像陈词滥调，但是它的实际意义要比我们想象得广和深。思考并不是简单地培养特定学科所需的思维技能（比如解决方程式或者分析文章），甚至不是获取跨学科的工作能力。思考实质上是培养思辨的习惯，并把这一习惯运用于实际生活中。简单来讲，学会思考就是以批判的眼光审视身边的所有事物，从而能够得出自己的结论。 #优秀的绵羊\n真正的教育（即博雅教育）的首要责任是教导人类识别以讹传讹所形成的“意见”，并质疑它，最后从新的角度进行思考。 #优秀的绵羊\n我们生活中需要的是，有专业人士提醒我们到底哪里出错了。 #优秀的绵羊\n真正的教育是让学生带着问题迎接社会，而不是带着一份个人简历。 #优秀的绵羊\n难道你不觉得世界上的痛楚和困难对培养人的理智并铸就灵魂是必要的吗？ #优秀的绵羊\n每个人在大学期间真正需要培养的是反思的习惯，即拥有从变化中成长的能力。 #优秀的绵羊\n2025-07-31 # 一人，一家，一团体，一地方，乃至一国，不少单位都没有能跳出这周期律的支配力，大凡初时聚精会神，没有一事不用心，没有一人不卖力，也许那时艰难困苦，只有从万死中觅取一生。既而环境渐渐好转了，精神也就渐渐放下了。\n贾思楠：《1915—1976——毛泽东人际交往实录》，江苏文艺出版社，1989，第73～74页。\n所以中国史书中并没有“主逼佃反”这个词，而只有“官逼民反”。\n2025-07-30 # 我有一个愿望:希望每年读的书摞起来都能达到我的身高。我认为阅读的厚度决定人生的高度。这样，日复一日，经年累月，我就会成为思想上的“巨人”。\n尤里卡\n每当读完一本好书，就像洗了一次澡，也许你不会发现有什么明显的变化，但身上的污垢已经减少了很多。这种变化以一种极为显著却难以察觉的方式时刻在进行着。\n尤里卡\n对我来说，阅读是一场自我革命，它借由充沛的思想资源，哪怕是刹那间阿基米德式的“尤里卡”时刻，丰厚自身的生命体验，走出“洞穴”，摆脱封闭的可见世界，从而看见“太阳\u0026quot;，迎接崭新的可知世界，甚至实现灵魂转向。正如海子的那句诗，“你来人间一趟，你要看看太阳”。\n尤里卡\n2025-07-21 # “我不是来树敌的，但这是环法，有机会赢赛段的话不能退缩，” 波加查辩解道，“你永远不知道自己在环法的最后一天会是什么时候。说实话，车队付你薪水是让你赢，不是让你让出冠军的，身后有庞大的团队支持你，他们职业生涯的每一天都在为环法、为赢得环法而努力。”\n“我觉得如果我单方面决定放弃所有能争取的机会，团队不会高兴的。有机会就该去拼。说实话，当我结束职业生涯时，可能 99% 的 peloton（车手集团）成员我都不会再联系，我会专注于亲近的朋友和家人。”\n当被问及是否不可战胜时，波加查回应：“不，显然不是。你看看我 2022 和 2023 年的环法，我有过状态不佳的时候，有过崩溃，输掉了比赛。那两年我也有很棒的表现，拿到亚军，赢了赛段，但确实有被别人拉开差距的时候。谁也说不准，我可能会有状态不好的时候，别人也可能比我表现好，所以我不会说自己不可战胜。我会努力做到不可战胜，但糟糕的日子可能会来。”\n当被问及赛后是否能继续激励自己去赢、去突破，以及最终意义何在时，这位 26 岁的车手语气中带着几分哲理。\n“我不知道。这是个好问题，很难回答，” 他说，“你知道吗，任何事情的意义是什么呢？我 8 岁开始骑车，生活围绕自行车展开。我在自行车上找到了最亲密的朋友，找到了我的未婚妻。所以意义在于要享受当下，享受那些小事，不只是胜利，就像你说的，赢了之后人们会想着下一次胜利，或者觉得你赢太多了。”\n“所以要享受当下，享受你正在做的事，享受你为之付出一切的事，活在当下就是这个问题的答案。别太在意别人怎么想。”\n2025-01-05 # 称职的程序员都知道自己头颅的尺寸是有限的，所以他们以谦逊的态度来对待工作，像回避瘟疫一样地回避小聪明。\n为什么这么少的人追求优雅？这就是现实。如果说优雅也有缺点的话，那就是你需要艰巨的工作才能得到它，需要良好的教育才能欣赏它\n王垠，我知道你在 Cornell 上过这种课。我也知道 Cornell 是比 IU 好很多的学校。可是每个老师的教学方法都是不一样的，你应该来上我的课。我和我的朋友们在这里做教授，不是因为喜欢这个学校，而是因为我们的家人和朋友都在这里。\n2024 # 2024-11-17 # 尽吾志也而不能至者，可以无悔矣，其孰能讥之乎？此余之所得也！\nyou don\u0026rsquo;t give up, then there\u0026rsquo;s no limitation.\n真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。\n梦里不知身是客，一晌贪欢\n2024-11-15 # Some people say that, like people like us are idealists, always think of some irrelevant things, but I want to a million times, said: Yes we do. \u0026mdash;- Che Guevara\n有人说像我们这样的人是理想主义者，总是想着一些不着边际的事情，但我要第一万次说：是的，我们就是这样的人 \u0026mdash;- 切格瓦拉\n2024-07-07 # 受伤越深，我的爱也越炽热，危险只会增添这份爱，让它更清晰，更丰富，我会是你唯一的天使，你生命的结局会比开端更美丽，连对你敞开怀抱的天堂也会说“只有一样东西能让一个灵魂如此完整，那就是爱情.”\nIf people like you can not learn from what happened to people like me，then what the hell is the piont of anything?\n2024-06-28 # 难道不丹不渴望工业化吗？难道他们不知道”国民幸福指数“只是愚蠢的心理按摩吗？廷布的年轻人也向往澳大利亚啊！如雪山般纯净的心灵和笑容也拦不住不丹青年想要出走的心啊。还是老村长明白人，“都说我们是世界上最幸福的国家，可为什么我们受过高等教育、能担起国家未来的年轻人总要到外面去寻找幸福呢？“，对啊，为什么呢？你们的国王知道答案，印度知道答案，本片的导演也知道答案。 #教室里的一头牦牛\n2024-06-24 # 工夫，不等於時間加數量，工夫是準確的積累\n未经审视的生活是不值得过的，还有不知名的后半句，前提是你要有闲暇\n改變一個人有三種方法：第一是改變他的時間分配，第二是改變他的居住環境，第三是改變他的交往人群。\n痛苦的時候，就走著痛苦的小徑以度日；愉悅的時候，就走著愉悅的大道以度日。精心地、一念地走去，那朦朧的真實就會顯現。\n把想说的话都表达出来，不要等到最后一刻\nlearn to fail or fail to learn\nDon\u0026rsquo;t fall into the trap of setting up a system for hours only to abandon it once you start going, like buying the nicest journal only to realize you don\u0026rsquo;t want to write regularly. Do you have somewhere you can quickly type? Good. You\u0026rsquo;re ready!\n不要陷入一个陷阱，设置一个系统几个小时，一旦你开始就放弃它，就像买了最好的日记，却发现你不想经常写作。你有可以快速打字的地方吗？好。你准备好了！\n2024-06-14 # 苏子曰：“客亦知夫水与月乎？逝者如斯，而未尝往也；盈虚者如彼，而卒莫消长也。盖将自其变者而观之，则天地曾不能以一瞬；自其不变者而观之，则物与我皆无尽也，而又何羡乎！且夫天地之间，物各有主，苟非吾之所有，虽一毫而莫取。惟江上之清风，与山间之明月，耳得之而为声，目遇之而成色，取之无禁，用之不竭。是造物者之无尽藏也，而吾与子之所共适。”\n2024-06-12 # 夫夷以近，则游者众；险以远，则至者少。而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也。有志矣，不随以止也，然力不足者，亦不能至也。有志与力，而又不随以怠，至于幽暗昏惑而无物以相之，亦不能至也。然力足以至焉，于人为可讥，而在己为有悔；尽吾志也而不能至者，可以无悔矣，其孰能讥之乎？此余之所得也！\n这个世界不是一元的，可能性很多，就看你能否接受，如果你只能接受一种，那这个世界确实就是一元的。\n2024-06-01 # 我们能怎么办？我们必须过好我们的生活。是的，我们得活下去，万尼亚舅舅，我们得熬过漫长的岁月，穿越漫漫长夜，我们得耐心忍耐命运带来的考验，即使我们不能休息，我们也得继续为别人工作，无论是现在还是到我们垂暮之年，直到我们生命的最后一刻到来，我们会默默离开。到了来世，我们可以告诉上帝，我们饱经风霜，我们昼吟夜哭，生活太艰难了，而上帝会怜惜我们，而你和我，我们会看到那明亮而奇妙的梦幻般的生活映入我们的眼帘，我们将欢欣鼓舞，而且，脸上挂着温柔的微笑，再回望我们此时的悲哀，最后，我们就能好好休息了。我相信，我内心矢志不渝地坚信，等到那时，我们就能好好地休息了。 #驾驶我的车\n2023 # 2023-10-24 # 艾柯：將來，教育目的是教人“篩選”這種藝術。再沒必要教加德滿都在哪裏，或者查理大帝之後誰是第一個法蘭西國王，因為我們隨處找到答案。不過，我們應該叫學生考查十五個網絡頁面，讓他們自己判斷哪個最差。需要教會他們“比較”這種技巧。\n"},{"id":6,"href":"/post/computer-science/java/java/","title":"java","section":"Java","content":" github repository # binarywang/qrcode-utils 二维码生成工具 String # StringBuffer 是怎么保证线程安全的？ # StringBuffer 是通过 同步机制 来保证线程安全的。具体来说，它的所有关键方法（如 append()、insert()、delete()、reverse() 等）都使用了 synchronized 关键字进行修饰，确保同一时间只有一个线程可以执行这些方法127。\n1. 同步方法 # StringBuffer 的方法在设计时都加了 synchronized 关键字，例如：\npublic synchronized StringBuffer append(String str){ // 方法实现 } 这种机制确保了在多线程环境下，只有一个线程可以访问和修改 StringBuffer 的内容，避免了竞态条件（Race Condition）和数据不一致的问题12。\n2. 锁机制 # StringBuffer 内部使用了一个锁对象（即 this 锁），当一个线程调用 StringBuffer 的同步方法时，会获取这个锁，其他线程必须等待锁释放后才能继续执行。这种锁机制保证了线程间的同步17。\n3. 性能影响 # 虽然 StringBuffer 的同步机制确保了线程安全，但也带来了性能开销。因为在多线程环境下，每次只能有一个线程操作 StringBuffer ，其他线程会被阻塞。因此，在单线程环境下，推荐使用性能更高的 StringBuilder，它没有同步机制158。\n4. 适用场景 # 多线程环境：如果需要在多线程环境下对字符串进行操作，StringBuffer 是合适的选择，因为它确保了线程安全29。 单线程环境：在单线程环境下，建议使用 StringBuilder，因为它没有同步开销，性能更高18。 总结 # StringBuffer 通过 synchronized 关键字实现的同步机制，确保了多线程环境下的线程安全性。虽然这种机制带来了性能开销，但在需要线程安全的场景下，它是一个可靠的选择127。\nStringBuffer 和 StringBuilder 字符串在底层是以什么数据结构保存的 # StringBuffer 和 StringBuilder 在底层都是使用 字符数组（char[]） 来保存字符串数据的。具体来说，它们继承了 AbstractStringBuilder 类，而 AbstractStringBuilder 类中定义了一个 char[] value 数组，用于存储字符序列134。\n1. 底层数据结构 # StringBuffer 和 StringBuilder 的底层数据结构是一个动态的 char[] 数组，数组名为 value。 value 数组的长度会根据字符串的长度动态扩容，以适应字符串的修改操作34。 2. 初始容量 # 如果使用无参构造函数创建 StringBuffer 或 StringBuilder，默认的初始容量为 16。 如果使用带参构造函数（如 new StringBuilder(\u0026quot;abc\u0026quot;)），初始容量为 字符串长度 + 1634。 3. 扩容机制 # 当 value 数组的容量不足以容纳新的字符时，会触发扩容操作。 扩容的规则是：新容量 = 原容量 * 2 + 2。如果仍然不足，则直接扩容到所需的最小容量34。 4. 示例代码 # 以下是 AbstractStringBuilder 类中定义 value 数组的部分源码：\nabstract class AbstractStringBuilder { char[] value; // 用于存储字符序列的数组 int count; // 当前字符数 } 5. 总结 # StringBuffer 和 StringBuilder 的底层数据结构是 char[] 数组，通过动态扩容机制支持字符串的修改操作。两者的主要区别在于线程安全性：\nStringBuffer 是线程安全的，所有方法都加了 synchronized 修饰。 StringBuilder 是线程不安全的，但性能更高567。 如果需要在多线程环境下操作字符串，建议使用 StringBuffer；在单线程环境下，建议使用 StringBuilder 以获得更好的性能567。\n虚拟线程 # 什么是虚拟线程？ # 虚拟线程（Virtual Threads） 是 Java 19 引入的一种轻量级线程，旨在简化和增强并发编程，特别是在处理大量 I/O 密集型任务时12。它是由 JVM 管理的线程，与传统线程（平台线程）相比，虚拟线程具有更高的并发性和更低的资源开销16。\n虚拟线程的核心特点 # 轻量级：虚拟线程的创建和切换开销非常小，可以轻松创建数百万个虚拟线程，而不会像传统线程那样消耗大量系统资源16。 I/O 优化：虚拟线程在遇到 I/O 阻塞（如网络通信、文件读取）时，会暂时放弃等待并切换到其他任务，从而提高 CPU 利用率，避免线程空闲12。 JVM 管理：虚拟线程由 JVM 调度和管理，而不是由操作系统直接管理。这使得虚拟线程的创建和销毁更加高效16。 与传统线程的区别：传统线程与操作系统线程是一对一的关系，资源消耗较大；而虚拟线程与操作系统线程是多对一的关系，多个虚拟线程可以在少量操作系统线程上运行6。 虚拟线程的适用场景 # 虚拟线程特别适合以下场景：\n高并发任务：如处理大量网络请求或文件 I/O 操作16。 I/O 密集型任务：任务中涉及大量等待时间（如数据库查询、HTTP 请求）16。 高吞吐量应用：需要同时处理大量任务的应用6。 虚拟线程的使用 # 在 Java 21 中，虚拟线程已经成为正式功能，可以通过以下方式创建和使用：\n直接创建虚拟线程： Thread.ofVirtual().start(() -\u0026gt; { System.out.println(\u0026#34;这是一个虚拟线程\u0026#34;); }); 使用虚拟线程池： try (var executor = Executors.newVirtualThreadPerTaskExecutor()) { executor.submit(() -\u0026gt; { System.out.println(\u0026#34;任务在虚拟线程中执行\u0026#34;); }); } 虚拟线程的局限性 # CPU 密集型任务：虚拟线程在处理计算密集型任务时，性能与传统线程相比没有明显优势，因为计算任务不存在大量 I/O 等待16。 内存占用：虽然虚拟线程轻量，但大量虚拟线程仍会增加内存占用和垃圾回收的压力3。 总结 # 虚拟线程是 Java 并发编程的重要改进，特别适合高并发和 I/O 密集型任务。它通过轻量级的设计和高效的调度机制，显著提升了应用的吞吐量和资源利用率126。\n响应式编程和虚拟线程都能提高程序的并发量，它们的差异是什么 # 响应式编程和虚拟线程虽然都能提高程序的并发量，但它们的实现方式、适用场景以及开发体验存在显著差异。以下是两者的主要区别：\n1. 实现原理 # 响应式编程：\n响应式编程基于异步数据流和事件驱动模型，使用发布/订阅模式（如 Flux 和 Mono）来处理异步任务。它通过非阻塞 I/O 和回调机制，确保线程在等待 I/O 操作时不会阻塞，而是继续处理其他任务。响应式编程的核心是“** 非阻塞**”和“事件驱动”12。 虚拟线程：\n虚拟线程是 JVM 管理的轻量级线程，底层仍然依赖于操作系统的平台线程（内核线程），但虚拟线程的创建和切换开销远低于传统线程。当虚拟线程遇到阻塞操作时，JVM 会将其挂起并切换到其他虚拟线程，从而避免线程资源的浪费37。 2. 编程模型 # 响应式编程：\n响应式编程采用声明式编程范式，代码通常由一系列操作符（如 map、flatMap）组成，形成数据流的转换管道。这种模型需要开发者熟悉函数式编程和响应式 API，代码可读性较差，调试难度较高14。 虚拟线程：\n虚拟线程保留了传统的阻塞式编程模型，开发者可以像使用平台线程一样编写代码，无需改变编程习惯。虚拟线程的引入使得高并发编程更加简单和直观37。 3. 适用场景 # 响应式编程：\n适用于 I/O 密集型任务，如网络请求、数据库操作等。它通过非阻塞 I/O 和事件驱动机制，最大化线程的利用率。但在 CPU 密集型任务中，响应式编程的性能提升有限，甚至可能适得其反24。 虚拟线程：\n同样适用于 I/O 密集型任务，能够显著提高并发性能。虚拟线程的优势在于其轻量化和低开销，适合处理大量并发请求。但对于 CPU 密集型任务，虚拟线程的性能提升有限，因为虚拟线程的调度仍然依赖于平台线程37 。 4. 开发体验 # 响应式编程：\n响应式编程的代码通常难以理解和调试，尤其是回调嵌套和复杂的操作符链。开发者需要具备函数式编程和响应式编程的知识，学习成本较高。 虚拟线程：\n虚拟线程的使用与传统的线程编程类似，开发者无需学习新的编程范式，代码更直观且易于维护。虚拟线程的引入降低了高并发编程的门槛。 5. 性能优化 # 响应式编程：\n通过减少线程阻塞和上下文切换，响应式编程能够提高 CPU 和内存的利用率。但它依赖于开发者正确使用非阻塞 API 和操作符。 虚拟线程：\n虚拟线程通过轻量化的线程管理和高效的调度机制，减少了线程创建和上下文切换的开销。虚拟线程的性能优化由 JVM 自动完成，开发者无需额外干预。 总结 # 响应式编程和虚拟线程的目标都是提高程序的并发性能，但它们的实现方式和适用场景不同。 响应式编程适合需要高度优化的 I/O 密集型任务，但代码复杂且学习成本高。 虚拟线程提供了一种更简单、直观的方式来实现高并发，特别适合需要快速开发和维护的场景 如果需要更深入的技术细节，可以参考相关文档或实践案例。\n虚拟线程在jvm中的内存模型是怎样的 # 虚拟线程（Virtual Threads）是Java 19引入并在Java 21中正式发布的一项新特性，旨在提高I/O密集型任务的性能。虚拟线程的内存模型与传统平台线程（Platform Threads）有所不同，主要体现在以下几个方面：\n1. 虚拟线程的内存结构 # 虚拟线程由JVM管理，而不是操作系统，因此它们的内存占用远小于平台线程。每个虚拟线程通常只占用几KB的内存，而平台线程则需要1MB左右的内存4 。虚拟线程的轻量化设计使得JVM能够轻松支持数百万个虚拟线程，而不会显著增加内存负担。\n2. 虚拟线程与JVM内存模型的关系 # 虚拟线程仍然依赖于JVM的内存模型，包括程序计数器、虚拟机栈、本地方法栈、堆和方法区等12。具体来说：\n程序计数器：每个虚拟线程都有自己的程序计数器，用于记录当前执行的字节码指令位置。 虚拟机栈：虚拟线程的栈帧存储在JVM的栈内存中，但由于虚拟线程的轻量化设计，栈帧的创建和销毁开销较小。 堆：虚拟线程创建的对象实例仍然存储在堆中，与平台线程共享堆内存26。 3. 虚拟线程的调度与内存使用 # 虚拟线程的调度由JVM负责，而不是操作系统。当虚拟线程遇到I/O阻塞时，JVM会将其挂起并切换到其他虚拟线程，从而避免CPU资源的浪费。这种机制减少了线程上下文切换的开销，并提高了内存的利用率45。\n4. 虚拟线程与垃圾回收 # 虚拟线程创建的对象实例仍然受到JVM垃圾回收机制的管理。虚拟线程的轻量化设计不会增加垃圾回收的负担，反而通过减少线程阻塞和上下文切换，提高了垃圾回收的效率56。\n5. 虚拟线程的适用场景 # 虚拟线程特别适用于高并发、I/O密集型任务，例如网络请求、文件读写等。在这些场景下，虚拟线程可以显著减少线程阻塞带来的性能损失，从而提高整体吞吐量45。\n总结 # 虚拟线程在JVM中的内存模型与传统平台线程类似，但由于其轻量化设计和由JVM管理的特性，虚拟线程的内存占用和调度开销显著降低。虚拟线程的内存模型仍然依赖于JVM的程序计数器、虚拟机栈、堆等结构，但其高效的调度机制和轻量化的内存占用使其在处理高并发任务时表现出色124 。\n虚拟线程会增加jvm的性能消耗吗 # 虚拟线程在JVM中的性能消耗相对较低，尤其是在处理I/O密集型任务时，它们通过提高CPU利用率来优化性能。以下是具体分析：\n1. 虚拟线程的资源消耗 # 虚拟线程由JVM管理，而不是操作系统，因此它们的创建和切换开销远低于传统的平台线程。每个虚拟线程仅占用几KB的内存，而平台线程通常需要1MB左右的内存5 。这种轻量化设计使得JVM能够轻松支持数百万个虚拟线程，而不会显著增加内存负担6。\n2. 性能优势 # 虚拟线程的主要优势在于处理I/O密集型任务时的高效性。当虚拟线程遇到I/O阻塞时，JVM会将其挂起并切换到其他虚拟线程，从而避免CPU资源的浪费。这种机制显著提高了CPU的利用率，尤其是在高并发场景下12。\n3. CPU密集型任务的限制 # 对于CPU密集型任务，虚拟线程的性能与平台线程相当，因为它们并没有增加实际的CPU资源。虚拟线程的优势主要体现在I/O阻塞时的任务切换上，而不是计算能力的提升15。\n4. JVM的性能消耗 # 虚拟线程的管理由JVM负责，虽然这会增加一定的调度开销，但由于虚拟线程的轻量化设计，这种开销通常可以忽略不计。尤其是在高并发场景下，虚拟线程的资源消耗远低于平台线程56。\n5. 适用场景 # 虚拟线程特别适用于高并发、I/O密集型任务，例如网络请求、文件读写等。在这些场景下，虚拟线程可以显著减少线程阻塞带来的性能损失，从而提高整体吞吐量25。\n总结 # 虚拟线程不会显著增加JVM的性能消耗，反而通过优化任务调度和减少线程阻塞来提高性能。然而，对于CPU密集型任务，虚拟线程的性能提升有限156。\n在 springboot 项目中虚拟线程可以怎么使用 # 在 Spring Boot 项目中使用虚拟线程可以显著提升应用的并发性能，尤其是在 I/O 密集型场景中。以下是几种常见的虚拟线程使用方式及其配置方法：\n1. 启用虚拟线程处理 HTTP 请求 # Spring Boot 默认使用 Tomcat 作为 Web 容器，通常使用平台线程处理请求。可以通过配置将 Tomcat 的线程池替换为虚拟线程池。\n配置代码： # import org.apache.coyote.ProtocolHandler; import org.springframework.boot.web.embedded.tomcat.TomcatProtocolHandlerCustomizer; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.concurrent.Executors; @Configuration public class TomcatConfig { @Bean public TomcatProtocolHandlerCustomizer\u0026lt;?\u0026gt; protocolHandlerVirtualThreadExecutorCustomizer() { return protocolHandler -\u0026gt; { protocolHandler.setExecutor(Executors.newVirtualThreadPerTaskExecutor()); }; } } 说明： # 该配置将 Tomcat 的线程池替换为虚拟线程池，所有 HTTP 请求将在虚拟线程中处理 2. 使用虚拟线程执行异步任务 # Spring Boot 中的 @Async 注解通常用于异步执行任务。可以通过配置将异步任务的线程池替换为虚拟线程池。\n配置代码： # import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.task.TaskExecutor; import org.springframework.scheduling.annotation.EnableAsync; import org.springframework.scheduling.concurrent.TaskExecutorAdapter; import java.util.concurrent.Executors; @Configuration @EnableAsync public class AsyncConfig { @Bean public TaskExecutor asyncTaskExecutor() { return new TaskExecutorAdapter(Executors.newVirtualThreadPerTaskExecutor()); } } 使用示例： # @Service public class AsyncService { @Async public void doSomething() throws InterruptedException { Thread.sleep(1000); // 模拟耗时操作 System.out.println(\u0026#34;任务完成\u0026#34;); } } 说明： # 通过 @Async 注解执行的任务将在虚拟线程中运行 3. 使用虚拟线程执行定时任务 # Spring Boot 中的 @Scheduled 注解用于定时任务。可以通过配置将定时任务的线程池替换为虚拟线程池。\n配置代码： # import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.TaskScheduler; import org.springframework.scheduling.annotation.EnableScheduling; import org.springframework.scheduling.concurrent.ConcurrentTaskScheduler; import java.util.concurrent.Executors; @Configuration @EnableScheduling public class SchedulingConfig { @Bean public TaskScheduler taskScheduler() { return new ConcurrentTaskScheduler(Executors.newScheduledThreadPool(0, Thread.ofVirtual().factory())); } } 使用示例： # @Service public class ScheduledService { @Scheduled(fixedRate = 1000) public void runTask() { System.out.println(\u0026#34;定时任务执行\u0026#34;); } } 说明： # 定时任务将在虚拟线程中执行5。 4. 使用虚拟线程执行自定义任务 # 可以通过 Executors.newVirtualThreadPerTaskExecutor() 创建一个虚拟线程池，用于执行自定义任务。\n示例代码： # import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class CustomTaskExecutor { public static void main(String[] args) { ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor(); for (int i = 0; i \u0026lt; 1000; i++) { executor.submit(() -\u0026gt; { System.out.println(\u0026#34;任务执行\u0026#34;); }); } executor.shutdown(); } } 说明： # 该方式适合在非 Spring 管理的环境中使用虚拟线程15。 5. 虚拟线程的最佳实践 # 避免池化虚拟线程：虚拟线程的创建和销毁成本极低，无需池化1。 适合 I/O 密集型任务：虚拟线程在 I/O 阻塞时自动挂起，适合网络请求、数据库操作等场景2。 逐步迁移：可以在现有项目中逐步启用虚拟线程，无需一次性替换所有线程3。 6. 环境要求 # JDK 版本：Java 19+（预览功能），Java 21+（正式功能）。 Spring Boot 版本：Spring Boot 3.2+ 开始支持虚拟线程25。 通过以上方式，可以在 Spring Boot 项目中充分利用虚拟线程提升并发性能，同时保持代码简洁。\n虚拟线程的M:N模型具体是如何工作的？ # 虚拟线程的 M:N 模型 是一种线程调度机制，它将 M 个虚拟线程 映射到 N 个操作系统线程 上执行。这种模型的目的是在保持轻量级线程的同时，充分利用操作系统的线程资源。以下是 M:N 模型的具体工作原理：\n1. 基本概念 # 虚拟线程（Virtual Threads）： 由 JVM 管理的轻量级线程。 内存占用小，创建和销毁成本低。 数量可以非常多（数百万个）。 操作系统线程（Platform Threads）： 由操作系统管理的线程。 内存占用大（默认 1MB 栈空间），创建和销毁成本高。 数量有限（通常数千个）。 2. M:N 模型的核心思想 # 将大量虚拟线程（M）映射到少量操作系统线程（N）上执行。 虚拟线程在执行任务时，由 JVM 调度到可用的操作系统线程上运行。 当虚拟线程遇到阻塞操作（如 I/O）时，JVM 会将其挂起，并释放操作系统线程去执行其他虚拟线程。 3. 具体工作流程 # 虚拟线程创建： 当创建一个虚拟线程时，JVM 会为其分配一个轻量级的上下文（如栈、程序计数器等）。 虚拟线程不会直接绑定到操作系统线程，而是由 JVM 管理。 任务调度： 当虚拟线程需要执行任务时，JVM 会将其调度到一个可用的操作系统线程上运行。 操作系统线程是实际执行任务的载体。 阻塞操作处理： 如果虚拟线程执行了阻塞操作（如 I/O 或等待锁），JVM 会将其挂起。 挂起后，操作系统线程会被释放，并可以执行其他虚拟线程。 任务恢复： 当阻塞操作完成后，JVM 会重新调度该虚拟线程到某个操作系统线程上继续执行。 线程切换： 虚拟线程的切换由 JVM 管理，不需要操作系统介入。 切换开销极小，因为虚拟线程的上下文是轻量级的。 4. M:N 模型的优势 # 高并发： 可以轻松创建数百万个虚拟线程，适合高并发场景。 资源高效利用： 少量操作系统线程可以服务大量虚拟线程，避免线程资源浪费。 简化编程： 开发者可以使用同步编程模型，同时获得异步性能。 低延迟： 虚拟线程的切换开销极小，任务可以快速恢复执行。 5. M:N 模型的实现细节 # 调度器（Scheduler）： JVM 内置了一个调度器，负责将虚拟线程分配到操作系统线程上执行。 调度器会根据任务的状态（如运行、阻塞、就绪）动态管理虚拟线程。 栈管理： 虚拟线程的栈是动态分配的，可以根据需要扩展或收缩。 挂起时，栈状态会被保存；恢复时，栈状态会被恢复。 阻塞操作感知： JVM 会识别虚拟线程的阻塞操作（如 I/O、锁等待），并自动挂起和恢复线程。 6. 示例 # 以下是一个简单的示例，展示了虚拟线程的 M:N 模型：\nimport java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class VirtualThreadExample { public static void main(String[] args) { // 创建一个虚拟线程调度器（M:N 模型） try (ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor()) { // 提交 1000 个任务 for (int i = 0; i \u0026lt; 1000; i++) { int taskId = i; executor.submit(() -\u0026gt; { System.out.println(\u0026#34;任务 \u0026#34; + taskId + \u0026#34; 开始运行...\u0026#34;); try { Thread.sleep(1000); // 模拟 I/O 阻塞操作 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;任务 \u0026#34; + taskId + \u0026#34; 结束运行。\u0026#34;); }); } } } } 在这个例子中：\n1000 个虚拟线程被创建并提交到虚拟线程调度器。 这些虚拟线程会被映射到少量的操作系统线程上执行。 当虚拟线程执行 Thread.sleep 时，JVM 会将其挂起，并释放操作系统线程去执行其他虚拟线程。 7. 与传统线程模型的对比 # 特性 传统线程（1:1 模型） 虚拟线程（M:N 模型） 线程数量 受操作系统限制（通常数千个） 可轻松创建数百万个 内存占用 高（默认 1MB 栈空间） 低（动态分配栈空间） 线程切换 操作系统介入，开销大 JVM 管理，开销小 阻塞操作处理 操作系统线程被占用 虚拟线程挂起，操作系统线程释放 适用场景 CPU 密集型任务 I/O 密集型任务 总结 # M:N 模型通过将大量轻量级虚拟线程映射到少量操作系统线程上，实现了高并发、低资源占用的线程管理。这种模型特别适合现代高并发、I/O 密集型的应用场景，同时简化了开发者的编程复杂度。\nJava虚拟线程和传统线程有什么区别 # Java 虚拟线程（Virtual Threads）与传统线程（Platform Threads）在实现、性能和适用场景上有显著区别。以下是两者的主要对比：\n1. 实现方式 # 传统线程： 直接映射到操作系统的线程（内核线程）。 每个线程都需要分配一个固定的栈空间（默认 1MB）。 创建和销毁成本较高，线程数量受操作系统限制。 虚拟线程： 由 JVM 管理，不直接映射到操作系统线程。 虚拟线程的栈空间是动态分配的，内存占用更小。 创建和销毁成本极低，可以轻松创建数百万个虚拟线程。 2. 线程模型 # 传统线程： 采用 \u0026ldquo;1:1\u0026rdquo; 模型，即一个 Java 线程对应一个操作系统线程。 线程在执行 I/O 或阻塞操作时会一直占用操作系统线程。 虚拟线程： 采用 \u0026ldquo;M:N\u0026rdquo; 模型，即多个虚拟线程映射到少数操作系统线程。 虚拟线程在执行 I/O 或阻塞操作时会被挂起，释放操作系统线程去执行其他虚拟线程。 3. 性能 # 传统线程： 线程数量有限，无法高效处理大量并发任务。 线程切换需要操作系统介入，开销较大。 虚拟线程： 可以轻松创建大量线程，适合高并发场景。 线程切换由 JVM 管理，开销极小。 4. 适用场景 # 传统线程： 适合 CPU 密集型任务，如计算密集型操作。 需要直接控制操作系统线程的场景。 虚拟线程： 适合 I/O 密集型任务，如网络请求、文件读写等。 需要处理大量并发任务的场景，如微服务、Web 服务器等。 5. 编程模型 # 传统线程： 需要手动管理线程池，避免创建过多线程。 代码复杂度较高，尤其是在处理异步任务时。 虚拟线程： 无需手动管理线程池，可以按需创建虚拟线程。 代码更简洁，支持同步编程模型，同时具备异步性能。 6. 资源占用 # 传统线程： 每个线程占用固定的栈空间（默认 1MB），内存消耗较大。 线程数量受操作系统限制（通常数千个）。 虚拟线程： 栈空间动态分配，内存占用更小。 可以轻松创建数百万个虚拟线程。 7. 兼容性 # 传统线程： 所有 Java 版本都支持。 虚拟线程： 从 Java 19 开始引入，默认是预览功能，需在运行时添加 --enable-preview 参数。 在 Java 21 中成为正式功能。 8. 示例对比 # 传统线程： ExecutorService executor = Executors.newFixedThreadPool(10); for (int i = 0; i \u0026lt; 1000; i++) { executor.submit(() -\u0026gt; { System.out.println(\u0026#34;传统线程执行任务\u0026#34;); }); } executor.shutdown(); 虚拟线程： try (ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor()) { for (int i = 0; i \u0026lt; 1000; i++) { executor.submit(() -\u0026gt; { System.out.println(\u0026#34;虚拟线程执行任务\u0026#34;); }); } } 总结 # 特性 传统线程 虚拟线程 实现方式 1:1 映射到操作系统线程 M:N 映射到操作系统线程 内存占用 高（默认 1MB 栈空间） 低（动态分配栈空间） 创建成本 高 极低 线程切换 操作系统介入，开销大 JVM 管理，开销小 适用场景 CPU 密集型任务 I/O 密集型任务 线程数量 受操作系统限制（通常数千个） 可轻松创建数百万个 编程复杂度 高（需手动管理线程池） 低（按需创建，无需池化） 虚拟线程是 Java 在并发编程领域的一次重大改进，特别适合现代高并发、I/O 密集型的应用场景。\n可以生成一个java使用虚拟线程的例子吗 # 以下是一个使用 Java 虚拟线程的示例代码，展示了如何创建和运行虚拟线程：\n示例代码 # import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class VirtualThreadExample { public static void main(String[] args) { // 方法 1: 直接创建并运行虚拟线程 Thread.startVirtualThread(() -\u0026gt; { System.out.println(\u0026#34;虚拟线程 1 开始运行...\u0026#34;); try { Thread.sleep(1000); // 模拟耗时操作 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;虚拟线程 1 结束运行。\u0026#34;); }); // 方法 2: 创建虚拟线程但不自动运行，手动调用 start() Thread virtualThread = Thread.ofVirtual().unstarted(() -\u0026gt; { System.out.println(\u0026#34;虚拟线程 2 开始运行...\u0026#34;); try { Thread.sleep(1000); // 模拟耗时操作 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;虚拟线程 2 结束运行。\u0026#34;); }); virtualThread.start(); // 方法 3: 使用 ExecutorService 调度虚拟线程 try (ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor()) { for (int i = 3; i \u0026lt;= 5; i++) { int threadId = i; executor.submit(() -\u0026gt; { System.out.println(\u0026#34;虚拟线程 \u0026#34; + threadId + \u0026#34; 开始运行...\u0026#34;); try { Thread.sleep(1000); // 模拟耗时操作 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;虚拟线程 \u0026#34; + threadId + \u0026#34; 结束运行。\u0026#34;); }); } } } } 代码说明 # 方法 1: 使用 Thread.startVirtualThread() 直接创建并运行虚拟线程。这种方式适合简单的任务。 方法 2: 使用 Thread.ofVirtual().unstarted() 创建虚拟线程，但不自动运行，需要手动调用 start() 启动。 方法 3: 使用 Executors.newVirtualThreadPerTaskExecutor() 创建一个虚拟线程池，适合需要管理多个虚拟线程的场景。 运行说明 # 虚拟线程在 Java 19 中引入，但默认是预览功能，需在运行代码时添加 --enable-preview 参数。 虚拟线程适用于 I/O 密集型任务，如网络请求、文件读写等，能够在等待 I/O 时自动挂起并切换到其他虚拟线程，提升资源利用率1。 运行命令 # java --source 19 --enable-preview VirtualThreadExample.java 注意事项 # 虚拟线程不应池化，因为其创建和销毁成本极低，适合按需创建1。 虚拟线程的 I/O 操作会自动挂起并切换，而普通线程的 I/O 操作仍会阻塞1。 以上示例展示了虚拟线程的基本用法，适用于 Java 19 及以上版本。\njava的虚拟线程是如何对I/O操作进行优化的 # Java 的虚拟线程（Virtual Threads）通过非阻塞和轻量级调度的方式对 I/O 操作进行了显著优化，具体体现在以下几个方面：\n1. 非阻塞 I/O 操作 # 虚拟线程在执行 I/O 操作（如读写文件、网络请求、数据库查询）时，不会阻塞当前线程。当虚拟线程遇到 I/O 操作时，它会立即被挂起，并释放底层的平台线程（Platform Thread），以便该平台线程可以去执行其他虚拟线程的任务。当 I/O 操作完成后，虚拟线程会被重新调度并继续执行5556。\n这种方式避免了传统线程模型中线程因等待 I/O 操作而阻塞的问题，从而显著提高了线程的利用率。\n2. 轻量级线程调度 # 虚拟线程是由 JVM 管理的轻量级线程，其创建和销毁成本极低。与传统线程（平台线程）相比，虚拟线程的数量可以轻松达到数百万个，而不会占用大量系统资源1755。\n虚拟线程的调度由 JVM 负责，底层使用 ForkJoinPool 作为调度器。虚拟线程在执行 I/O 操作时会被挂起，调度器会立即切换到其他虚拟线程，从而避免了线程资源的浪费155。\n3. 减少线程上下文切换 # 在传统线程模型中，线程的上下文切换由操作系统负责，开销较大。而虚拟线程的上下文切换由 JVM 管理，切换成本极低。这使得虚拟线程在处理大量 I/O 密集型任务时，能够更高效地切换任务，减少 CPU 资源的浪费1755。\n4. 与异步编程的结合 # 虚拟线程的接口与传统线程完全一致，开发者可以像编写同步代码一样编写异步任务。当虚拟线程执行 I/O 操作时，代码看起来是同步的，但实际上是异步执行的。这种方式既简化了代码的编写，又避免了回调地狱的问题5556 。\n例如，以下代码展示了虚拟线程如何处理 I/O 操作：\nThread.startVirtualThread(()-\u0026gt;{ String data=readFromDatabase(); // I/O 操作，虚拟线程会被挂起 System.out.println(data); }); 在执行 readFromDatabase() 时，虚拟线程会被挂起，平台线程可以继续执行其他任务55。\n5. 适用于高并发场景 # 虚拟线程特别适合处理 I/O 密集型任务，如网络请求、文件读写和数据库查询。在这些场景中，任务的大部分时间都花在等待 I/O 操作上，而虚拟线程的非阻塞特性可以显著提高系统的吞吐量和并发能力117。\n总结 # Java 的虚拟线程通过非阻塞 I/O、轻量级调度和减少上下文切换等机制，显著优化了 I/O 操作的性能。它使得开发者可以轻松编写高并发的 I/O 密集型应用，同时保持代码的简洁性和可维护性15556。\nJava虚拟线程的ForkJoinPool调度器是如何工作的 # Java 虚拟线程的调度器是基于 ForkJoinPool 实现的，它负责管理虚拟线程的执行和调度。以下是 ForkJoinPool 调度器的工作原理及其在虚拟线程中的应用：\n1. ForkJoinPool 的基本原理 # ForkJoinPool 是 Java 并发框架中的一种线程池，专门用于执行分治任务（Divide-and-Conquer Tasks）。它的核心特点是：\n工作窃取（Work-Stealing）：每个工作线程都有自己的任务队列，当某个线程的任务队列为空时，它会从其他线程的队列中“窃取”任务来执行。这种机制可以平衡线程之间的负载，提高资源利用率。 分治任务：任务可以分解为多个子任务，子任务可以并行执行，最后将结果合并。 2. 虚拟线程的调度器 # 虚拟线程的调度器是基于 ForkJoinPool 的，但它对 ForkJoinPool 进行了扩展和优化，以支持虚拟线程的轻量级调度。以下是调度器的工作机制：\n(1) 虚拟线程的挂起与恢复 # 当虚拟线程执行 I/O 操作或其他阻塞操作时，虚拟线程会被挂起，并释放底层的平台线程。 当 I/O 操作完成或任务可以继续执行时，虚拟线程会被重新调度到 ForkJoinPool 中，由某个平台线程继续执行。 (2) 任务队列与工作窃取 # 虚拟线程的任务被存储在 ForkJoinPool 的任务队列中。 当平台线程空闲时，它会从队列中获取任务（虚拟线程）并执行。 如果某个平台线程的任务队列为空，它会从其他线程的队列中“窃取”任务，从而避免线程闲置。 (3) 轻量级调度 # 虚拟线程的调度由 JVM 负责，调度开销极低。 虚拟线程的上下文切换比传统线程快得多，因为它不需要操作系统的介入。 3. 调度器的配置 # 虚拟线程的调度器默认使用 ForkJoinPool，但可以通过 JVM 参数进行调整：\n线程池大小：默认情况下，ForkJoinPool 的线程数等于 CPU 核心数。可以通过 -Djdk.virtualThreadScheduler.parallelism 参数进行调整。 任务队列大小：可以通过 -Djdk.virtualThreadScheduler.maxPoolSize 参数设置任务队列的最大容量。 4. 虚拟线程与平台线程的关系 # 虚拟线程是轻量级的，由 JVM 管理。 平台线程是操作系统的线程，虚拟线程最终由平台线程执行。 一个平台线程可以同时执行多个虚拟线程，通过挂起和恢复机制实现切换。 5. 示例 # 以下是一个虚拟线程的示例，展示了虚拟线程的调度和执行：\nThread.startVirtualThread(()-\u0026gt;{ System.out.println(\u0026#34;Virtual Thread 1: Start\u0026#34;); try{ Thread.sleep(1000); // 模拟 I/O 操作，虚拟线程会被挂起 }catch(InterruptedException e){ e.printStackTrace(); } System.out.println(\u0026#34;Virtual Thread 1: End\u0026#34;); }); Thread.startVirtualThread(()-\u0026gt;{ System.out.println(\u0026#34;Virtual Thread 2: Start\u0026#34;); try{ Thread.sleep(500); // 模拟 I/O 操作，虚拟线程会被挂起 }catch(InterruptedException e){ e.printStackTrace(); } System.out.println(\u0026#34;Virtual Thread 2: End\u0026#34;); }); 在上述代码中：\n两个虚拟线程由 ForkJoinPool 调度器管理。 当虚拟线程执行 Thread.sleep() 时，虚拟线程会被挂起，平台线程可以继续执行其他任务。 总结 # Java 虚拟线程的调度器基于 ForkJoinPool，通过工作窃取和轻量级调度机制，高效地管理虚拟线程的执行。它使得虚拟线程在执行 I/O 操作时可以被挂起，从而释放平台线程资源，提高系统的并发性能和资源利用率。虚拟线程的引入为 Java 提供了更简洁、更高效的高并发编程模型。\nJava虚拟线程与其他编程语言的异步编程模型相比有什么优势 # Java 虚拟线程（Virtual Threads）是 JDK 21 引入的一项新特性，它通过轻量级线程模型显著提升了并发性能，特别适合处理 I/O 密集型任务。与其他编程语言的异步编程模型相比，Java 虚拟线程具有以下优势：\n1. 轻量级与高并发 # 虚拟线程的轻量级特性：虚拟线程由 JVM 管理，创建和销毁的成本极低，每个虚拟线程仅占用极少的内存资源。这使得 Java 应用程序可以轻松创建数百万个虚拟线程，而不会像传统线程那样消耗大量系统资源18。 对比其他语言的异步模型：例如，Go 语言的协程（Goroutine）虽然也很轻量，但其调度器由 Go 运行时管理，而 Java 虚拟线程的调度器基于 ForkJoinPool，能够更好地与 JVM 生态集成41。 2. 非阻塞与高效 I/O 处理 # 非阻塞 I/O 操作：虚拟线程在执行 I/O 操作时会被挂起，释放底层的平台线程，从而避免线程资源的浪费。当 I/O 操作完成后，虚拟线程会被重新调度，继续执行任务。这种方式显著提高了 CPU 利用率1824。 对比其他语言的异步模型：例如，JavaScript 的异步模型依赖于事件循环和回调函数，代码结构复杂且容易陷入“回调地狱”。而 Java 虚拟线程的代码编写方式与传统同步代码一致，简化了开发逻辑124。 3. 简化异步编程 # 同步代码风格：虚拟线程允许开发者以同步的方式编写异步代码，无需使用复杂的回调或 Future/Promise 机制。这种方式不仅提高了代码的可读性，还降低了调试和维护的难度124。 对比其他语言的异步模型：例如，Python 的 asyncio 或 C# 的 async/await 虽然也提供了同步风格的异步编程，但其底层实现依赖于事件循环，而 Java 虚拟线程的调度器更高效且与 JVM 深度集成2441。 4. 与现有生态的无缝集成 # 兼容现有 API：虚拟线程与 Java 现有的并发工具（如 CompletableFuture、ExecutorService ）无缝集成，开发者无需重写代码即可享受虚拟线程带来的性能提升118。 对比其他语言的异步模型：例如，Rust 的异步编程模型需要依赖特定的运行时（如 tokio），而 Java 虚拟线程直接由 JVM 支持，无需额外的运行时环境41。 5. 高效的上下文切换 # 低开销的上下文切换：虚拟线程的上下文切换由 JVM 管理，开销极低。相比之下，传统线程的上下文切换需要操作系统的介入，成本较高2441。 对比其他语言的异步模型：例如，Go 的协程虽然上下文切换成本也很低，但 Java 虚拟线程在 JVM 生态中的集成度更高，更适合复杂的 Java 应用场景41。 6. 结构化并发支持 # 结构化并发：JDK 21 引入了结构化并发（Structured Concurrency），使得多线程编程更加清晰和易于管理。虚拟线程与结构化并发结合，可以更好地控制线程的生命周期，避免资源泄漏1838。 对比其他语言的异步模型：例如，C++ 的异步编程模型缺乏类似的结构化并发支持，开发者需要手动管理线程和任务的生命周期38。 总结 # Java 虚拟线程在轻量级、非阻塞 I/O、简化异步编程、与现有生态集成、上下文切换效率和结构化并发等方面具有显著优势。与其他编程语言的异步模型相比，虚拟线程不仅提供了更高的并发性能，还简化了开发流程，降低了代码复杂性，特别适合处理 I/O 密集型任务和高并发场景1182441。\nJava虚拟线程技术对现有应用程序的性能提升有多大影响 # Java 虚拟线程技术（Virtual Threads）是 JDK 21 引入的一项重要特性，旨在显著提升现有应用程序的性能，尤其是在高并发和 I/O 密集型场景下。以下是虚拟线程技术对现有应用程序性能提升的主要影响及其实际应用案例：\n1. 性能提升的核心机制 # 虚拟线程通过以下机制提升性能：\n轻量级线程：虚拟线程由 JVM 管理，创建和销毁的开销极低，允许应用程序轻松创建数百万个线程，而不会像传统线程那样消耗大量系统资源111。 非阻塞 I/O：虚拟线程在执行 I/O 操作时会被挂起，释放底层平台线程，从而避免线程资源的浪费。当 I/O 操作完成后，虚拟线程会被重新调度，继续执行任务。这种方式显著提高了 CPU 利用率118。 高效调度：虚拟线程的调度器基于 ForkJoinPool，采用 FIFO 模式，能够高效地管理虚拟线程的挂起和恢复，减少上下文切换的开销18。 2. 性能提升的具体表现 # I/O 密集型任务：虚拟线程特别适合处理大量 I/O 阻塞任务，如网络请求、文件读写和数据库查询。在这些场景中，虚拟线程的性能提升尤为显著。例如，在测试中，虚拟线程处理 100,000 个任务的耗时仅为传统线程池的一半159。 高并发场景：虚拟线程允许应用程序同时处理大量并发请求，而不会因为线程数量限制而出现性能瓶颈。这对于 Web 服务器、微服务等需要处理大量并发请求的应用场景非常有利1118。 资源利用率：虚拟线程通过减少线程阻塞和上下文切换，提高了 CPU 和内存的利用率，从而提升了整体系统的吞吐量1118。 3. 实际应用案例 # 文件读取优化：在处理百万级数据文件读取任务时，使用虚拟线程可以将任务耗时从数分钟减少到数秒，显著提升了处理效率31。 Web 服务性能提升：在 Spring Boot 3 中使用虚拟线程后，Web 服务的并发处理能力大幅提升，能够同时处理更多请求，响应时间显著缩短31。 数据库查询优化：在需要频繁进行数据库查询的应用中，虚拟线程通过非阻塞 I/O 机制，减少了线程等待时间，提高了查询效率1118。 4. 适用场景与限制 # 适用场景： I/O 密集型任务（如网络请求、文件读写、数据库查询）。 高并发场景（如 Web 服务器、微服务）。 需要处理大量短生命周期任务的场景1118。 限制： 虚拟线程在计算密集型任务中的性能提升有限，因为这类任务本身不涉及大量 I/O 阻塞1118。 虚拟线程的性能提升依赖于底层平台线程的数量和调度器的配置，需要根据具体应用场景进行调优18。 5. 总结 # Java 虚拟线程技术通过轻量级线程、非阻塞 I/O 和高效调度机制，显著提升了现有应用程序的性能，特别是在 I/O 密集型和高并发场景下。实际应用案例表明，虚拟线程可以将任务处理时间减少 50% 以上，并大幅提高系统的吞吐量和资源利用率11118。然而，在计算密集型任务中，虚拟线程的性能提升有限，开发者需要根据具体应用场景合理选择使用虚拟线程。\nJava虚拟线程技术在实际项目中面临哪些挑战 # Java 虚拟线程技术（Virtual Threads）在 JDK 21 中正式引入，虽然它显著提升了并发性能，但在实际项目中仍面临一些挑战。以下是主要挑战及其分析：\n1. 兼容性问题 # 现有代码库的适配：虚拟线程虽然兼容传统的线程 API，但并非所有现有代码都能无缝迁移。例如，依赖于线程本地存储（ThreadLocal）或线程池行为的代码可能需要调整1。 第三方库的支持：许多第三方库（如数据库驱动、网络框架）尚未完全适配虚拟线程，可能导致性能瓶颈或意外行为2。 2. 调试与监控复杂性 # 线程堆栈的可读性：虚拟线程的堆栈信息与传统线程不同，可能导致调试工具（如调试器、日志分析工具）无法准确显示线程状态1。 监控工具的支持：现有的监控工具（如 JFR、JMC）可能无法完全支持虚拟线程的跟踪和分析，增加了排查问题的难度2。 3. 资源管理挑战 # 内存占用：虽然虚拟线程比传统线程更轻量，但在极端高并发场景下（如数百万个虚拟线程），仍可能占用大量内存，需要优化内存管理策略1。 线程池配置：虚拟线程的调度依赖于 ForkJoinPool，其默认配置可能不适用于所有场景，需要根据具体需求调整线程池参数2。 4. 性能瓶颈 # 计算密集型任务：虚拟线程在 I/O 密集型任务中表现优异，但在计算密集型任务中性能提升有限，甚至可能因频繁切换上下文而降低效率1。 锁竞争问题：虚拟线程的高并发特性可能加剧锁竞争问题，导致性能下降2。 5. 学习曲线与最佳实践 # 开发者的学习成本：虚拟线程引入了新的编程模型和概念（如结构化并发），开发者需要重新学习并掌握最佳实践1。 缺乏成熟案例：虚拟线程技术较新，实际项目中的应用案例较少，缺乏成熟的实践经验和优化方案2。 6. 与现有生态的集成 # 数据库连接池：虚拟线程的高并发能力可能使数据库连接池成为瓶颈，需要优化连接池配置或使用异步数据库驱动1。 网络框架适配：某些网络框架（如 Netty）可能需要调整以充分利用虚拟线程的性能优势2。 7. 线程安全问题 # 共享资源的并发访问：虚拟线程的高并发特性可能加剧线程安全问题（如竞争条件、死锁），需要更精细的同步机制1。 线程本地存储的滥用：过度依赖 ThreadLocal 可能导致内存泄漏或性能问题，需谨慎使用2。 总结 # Java 虚拟线程技术在实际项目中面临兼容性、调试、资源管理、性能瓶颈、学习曲线、生态集成和线程安全等多方面的挑战。尽管它显著提升了并发性能，但开发者需要根据具体场景进行优化和调整，以充分发挥其潜力。随着技术的成熟和生态的完善，这些挑战将逐步得到解决12 。\nJava虚拟线程技术未来可能会带来哪些新的编程范式 # Java 虚拟线程技术（Virtual Threads）的引入不仅显著提升了并发性能，还可能催生一些新的编程范式和实践，进一步简化并发编程并提高开发效率。以下是未来可能出现的几种新编程范式：\n1. 结构化并发（Structured Concurrency） # 结构化并发是一种通过显式控制线程生命周期来简化并发编程的范式。虚拟线程与结构化并发结合，可以更清晰地管理任务和线程的父子关系，避免线程泄漏和资源浪费。\n示例：\ntry (var scope = new StructuredTaskScope\u0026lt;Void\u0026gt;()) { scope.fork(() -\u0026gt; task1()); scope.fork(() -\u0026gt; task2()); scope.join(); } 在 StructuredTaskScope 中，所有任务的生命周期被限制在作用域内，作用域结束时所有任务都会被取消或完成。\n优势：\n避免线程泄漏。 简化并发任务的管理和调试。 2. 无回调的异步编程 # 虚拟线程允许开发者以同步的方式编写异步代码，无需使用复杂的回调机制或 Future/Promise。这种范式使得异步编程更加直观和易于维护。\n示例：\nThread.startVirtualThread(() -\u0026gt; { String data = fetchDataFromNetwork(); // 非阻塞 I/O 操作 System.out.println(data); }); 优势：\n代码更易读、更易维护。 避免回调地狱（Callback Hell）。 3. 事件驱动与反应式编程的简化 # 虚拟线程可以与事件驱动和反应式编程模型结合，简化复杂的事件处理逻辑。开发者可以以同步的方式编写事件处理器，而无需手动管理线程和回调。\n示例：\neventBus.subscribe(\u0026#34;event\u0026#34;, event -\u0026gt; { Thread.startVirtualThread(() -\u0026gt; handleEvent(event)); }); 优势：\n简化事件驱动和反应式编程的复杂性。 提高代码的可读性和可维护性。 4. 轻量级任务并发 # 虚拟线程的轻量级特性使得开发者可以更自由地分解任务，将复杂任务拆分为多个小任务并行执行，而无需担心线程开销。\n示例：\nList\u0026lt;Thread\u0026gt; threads = IntStream.range(0, 1000) .mapToObj(i -\u0026gt; Thread.startVirtualThread(() -\u0026gt; processTask(i))) .toList(); threads.forEach(Thread::join); 优势：\n提高任务并发度。 更高效地利用系统资源。 5. 微服务与云原生架构的优化 # 虚拟线程的高并发性能使得它在微服务和云原生架构中具有显著优势。开发者可以更高效地处理大量并发请求，而无需依赖复杂的线程池配置。\n示例：\n在 Spring Boot 3 中，虚拟线程可以显著提升 Web 服务的并发处理能力，减少响应时间。 在云原生应用中，虚拟线程可以更高效地处理高并发请求，降低资源消耗。 优势：\n提高微服务的性能和可扩展性。 简化云原生应用的并发管理。 6. 更高效的批处理与流处理 # 虚拟线程可以显著提升批处理和流处理任务的性能，特别是在涉及大量 I/O 操作的场景中。\n示例：\nList\u0026lt;String\u0026gt; results = Files.lines(Paths.get(\u0026#34;data.txt\u0026#34;)) .parallel() .map(line -\u0026gt; processLine(line)) .collect(Collectors.toList()); 优势：\n提高批处理和流处理任务的效率。 简化并发任务的管理。 7. 更友好的并发调试与监控 # 虚拟线程的引入使得并发调试和监控更加直观。开发者可以更容易地跟踪虚拟线程的执行状态，定位并发问题。\n示例：\n使用 JVM 工具（如 JFR）监控虚拟线程的状态。 通过日志记录虚拟线程的执行路径。 优势：\n简化并发调试和监控。 提高开发效率。 总结 # Java 虚拟线程技术的引入不仅提升了并发性能，还可能催生多种新的编程范式，如结构化并发、无回调的异步编程、事件驱动与反应式编程的简化、轻量级任务并发等。这些范式将显著简化并发编程，提高代码的可读性、可维护性和性能，同时为微服务、云原生架构和批处理等场景提供更高效的解决方案。随着虚拟线程技术的普及，Java 生态将迎来更多创新和优化。\njava # 学习资料 # CS-Notes面试笔记 mall-swarm视频教程 basic # java array 转 list # 在Java中，你可以使用Arrays.asList()方法将数组转换为列表。这是一个简单的方法来创建一个固定大小的List。如果你需要一个能够改变大小的List ，你需要使用new ArrayList\u0026lt;\u0026gt;(Arrays.asList(array))来创建一个新的ArrayList实例。\n以下是两种情况的代码示例：\n创建一个固定大小的列表 # import java.util.Arrays; import java.util.List; public class ArrayToListExample { public static void main(String[] args) { String[] array = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}; List\u0026lt;String\u0026gt; list = Arrays.asList(array); System.out.println(list); // 输出: [a, b, c] } } 创建一个可变大小的列表 # import java.util.ArrayList; import java.util.Arrays; import java.util.List; public class ArrayToArrayListExample { public static void main(String[] args) { String[] array = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}; List\u0026lt;String\u0026gt; arrayList = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(array)); // 现在可以添加或删除元素了 arrayList.add(\u0026#34;d\u0026#34;); System.out.println(arrayList); // 输出: [a, b, c, d] } } 请注意，当你使用Arrays.asList()时，它返回的是一个受数组支持的固定大小的列表。这意味着你不能添加或移除元素（除非你将其转换为像ArrayList 这样的可调整大小的列表），但是你可以修改已经存在的元素。如果你尝试对固定大小的列表执行添加或移除操作，将会抛出UnsupportedOperationException异常。\njava， 怎么用二进制打印int # 在Java中，可以使用Integer.toBinaryString()方法来将一个int类型的数值转换为二进制字符串表示。此方法返回的是一个不带前导零的字符串，也就是说它不会打印出完整的32位（对于int 类型），如果需要显示所有位，包括前导零，则需要额外处理。\n以下是一些例子：\n使用 Integer.toBinaryString() # public class BinaryPrintExample { public static void main(String[] args) { int number = 42; String binaryString = Integer.toBinaryString(number); System.out.println(\u0026#34;The binary representation of \u0026#34; + number + \u0026#34; is: \u0026#34; + binaryString); } } 打印包含前导零的完整32位 # 如果你想要打印出完整的32位二进制数，包括前导的0，你可以使用String.format()或者BitSet，但最简单的方法是用String.format()配合循环补足前导零：\npublic class FullBinaryPrintExample { public static void main(String[] args) { int number = 42; // Convert to binary string and ensure it\u0026#39;s 32 bits long with leading zeros String binaryString = String.format(\u0026#34;%32s\u0026#34;, Integer.toBinaryString(number)).replace(\u0026#39; \u0026#39;, \u0026#39;0\u0026#39;); System.out.println(\u0026#34;The full 32-bit binary representation of \u0026#34; + number + \u0026#34; is: \u0026#34; + binaryString); } } 上面的代码中，%32s指定了格式化后的字符串总长度为32，不足的部分用空格填充，然后我们用replace(' ', '0')把所有的空格替换成'0\u0026rsquo;。\n使用位运算手动构建二进制字符串 # 如果你想自己实现这个功能，你也可以使用位运算来构建二进制字符串：\npublic class ManualBinaryPrintExample { public static void main(String[] args) { int number = 42; StringBuilder binaryString = new StringBuilder(); for (int i = 31; i \u0026gt;= 0; i--) { int k = number \u0026gt;\u0026gt; i; if ((k \u0026amp; 1) \u0026gt; 0) { binaryString.append(\u0026#34;1\u0026#34;); } else { binaryString.append(\u0026#34;0\u0026#34;); } } System.out.println(\u0026#34;The manually constructed 32-bit binary representation of \u0026#34; + number + \u0026#34; is: \u0026#34; + binaryString.toString()); } } 这段代码通过逐位检查整数的每一位是否为1，并相应地添加\u0026quot;1\u0026quot;或\u0026quot;0\u0026quot;到StringBuilder对象中，最终构建出完整的32位二进制字符串。\nconcurrent # 每一个java的版本的主要更新 # 以下是Java主要版本的主要更新内容：\nJava 1.0 (1996) # 初始版本：包含核心API和基础功能，如AWT、线程、IO等。 Java 1.1 (1997) # JDBC：支持数据库连接。 RMI：支持远程方法调用。 内部类：引入内部类。 JavaBeans：引入组件模型。 Java 1.2 (1998) # 集合框架：引入集合框架（如List、Set、Map）。 Swing：引入新的GUI库。 JIT编译器：引入即时编译器提升性能。 Java 1.3 (2000) # HotSpot JVM：引入HotSpot虚拟机。 JNDI：支持命名和目录服务。 Java 1.4 (2002) # 正则表达式：引入正则表达式支持。 NIO：引入非阻塞IO。 日志API：引入日志功能。 Java 5 (2004) # 泛型：引入泛型支持。 注解：引入注解功能。 自动装箱/拆箱：支持基本类型与包装类的自动转换。 枚举：引入枚举类型。 并发工具：引入java.util.concurrent包。 Java 6 (2006) # 脚本引擎：支持脚本语言（如JavaScript）。 JDBC 4.0：增强数据库连接功能。 JAX-WS：支持Web服务。 Java 7 (2011) # try-with-resources：自动资源管理。 NIO.2：增强文件IO操作。 钻石操作符：简化泛型实例化。 多异常捕获：支持一次捕获多个异常。 Java 8 (2014) # Lambda表达式：引入函数式编程。 Stream API：支持流式数据处理。 默认方法：接口支持默认方法。 新的日期时间API：引入java.time包。 Java 9 (2017) # 模块系统：引入模块化系统（Jigsaw）。 JShell：引入交互式编程工具。 集合工厂方法：简化集合创建。 Java 10 (2018) # 局部变量类型推断：引入var关键字。 G1垃圾回收器：并行全堆回收。 Java 11 (2018) # HTTP Client API：标准化HTTP客户端。 局部变量语法扩展：支持Lambda表达式中的var。 移除模块：移除Java EE和CORBA模块。 Java 12 (2019) # Switch表达式：增强switch语句。 JVM常量API：引入常量API。 Java 13 (2019) # 文本块：支持多行字符串。 动态CDS归档：优化类数据共享。 Java 14 (2020) # Records：引入记录类。 Pattern Matching for instanceof：增强instanceof操作符。 Java 15 (2020) # Sealed Classes：引入密封类。 文本块：正式支持多行字符串。 Java 16 (2021) # Records：正式支持记录类。 Pattern Matching for instanceof：正式支持模式匹配。 Java 17 (2021) # Sealed Classes：正式支持密封类。 移除RMI激活系统：移除过时功能。 Java 18 (2022) # 简单Web服务器：引入简单HTTP服务器。 UTF-8默认字符集：默认使用UTF-8编码。 Java 19 (2022) # 虚拟线程：引入虚拟线程（预览）。 结构化并发：简化多线程编程（孵化器）。 Java 20 (2023) # Scoped Values：引入作用域值（预览）。 Record Patterns：引入记录模式（预览）。 Java 21 (2023) # 虚拟线程：正式支持虚拟线程。 字符串模板：引入字符串模板（预览）。 总结 # Java每个版本都带来了新特性和改进，从基础功能到高级特性，不断提升开发效率和性能。\n面试java的时候可能会问到有没有了解最新的技术，这个我该怎么准备，提前了解哪些知识 # 在Java面试中，面试官可能会询问你对最新技术的了解，尤其是Java的最新版本和相关生态技术的发展。为了应对这类问题，你可以从以下几个方面进行准备：\n1. Java最新版本特性 # Java的每个版本都会引入新特性，了解这些特性不仅能展现你的技术敏锐度，还能体现你对语言发展的关注。以下是Java 17及之后版本的重要特性：\nJava 17 (LTS)： 密封类（Sealed Classes）：限制类的继承，增强代码的安全性。 模式匹配（Pattern Matching）：简化instanceof的使用，减少冗余代码。 文本块（Text Blocks）：简化多行字符串的处理。 Java 21： 虚拟线程（Virtual Threads）：轻量级线程，显著提升并发性能。 结构化并发（Structured Concurrency）：简化多线程编程，提升代码可维护性。 2. 微服务与云原生技术 # 微服务和云原生是当前Java开发的热门方向，面试官可能会问到相关技术栈：\nSpring Cloud：了解服务发现（Eureka）、配置中心（Spring Cloud Config）、负载均衡（Ribbon）等。 Docker与Kubernetes：掌握容器化部署和编排工具的使用场景。 服务网格（Service Mesh）：了解Istio或Linkerd在微服务中的作用。 3. 数据库与缓存技术 # 数据库和缓存是Java开发中的核心组件，面试官可能会问到最新趋势：\nNoSQL数据库：了解MongoDB、Cassandra等非关系型数据库的使用场景。 Redis：掌握Redis在缓存、分布式锁、消息队列中的应用。 NewSQL：了解TiDB、CockroachDB等分布式数据库的特点。 4. 性能优化与JVM调优 # JVM调优是Java开发中的高级技能，面试官可能会问到相关实践：\n垃圾回收器：了解G1、ZGC、Shenandoah等新型垃圾回收器的特点。 性能监控工具：掌握JProfiler、VisualVM等工具的使用。 内存模型：理解JVM内存分区（堆、栈、方法区）及优化策略。 5. 前沿技术与趋势 # 响应式编程：了解Spring WebFlux和Project Reactor的使用场景。 AI与大数据：了解Java在机器学习（如DL4J）和大数据处理（如Apache Flink）中的应用。 低代码/无代码平台：了解Java在低代码开发中的角色。 6. 实践与项目结合 # 项目中的应用：如果你在实际项目中使用过上述技术，可以结合项目经验进行说明。例如，如何在项目中利用虚拟线程提升并发性能，或如何使用Redis优化缓存策略。 学习资源：关注技术博客、官方文档、GitHub开源项目，保持对最新技术的敏感度。 7. 面试中的表达技巧 # 结构化回答：使用STAR法则（情境、任务、行动、结果）描述你对新技术的理解和应用。 展现学习能力：如果对某些技术不熟悉，可以表达出学习的意愿和计划。 通过以上准备，你可以在面试中展现出对最新技术的深刻理解和实际应用能力，从而提升竞争力。如果需要更详细的学习资源或具体技术点的深入解析，可以参考相关文档或技术社区。\ncollection # Collection 和 Collections 有什么区别？ # Collection 和 Collections 是 Java 中两个不同的概念，主要区别体现在它们的定义、性质和使用方式上。以下是详细对比：\n1. 定义与性质 # Collection\n定义：Collection 是 Java 集合框架中的一个接口，表示一组对象的集合。它是所有集合类的父接口，为集合操作提供了基本的规范。 性质：Collection 是一个抽象的概念，定义了集合的基本操作，如添加（add）、删除（remove）、遍历（iterator）等。常见的实现类包括 List、Set 等12。 Collections\n定义：Collections 是 Java 提供的一个工具类，包含了一系列对集合进行操作的静态方法。 性质：Collections 是一个具体的类，不能被实例化。它提供了许多实用的静态方法，用于对集合进行排序、查找、替换、复制、同步等操作123。 2. 功能与使用 # Collection\n功能：Collection 接口定义了集合的基本操作，如添加、删除、遍历等。这些操作是所有集合类必须实现的方法2。 使用：通常需要创建一个实现了 Collection 接口的集合类对象（如 ArrayList、HashSet），然后调用其提供的方法来操作集合中的元素2。 Collections\n功能：Collections 类提供了许多实用的静态方法，如排序（sort）、查找（max、min）、替换（replaceAll）、复制（copy ）、同步（synchronizedCollection）等23。 使用：由于 Collections 是一个工具类，其方法都是静态的，因此可以直接通过类名调用。例如，Collections.sort(list) 可以对列表进行排序，Collections.max(list) 可以查找集合中的最大值23。 3. 示例代码 # import java.util.ArrayList; import java.util.Collections; import java.util.List; public class Main { public static void main(String[] args) { // 创建一个 ArrayList 集合 List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(3); list.add(1); list.add(2); // 使用 Collections 类的 sort 方法对集合进行排序 Collections.sort(list); // 遍历集合并打印元素 for (Integer num : list) { System.out.println(num); } // 使用 Collections 类的 max 方法获取集合中的最大值 Integer max = Collections.max(list); System.out.println(\u0026#34;Max value: \u0026#34; + max); // 使用 Collections 类的 unmodifiableList 方法创建一个不可修改的集合 List\u0026lt;Integer\u0026gt; unmodifiableList = Collections.unmodifiableList(list); // 尝试修改不可修改的集合会抛出 UnsupportedOperationException 异常 // unmodifiableList.add(4); // 会抛出异常 } } 在上述代码中，Collection 接口用于定义集合的基本行为，而 Collections 类提供了对集合进行排序、查找等操作的静态方法2。\n4. 总结 # Collection 是一个接口：它定义了集合的基本操作和行为规范，是 Java 集合框架的基础12。 Collections 是一个工具类：它提供了许多实用的静态方法，用于对集合进行各种操作23。\n在实际开发中，应根据具体需求选择合适的集合类或接口。如果需要定义一个自定义的集合类，可以继承或实现 Collection 接口；如果需要对集合进行排序、查找等操作，可以使用 Collections 类提供的静态方法2。 Arrays.sort 和 Collections.sort 的区别 # Arrays.sort 和 Collections.sort 是 Java 中用于排序的两个常用方法，它们的主要区别体现在 适用对象、底层实现 和 使用场景 上。以下是详细对比：\n1. 适用对象 # Arrays.sort\n用于对 数组 进行排序，支持基本数据类型（如 int[]、double[]）和对象数组（如 String[]、Integer[]）。 示例： int[] arr = {3, 1, 2}; Arrays.sort(arr); Collections.sort\n用于对 集合（如 List）进行排序，仅支持实现了 List 接口的集合（如 ArrayList、LinkedList）。 示例： List\u0026lt;Integer\u0026gt; list = Arrays.asList(3, 1, 2); Collections.sort(list); 2. 底层实现 # Arrays.sort\n对于 基本数据类型，使用 双轴快速排序（Dual-Pivot Quicksort），性能高效但不稳定。 对于 对象数组，使用 归并排序（Merge Sort）或 TimSort，保证稳定性23。 Collections.sort\n底层调用 Arrays.sort，但针对集合的特性进行了封装。对于 List，使用 TimSort，保证稳定性23。 3. 排序规则 # 默认排序\n两者都支持默认的 自然排序（基于 Comparable 接口）。 示例： Arrays.sort(arr); // 默认升序 Collections.sort(list); // 默认升序 自定义排序\n两者都支持通过 Comparator 接口实现自定义排序。 示例： Arrays.sort(arr, Comparator.reverseOrder()); // 降序 Collections.sort(list, Comparator.reverseOrder()); // 降序 4. 性能与稳定性 # 性能\nArrays.sort 在处理基本数据类型时性能更高，因为直接操作数组；Collections.sort 需要先将集合转换为数组，排序后再转换回集合，性能稍低3。 稳定性\nArrays.sort 对对象数组和 Collections.sort 对集合的排序都是 稳定 的（即相等元素的相对顺序不变）3。 5. 使用场景 # Arrays.sort\n适用于需要对 数组 进行排序的场景，尤其是基本数据类型数组。 Collections.sort\n适用于需要对 集合（如 List）进行排序的场景，特别是需要自定义排序规则时。 总结 # 特性 Arrays.sort Collections.sort 适用对象 数组（基本数据类型、对象数组） 集合（如 List） 底层实现 基本类型：快速排序；对象：归并排序/TimSort 调用 Arrays.sort，使用 TimSort 默认排序 自然排序（升序） 自然排序（升序） 自定义排序 支持 Comparator 支持 Comparator 性能 较高 稍低（需转换集合） 稳定性 对象数组稳定，基本类型不稳定 稳定 使用场景 数组排序 集合排序 根据具体需求选择合适的排序方法：数组排序用 Arrays.sort，集合排序用 Collections.sort123。\nHashMap # HashMap底层的数据结构是怎样的 # HashMap 底层的数据结构在 JDK 1.7 和 JDK 1.8 中有显著的不同，主要体现在如何处理哈希冲突和存储数据的方式上。\nJDK 1.7 及之前 # 数据结构：数组 + 链表 数组：是 HashMap 的主体，用于存储键值对（Entry 对象）。数组的每个位置称为一个 桶（bucket）。 链表：用于解决哈希冲突。当多个键的哈希值相同（即计算出的数组索引相同）时，这些键值对会以链表的形式存储在同一个桶中。 哈希冲突解决：通过 拉链法（Chaining）解决哈希冲突，即链表的形式。 性能问题：当链表过长时，查询效率会降低，时间复杂度退化为 O(n)。 JDK 1.8 及之后 # 数据结构：数组 + 链表 + 红黑树 数组：仍然是 HashMap 的主体，用于存储键值对（Node 对象）。 链表：当哈希冲突时，键值对首先以链表的形式存储。 红黑树：当链表长度超过 阈值（默认是 8） 且 数组长度大于 64 时，链表会转换为 红黑树，以提高查询效率。 哈希冲突解决：仍然使用 拉链法，但当链表过长时会转换为红黑树，时间复杂度优化为 O(log n)。 性能优化：红黑树的引入大大减少了哈希冲突严重时的查询时间。 核心机制 # 哈希计算\n通过 key.hashCode() 计算哈希值，再通过 (n - 1) \u0026amp; hash 计算数组索引（n 是数组长度）。 为了减少哈希冲突，JDK 1.8 对哈希值进行了优化，将高 16 位与低 16 位进行异或运算，使哈希分布更均匀13。 扩容机制\n当 HashMap 中的元素数量超过 容量 * 负载因子 时，会触发扩容（默认容量为 16，负载因子为 0.75）。 扩容时，数组长度变为原来的 2 倍，所有元素会重新计算哈希并分配到新的桶中13。 红黑树转换\n当链表长度超过 8 且数组长度大于 64 时，链表会转换为红黑树；当红黑树节点数小于 6 时，红黑树会退化为链表13。 总结 # JDK 1.7：数组 + 链表，通过拉链法解决哈希冲突，性能较差。 JDK 1.8：数组 + 链表 + 红黑树，通过链表和红黑树结合，优化了查询性能。 这种数据结构的设计使得 HashMap 在大多数情况下能够以 O(1) 的时间复杂度进行查找、插入和删除操作，同时在高并发场景下也能保持较好的性能123。\n为什么HashMap要使用红黑树而不使用其他的树结构？ # \u0026lt;icon\u0026gt;https://wy-static.wenxiaobai.com/bot-capability/prod/%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83.png\u0026lt;/icon\u0026gt; \u0026lt;start\u0026gt;思考中...\u0026lt;/start\u0026gt; 嗯，用户问为什么HashMap用红黑树而不是其他树结构。我得仔细看看搜索结果里的内容。首先，记得之前学过的，红黑树是自平衡二叉搜索树，而HashMap在链表过长时转成红黑树是为了提高查询效率。那为什么要选红黑树而不是比如AVL树或者其他树呢？ 搜索结果里，网页1提到红黑树的平均查找长度是log(n)，链表是n/2，当长度超过8的时候，转换成树更有必要。同时，网页6和网页8也讨论了红黑树和AVL树的区别。网页6说红黑树在插入和删除时效率更高，因为旋转次数少。而AVL树虽然查询更快，但维护平衡的成本高，每次调整可能需要更多旋转。 网页8提到红黑树的平衡性不如AVL严格，但这样换来的是更高效的插入和删除操作。对于HashMap这种需要频繁插入和删除的场景，红黑树的性能更好。另外，红黑树在调整时最多三次旋转就能恢复平衡，而AVL可能需要O(log n)次，这在多线程或高并发情况下更有优势。 还有网页4和网页7也提到，红黑树在解决哈希冲突时，能提供O(log n)的时间复杂度，而链表是O(n)。当链表长度增加到一定阈值时，转换为树结构能有效提升性能。而选择红黑树而不是其他树结构，比如B树或者二叉搜索树，可能是因为红黑树在内存中操作更高效，不需要像B树那样处理大量子节点，适合内存中的数据结构。 另外，网页9和网页10提到HashMap在JDK8之后使用红黑树的条件是链表长度超过8且数组容量达到64。这说明红黑树的使用是有严格条件的，而红黑树的结构特性刚好满足这种需要部分平衡的场景，既保证了查询效率，又减少了维护平衡的开销。 所以总结下来，HashMap选择红黑树主要是因为它在插入、删除和查询之间找到了一个平衡点，适合频繁修改的场景。而其他树结构如AVL树可能在查询上更快，但维护成本高；二叉堆或B树可能结构不适合HashMap的需求。红黑树的这些特性使得它在HashMap中表现更优。 \u0026lt;end\u0026gt;已深度思考（用时14秒）\u0026lt;/end\u0026gt; 在 Java 的 HashMap 中，当哈希冲突导致链表长度超过阈值（默认为 8）时，链表会转换为红黑树以优化性能。选择红黑树而非其他树结构（如 AVL 树、普通二叉搜索树等）是经过多方面权衡后的结果，主要原因如下：\n一、红黑树的特性优势 # 红黑树是一种自平衡二叉搜索树，其核心优势在于平衡性与操作效率的折中。以下是其关键特性：\n近似平衡\n红黑树通过约束条件（如红色节点不能连续、从根到叶子的黑节点数相同）保证最长路径不超过最短路径的两倍159。这种“非严格平衡”使得维护成本低于 AVL 树，同时仍能保证对数级时间复杂度（O(log n)）的查找效率。\n高效的增删操作\n插入/删除性能：红黑树在调整平衡时最多需要3次旋转即可完成，而 AVL 树可能需要多次旋转甚至 O(log n) 次调整68。例如，删除节点时，AVL 需维护从删除节点到根的路径平衡，而红黑树只需局部调整8。 时间复杂度：红黑树的插入、删除和查找均为 O(log n)，且实际性能稳定，适合频繁修改的场景712。 内存占用优化\n红黑树仅需存储颜色标记（1 bit），而 AVL 树需存储平衡因子（通常为整型），内存开销更小8。\n二、与其他树结构的对比 # 1. 与 AVL 树的对比 # 平衡性：AVL 树追求严格平衡（左右子树高度差≤1），查询效率略高于红黑树，但插入/删除时维护平衡的代价更高68。 适用场景：AVL 树适合读多写少的场景（如数据库索引），而 HashMap 需要频繁插入和删除节点，红黑树的综合性能更优812。 2. 与普通二叉搜索树的对比 # 退化问题：普通二叉搜索树在极端情况下（如数据有序插入）会退化为链表，时间复杂度退化为 O(n)，而红黑树通过自平衡机制避免此问题59。 3. 与 B 树/B+ 树的对比 # 内存与磁盘优化：B 树适用于磁盘存储（减少 I/O 次数），而红黑树作为内存数据结构，更适合 HashMap 的哈希桶管理8。 三、HashMap 的特定需求 # 哈希冲突的局部性\nHashMap 仅在单个哈希桶内使用红黑树，冲突节点数量通常较小（默认阈值 8），红黑树的局部调整特性更契合这种场景3710。\n性能与成本的权衡\n树化阈值选择：链表长度超过 8 才转换为红黑树，因为此时链表的平均查找长度为 4，而红黑树为 3，性能提升显著13。 树退化阈值：当节点数降至 6 时还原为链表，避免频繁树化与退化（中间差值 7 作为缓冲）110。 工程实践验证\n红黑树的实现复杂度适中，且经过大量工程验证（如 Linux 内核、Java 集合框架），其稳定性和效率已被广泛认可68。\n四、总结 # HashMap 选择红黑树的核心原因在于：\n平衡效率与维护成本：在近似平衡的基础上，以更低的代价实现高效的增删操作。 适应哈希冲突场景：适合局部、小规模的数据结构管理需求。 工程实践优势：经过长期验证，性能稳定且实现成熟。 相比之下，其他树结构或过于追求平衡（如 AVL 树），或缺乏自适应性（如普通二叉搜索树），无法在 HashMap 的特定场景中达到最优性能168。\nHashMap get 的时间复杂度 # HashMap 的 get 方法的时间复杂度在理想情况下是 O(1)，但在最坏情况下可能退化为 O(n)。以下是详细说明：\n1. 理想情况（O(1)） # 哈希函数均匀分布：当哈希函数能够将键均匀地分布到各个桶（bucket）中时，HashMap 的 get 操作可以通过计算键的哈希值直接定位到对应的桶，从而在常数时间内获取值。 无哈希冲突：如果每个桶中只有一个元素（没有哈希冲突），get 操作的时间复杂度为 O(1)。 2. 最坏情况（O(n)） # 哈希冲突严重：当多个键的哈希值相同（哈希冲突），且这些键被存储在同一个桶中时，HashMap 会使用链表或红黑树来存储这些键值对。在这种情况下，get 操作需要遍历链表或红黑树来查找目标键。 链表：如果桶中的元素以链表形式存储，时间复杂度为 O(n)，其中n是链表的长度。 红黑树：在 JDK 1.8 及之后，当链表长度超过一定阈值（默认是 8）且桶数组长度大于等于 64 时，链表会转换为红黑树。此时，get 操作的时间复杂度为 O(log n)，其中 n 是树中节点的数量34。 3. 总结 # 平均时间复杂度：O(1)，在哈希函数分布均匀且哈希冲突较少的情况下。 最坏时间复杂度：O(n)，在哈希冲突严重且链表未转换为红黑树的情况下。 优化后的最坏时间复杂度：O(log n)，在链表转换为红黑树的情况下45。 通过合理的哈希函数设计和 HashMap 的扩容机制，可以尽量减少哈希冲突，使 get 操作的时间复杂度接近 O(1)。\nHashMap如何保证线程安全 # HashMap 本身是 非线程安全 的，在多线程环境下可能会出现数据不一致、死循环等问题。为了保证线程安全，可以使用以下几种方法：\n1. 使用 Collections.synchronizedMap # Collections.synchronizedMap 方法可以将普通的 HashMap 包装为一个线程安全的 Map。它通过在 HashMap 的所有操作方法上加锁（synchronized）来保证线程安全。\n示例代码：\nMap\u0026lt;String, String\u0026gt; map=Collections.synchronizedMap(new HashMap\u0026lt;\u0026gt;()); 特点：\n优点：使用简单，适合低并发场景。 缺点：锁粒度较大（整个 Map），性能较差2。 2. 使用 ConcurrentHashMap # ConcurrentHashMap 是 Java 并发包中提供的线程安全的 Map 实现。它通过 分段锁（JDK 1.7）或 CAS + synchronized（JDK 1.8 及之后）来保证线程安全。\n示例代码：\nMap\u0026lt;String, String\u0026gt; map=new ConcurrentHashMap\u0026lt;\u0026gt;(); 特点：\n优点：锁粒度更细，性能更高，适合高并发场景。 缺点：内存开销较大，实现复杂34。 3. 使用读写锁 (ReadWriteLock) # 读写锁将锁分为 读锁 和 写锁，允许多个线程同时读取数据，但写操作是独占的。\n示例代码：\nReadWriteLock lock=new ReentrantReadWriteLock(); Map\u0026lt;String, String\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); // 写操作 lock. writeLock(). lock(); try{ map. put(\u0026#34;key\u0026#34;,\u0026#34;value\u0026#34;); }finally{ lock. writeLock(). unlock(); } // 读操作 lock. readLock(). lock(); try{ String value=map.get(\u0026#34;key\u0026#34;); }finally{ lock. readLock(). unlock(); } 特点：\n优点：适合读多写少的场景，性能较好。 缺点：实现较为复杂2。 4. 方法内部使用局部 HashMap # 如果 HashMap 只在方法内部使用，且每个线程都有自己的实例，则无需额外同步。\n示例代码：\npublic void process(){ Map\u0026lt;String, String\u0026gt; localMap=new HashMap\u0026lt;\u0026gt;(); localMap.put(\u0026#34;key\u0026#34;,\u0026#34;value\u0026#34;); // 其他操作 } 特点：\n优点：简单且线程安全。 缺点：仅适用于局部变量场景2。 5. 初始化写，后续只读 # 如果 HashMap 在初始化后不再修改，可以将其设为只读，从而避免线程安全问题。\n示例代码：\nMap\u0026lt;String, String\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); map. put(\u0026#34;key\u0026#34;,\u0026#34;value\u0026#34;); map=Collections. unmodifiableMap(map); 特点：\n优点：简单且线程安全。 缺点：仅适用于初始化后不再修改的场景2。 总结 # 方法 适用场景 优点 缺点 Collections.synchronizedMap 低并发场景 使用简单 锁粒度大，性能差 ConcurrentHashMap 高并发场景 锁粒度细，性能高 内存开销大，实现复杂 读写锁 (ReadWriteLock) 读多写少场景 读操作并发性好 实现复杂 局部 HashMap 方法内部使用 简单且线程安全 仅适用于局部变量 初始化写，后续只读 初始化后不再修改的场景 简单且线程安全 仅适用于只读场景 在实际开发中，ConcurrentHashMap 是保证 HashMap 线程安全的首选方案，尤其在高并发场景下34。\nHashMap 和 Hashtable 有什么区别？ # HashMap 和 Hashtable 是 Java 中两种常用的键值对存储结构，它们虽然功能相似，但在线程安全性、性能、对 null 值的支持等方面存在显著区别。以下是它们的详细对比：\n1. 线程安全性 # Hashtable：是线程安全的，其所有公共方法都使用了 synchronized 关键字进行同步，因此在多线程环境下可以直接使用，但性能较低123。 HashMap：是非线程安全的，多线程环境下可能导致数据不一致。如果需要在多线程环境中使用，可以通过 Collections.synchronizedMap 方法将其包装为线程安全的 Map ，或者使用 ConcurrentHashMap123。 2. 对 null 值的支持 # Hashtable：不允许键或值为 null，否则会抛出 NullPointerException123。 HashMap：允许键和值均为 null，但键为 null 的情况只能有一个，因为键必须唯一123。 3. 性能 # Hashtable：由于所有方法都是同步的，性能较低，尤其在多线程环境下23。 HashMap：非同步实现，性能较高，适合单线程环境。在多线程环境下，可以通过 ConcurrentHashMap 获得更好的性能123。 4. 继承与实现 # Hashtable：继承自 Dictionary 类（已过时），并实现了 Map 接口13。 HashMap：继承自 AbstractMap 类，并实现了 Map 接口13。 5. 扩容机制 # Hashtable：默认初始容量为 11，扩容时容量变为原来的 2 倍加 113。 HashMap：默认初始容量为 16，扩容时容量变为原来的 2 倍13。 6. 迭代器 # Hashtable：使用 Enumeration 进行遍历，不支持 fail-fast 机制13。 HashMap：使用 Iterator 进行遍历，支持 fail-fast 机制。如果在迭代过程中修改了 HashMap 的结构（如添加或删除元素），会抛出 ConcurrentModificationException13。 7. 计算哈希值的方式 # Hashtable：直接使用对象的 hashCode 方法计算哈希值13。 HashMap：对 hashCode 进行二次处理，通过 (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16) 重新计算哈希值，以减少哈希冲突13。 总结 # 特性 Hashtable HashMap 线程安全性 线程安全（同步方法） 非线程安全 对 null 值的支持 不允许键或值为 null 允许键和值为 null 性能 较低 较高 继承类 Dictionary（已过时） AbstractMap 扩容机制 容量变为 2 倍加 1 容量变为 2 倍 迭代器 Enumeration，不支持 fail-fast Iterator，支持 fail-fast 哈希值计算 直接使用 hashCode 对 hashCode 进行二次处理 在实际开发中，HashMap 是更常用的选择，尤其是在单线程环境下。如果需要线程安全，推荐使用 ConcurrentHashMap，而不是 Hashtable123 。\n当 HashMap 扩容时，所有的红黑树或者链表都会重新构造吗 # 是的，当 HashMap 扩容 时，所有的 链表 和 红黑树 都会重新构造。这是因为扩容后，数组的长度发生了变化，原有的哈希值计算方式也会随之改变，因此需要对所有元素进行重新哈希和分配。以下是详细的过程：\n1. 链表重新构造 # 在扩容过程中，链表会被拆分为 高位链表 和 低位链表，分别对应新数组中的不同位置。具体步骤如下：\n遍历链表：从链表的头节点开始，逐个遍历每个节点。 计算新位置：通过位运算 e.hash \u0026amp; oldCap 判断节点应该分配到高位还是低位。 如果结果为 0，节点放入 低位链表，位置为 原索引。 如果结果为 1，节点放入 高位链表，位置为 原索引 + 旧数组长度。 重新连接链表：将拆分后的链表重新连接到新数组的对应位置13。 2. 红黑树重新构造 # 红黑树的重新构造与链表类似，但会涉及到红黑树的拆分和可能的 树转链表 操作：\n遍历红黑树：红黑树的节点保留了链表的结构，因此可以像链表一样遍历。 计算新位置：同样通过 e.hash \u0026amp; oldCap 判断节点应该分配到高位还是低位。 拆分红黑树：将红黑树拆分为 高位树 和 低位树。 判断是否需要转链表： 如果拆分后的树节点数小于等于 UNTREEIFY_THRESHOLD（默认是 6），则将红黑树转换为链表。 否则，将拆分后的树重新插入新数组的对应位置135。 3. 重新哈希的原因 # 扩容后，数组的长度变为原来的两倍（例如从 16 变为 32），哈希值的计算方式从 (n - 1) \u0026amp; hash 变为 (2n - 1) \u0026amp; hash 。因此，原有的哈希值可能会映射到不同的位置，需要重新计算和分配13。\n总结 # 当 HashMap 扩容时，所有的链表和红黑树都会重新构造。链表会被拆分为高位和低位链表，红黑树会被拆分为高位和低位树，并根据节点数决定是否转换为链表。这一过程确保了扩容后元素的分布依然均匀，维持了 HashMap 的高效性135。\n为什么HashMap选择红黑树而不选择B+树 # HashMap 选择红黑树而不是 B+ 树的原因主要有以下几点：\n1. 算法实现复杂度 # 红黑树：Java 中已经实现了红黑树，且红黑树的实现相对简单，复杂度较低。红黑树是一种自平衡二叉查找树，适合内存中的数据结构操作22。 B+ 树：B+ 树的实现较为复杂，尤其是在内存中维护 B+ 树的结构需要更多的指针和节点管理，增加了实现的难度22。 2. 底层数据结构匹配 # 红黑树：HashMap 的底层是哈希表，红黑树作为链表过长时的替代结构，能够很好地与哈希表结合，解决哈希冲突问题22。 B+ 树：B+ 树通常用于磁盘存储结构，其设计目标是减少磁盘 I/O 操作。而 HashMap 是基于内存的数据结构，B+ 树的优势在内存中并不明显22。 3. 修改效率 # 红黑树：红黑树在插入、删除和查找操作上都有较好的性能，且维护平衡的代价较低。红黑树的旋转操作次数较少，适合频繁修改的场景22。 B+ 树：B+ 树的修改操作需要调整节点和指针，尤其是在内存中频繁修改时，开销较大。B+ 树更适合静态或冷数据存储22。 4. 内存占用 # 红黑树：红黑树的结构相对简单，内存占用较少，适合内存中的高效操作22。 B+ 树：B+ 树的节点通常包含多个子节点，需要更多的指针和空间来维护结构，内存占用较高22。 5. 适用场景 # 红黑树：红黑树适合内存中的动态数据管理，尤其是需要频繁插入、删除和查找的场景。HashMap 在链表长度超过阈值（默认为 8）时，将链表转换为红黑树，以提高查询效率55。 B+ 树：B+ 树更适合磁盘存储，其设计目标是减少磁盘 I/O 操作，适用于数据库和文件系统等场景22。 6. 维护成本 # 红黑树：红黑树的维护成本较低，适合高并发的场景。HashMap 在链表长度小于 6 时，会将红黑树转换回链表，进一步降低维护成本56。 B+ 树：B+ 树的维护成本较高，尤其是在内存中频繁修改时，需要复杂的节点调整和指针管理22。 总结 # HashMap 选择红黑树而不是 B+ 树的主要原因在于红黑树更适合内存中的动态数据管理，实现简单、修改效率高、内存占用少，且维护成本低。而 B+ 树更适合磁盘存储，其优势在内存中无法充分发挥225556。\nI/O模型 # select、poll和epoll的区别 # select、poll 和 epoll 都是用于实现 I/O 多路复用的机制，允许单个进程或线程同时监控多个文件描述符（如套接字），并在其中任何一个就绪时通知程序进行读写操作。尽管它们的功能相似，但在实现方式、性能和适用场景上有显著区别。以下是它们的详细对比：\n1. select # 定义：select 是最早的 I/O 多路复用机制，通过一个系统调用监控多个文件描述符的状态。 特点： 使用 fd_set 数据结构来存储文件描述符集合。 每次调用 select 时，需要将 fd_set 从用户态拷贝到内核态，并在内核中遍历所有文件描述符。 支持的文件描述符数量有限，默认是 1024 个。 超时精度较低，使用的是 struct timeval 结构。 优点： 跨平台支持较好，几乎在所有操作系统上都可用。 缺点： 文件描述符数量受限。 每次调用都需要重新设置 fd_set，且需要从用户态拷贝到内核态，开销较大。 内核需要遍历所有文件描述符，效率较低13。 2. poll # 定义：poll 是对 select 的改进，使用 pollfd 结构来管理文件描述符集合。 特点： 使用 pollfd 数组存储文件描述符及其关注的事件。 没有文件描述符数量的限制（基于链表实现）。 每次调用 poll 时，需要将 pollfd 数组从用户态拷贝到内核态，并在内核中遍历所有文件描述符。 超时精度较高，使用的是毫秒级超时。 优点： 文件描述符数量不受限制。 事件类型更丰富（如 POLLIN、POLLOUT 等）。 缺点： 每次调用需要拷贝 pollfd 数组，开销较大。 内核仍需遍历所有文件描述符，效率较低13。 3. epoll # 定义：epoll 是 Linux 特有的高效 I/O 多路复用机制，专为处理大量文件描述符设计。 特点： 使用事件驱动模型，通过 epoll_create、epoll_ctl 和 epoll_wait 三个函数实现。 文件描述符只需在 epoll_ctl 时拷贝一次到内核，后续调用 epoll_wait 时无需重复拷贝。 内核通过回调机制通知就绪的文件描述符，无需遍历所有文件描述符。 支持水平触发（LT）和边缘触发（ET）模式： 水平触发（LT）：只要文件描述符就绪，就会持续通知。 边缘触发（ET）：仅在状态变化时通知一次，需一次性处理所有数据。 优点： 文件描述符数量不受限制。 性能高效，尤其适合高并发场景。 事件通知机制更灵活。 缺点： 仅支持 Linux 系统，跨平台性差123。 对比总结 # 特性 select poll epoll 文件描述符数量 有限（默认 1024） 无限制 无限制 数据结构 fd_set pollfd 数组 事件表（红黑树 + 就绪链表） 拷贝开销 每次调用需拷贝 fd_set 每次调用需拷贝 pollfd 数组 仅 epoll_ctl 时拷贝一次 内核遍历方式 遍历所有文件描述符 遍历所有文件描述符 回调机制，无需遍历 事件通知机制 水平触发 水平触发 支持水平触发和边缘触发 适用场景 低并发、跨平台场景 中低并发场景 高并发场景（如 Web 服务器） 跨平台性 跨平台支持 跨平台支持 仅支持 Linux 总结 # select：适合低并发场景，跨平台支持好，但性能较差。 poll：解决了 select 的文件描述符数量限制问题，但仍存在性能瓶颈。 epoll：性能最优，适合高并发场景，但仅支持 Linux 系统123。 提供一个java异步I/O的例子 # 以下是一个使用 Java 异步 I/O（AIO）的代码示例，展示了如何通过 AsynchronousFileChannel 进行异步文件读取操作：\n示例代码：异步文件读取 # import java.io.IOException; import java.nio.ByteBuffer; import java.nio.channels.AsynchronousFileChannel; import java.nio.file.Path; import java.nio.file.Paths; import java.nio.file.StandardOpenOption; import java.util.concurrent.Future; public class AsyncFileReadExample { public static void main(String[] args) { try { // 打开异步文件通道 Path path = Paths.get(\u0026#34;example.txt\u0026#34;); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); // 分配缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); // 发起异步读取操作 Future\u0026lt;Integer\u0026gt; future = fileChannel.read(buffer, 0); // 继续执行其他任务 System.out.println(\u0026#34;异步读取操作已发起，继续执行其他任务...\u0026#34;); // 等待读取操作完成 while (!future.isDone()) { System.out.println(\u0026#34;等待读取操作完成...\u0026#34;); Thread.sleep(500); // 模拟其他任务 } // 获取读取结果 int bytesRead = future.get(); buffer.flip(); // 切换缓冲区为读模式 byte[] data = new byte[buffer.remaining()]; buffer.get(data); System.out.println(\u0026#34;读取到的数据: \u0026#34; + new String(data)); // 关闭通道 fileChannel.close(); } catch (Exception e) { e.printStackTrace(); } } } 代码说明 # 打开异步文件通道：\n使用 AsynchronousFileChannel.open() 打开文件通道，并指定 StandardOpenOption.READ 以允许读取操作1。 分配缓冲区：\n使用 ByteBuffer.allocate() 分配一个缓冲区，用于存储读取的数据1。 发起异步读取操作：\n调用 fileChannel.read() 发起异步读取操作，返回一个 Future\u0026lt;Integer\u0026gt; 对象，表示读取操作的完成状态1。 继续执行其他任务：\n在等待读取操作完成的过程中，可以继续执行其他任务，体现了异步 I/O 的非阻塞特性1。 等待读取操作完成：\n使用 future.isDone() 检查读取操作是否完成，并通过 future.get() 获取读取的字节数1。 处理读取结果：\n将缓冲区中的数据转换为字符串并输出1。 关闭通道：\n使用 fileChannel.close() 关闭异步文件通道1。 异步 I/O 的优势 # 非阻塞：发起 I/O 操作后，线程可以继续执行其他任务，无需等待 I/O 操作完成1。 高性能：适合高并发场景，能够充分利用系统资源1。 参考 # 1: Java 异步 I/O 示例，https://www.cnblogs.com/robothy/p/15734643.html 2: 使用 Java NIO 进行异步 I/O 编程，https://baijiahao.baidu.com/s?id=1768046800211280021 4: Java 异步 I/O（AIO）：解析与实例，https://m.blog.csdn.net/DxProgram/article/details/133594390 在java中非阻塞IO就是IO多路复用吗 # 在 Java 中，非阻塞 I/O（Non-blocking I/O） 和 I/O 多路复用（I/O Multiplexing） 是两个相关但不同的概念。它们都用于提高 I/O 操作的效率和性能，但实现方式和应用场景有所不同。\n1. 非阻塞 I/O（Non-blocking I/O） # 非阻塞 I/O 是一种 I/O 模型，其核心特点是当进行 I/O 操作时，如果数据没有准备好，I/O 操作会立即返回，而不是阻塞线程等待数据就绪。线程可以继续执行其他任务，稍后再尝试执行 I/O 操作。\n特点：\n通过 Channel.configureBlocking(false) 将通道设置为非阻塞模式。 线程不会被阻塞，可以同时处理多个 I/O 操作。 需要不断轮询检查 I/O 操作是否完成，可能会消耗 CPU 资源。 示例： 在 Java NIO 中，SocketChannel 和 ServerSocketChannel 可以设置为非阻塞模式。例如：\nSocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\u0026#34;example.com\u0026#34;, 80)); 2. I/O 多路复用（I/O Multiplexing） # I/O 多路复用是一种机制，通过一个线程同时监控多个 I/O 通道（Channel），当某个通道有 I/O 事件就绪时，通知应用程序进行处理。Java NIO 中的 Selector 是实现 I/O 多路复用的核心组件。\n特点：\n使用 Selector 监控多个 Channel 的 I/O 事件（如可读、可写、连接等）。 单线程可以高效地管理多个 I/O 通道，适合高并发场景。 避免了非阻塞 I/O 中轮询的开销，提高了资源利用率。 示例：\nSelector selector = Selector.open(); ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); serverChannel.register(selector, SelectionKey.OP_ACCEPT); 3. 非阻塞 I/O 与 I/O 多路复用的关系 # 非阻塞 I/O 是 I/O 多路复用的基础：I/O 多路复用依赖于通道的非阻塞模式。只有将通道设置为非阻塞模式，Selector 才能有效地监控多个通道的 I/O 事件。 I/O 多路复用是对非阻塞 I/O 的优化：非阻塞 I/O 需要不断轮询检查 I/O 操作是否完成，而 I/O 多路复用通过 Selector 实现了事件驱动机制，避免了轮询的开销125。 4. 总结 # 非阻塞 I/O 是一种 I/O 模型，强调 I/O 操作不会阻塞线程，适用于简单的 I/O 场景。 I/O 多路复用 是一种机制，通过 Selector 高效管理多个非阻塞 I/O 通道，适合高并发场景。 在 Java 中，I/O 多路复用通常基于非阻塞 I/O 实现，但两者并非等同125。 在java中selector算非阻塞还是多路复用 # 在 Java 中，Selector 既是 非阻塞 I/O 的实现机制，也是 I/O 多路复用 的核心组件。它结合了这两种技术，使得单线程可以高效地管理多个 I/O 通道。以下是详细解释：\n1. Selector 是非阻塞 I/O 的实现 # 非阻塞 I/O 的核心特点是，当进行 I/O 操作时，如果数据没有准备好，操作会立即返回，而不是阻塞线程等待数据就绪。在 Java 中，Selector 依赖于 Channel 的非阻塞模式。\n非阻塞模式：在使用 Selector 时，必须将 Channel 设置为非阻塞模式： channel.configureBlocking(false); 这样，Channel 的 I/O 操作（如 read、write）不会阻塞线程，而是立即返回结果（可能是 0 或 -1）。 事件驱动：Selector 通过监听 Channel 的 I/O 事件（如可读、可写、连接等），实现了非阻塞的事件驱动模型。 2. Selector 是 I/O 多路复用的核心 # I/O 多路复用是一种机制，通过一个线程同时监控多个 I/O 通道，当某个通道有事件就绪时，通知应用程序进行处理。Selector 是 Java 中实现 I/O 多路复用的核心组件。\n多路复用机制：Selector 使用底层的系统调用（如 Linux 的 epoll、Windows 的 IOCP）监控多个 Channel。当某个 Channel 的 I/O 事件就绪时，Selector 会将其标记为“就绪状态”，并通过 selectedKeys() 返回这些 Channel 的集合。 单线程管理多通道：通过 Selector，单线程可以同时管理成千上万的 Channel，避免了传统阻塞 I/O 中每个连接需要一个线程的开销。 3. Selector 的工作原理 # Selector 的工作流程如下：\n创建 Selector： Selector selector = Selector.open(); 将 Channel 注册到 Selector： channel.configureBlocking(false); SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 这里指定了感兴趣的事件（如 OP_READ、OP_WRITE）。 轮询就绪事件： int readyChannels = selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); for (SelectionKey key : selectedKeys) { if (key.isReadable()) { // 处理读事件 } else if (key.isWritable()) { // 处理写事件 } } 处理事件：根据 SelectionKey 的类型，执行相应的 I/O 操作。 4. 总结 # Selector 是非阻塞 I/O 的实现：它依赖于 Channel 的非阻塞模式，确保 I/O 操作不会阻塞线程。 Selector 是 I/O 多路复用的核心：它通过监控多个 Channel 的 I/O 事件，实现了单线程管理多通道的高效机制。 因此，Selector 既是非阻塞 I/O 的实现，也是 I/O 多路复用的核心组件123。\nsocket # 我有这样一个开发场景，服务端需要和多个客户端进行tcp连接，服务端会发送指令给客户端，客户端会返回指令执行结果；客户端会定时返回心跳报文上报状态；客户端会不定时上报事件报文。我该怎么实现上述功能？ # 要实现上述功能，可以按照以下步骤进行设计和开发：\n1. 服务端设计 # 1.1 建立TCP连接 # 使用一个主线程监听指定端口，接受客户端的连接请求。 为每个客户端连接创建一个独立的线程或使用I/O多路复用（如select、poll、epoll）处理多个连接。 1.2 指令发送 # 服务端根据需要向特定客户端发送指令，指令可以封装成特定的协议格式（如JSON、XML或自定义二进制格式）。 通过客户端的TCP连接发送指令，并等待客户端返回执行结果。 1.3 处理客户端返回 # 接收客户端返回的指令执行结果，解析并处理。 如果在一定时间内未收到响应，可以进行超时重发或标记客户端为不可用。 1.4 心跳处理 # 接收客户端定时发送的心跳报文，更新客户端的状态和最后活跃时间。 如果长时间未收到心跳，可以认为客户端断开连接，进行清理。 1.5 事件处理 # 接收客户端不定时发送的事件报文，解析并处理。 事件报文可能包含重要信息，需要及时处理。 2. 客户端设计 # 2.1 连接服务端 # 客户端启动时，主动连接服务端的指定IP和端口。 连接成功后，进入主循环等待服务端指令。 2.2 指令执行 # 接收服务端发送的指令，解析并执行。 执行完成后，将结果封装成协议格式，通过TCP连接返回给服务端。 2.3 心跳发送 # 定时（如每30秒）向服务端发送心跳报文，报文可以简单包含客户端ID和当前状态。 心跳报文用于告知服务端客户端仍然存活。 2.4 事件上报 # 当客户端检测到某些事件发生时，主动将事件信息封装成协议格式，通过TCP连接发送给服务端。 3. 协议设计 # 为了确保服务端和客户端之间的通信有序，需要设计一个简单的通信协议。例如：\n指令格式：\n指令类型（1字节） 指令长度（2字节） 指令数据（可变长度） 返回结果格式：\n返回码（1字节） 返回长度（2字节） 返回数据（可变长度） 心跳报文格式：\n心跳标识（1字节） 客户端ID（4字节） 事件报文格式：\n事件类型（1字节） 事件长度（2字节） 事件数据（可变长度） 4. 实现示例 # 服务端示例（Python伪代码） # import socket import threading def handle_client(conn, addr): while True: data = conn.recv(1024) if not data: break # 解析和处理数据 # 发送响应 conn.send(response) conn.close() server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.bind((\u0026#39;0.0.0.0\u0026#39;, 12345)) server.listen(5) while True: conn, addr = server.accept() threading.Thread(target=handle_client, args=(conn, addr)).start() 客户端示例（Python伪代码） # import socket import time client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) client.connect((\u0026#39;server_ip\u0026#39;, 12345)) def send_heartbeat(): while True: time.sleep(30) client.send(heartbeat_message) def monitor_events(): while True: event = detect_event() if event: client.send(event_message) # 启动心跳和事件监控线程 threading.Thread(target=send_heartbeat).start() threading.Thread(target=monitor_events).start() while True: data = client.recv(1024) if data: # 解析和处理指令 client.send(response) 5. 注意事项 # 并发处理：服务端需要处理多个客户端连接，确保并发处理能力。 异常处理：网络连接可能不稳定，需要处理各种异常情况（如连接断开、超时等）。 安全性：考虑使用SSL/TLS加密通信，防止数据被窃听或篡改。 性能优化：根据实际需求，选择合适的I/O模型（如异步I/O）和协议格式，优化性能。 通过以上设计和实现，可以满足服务端与多个客户端之间的TCP通信需求。\n如果我使用IO多路复用来实现，给我一个java版本代码示例 # 使用I/O多路复用（如Java NIO）可以更高效地处理多个客户端连接。以下是一个基于Java NIO的示例代码，展示了如何实现服务端与多个客户端的TCP通信，包括指令发送、心跳处理和事件上报。\n服务端代码示例 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; public class NIOServer { private static final int PORT = 12345; private static final int BUFFER_SIZE = 1024; public static void main(String[] args) throws IOException { // 创建Selector Selector selector = Selector.open(); // 创建ServerSocketChannel并绑定端口 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(PORT)); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\u0026#34;Server started on port \u0026#34; + PORT); while (true) { // 阻塞等待就绪的Channel selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { // 接受客户端连接 ServerSocketChannel serverChannel = (ServerSocketChannel) key.channel(); SocketChannel clientChannel = serverChannel.accept(); clientChannel.configureBlocking(false); clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Client connected: \u0026#34; + clientChannel.getRemoteAddress()); } else if (key.isReadable()) { // 读取客户端数据 SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 客户端断开连接 System.out.println(\u0026#34;Client disconnected: \u0026#34; + clientChannel.getRemoteAddress()); clientChannel.close(); } else if (bytesRead \u0026gt; 0) { // 处理接收到的数据 buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from client: \u0026#34; + message); // 根据消息类型处理 if (message.startsWith(\u0026#34;HEARTBEAT\u0026#34;)) { System.out.println(\u0026#34;Heartbeat received from client: \u0026#34; + clientChannel.getRemoteAddress()); } else if (message.startsWith(\u0026#34;EVENT\u0026#34;)) { System.out.println(\u0026#34;Event received from client: \u0026#34; + clientChannel.getRemoteAddress()); } else { // 发送指令响应 String response = \u0026#34;ACK: \u0026#34; + message; ByteBuffer responseBuffer = ByteBuffer.wrap(response.getBytes()); clientChannel.write(responseBuffer); } } } } } } } 客户端代码示例 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SocketChannel; import java.util.Scanner; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class NIOClient { private static final String SERVER_IP = \u0026#34;localhost\u0026#34;; private static final int SERVER_PORT = 12345; private static final int BUFFER_SIZE = 1024; public static void main(String[] args) throws IOException { // 连接服务器 SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(SERVER_IP, SERVER_PORT)); socketChannel.configureBlocking(false); System.out.println(\u0026#34;Connected to server at \u0026#34; + SERVER_IP + \u0026#34;:\u0026#34; + SERVER_PORT); // 定时发送心跳 ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1); scheduler.scheduleAtFixedRate(() -\u0026gt; { try { String heartbeat = \u0026#34;HEARTBEAT\u0026#34;; ByteBuffer buffer = ByteBuffer.wrap(heartbeat.getBytes()); socketChannel.write(buffer); System.out.println(\u0026#34;Sent heartbeat to server\u0026#34;); } catch (IOException e) { e.printStackTrace(); } }, 0, 30, TimeUnit.SECONDS); // 监听服务器指令 new Thread(() -\u0026gt; { ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); while (true) { try { int bytesRead = socketChannel.read(buffer); if (bytesRead \u0026gt; 0) { buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from server: \u0026#34; + message); buffer.clear(); } } catch (IOException e) { e.printStackTrace(); break; } } }).start(); // 模拟事件上报 Scanner scanner = new Scanner(System.in); while (true) { System.out.println(\u0026#34;Enter an event to send (or \u0026#39;exit\u0026#39; to quit):\u0026#34;); String input = scanner.nextLine(); if (\u0026#34;exit\u0026#34;.equalsIgnoreCase(input)) { break; } String event = \u0026#34;EVENT: \u0026#34; + input; ByteBuffer buffer = ByteBuffer.wrap(event.getBytes()); socketChannel.write(buffer); System.out.println(\u0026#34;Sent event to server: \u0026#34; + event); } // 关闭连接 socketChannel.close(); scheduler.shutdown(); System.out.println(\u0026#34;Disconnected from server\u0026#34;); } } 代码说明 # 服务端：\n使用Selector监听多个客户端连接。 处理客户端连接、读取数据、发送响应。 根据接收到的消息类型（心跳、事件、指令）进行相应处理。 客户端：\n连接服务端并定时发送心跳报文。 监听服务端指令并打印响应。 支持用户输入模拟事件上报。 协议：\n使用简单的字符串协议，例如： 心跳报文：HEARTBEAT 事件报文：EVENT: \u0026lt;event_data\u0026gt; 指令响应：ACK: \u0026lt;message\u0026gt; 并发：\n使用ScheduledExecutorService定时发送心跳。 使用单独的线程监听服务端指令。 运行方式 # 启动服务端：java NIOServer 启动一个或多个客户端：java NIOClient 在客户端输入事件内容，观察服务端和客户端的日志输出。 扩展建议 # 协议优化：可以使用更复杂的协议（如JSON或自定义二进制协议）来封装数据。 异常处理：增加对网络异常、超时等的处理逻辑。 性能优化：根据实际需求调整缓冲区大小、线程池配置等。 我有一个服务端，需要连接多个服务端进行tcp连接，给我一个java的代码示例 # 以下是基于Java NIO的实现示例，展示了一个服务端如何连接多个服务端并进行TCP通信。该示例使用了Selector实现I/O多路复用，能够高效处理多个连接。\n代码示例 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; public class MultiServerConnector { private static final int BUFFER_SIZE = 1024; public static void main(String[] args) throws IOException { // 创建Selector Selector selector = Selector.open(); // 连接多个服务端 connectToServers(selector, new String[]{\u0026#34;127.0.0.1:8081\u0026#34;, \u0026#34;127.0.0.1:8082\u0026#34;}); System.out.println(\u0026#34;Connected to multiple servers.\u0026#34;); while (true) { // 阻塞等待就绪的Channel selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isConnectable()) { // 处理连接完成事件 SocketChannel clientChannel = (SocketChannel) key.channel(); if (clientChannel.isConnectionPending()) { clientChannel.finishConnect(); } clientChannel.configureBlocking(false); clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Connected to server: \u0026#34; + clientChannel.getRemoteAddress()); } else if (key.isReadable()) { // 处理读取事件 SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 服务端断开连接 System.out.println(\u0026#34;Server disconnected: \u0026#34; + clientChannel.getRemoteAddress()); clientChannel.close(); } else if (bytesRead \u0026gt; 0) { // 处理接收到的数据 buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from server: \u0026#34; + message); } } } } } // 连接多个服务端 private static void connectToServers(Selector selector, String[] serverAddresses) throws IOException { for (String address : serverAddresses) { String[] parts = address.split(\u0026#34;:\u0026#34;); String host = parts[0]; int port = Integer.parseInt(parts[1]); // 创建SocketChannel并连接服务端 SocketChannel clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false); clientChannel.connect(new InetSocketAddress(host, port)); clientChannel.register(selector, SelectionKey.OP_CONNECT); } } } 代码说明 # Selector：\n使用Selector监听多个服务端的连接和读取事件，实现I/O多路复用12。 连接多个服务端：\n在connectToServers方法中，遍历服务端地址列表，创建SocketChannel并连接服务端。 将SocketChannel注册到Selector，监听OP_CONNECT事件。 处理连接完成事件：\n当SocketChannel连接成功时，触发OP_CONNECT事件，调用finishConnect完成连接，并注册OP_READ事件以监听数据读取。 处理读取事件：\n当服务端发送数据时，触发OP_READ事件，读取数据并处理。 异常处理：\n如果服务端断开连接，关闭SocketChannel并清理资源。 运行方式 # 启动多个服务端，分别监听8081和8082端口。 运行MultiServerConnector，它将连接这些服务端并处理数据。 参考 # 使用Selector实现I/O多路复用12。 连接多个服务端的最佳实践3。 扩展建议 # 心跳机制：可以定时向服务端发送心跳报文，检测连接状态1。 协议设计：使用更复杂的协议（如JSON或自定义二进制协议）封装数据2。 异常重连：在连接断开时实现自动重连机制3。 我在tcp连接的过程中，可能会新增连接，修改连接信息（ip或端口号）或者删除连接，这个该怎么实现 # 为了支持在TCP连接过程中动态新增连接、修改连接信息（如IP或端口号）或删除连接，可以使用以下设计思路：\n设计思路 # 连接管理：\n使用一个Map来管理所有连接，键为连接的唯一标识（如ip:port），值为SocketChannel。 提供方法来新增、修改和删除连接。 动态更新连接：\n新增连接：创建新的SocketChannel并注册到Selector。 修改连接信息：先关闭旧的SocketChannel，然后使用新的IP和端口创建新的连接。 删除连接：关闭SocketChannel并从Map中移除。 线程安全：\n使用ConcurrentHashMap管理连接，确保多线程操作的安全性。 在修改连接信息时，使用同步机制（如synchronized）避免竞争条件。 事件处理：\n使用Selector监听所有连接的读写事件。 在事件循环中处理连接的新增、修改和删除操作。 代码实现 # 以下是完整的Java实现示例：\nimport java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Map; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; public class DynamicTCPConnector { private static final int BUFFER_SIZE = 1024; private final Selector selector; private final Map\u0026lt;String, SocketChannel\u0026gt; connections; public DynamicTCPConnector() throws IOException { this.selector = Selector.open(); this.connections = new ConcurrentHashMap\u0026lt;\u0026gt;(); } public void start() throws IOException { System.out.println(\u0026#34;Dynamic TCP Connector started.\u0026#34;); while (true) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isConnectable()) { // 处理连接完成事件 SocketChannel clientChannel = (SocketChannel) key.channel(); if (clientChannel.isConnectionPending()) { clientChannel.finishConnect(); } clientChannel.configureBlocking(false); clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Connected to server: \u0026#34; + clientChannel.getRemoteAddress()); } else if (key.isReadable()) { // 处理读取事件 SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 服务端断开连接 System.out.println(\u0026#34;Server disconnected: \u0026#34; + clientChannel.getRemoteAddress()); clientChannel.close(); removeConnection(clientChannel); } else if (bytesRead \u0026gt; 0) { // 处理接收到的数据 buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from server: \u0026#34; + message); } } } } } // 新增连接 public void addConnection(String ip, int port) throws IOException { String key = ip + \u0026#34;:\u0026#34; + port; if (connections.containsKey(key)) { System.out.println(\u0026#34;Connection already exists: \u0026#34; + key); return; } SocketChannel clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false); clientChannel.connect(new InetSocketAddress(ip, port)); clientChannel.register(selector, SelectionKey.OP_CONNECT); connections.put(key, clientChannel); System.out.println(\u0026#34;Added new connection: \u0026#34; + key); } // 修改连接信息 public void updateConnection(String oldIp, int oldPort, String newIp, int newPort) throws IOException { String oldKey = oldIp + \u0026#34;:\u0026#34; + oldPort; String newKey = newIp + \u0026#34;:\u0026#34; + newPort; if (!connections.containsKey(oldKey)) { System.out.println(\u0026#34;Connection not found: \u0026#34; + oldKey); return; } // 关闭旧连接 SocketChannel oldChannel = connections.get(oldKey); oldChannel.close(); connections.remove(oldKey); // 创建新连接 addConnection(newIp, newPort); System.out.println(\u0026#34;Updated connection from \u0026#34; + oldKey + \u0026#34; to \u0026#34; + newKey); } // 删除连接 public void removeConnection(SocketChannel channel) throws IOException { String key = null; for (Map.Entry\u0026lt;String, SocketChannel\u0026gt; entry : connections.entrySet()) { if (entry.getValue().equals(channel)) { key = entry.getKey(); break; } } if (key != null) { connections.remove(key); System.out.println(\u0026#34;Removed connection: \u0026#34; + key); } } public static void main(String[] args) throws IOException { DynamicTCPConnector connector = new DynamicTCPConnector(); // 启动事件循环 new Thread(() -\u0026gt; { try { connector.start(); } catch (IOException e) { e.printStackTrace(); } }).start(); // 示例：动态管理连接 try { // 新增连接 connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8081); connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8082); // 修改连接 Thread.sleep(5000); connector.updateConnection(\u0026#34;127.0.0.1\u0026#34;, 8081, \u0026#34;127.0.0.1\u0026#34;, 8083); // 删除连接 Thread.sleep(5000); for (SocketChannel channel : connector.connections.values()) { connector.removeConnection(channel); } } catch (InterruptedException e) { e.printStackTrace(); } } } 代码说明 # DynamicTCPConnector类：\n使用Selector监听所有连接的读写事件。 使用ConcurrentHashMap管理所有连接。 动态管理连接：\naddConnection：新增连接。 updateConnection：修改连接信息（先关闭旧连接，再创建新连接）。 removeConnection：删除连接。 事件处理：\n处理连接完成事件（OP_CONNECT）。 处理读取事件（OP_READ）。 线程安全：\n使用ConcurrentHashMap确保多线程操作的安全性。 运行方式 # 启动多个服务端，分别监听8081、8082和8083端口。 运行DynamicTCPConnector，它将动态管理连接并与服务端通信。 扩展建议 # 心跳机制：可以定时向服务端发送心跳报文，检测连接状态。 异常重连：在连接断开时实现自动重连机制。 日志记录：记录连接的新增、修改和删除操作，便于排查问题。 使用 socketChannel 的 close 方法，是否会导致tcp连接还在传输数据的时候意外断开的情况 # 使用 SocketChannel 的 close 方法时，不会导致 TCP 连接在传输数据时意外断开。close 方法会按照 TCP 协议的正常流程关闭连接，确保数据传输的完整性。以下是详细说明：\n1. SocketChannel.close 的行为 # 当调用 SocketChannel.close 方法时，底层 TCP 协议会执行以下操作：\n如果连接处于数据传输状态，close 会触发 TCP 的四次挥手过程，确保双方都能正常关闭连接。 close 方法会发送 FIN 报文给对方，表示本方不再发送数据，但仍可以接收对方的数据，直到对方也发送 FIN 报文15。 2. 数据传输中的关闭 # 如果在数据传输过程中调用 close 方法，TCP 协议会确保以下行为：\n已经发送的数据会继续传输，直到对方确认接收。 对方可以继续发送数据，直到本方也发送 FIN 报文。 只有在双方都完成数据传输并确认后，连接才会完全关闭25。 因此，close 方法不会导致数据意外丢失或连接意外断开。\n3. 异常情况 # 在以下异常情况下，close 方法可能会导致连接异常断开：\n网络故障：如果网络在关闭过程中发生故障，可能导致 FIN 报文无法送达对方，从而触发超时重传机制2。 进程崩溃：如果调用 close 的进程突然崩溃，操作系统会强制关闭连接，可能导致数据未完全传输2。 4. 最佳实践 # 为了避免意外情况，建议在调用 close 方法前：\n确保所有数据都已发送并确认（例如，调用 SocketChannel.finishConnect 或检查 SocketChannel.write 的返回值）14。 使用 SocketChannel.shutdownOutput 先关闭输出流，确保对方知道本方不再发送数据，然后再调用 close5。 总结 # SocketChannel.close 方法会按照 TCP 协议的正常流程关闭连接，不会导致数据传输时意外断开。但在网络故障或进程崩溃等异常情况下，可能会导致连接异常关闭。因此，建议在关闭连接前确保数据传输完成，并遵循 TCP 关闭的最佳实践125。\n我还需要实现对特定连接发送命令报文 # 为了实现向特定连接发送命令报文，可以在现有的 DynamicTCPConnector 基础上增加以下功能：\n查找特定连接：根据连接的标识（如 ip:port）查找对应的 SocketChannel。 发送命令报文：通过 SocketChannel.write 方法向特定连接发送数据。 线程安全：确保在发送数据时，连接不会被意外关闭或修改。 以下是完整的实现示例：\n代码实现 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Map; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; public class DynamicTCPConnector { private static final int BUFFER_SIZE = 1024; private final Selector selector; private final Map\u0026lt;String, SocketChannel\u0026gt; connections; public DynamicTCPConnector() throws IOException { this.selector = Selector.open(); this.connections = new ConcurrentHashMap\u0026lt;\u0026gt;(); } public void start() throws IOException { System.out.println(\u0026#34;Dynamic TCP Connector started.\u0026#34;); while (true) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isConnectable()) { // 处理连接完成事件 SocketChannel clientChannel = (SocketChannel) key.channel(); if (clientChannel.isConnectionPending()) { clientChannel.finishConnect(); } clientChannel.configureBlocking(false); clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Connected to server: \u0026#34; + clientChannel.getRemoteAddress()); } else if (key.isReadable()) { // 处理读取事件 SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 服务端断开连接 System.out.println(\u0026#34;Server disconnected: \u0026#34; + clientChannel.getRemoteAddress()); clientChannel.close(); removeConnection(clientChannel); } else if (bytesRead \u0026gt; 0) { // 处理接收到的数据 buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from server: \u0026#34; + message); } } } } } // 新增连接 public void addConnection(String ip, int port) throws IOException { String key = ip + \u0026#34;:\u0026#34; + port; if (connections.containsKey(key)) { System.out.println(\u0026#34;Connection already exists: \u0026#34; + key); return; } SocketChannel clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false); clientChannel.connect(new InetSocketAddress(ip, port)); clientChannel.register(selector, SelectionKey.OP_CONNECT); connections.put(key, clientChannel); System.out.println(\u0026#34;Added new connection: \u0026#34; + key); } // 修改连接信息 public void updateConnection(String oldIp, int oldPort, String newIp, int newPort) throws IOException { String oldKey = oldIp + \u0026#34;:\u0026#34; + oldPort; String newKey = newIp + \u0026#34;:\u0026#34; + newPort; if (!connections.containsKey(oldKey)) { System.out.println(\u0026#34;Connection not found: \u0026#34; + oldKey); return; } // 关闭旧连接 SocketChannel oldChannel = connections.get(oldKey); oldChannel.close(); connections.remove(oldKey); // 创建新连接 addConnection(newIp, newPort); System.out.println(\u0026#34;Updated connection from \u0026#34; + oldKey + \u0026#34; to \u0026#34; + newKey); } // 删除连接 public void removeConnection(SocketChannel channel) throws IOException { String key = null; for (Map.Entry\u0026lt;String, SocketChannel\u0026gt; entry : connections.entrySet()) { if (entry.getValue().equals(channel)) { key = entry.getKey(); break; } } if (key != null) { connections.remove(key); System.out.println(\u0026#34;Removed connection: \u0026#34; + key); } } // 向特定连接发送命令报文 public void sendCommand(String ip, int port, String command) throws IOException { String key = ip + \u0026#34;:\u0026#34; + port; SocketChannel clientChannel = connections.get(key); if (clientChannel == null) { System.out.println(\u0026#34;Connection not found: \u0026#34; + key); return; } if (!clientChannel.isConnected()) { System.out.println(\u0026#34;Connection is not active: \u0026#34; + key); return; } // 发送命令报文 ByteBuffer buffer = ByteBuffer.wrap(command.getBytes()); clientChannel.write(buffer); System.out.println(\u0026#34;Sent command to \u0026#34; + key + \u0026#34;: \u0026#34; + command); } public static void main(String[] args) throws IOException { DynamicTCPConnector connector = new DynamicTCPConnector(); // 启动事件循环 new Thread(() -\u0026gt; { try { connector.start(); } catch (IOException e) { e.printStackTrace(); } }).start(); // 示例：动态管理连接 try { // 新增连接 connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8081); connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8082); // 向特定连接发送命令 Thread.sleep(2000); connector.sendCommand(\u0026#34;127.0.0.1\u0026#34;, 8081, \u0026#34;COMMAND: START\u0026#34;); connector.sendCommand(\u0026#34;127.0.0.1\u0026#34;, 8082, \u0026#34;COMMAND: STOP\u0026#34;); // 修改连接 Thread.sleep(5000); connector.updateConnection(\u0026#34;127.0.0.1\u0026#34;, 8081, \u0026#34;127.0.0.1\u0026#34;, 8083); // 删除连接 Thread.sleep(5000); for (SocketChannel channel : connector.connections.values()) { connector.removeConnection(channel); } } catch (InterruptedException e) { e.printStackTrace(); } } } 代码说明 # sendCommand 方法：\n根据 ip 和 port 查找对应的 SocketChannel。 检查连接是否处于活动状态。 使用 SocketChannel.write 发送命令报文。 线程安全：\n使用 ConcurrentHashMap 管理连接，确保多线程操作的安全性。 在发送数据时，连接不会被意外关闭或修改。 动态管理连接：\n支持新增、修改和删除连接。 使用 Selector 监听所有连接的读写事件。 运行方式 # 启动多个服务端，分别监听 8081、8082 和 8083 端口。 运行 DynamicTCPConnector，它将动态管理连接并向特定连接发送命令报文。 扩展建议 # 超时重试：在发送命令时，如果连接不可用，可以加入重试机制。 日志记录：记录命令发送的结果，便于排查问题。 协议设计：使用更复杂的协议（如 JSON 或自定义二进制协议）封装命令报文。 发送完命令之后我需要等待收到一个回复的报文，命令执行才算完成 # 为了在发送命令后等待接收回复报文，可以扩展 sendCommand 方法，使其支持同步等待回复。以下是实现思路和代码示例：\n设计思路 # 发送命令：\n向特定连接发送命令报文。 使用 SocketChannel.write 发送数据。 等待回复：\n在发送命令后，阻塞等待接收回复报文。 使用 Selector 监听 OP_READ 事件，等待对方发送数据。 超时机制：\n如果在一定时间内未收到回复，抛出超时异常。 线程安全：\n确保在等待回复时，连接不会被意外关闭或修改。 代码实现 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Map; import java.util.Set; import java.util.concurrent.ConcurrentHashMap; public class DynamicTCPConnector { private static final int BUFFER_SIZE = 1024; private static final long REPLY_TIMEOUT = 5000; // 等待回复的超时时间（毫秒） private final Selector selector; private final Map\u0026lt;String, SocketChannel\u0026gt; connections; public DynamicTCPConnector() throws IOException { this.selector = Selector.open(); this.connections = new ConcurrentHashMap\u0026lt;\u0026gt;(); } public void start() throws IOException { System.out.println(\u0026#34;Dynamic TCP Connector started.\u0026#34;); while (true) { selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isConnectable()) { // 处理连接完成事件 SocketChannel clientChannel = (SocketChannel) key.channel(); if (clientChannel.isConnectionPending()) { clientChannel.finishConnect(); } clientChannel.configureBlocking(false); clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Connected to server: \u0026#34; + clientChannel.getRemoteAddress()); } else if (key.isReadable()) { // 处理读取事件 SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_SIZE); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 服务端断开连接 System.out.println(\u0026#34;Server disconnected: \u0026#34; + clientChannel.getRemoteAddress()); clientChannel.close(); removeConnection(clientChannel); } else if (bytesRead \u0026gt; 0) { // 处理接收到的数据 buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); String message = new String(data); System.out.println(\u0026#34;Received from server: \u0026#34; + message); // 唤醒等待回复的线程 synchronized (clientChannel) { clientChannel.notifyAll(); } } } } } } // 新增连接 public void addConnection(String ip, int port) throws IOException { String key = ip + \u0026#34;:\u0026#34; + port; if (connections.containsKey(key)) { System.out.println(\u0026#34;Connection already exists: \u0026#34; + key); return; } SocketChannel clientChannel = SocketChannel.open(); clientChannel.configureBlocking(false); clientChannel.connect(new InetSocketAddress(ip, port)); clientChannel.register(selector, SelectionKey.OP_CONNECT); connections.put(key, clientChannel); System.out.println(\u0026#34;Added new connection: \u0026#34; + key); } // 修改连接信息 public void updateConnection(String oldIp, int oldPort, String newIp, int newPort) throws IOException { String oldKey = oldIp + \u0026#34;:\u0026#34; + oldPort; String newKey = newIp + \u0026#34;:\u0026#34; + newPort; if (!connections.containsKey(oldKey)) { System.out.println(\u0026#34;Connection not found: \u0026#34; + oldKey); return; } // 关闭旧连接 SocketChannel oldChannel = connections.get(oldKey); oldChannel.close(); connections.remove(oldKey); // 创建新连接 addConnection(newIp, newPort); System.out.println(\u0026#34;Updated connection from \u0026#34; + oldKey + \u0026#34; to \u0026#34; + newKey); } // 删除连接 public void removeConnection(SocketChannel channel) throws IOException { String key = null; for (Map.Entry\u0026lt;String, SocketChannel\u0026gt; entry : connections.entrySet()) { if (entry.getValue().equals(channel)) { key = entry.getKey(); break; } } if (key != null) { connections.remove(key); System.out.println(\u0026#34;Removed connection: \u0026#34; + key); } } // 向特定连接发送命令报文并等待回复 public String sendCommand(String ip, int port, String command) throws IOException, InterruptedException { String key = ip + \u0026#34;:\u0026#34; + port; SocketChannel clientChannel = connections.get(key); if (clientChannel == null) { throw new IOException(\u0026#34;Connection not found: \u0026#34; + key); } if (!clientChannel.isConnected()) { throw new IOException(\u0026#34;Connection is not active: \u0026#34; + key); } // 发送命令报文 ByteBuffer buffer = ByteBuffer.wrap(command.getBytes()); clientChannel.write(buffer); System.out.println(\u0026#34;Sent command to \u0026#34; + key + \u0026#34;: \u0026#34; + command); // 等待回复 synchronized (clientChannel) { clientChannel.wait(REPLY_TIMEOUT); } // 读取回复 buffer.clear(); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { throw new IOException(\u0026#34;Connection closed by server: \u0026#34; + key); } else if (bytesRead \u0026gt; 0) { buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); return new String(data); } else { throw new IOException(\u0026#34;No reply received from server: \u0026#34; + key); } } public static void main(String[] args) throws IOException { DynamicTCPConnector connector = new DynamicTCPConnector(); // 启动事件循环 new Thread(() -\u0026gt; { try { connector.start(); } catch (IOException e) { e.printStackTrace(); } }).start(); // 示例：动态管理连接 try { // 新增连接 connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8081); connector.addConnection(\u0026#34;127.0.0.1\u0026#34;, 8082); // 向特定连接发送命令并等待回复 String reply = connector.sendCommand(\u0026#34;127.0.0.1\u0026#34;, 8081, \u0026#34;COMMAND: START\u0026#34;); System.out.println(\u0026#34;Received reply: \u0026#34; + reply); // 修改连接 Thread.sleep(5000); connector.updateConnection(\u0026#34;127.0.0.1\u0026#34;, 8081, \u0026#34;127.0.0.1\u0026#34;, 8083); // 删除连接 Thread.sleep(5000); for (SocketChannel channel : connector.connections.values()) { connector.removeConnection(channel); } } catch (InterruptedException e) { e.printStackTrace(); } } } 代码说明 # sendCommand 方法：\n发送命令报文后，使用 wait 方法阻塞等待回复。 在收到回复后，使用 notifyAll 唤醒等待的线程。 如果超时未收到回复，抛出异常。 线程安全：\n使用 synchronized 确保在等待回复时，连接不会被意外关闭或修改。 超时机制：\n如果超过 REPLY_TIMEOUT 时间未收到回复，抛出超时异常。 运行方式 # 启动多个服务端，分别监听 8081、8082 和 8083 端口。 运行 DynamicTCPConnector，它将动态管理连接、发送命令并等待回复。 扩展建议 # 更复杂的协议：可以使用 JSON 或自定义二进制协议封装命令和回复。 重试机制：在超时或连接失败时，加入重试逻辑。 日志记录：记录命令发送和回复的详细信息，便于排查问题。 如果连接的tcp数量很多，使用一个selector接收有点慢，该怎么优化 # 当使用一个 Selector 处理大量 TCP 连接时，可能会遇到性能瓶颈。以下是优化建议和具体实现思路：\n1. 优化思路 # 1.1 使用多个 Selector # 将连接分散到多个 Selector 中，每个 Selector 负责处理一部分连接。 可以通过线程池管理多个 Selector，每个线程运行一个 Selector 的事件循环3。 1.2 分离连接处理和数据处理 # 使用一个 Selector 专门处理新连接（ACCEPT 事件），另一个或多个 Selector 处理已连接通道的读写事件（READ 和 WRITE 事件）。 这种方式可以避免单个 Selector 处理过多事件导致的性能下降3。 1.3 调整缓冲区大小 # 根据网络带宽和时延调整 TCP 缓冲区大小（tcp_wmem 和 tcp_rmem），确保缓冲区大小与带宽时延积（BDP）匹配，以充分利用网络性能1。 1.4 使用非阻塞 I/O # 确保所有 Channel 都设置为非阻塞模式（configureBlocking(false)），避免阻塞操作影响 Selector 的效率3。 1.5 减少事件处理的耗时 # 避免在事件处理逻辑中执行耗时操作（如数据库查询、复杂计算等），可以将这些操作委托给线程池处理。 2. 实现示例 # 以下是一个使用多个 Selector 优化大量 TCP 连接的示例：\nimport java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class MultiSelectorServer { private static final int PORT = 8080; private static final int SELECTOR_THREADS = 4; // 使用 4 个 Selector private static final ExecutorService selectorPool = Executors.newFixedThreadPool(SELECTOR_THREADS); public static void main(String[] args) throws IOException { // 创建主 Selector，专门处理 ACCEPT 事件 Selector acceptSelector = Selector.open(); ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); serverChannel.bind(new InetSocketAddress(PORT)); serverChannel.register(acceptSelector, SelectionKey.OP_ACCEPT); // 启动多个 Selector 线程处理读写事件 for (int i = 0; i \u0026lt; SELECTOR_THREADS; i++) { selectorPool.submit(new EventLoop()); } // 主线程运行 ACCEPT 事件循环 while (true) { acceptSelector.select(); Set\u0026lt;SelectionKey\u0026gt; keys = acceptSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = keys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { // 接受新连接并分配给一个 EventLoop ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel clientChannel = server.accept(); clientChannel.configureBlocking(false); // 将新连接分配给一个 EventLoop EventLoop.assignChannel(clientChannel); } } } } // EventLoop 类，处理读写事件 private static class EventLoop implements Runnable { private final Selector selector; public EventLoop() throws IOException { this.selector = Selector.open(); } public static void assignChannel(SocketChannel channel) throws IOException { // 将新连接注册到某个 EventLoop 的 Selector EventLoop eventLoop = (EventLoop) selectorPool.submit(new EventLoop()).get(); channel.register(eventLoop.selector, SelectionKey.OP_READ); } @Override public void run() { while (true) { try { selector.select(); Set\u0026lt;SelectionKey\u0026gt; keys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = keys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isReadable()) { // 处理读事件 SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); int bytesRead = channel.read(buffer); if (bytesRead == -1) { channel.close(); } else if (bytesRead \u0026gt; 0) { buffer.flip(); byte[] data = new byte[buffer.remaining()]; buffer.get(data); System.out.println(\u0026#34;Received: \u0026#34; + new String(data)); } } } } catch (IOException e) { e.printStackTrace(); } } } } } 3. 优化建议 # 动态调整 Selector 数量：\n根据连接的负载情况动态调整 Selector 的数量，避免资源浪费3。 使用更高效的 I/O 模型：\n如果 Selector 仍然无法满足性能需求，可以考虑使用更高效的 I/O 模型，如 Linux 的 epoll 或 Windows 的 IOCP。 监控和调优：\n使用工具（如 netstat、ss）监控连接状态，调整系统参数（如 tcp_max_syn_backlog、somaxconn）以优化 TCP 连接处理能力1。 4. 参考外部资料 # 1：优化 TCP 缓冲区大小和滑动窗口。 3：使用多个 Selector 和线程池处理大量连接。 通过以上优化措施，可以有效提升 Selector 处理大量 TCP 连接的性能。\n如果我需要维护100个tcp连接，使用一个selector够吗 # 维护100个TCP连接时，使用单个Selector是可行的，但可能会遇到性能瓶颈，尤其是在连接数量进一步增加或网络负载较高的情况下。以下是详细分析和优化建议：\n1. 单个 Selector 的局限性 # 事件处理延迟：单个Selector需要轮询所有注册的Channel，随着连接数量增加，事件处理的延迟可能会增加。 单线程瓶颈：如果所有连接的事件处理都由一个线程完成，CPU 和 I/O 资源可能无法充分利用，尤其是在多核系统上。 扩展性差：当连接数量进一步增加（如1000个以上），单个Selector的性能可能无法满足需求。 2. 优化方案 # 2.1 使用多个 Selector # 将连接分散到多个Selector中，每个Selector负责处理一部分连接。可以通过线程池管理多个Selector，每个线程运行一个Selector的事件循环。 示例： Selector[] selectors = new Selector[4]; // 使用 4 个 Selector for (int i = 0; i \u0026lt; selectors.length; i++) { selectors[i] = Selector.open(); } 将连接均匀分配到不同的Selector中，例如通过哈希算法将连接分配到特定的Selector。 2.2 分离连接处理和数据处理 # 使用一个Selector专门处理新连接（ACCEPT事件），另一个或多个Selector处理已连接通道的读写事件（READ和WRITE事件）。 示例： Selector acceptSelector = Selector.open(); ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); serverChannel.bind(new InetSocketAddress(PORT)); serverChannel.register(acceptSelector, SelectionKey.OP_ACCEPT); 2.3 调整缓冲区大小 # 根据网络带宽和时延调整 TCP 缓冲区大小（tcp_wmem 和 tcp_rmem），确保缓冲区大小与带宽时延积（BDP）匹配，以充分利用网络性能。 2.4 使用非阻塞 I/O # 确保所有Channel都设置为非阻塞模式（configureBlocking(false)），避免阻塞操作影响Selector的效率。 2.5 减少事件处理的耗时 # 避免在事件处理逻辑中执行耗时操作（如数据库查询、复杂计算等），可以将这些操作委托给线程池处理。 3. 参考外部资料 # 单个 Selector 的性能瓶颈：单个Selector在处理大量连接时，可能会因为轮询和单线程限制导致性能下降2。 使用多个 Selector 的优化：通过将连接分散到多个Selector中，可以充分利用多核 CPU 和 I/O 资源3。 分离连接处理和数据处理：将新连接和已连接通道的事件处理分离，可以提高系统的扩展性和性能4。 4. 示例代码 # 以下是使用多个Selector的示例代码：\nimport java.nio.channels.*; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class MultiSelectorServer { private static final int PORT = 8080; private static final int SELECTOR_THREADS = 4; // 使用 4 个 Selector private static final ExecutorService selectorPool = Executors.newFixedThreadPool(SELECTOR_THREADS); public static void main(String[] args) throws IOException { // 创建主 Selector，专门处理 ACCEPT 事件 Selector acceptSelector = Selector.open(); ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); serverChannel.bind(new InetSocketAddress(PORT)); serverChannel.register(acceptSelector, SelectionKey.OP_ACCEPT); // 启动多个 Selector 线程处理读写事件 for (int i = 0; i \u0026lt; SELECTOR_THREADS; i++) { selectorPool.submit(new EventLoop()); } // 主线程运行 ACCEPT 事件循环 while (true) { acceptSelector.select(); Set\u0026lt;SelectionKey\u0026gt; keys = acceptSelector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = keys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { // 接受新连接并分配给一个 EventLoop ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel clientChannel = server.accept(); clientChannel.configureBlocking(false); // 将新连接分配给一个 EventLoop EventLoop.assignChannel(clientChannel); } } } } } 5. 总结 # 对于维护100个TCP连接，单个Selector可以满足需求，但在高负载或连接数量进一步增加时，建议使用多个Selector、分离连接处理和数据处理等优化措施，以提高系统性能和扩展性。\n在java中，一个tcp连接使用一个socket，连接多个tcp，这样占用很多内存吗 # 在Java中，每个TCP连接确实会使用一个Socket，而每个Socket都会占用一定的内存。具体的内存消耗取决于多个因素，包括操作系统内核的实现、缓冲区的大小以及其他相关的数据结构。\n根据搜索结果，每个TCP连接（即一个Socket）在内核中会涉及多个数据结构，例如 struct tcp_sock、struct file、struct dentry 等。这些结构的内存占用总和大约在3KB左右。此外，如果使用了 epoll 等事件处理机制，每个连接还会额外占用一些内存（例如 epitem 对象，大小为128字节）3。\n对于接收和发送缓冲区，如果没有数据传输，它们不会占用内存。只有当有数据在缓冲区中等待处理时，才会占用内存。默认情况下，接收和发送缓冲区的最小大小各为4KB，因此每个连接在数据传输时可能会额外占用8KB的内存3。\n总的来说，一个TCP连接在不传输数据时，占用的内存大约为3KB左右；在传输数据时，可能会增加到10KB以上。因此，连接多个TCP连接确实会占用较多的内存，尤其是在高并发的情况下。例如，10万个TCP连接在不传输数据时，大约会占用300MB的内存；在传输数据时，可能会占用超过1GB的内存3 。\n如果需要支持大量并发连接，可以通过调整内核参数（如 tcp_rmem、tcp_wmem 和 tcp_mem）来优化内存使用3 。此外，在Java中，可以通过优化代码和合理设置缓冲区大小来减少内存占用1。\n综上所述，连接多个TCP连接确实会占用较多内存，特别是在高并发场景下。通过优化系统和代码，可以有效地管理和减少内存消耗。\n在java中创建线程的内存开销 # 在Java中，创建线程确实会带来一定的内存开销。以下是关于Java线程内存开销的详细说明：\n1. 线程栈的内存开销 # Java线程的线程栈区别于堆，它不受Java程序直接控制，而是由操作系统管理。默认情况下，每个线程的线程栈大小为1MB。这意味着如果创建了1024个线程，仅线程栈就会占用1GB的内存。这种内存消耗在高并发场景下可能会迅速耗尽系统资源，导致程序崩溃14 。\n然而，实际内存占用可能比默认值低，因为操作系统会以延迟分配的方式分配内存页面（例如在第一次使用时分配），因此每个线程栈实际占用的内存可能在80KB到200KB之间2。\n2. 其他内存开销 # 除了线程栈，线程的创建和运行还会带来其他内存开销，包括：\n线程控制块（TCB）：操作系统为每个线程维护的数据结构，用于管理线程的状态和上下文。 本地内存：JVM本身也会为线程分配一些本地内存，用于管理线程的元数据和资源2。 3. 线程创建和销毁的开销 # 频繁创建和销毁线程会带来额外的性能开销，包括：\n系统调用：创建线程需要操作系统介入，分配资源和初始化数据结构。 上下文切换：线程切换时，CPU缓存会被清空，内存页面可能需要换入换出，这些操作都会影响性能16。 4. 线程池的优化 # 为了减少线程创建和销毁的开销，Java中通常使用线程池（如ThreadPoolExecutor）来管理线程。线程池通过复用线程资源，显著降低了内存和性能开销。线程池的主要优点包括：\n资源复用：线程池中的线程可以重复使用，避免了频繁创建和销毁线程的开销。 内存控制：线程池可以限制最大线程数，防止内存被过多占用13。 5. 如何减少线程内存开销 # 调整线程栈大小：通过JVM参数-Xss可以设置线程栈的大小，例如-Xss256k将线程栈大小设置为256KB。 使用线程池：通过线程池管理线程，避免频繁创建和销毁线程。 优化任务设计：将任务拆分为更小的可并行单元，充分利用线程池的并发能力23。 总结 # 在Java中，每个线程默认会占用1MB的线程栈内存（实际可能为80KB到200KB），加上其他内存开销，创建大量线程可能会导致内存耗尽。通过使用线程池和优化线程栈大小，可以有效减少内存开销，提升系统性能123 。\njava中的selector使用的是select还是epoll # 在Java中，Selector的实现依赖于底层操作系统的支持，具体使用的是select还是epoll取决于操作系统和JDK的实现。\n在Linux系统中，Java NIO的Selector通常使用的是epoll模型。这是因为epoll在处理大量连接时性能优于select，尤其是在高并发场景下。epoll 基于事件驱动，能够高效地管理大量文件描述符，而不会像select那样随着文件描述符数量的增加而性能下降156。\n具体来说，Java的Selector是通过SelectorProvider来创建的。在Linux系统中，SelectorProvider会返回一个EPollSelectorProvider，这意味着Selector 的底层实现是基于epoll的。而在Windows系统中，Selector的实现则是基于select的，因为Windows不支持epoll6。\n总结：\nLinux系统：Java的Selector使用的是epoll模型，性能更优156。 Windows系统：Java的Selector使用的是select模型6。 因此，Java中的Selector具体使用select还是epoll取决于操作系统和JDK的实现。\nselector # java selector 的原理 # Java 中的 Selector 是 Java NIO（非阻塞 I/O）的核心组件之一，用于实现 I/O 多路复用。它的主要作用是通过单个线程管理多个 Channel，监控这些 Channel 上的 I/O 事件（如读、写、连接等），从而提高系统的并发性能。以下是 Selector 的工作原理和关键点：\n1. Selector 的核心功能 # Selector 允许单个线程同时监控多个 Channel 的 I/O 事件。通过注册 Channel 到 Selector 并指定感兴趣的事件（如 OP_READ、OP_WRITE、OP_ACCEPT 等），程序可以在事件就绪时进行处理，而不需要为每个 Channel 创建单独的线程1。\n2. Selector 的工作流程 # 创建 Selector\n通过 Selector.open() 方法创建一个 Selector 实例。底层会根据操作系统的不同选择适当的实现（如 Linux 使用 epoll，Windows 使用 select ）26。\n注册 Channel\n将 Channel 注册到 Selector，并指定感兴趣的事件。例如：\nchannel.configureBlocking(false); // 必须设置为非阻塞模式 SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 注册后会返回一个 SelectionKey，用于跟踪 Channel 和事件的状态1。\n事件监听\n调用 Selector.select() 方法，该方法会阻塞，直到至少有一个 Channel 的事件就绪。返回后，可以通过 selectedKeys() 获取就绪的 SelectionKey 集合12。\n事件处理\n遍历 selectedKeys()，根据事件类型（如 OP_READ、OP_WRITE）进行相应的 I/O 操作。处理完成后，需要手动移除 SelectionKey，否则下次 select() 会重复处理1。\n关闭资源\n当 Selector 或 Channel 不再使用时，需要调用 close() 方法释放资源1。\n3. Selector 的底层实现 # Linux 系统：Selector 的底层通常使用 epoll 实现。epoll 基于事件驱动，通过红黑树管理文件描述符，并通过就绪队列高效地返回就绪事件36。\n红黑树：存储所有被监控的文件描述符（fd）。 就绪队列：存放已就绪的事件。 性能优势：epoll 避免了 select 和 poll 的线性扫描问题，时间复杂度为 O(1)，适合高并发场景3。 Windows 系统：Selector 的底层使用 select 实现，性能相对较低6。\n4. Selector 的优点 # 单线程管理多 Channel：减少了线程切换的开销，适合处理大量低流量的连接14。 高效的事件通知：通过事件驱动机制，避免轮询带来的性能损耗3。 资源占用少：相比于为每个 Channel 创建线程，Selector 的资源消耗更小4。 5. Selector 的注意事项 # 非阻塞模式：注册到 Selector 的 Channel 必须设置为非阻塞模式1。 事件处理：处理完事件后，需要手动移除 SelectionKey，否则会导致重复处理1。 线程安全：Selector 本身是线程安全的，但 selectedKeys() 返回的集合不是，多线程访问时需要同步1。 6. 与 select/poll/epoll 的关系 # select：线性扫描所有文件描述符，性能较差，适合低并发场景6。 poll：与 select 类似，但没有文件描述符数量限制6。 epoll：基于事件驱动，性能最优，适合高并发场景，是 Linux 下 Selector 的默认实现36。 7. 示例代码 # Selector selector=Selector.open(); ServerSocketChannel serverChannel=ServerSocketChannel.open(); serverChannel. bind(new InetSocketAddress(8080)); serverChannel. configureBlocking(false); serverChannel. register(selector,SelectionKey.OP_ACCEPT); while(true){ selector. select(); Set\u0026lt;SelectionKey\u0026gt;selectedKeys=selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt;iter=selectedKeys.iterator(); while(iter. hasNext()){ SelectionKey key=iter.next(); if(key. isAcceptable()){ // 处理连接事件 }else if(key. isReadable()){ // 处理读事件 } iter. remove(); } } 通过上述机制，Selector 能够高效地管理多个 Channel，提升 I/O 操作的性能，特别适合高并发的网络应用136。\nselector中事件是由谁产生的？ # 在 Java 的 Selector 机制中，事件是由 注册到 Selector 的 Channel 产生的。具体来说，当 Channel 上发生了与注册事件相关的 I/O 操作时，Selector 会检测到这些事件并将其标记为就绪状态。以下是详细说明：\n1. 事件的产生 # Channel 是事件的来源\n每个 Channel（如 SocketChannel、ServerSocketChannel）都可以注册到 Selector，并指定感兴趣的事件类型（如 OP_READ、OP_WRITE、OP_ACCEPT 、OP_CONNECT）。当 Channel 上发生了这些事件时，Selector 会将其标记为就绪状态。 事件类型 OP_ACCEPT：由 ServerSocketChannel 产生，表示有新的客户端连接请求。 OP_CONNECT：由 SocketChannel 产生，表示客户端已成功连接到服务器。 OP_READ：由 SocketChannel 产生，表示通道中有数据可读。 OP_WRITE：由 SocketChannel 产生，表示通道已准备好写入数据。 2. 事件的检测 # Selector 负责检测事件\nSelector 通过调用 select() 方法，检测所有注册的 Channel 是否有就绪的事件。如果有，select() 会返回就绪事件的数量，并将这些事件存储在 selectedKeys() 集合中。 事件的处理\n程序通过遍历 selectedKeys() 集合，获取每个 SelectionKey（包含了事件和对应的 Channel），并根据事件类型进行相应的处理。 3. 事件的触发机制 # 底层操作系统通知\nSelector 的底层实现依赖于操作系统的 I/O 多路复用机制（如 Linux 的 epoll 或 Windows 的 select）。当 Channel 上的 I/O 操作就绪时，操作系统会通知 Selector，Selector 再将事件传递给应用程序。 非阻塞模式\n注册到 Selector 的 Channel 必须设置为非阻塞模式，否则无法正常工作。非阻塞模式确保了 Channel 在 I/O 操作未就绪时不会阻塞，而是由 Selector 统一管理。 4. 示例 # 以下代码展示了 Selector 如何检测和处理事件：\nSelector selector=Selector.open(); ServerSocketChannel serverChannel=ServerSocketChannel.open(); serverChannel. bind(new InetSocketAddress(8080)); serverChannel. configureBlocking(false); serverChannel. register(selector,SelectionKey.OP_ACCEPT); while(true){ selector. select(); // 检测事件 Set\u0026lt;SelectionKey\u0026gt;selectedKeys=selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt;iter=selectedKeys.iterator(); while(iter. hasNext()){ SelectionKey key=iter.next(); if(key. isAcceptable()){ // 处理连接事件 }else if(key. isReadable()){ // 处理读事件 } iter. remove(); // 移除已处理的事件 } } 总结 # Selector 中的事件是由 注册到 Selector 的 Channel 产生的，Selector 负责检测这些事件并将其传递给应用程序进行处理。底层操作系统的 I/O 多路复用机制（如 epoll 或 select）是事件通知的关键14。\njava的selector的使用过程中概念总结一下 # 在 Java NIO 中，Selector 是一个关键组件，用于实现非阻塞 I/O 操作，允许单个线程管理多个 Channel，从而提高并发性能。以下是 Selector 的核心概念和使用方法的总结：\n1. Selector 的作用 # 多路复用：Selector 可以监控多个 Channel 的 I/O 事件（如读、写、连接、接受等），并通过单个线程处理这些事件，减少线程数量，降低系统资源消耗。 非阻塞模式：Selector 只能与非阻塞的 Channel 一起使用，避免线程阻塞，提高效率13。 2. 核心概念 # Channel：表示一个 I/O 操作的通道，如 SocketChannel（用于客户端）和 ServerSocketChannel（用于服务器端）。必须设置为非阻塞模式才能与 Selector 一起使用13。 SelectionKey：当 Channel 注册到 Selector 时，会返回一个 SelectionKey，它包含了以下信息： Interest Set：表示 Channel 感兴趣的事件（如 OP_READ、OP_WRITE 等）。 Ready Set：表示 Channel 已就绪的事件。 Channel 和 Selector：与 SelectionKey 关联的 Channel 和 Selector。 附加对象：可以通过 attach() 方法将任意对象附加到 SelectionKey，用于存储与 Channel 相关的额外信息134。 3. Selector 的使用步骤 # 创建 Selector\n通过 Selector.open() 方法创建一个 Selector 实例13：\nSelector selector = Selector.open(); 注册 Channel\n将 Channel 注册到 Selector，并指定感兴趣的事件：\nchannel.configureBlocking(false); // 必须设置为非阻塞模式 SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 支持的事件类型包括：\nOP_ACCEPT：接受连接（仅用于 ServerSocketChannel）。 OP_CONNECT：连接完成。 OP_READ：数据可读。 OP_WRITE：数据可写13。 事件监听\n调用 Selector.select() 方法，该方法会阻塞，直到至少有一个 Channel 的事件就绪。返回后，可以通过 selectedKeys() 获取就绪的 SelectionKey 集合13：\nint readyChannels = selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); 事件处理\n遍历 selectedKeys()，根据事件类型进行相应的 I/O 操作，处理完成后需手动移除 SelectionKey，避免重复处理13：\nIterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); if (key.isAcceptable()) { // 处理连接事件 } else if (key.isReadable()) { // 处理读事件 } iterator.remove(); // 移除已处理的 key } 关闭资源\n当不再需要 Selector 或 Channel 时，调用 close() 方法释放资源34：\nselector.close(); channel.close(); 4. Selector 的优势 # 减少线程数量：通过单线程管理多个 Channel，减少线程切换的开销。 高效的事件驱动：基于事件通知机制，避免轮询带来的性能损耗。 适用于高并发场景：如 Web 服务器、聊天服务器等134。 5. 注意事项 # 非阻塞模式：注册到 Selector 的 Channel 必须设置为非阻塞模式。 线程安全：Selector 本身是线程安全的，但 selectedKeys() 返回的集合不是，多线程访问时需要同步。 资源管理：确保在不使用时关闭 Selector 和 Channel，避免资源泄漏34。 6. 与底层机制的关系 # Linux 系统：Selector 的底层通常使用 epoll，性能最优。 Windows 系统：Selector 的底层使用 select，性能相对较低13。 通过以上机制，Selector 能够高效地管理多个 Channel，提升 I/O 操作的性能，特别适合高并发的网络应用134。\n密码学 # 在java中如何使用AES加密算法 # 在 Java 中使用 AES 加密算法可以通过 javax.crypto 包中的类实现。以下是详细的步骤和示例代码：\n1. 导入必要的包 # import javax.crypto.Cipher; import javax.crypto.KeyGenerator; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import java.util.Base64; 2. 生成 AES 密钥 # AES 密钥可以通过 KeyGenerator 生成，支持 128 位、192 位和 256 位密钥长度。\npublic static SecretKey generateKey(int keySize)throws Exception{ KeyGenerator keyGen=KeyGenerator.getInstance(\u0026#34;AES\u0026#34;); keyGen.init(keySize); // 128, 192, 或 256 return keyGen.generateKey(); } 3. 加密方法 # 使用 Cipher 类进行加密，并指定加密模式和填充方式（如 AES/CBC/PKCS5Padding）。\npublic static String encrypt(String data,SecretKey secretKey)throws Exception{ Cipher cipher=Cipher.getInstance(\u0026#34;AES/ECB/PKCS5Padding\u0026#34;); // 默认模式 cipher.init(Cipher.ENCRYPT_MODE,secretKey); byte[]encryptedBytes=cipher.doFinal(data.getBytes()); return Base64.getEncoder().encodeToString(encryptedBytes); // 返回 Base64 编码的密文 } 4. 解密方法 # 使用相同的密钥和模式进行解密。\npublic static String decrypt(String encryptedData,SecretKey secretKey)throws Exception{ Cipher cipher=Cipher.getInstance(\u0026#34;AES/ECB/PKCS5Padding\u0026#34;); cipher.init(Cipher.DECRYPT_MODE,secretKey); byte[]decodedBytes=Base64.getDecoder().decode(encryptedData); byte[]decryptedBytes=cipher.doFinal(decodedBytes); return new String(decryptedBytes); // 返回解密后的明文 } 5. 完整示例 # 以下是一个完整的示例，包括生成密钥、加密和解密：\npublic class AESExample { public static void main(String[] args) throws Exception { SecretKey secretKey = generateKey(128); // 生成 128 位密钥 System.out.println(\u0026#34;Secret Key (Base64): \u0026#34; + Base64.getEncoder().encodeToString(secretKey.getEncoded())); String originalText = \u0026#34;Hello, AES!\u0026#34;; System.out.println(\u0026#34;Original Text: \u0026#34; + originalText); String encryptedText = encrypt(originalText, secretKey); System.out.println(\u0026#34;Encrypted Text: \u0026#34; + encryptedText); String decryptedText = decrypt(encryptedText, secretKey); System.out.println(\u0026#34;Decrypted Text: \u0026#34; + decryptedText); } public static SecretKey generateKey(int keySize) throws Exception { KeyGenerator keyGen = KeyGenerator.getInstance(\u0026#34;AES\u0026#34;); keyGen.init(keySize); return keyGen.generateKey(); } public static String encrypt(String data, SecretKey secretKey) throws Exception { Cipher cipher = Cipher.getInstance(\u0026#34;AES/ECB/PKCS5Padding\u0026#34;); cipher.init(Cipher.ENCRYPT_MODE, secretKey); byte[] encryptedBytes = cipher.doFinal(data.getBytes()); return Base64.getEncoder().encodeToString(encryptedBytes); } public static String decrypt(String encryptedData, SecretKey secretKey) throws Exception { Cipher cipher = Cipher.getInstance(\u0026#34;AES/ECB/PKCS5Padding\u0026#34;); cipher.init(Cipher.DECRYPT_MODE, secretKey); byte[] decodedBytes = Base64.getDecoder().decode(encryptedData); byte[] decryptedBytes = cipher.doFinal(decodedBytes); return new String(decryptedBytes); } } 6. 注意事项 # 密钥管理：密钥应安全存储，避免硬编码在代码中。 加密模式：默认使用 ECB 模式，但安全性较低，建议使用 CBC 模式并指定初始化向量（IV）。 填充方式：常用 PKCS5Padding，确保明文长度符合 AES 分组要求。 异常处理：在实际应用中，应妥善处理可能抛出的异常（如 NoSuchAlgorithmException、InvalidKeyException 等）。 通过以上步骤，你可以在 Java 中轻松实现 AES 加密和解密。如果需要更安全的模式（如 CBC），请参考相关文档123。\n在Java中如何使用RSA算法进行加解密 # 在 Java 中使用 RSA 算法进行加解密可以通过 java.security 和 javax.crypto 包中的类实现。以下是详细的步骤和示例代码：\n1. 生成 RSA 密钥对 # 首先，需要生成 RSA 的公钥和私钥对：\nimport java.security.KeyPair; import java.security.KeyPairGenerator; import java.security.NoSuchAlgorithmException; import java.security.interfaces.RSAPrivateKey; import java.security.interfaces.RSAPublicKey; import java.util.Base64; public class RSAKeyGenerator { public static void main(String[] args) throws NoSuchAlgorithmException { // 创建 KeyPairGenerator 实例，指定算法为 RSA KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(\u0026#34;RSA\u0026#34;); keyPairGenerator.initialize(2048); // 设置密钥长度为 2048 位 // 生成密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); // 将密钥转换为 Base64 编码的字符串 String publicKeyStr = Base64.getEncoder().encodeToString(publicKey.getEncoded()); String privateKeyStr = Base64.getEncoder().encodeToString(privateKey.getEncoded()); System.out.println(\u0026#34;公钥: \u0026#34; + publicKeyStr); System.out.println(\u0026#34;私钥: \u0026#34; + privateKeyStr); } } 2. 使用公钥加密 # 使用公钥对数据进行加密：\nimport javax.crypto.Cipher; import java.security.KeyFactory; import java.security.PublicKey; import java.security.spec.X509EncodedKeySpec; import java.util.Base64; public class RSAEncryptor { public static String encrypt(String data, String publicKeyStr) throws Exception { // 将 Base64 编码的公钥字符串转换为 PublicKey 对象 byte[] publicKeyBytes = Base64.getDecoder().decode(publicKeyStr); X509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKeyBytes); KeyFactory keyFactory = KeyFactory.getInstance(\u0026#34;RSA\u0026#34;); PublicKey publicKey = keyFactory.generatePublic(keySpec); // 使用公钥初始化 Cipher 对象进行加密 Cipher cipher = Cipher.getInstance(\u0026#34;RSA\u0026#34;); cipher.init(Cipher.ENCRYPT_MODE, publicKey); // 加密数据并返回 Base64 编码的密文 byte[] encryptedBytes = cipher.doFinal(data.getBytes()); return Base64.getEncoder().encodeToString(encryptedBytes); } public static void main(String[] args) throws Exception { String publicKeyStr = \u0026#34;MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA...\u0026#34;; // 替换为生成的公钥 String data = \u0026#34;Hello, RSA!\u0026#34;; String encryptedData = encrypt(data, publicKeyStr); System.out.println(\u0026#34;加密后的数据: \u0026#34; + encryptedData); } } 3. 使用私钥解密 # 使用私钥对加密数据进行解密：\nimport javax.crypto.Cipher; import java.security.KeyFactory; import java.security.PrivateKey; import java.security.spec.PKCS8EncodedKeySpec; import java.util.Base64; public class RSADecryptor { public static String decrypt(String encryptedData, String privateKeyStr) throws Exception { // 将 Base64 编码的私钥字符串转换为 PrivateKey 对象 byte[] privateKeyBytes = Base64.getDecoder().decode(privateKeyStr); PKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(privateKeyBytes); KeyFactory keyFactory = KeyFactory.getInstance(\u0026#34;RSA\u0026#34;); PrivateKey privateKey = keyFactory.generatePrivate(keySpec); // 使用私钥初始化 Cipher 对象进行解密 Cipher cipher = Cipher.getInstance(\u0026#34;RSA\u0026#34;); cipher.init(Cipher.DECRYPT_MODE, privateKey); // 解密数据并返回明文 byte[] decryptedBytes = cipher.doFinal(Base64.getDecoder().decode(encryptedData)); return new String(decryptedBytes); } public static void main(String[] args) throws Exception { String privateKeyStr = \u0026#34;MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgE...\u0026#34;; // 替换为生成的私钥 String encryptedData = \u0026#34;加密后的数据\u0026#34;; // 替换为加密后的数据 String decryptedData = decrypt(encryptedData, privateKeyStr); System.out.println(\u0026#34;解密后的数据: \u0026#34; + decryptedData); } } 4. 注意事项 # 密钥长度：建议使用 2048 位或更长的密钥，以确保安全性1。 加密数据大小：RSA 加密的数据长度受密钥长度限制，通常用于加密对称密钥或小数据块3。 填充模式：默认使用 PKCS1Padding，也可以选择 OAEPPadding 等更安全的填充模式3。 通过以上步骤，你可以在 Java 中实现 RSA 算法的加解密功能。\n公钥只能用来加密，私钥只能用来解密吗？ # 公钥和私钥的使用不仅仅是“公钥加密，私钥解密”，它们的功能取决于具体的应用场景。以下是公钥和私钥的主要用途：\n1. 公钥加密，私钥解密 # 用途：用于数据加密，确保数据的机密性。 场景：当A想向B发送加密消息时，A使用B的公钥加密数据，B收到后用自己的私钥解密。由于只有B持有私钥，因此只有B能解密消息，确保了消息的安全性12。 2. 私钥签名，公钥验签 # 用途：用于数字签名，确保数据的完整性和身份认证。 场景：当A想向B发送一条消息并证明消息确实来自A时，A会用私钥对消息进行签名，B收到后用A的公钥验证签名。由于只有A持有私钥，因此B可以确认消息确实来自A，且未被篡改125。 3. 私钥加密，公钥解密 # 用途：用于身份认证或特定场景的加密。 场景：在某些特殊情况下（如密钥交换），私钥也可以用于加密，公钥用于解密。例如，在TLS/SSL协议中，服务器可能会用私钥加密某些信息，客户端用公钥解密以验证服务器的身份5。 总结 # 公钥和私钥的功能是灵活的，具体使用方式取决于应用场景：\n公钥加密，私钥解密：确保数据机密性。 私钥签名，公钥验签：确保数据完整性和身份认证。 私钥加密，公钥解密：用于特定场景的身份认证或密钥交换。 因此，公钥和私钥的使用并不仅限于“公钥加密，私钥解密”，而是根据需求灵活应用的125。\n对称加密中的加密模式是什么 # 对称加密中的加密模式是指将明文分组加密的方式，用于处理长度不固定的明文数据。常见的加密模式包括以下五种：\n1. ECB（Electronic Code Book，电子密码本模式） # 特点： 简单快速，支持并行计算。 相同的明文会生成相同的密文，容易被破解。 最后一个分组需要填充。 缺点： 安全性较低，容易受到密码本重放攻击。 不推荐使用13。 2. CBC（Cipher Block Chaining，密码分组链接模式） # 特点： 每个明文分组在加密前会与前一个密文分组进行异或操作。 需要初始化向量（IV），且加解密时 IV 必须相同。 最后一个分组需要填充。 优点： 安全性较高，密文无规律。 缺点： 不支持并行加密，解密支持并行13。 3. CFB（Cipher Feedback，密文反馈模式） # 特点： 将分组密码转换为流密码，按位或按字节加密。 需要初始化向量（IV），且加解密时 IV 必须相同。 不需要填充。 优点： 支持并行解密。 缺点： 不支持并行加密，存在错误扩散13。 4. OFB（Output Feedback，输出反馈模式） # 特点： 将分组密码转换为流密码，按位或按字节加密。 需要初始化向量（IV），且加解密时 IV 必须相同。 不需要填充。 优点： 加密和解密使用相同结构。 缺点： 不支持并行运算，存在错误扩散13。 5. CTR（Counter，计数器模式） # 特点： 将分组密码转换为流密码，按位或按字节加密。 不需要初始化向量（IV），使用计数器生成密钥流。 不需要填充。 优点： 支持并行加密和解密，效率高。 安全性高，推荐使用13。 总结 # 推荐模式：CBC 和 CTR 模式，尤其是 CTR 模式，因其高效性和安全性13。 不推荐模式：ECB 模式，因其安全性较低13。 以上五种模式各有特点，具体选择应根据应用场景和安全需求决定13。\nAES中的填充方式有哪些？ # AES（Advanced Encryption Standard）中的填充方式主要用于将明文数据填充到符合AES分组长度（128位）的整数倍，以便进行加密。以下是常见的填充方式：\n1. PKCS7 Padding # 描述：在明文末尾添加填充字节，填充字节的值等于需要填充的字节数。例如，如果需要填充5个字节，则填充值为05 05 05 05 05。 特点：适用于任意块大小（1~255字节），是AES中最常用的填充方式12。 2. PKCS5 Padding # 描述：与PKCS7类似，但块大小固定为8字节。在AES中，由于块大小为16字节，PKCS5与PKCS7的效果相同12。 3. No Padding # 描述：不进行任何填充，要求明文长度必须是分组长度的整数倍。如果明文长度不符合要求，则会抛出异常。 特点：适用于明文长度已知且为分组大小整数倍的场景12。 4. ISO10126 Padding # 描述：在明文末尾填充随机字节，最后一个字节为填充的数量数。例如，如果需要填充5个字节，则填充格式为XX XX XX XX 05，其中XX为随机字节。 特点：填充值随机，安全性较高12。 5. ISO7816-4 Padding # 描述：在明文末尾填充0x80，后面补0x00，直到分组长度。例如，如果需要填充5个字节，则填充格式为80 00 00 00 00。 特点：适用于特定场景，如智能卡应用12。 6. Zero Byte Padding # 描述：在明文末尾填充0x00，直到分组长度。例如，如果需要填充5个字节，则填充格式为00 00 00 00 00。 特点：简单易用，但无法区分填充和原始数据12。 7. X923 Padding # 描述：在明文末尾填充0x00，最后一个字节为填充的数量数。例如，如果需要填充5个字节，则填充格式为00 00 00 00 05。 特点：与PKCS7类似，但填充值为0x0012。 8. TBC Padding (Trailing-Bit-Compliment) # 描述：根据明文的最后一位进行填充。如果最后一位为1，则填充0x00；如果最后一位为0，则填充0xFF。 特点：适用于特定场景，如某些协议要求12。 9. PKCS1 Padding # 描述：主要用于RSA加密，填充格式为00 + BT + PS + 00 + D，其中BT为处理模式，PS为填充字节。 特点：适用于RSA加密，不常用于AES2。 总结 # AES中的填充方式多样，常见的包括 PKCS7、PKCS5、No Padding、ISO10126 等。选择填充方式时需根据具体应用场景和安全性需求进行权衡12。\nreactor # reference # 五分钟快速理解 Reactor 模型 1、线程模型1：传统阻塞 I/O 服务模型 2、线程模型2：Reactor 模式 I/O 复用 + 线程 Reactor 模式中的两个关键组成 Reactor Handler Reactor 的实现 单 Reactor 单线程 单 Reactor 多线程 主从 Reactor 多线程 给我举一个 reactor 模式的例子 # 以下是一个基于 Reactor 模式 的简单示例，使用 Java NIO 实现了一个非阻塞的服务器。这个示例展示了 Reactor 模式的核心思想：通过事件驱动机制，使用一个主线程（Reactor）监听多个 I/O 事件，并将事件分发给对应的处理器（Handler）进行处理。\n示例代码：Reactor 模式服务器 # import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; public class ReactorServer { public static void main(String[] args) throws IOException { // 创建 Selector（事件多路复用器） Selector selector = Selector.open(); // 创建 ServerSocketChannel 并绑定端口 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(8080)); serverSocketChannel.configureBlocking(false); // 设置为非阻塞模式 // 将 ServerSocketChannel 注册到 Selector，监听 ACCEPT 事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\u0026#34;Server started on port 8080...\u0026#34;); // 事件循环 while (true) { selector.select(); // 阻塞等待事件发生 Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectedKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { // 处理连接事件 handleAccept(key, selector); } else if (key.isReadable()) { // 处理读事件 handleRead(key); } } } } // 处理连接事件 private static void handleAccept(SelectionKey key, Selector selector) throws IOException { ServerSocketChannel serverChannel = (ServerSocketChannel) key.channel(); SocketChannel clientChannel = serverChannel.accept(); clientChannel.configureBlocking(false); // 设置为非阻塞模式 // 将客户端通道注册到 Selector，监听 READ 事件 clientChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;Client connected: \u0026#34; + clientChannel.getRemoteAddress()); } // 处理读事件 private static void handleRead(SelectionKey key) throws IOException { SocketChannel clientChannel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); int bytesRead = clientChannel.read(buffer); if (bytesRead == -1) { // 客户端断开连接 clientChannel.close(); System.out.println(\u0026#34;Client disconnected: \u0026#34; + clientChannel.getRemoteAddress()); } else if (bytesRead \u0026gt; 0) { buffer.flip(); // 切换为读模式 byte[] data = new byte[buffer.limit()]; buffer.get(data); System.out.println(\u0026#34;Received: \u0026#34; + new String(data)); // 回显数据给客户端 clientChannel.write(ByteBuffer.wrap(data)); } } } 代码说明 # Reactor：\nSelector 是 Reactor 的核心组件，用于监听多个 Channel 的 I/O 事件。 主线程通过 selector.select() 阻塞等待事件发生，然后遍历 selectedKeys 处理事件。 事件处理：\n连接事件（OP_ACCEPT）：当有客户端连接时，handleAccept 方法会接受连接，并将客户端通道注册到 Selector，监听 OP_READ 事件。 读事件（OP_READ）：当客户端发送数据时，handleRead 方法会读取数据并回显给客户端。 非阻塞模式：\n所有的 Channel 都被设置为非阻塞模式（configureBlocking(false)），确保 I/O 操作不会阻塞线程。 Reactor 模式的核心组件12 # Reactor：负责监听和分发事件，是事件循环的核心。 Handler：事件处理器，用于处理 Reactor 分发的事件。 Acceptor：用于接受新的连接请求。 Event Demultiplexer（Selector）：用于等待多个 I/O 事件的发生。 应用场景 # Reactor 模式适合以下场景5：\n高性能网络服务器（如 HTTP 服务器、聊天服务器）。 实时通信系统（如推送服务）。 分布式消息队列（如 Kafka）。 游戏服务器。 通过这个示例，你可以看到 Reactor 模式如何通过事件驱动机制高效地处理多个 I/O 事件，适合高并发场景。\n响应式编程 # reference # Java 虚拟线程对响应式编程开发有什么影响? 什么是响应式编程 # 响应式编程（Reactive Programming）是一种面向数据流和变化传播 的声明式编程范式。它允许开发者方便地表达静态或动态的数据流，并自动将数据流中的变化传播到相关计算模型中34。\n核心概念 # 数据流：响应式编程的核心是数据流，即数据的变化和流动。例如，在电子表格中，单元格的值会随着其他单元格的变化而自动更新34。 变化传播：当数据流中的某个值发生变化时，依赖该值的计算会自动更新，而不需要显式调用34。 声明式：开发者只需声明数据流和计算逻辑，而无需关注具体的执行细节3。 响应式编程的特点 # 可应答性（Responsive）：系统能够及时响应请求，保持快速和一致的响应时间14。 弹性（Resilient）：系统在出现故障时仍能提供响应，例如返回错误页面而不是直接崩溃14。 可伸缩性（Elastic）：系统能够根据负载动态调整资源，例如在高负载时扩容，低负载时释放资源14。 消息驱动（Message Driven）：系统通过异步消息传递实现高效的资源利用和故障隔离14。 应用场景 # 用户界面：响应式编程最初用于简化用户界面和实时系统动画的开发34。 实时数据处理：如金融交易系统、实时监控系统等1。 高并发服务器：通过异步和非阻塞的方式处理大量并发请求2。 优点 # 高效利用资源：通过异步和非阻塞的方式减少线程阻塞，提高 CPU 和内存的利用率15。 简化并发编程：开发者无需手动管理线程和同步问题12。 更好的扩展性：系统能够根据负载动态调整资源14。 缺点 # 复杂性：响应式编程的代码可能难以理解和调试，尤其是对于不熟悉异步编程的开发者5。 学习成本高：需要理解数据流、背压（Backpressure）等概念12。 示例 # 在命令式编程中，表达式 a = b + c 只会计算一次，而在响应式编程中，a 的值会随着 b 和 c 的变化而自动更新34。\n总结 # 响应式编程是一种以数据流为核心的编程范式，适合处理高并发、实时性和动态变化的场景。尽管它具有一定的复杂性，但在现代高并发和实时系统中，响应式编程提供了高效且灵活的解决方案134。\n在springboot中有哪些响应式编程的运用 # 在 Spring Boot 中，响应式编程主要通过 Spring WebFlux 和 Project Reactor 来实现。以下是 Spring Boot 中响应式编程的主要应用场景和实现方式：\n1. 响应式 Web 开发（Spring WebFlux） # Spring WebFlux 是 Spring Framework 5.0 引入的响应式 Web 框架，支持异步非阻塞的请求处理，适合高并发场景12。\n核心特性： # 非阻塞 I/O：使用异步非阻塞模型处理请求，提高并发能力。 Reactive Streams 支持：基于 Reactor 实现，支持背压（Backpressure）机制。 函数式编程：提供函数式 API（如 Router Functions）来定义路由和处理逻辑。 示例代码： # @RestController public class UserController { @GetMapping(\u0026#34;/users\u0026#34;) public Flux\u0026lt;User\u0026gt; getAllUsers() { return Flux.just( new User(\u0026#34;John\u0026#34;, 30), new User(\u0026#34;Jane\u0026#34;, 25) ); } } 在这个示例中，Flux 用于返回多个用户数据2。\n2. 响应式数据库访问 # Spring Boot 支持通过 Spring Data R2DBC 和 Spring Data MongoDB Reactive 实现响应式数据库访问25。\n核心特性： # 非阻塞数据库操作：通过异步方式访问数据库，避免线程阻塞。 Reactive Repository：提供响应式的 CRUD 操作接口。 示例代码： # @Repository public interface UserRepository extends ReactiveCrudRepository\u0026lt;User, Long\u0026gt; { } @Service public class UserService { @Autowired private UserRepository userRepository; public Flux\u0026lt;User\u0026gt; getAllUsers() { return userRepository.findAll(); } } 在这个示例中，ReactiveCrudRepository 用于实现响应式的数据库查询2。\n3. 响应式消息传递 # Spring Boot 支持通过 Spring Cloud Stream 和 Reactive Kafka 实现响应式消息传递5。\n核心特性： # 异步消息处理：通过非阻塞方式处理消息队列中的数据。 背压支持：根据消费者能力动态调整消息处理速度。 示例代码： # @Bean public Consumer\u0026lt;Flux\u0026lt;String\u0026gt;\u0026gt;processMessage(){ return messages-\u0026gt;messages .doOnNext(message-\u0026gt;System.out.println(\u0026#34;Received: \u0026#34;+message)) .subscribe(); } 在这个示例中，Flux 用于处理消息流5。\n4. 响应式安全（Spring Security Reactive） # Spring Boot 支持通过 Spring Security Reactive 实现响应式的安全控制5。\n核心特性： # 非阻塞认证和授权：通过异步方式处理用户认证和权限校验。 响应式上下文：支持在响应式环境中传递安全上下文。 示例代码： # @Bean public SecurityWebFilterChain securityWebFilterChain(ServerHttpSecurity http){ return http .authorizeExchange(exchanges-\u0026gt;exchanges.anyExchange().authenticated()) .httpBasic(withDefaults()) .build(); } 在这个示例中，ServerHttpSecurity 用于配置响应式安全规则5。\n5. 响应式测试 # Spring Boot 提供对响应式组件的测试支持，包括 WebTestClient 和 StepVerifier5。\n示例代码： # @Test public void testGetAllUsers(){ webTestClient.get().uri(\u0026#34;/users\u0026#34;) .exchange() .expectStatus().isOk() .expectBodyList(User.class).hasSize(2); } 在这个示例中，WebTestClient 用于测试响应式 Web 接口5。\n6. 响应式流处理 # 通过 Project Reactor，Spring Boot 支持对数据流进行处理，包括转换、过滤、合并等操作13。\n示例代码： # Flux\u0026lt;Integer\u0026gt; numbers=Flux.just(1,2,3,4,5) .filter(n-\u0026gt;n%2==0) .map(n-\u0026gt;n*2); 在这个示例中，Flux 用于对数据流进行过滤和转换3。\n总结 # 在 Spring Boot 中，响应式编程的应用主要包括：\n响应式 Web 开发（Spring WebFlux）。 响应式数据库访问（Spring Data R2DBC、Spring Data MongoDB Reactive）。 响应式消息传递（Spring Cloud Stream、Reactive Kafka）。 响应式安全（Spring Security Reactive）。 响应式测试（WebTestClient、StepVerifier）。 响应式流处理（Project Reactor）。 这些技术共同构成了 Spring Boot 的响应式编程生态，适合构建高并发、低延迟的现代应用125。\n响应式数据库访问和传统的数据库访问有什么区别 # 响应式数据库访问与传统数据库访问的主要区别在于它们的编程模型、性能特点以及适用场景。以下是两者的详细对比：\n1. 编程模型 # 传统数据库访问：\n基于 阻塞式 I/O，使用 JDBC（Java Database Connectivity）进行数据库操作。 每个数据库操作都会阻塞当前线程，直到操作完成1。 适合同步编程模型，代码逻辑直观，但并发能力有限3。 响应式数据库访问：\n基于 非阻塞 I/O，使用 R2DBC（Reactive Relational Database Connectivity）进行数据库操作。 数据库操作不会阻塞线程，而是通过异步方式处理，线程可以继续执行其他任务12。 适合异步和响应式编程模型，代码复杂度较高，但并发能力强3。 2. 性能特点 # 传统数据库访问：\n在高并发场景下，线程阻塞会导致资源浪费，性能瓶颈明显1。 每个连接都需要一个独立的线程，线程创建和切换开销较大3。 响应式数据库访问：\n非阻塞模型能够高效利用线程资源，支持更高的并发量2。 通过事件驱动和异步处理，减少线程阻塞，提升系统吞吐量13。 3. 适用场景 # 传统数据库访问：\n适合低并发、简单业务逻辑的场景，如传统的企业应用、小型网站7。 对事务一致性要求高的场景，如银行系统、财务系统7。 响应式数据库访问：\n适合高并发、I/O 密集型场景，如实时数据处理、大规模在线服务23。 对延迟敏感的场景，如实时通信、流媒体服务6。 4. 技术实现 # 传统数据库访问：\n使用 JDBC，基于阻塞式 API，开发简单但性能受限1。 支持 ACID 事务，适合强一致性要求的场景7。 响应式数据库访问：\n使用 R2DBC，基于 Reactive Streams 规范，支持非阻塞操作12。 支持异步事务处理，但事务管理复杂度较高3。 5. 优缺点对比 # 特性 传统数据库访问 响应式数据库访问 编程复杂度 简单，同步编程模型 复杂，异步编程模型 并发能力 低，受限于线程数量 高，非阻塞模型支持高并发 资源利用率 低，线程阻塞导致资源浪费 高，线程非阻塞，资源利用率高 适用场景 低并发、强一致性场景 高并发、低延迟场景 事务支持 支持 ACID 事务，实现简单 支持异步事务，实现复杂 技术生态 成熟，工具和文档丰富 较新，工具和文档仍在完善中23 总结 # 响应式数据库访问和传统数据库访问的主要区别在于：\n编程模型：传统数据库访问是阻塞式同步模型，而响应式数据库访问是非阻塞异步模型12。 性能：响应式数据库访问在高并发场景下性能更优，资源利用率更高3。 适用场景：传统数据库访问适合低并发、强一致性场景，响应式数据库访问适合高并发、低延迟场景67。 根据具体业务需求选择合适的数据库访问方式，可以显著提升系统性能和开发效率。\n一个请求在非响应式的后端服务中的处理响应和响应式的后端服务中的处理的过程比较 # 在处理请求时，非响应式后端服务 和 响应式后端服务 的工作机制和性能表现有显著差异。以下是两者的处理过程和比较：\n1. 非响应式后端服务的处理过程 # 非响应式后端服务通常采用 同步阻塞模型，其处理请求的过程如下：\n处理流程： # 接收请求：客户端发送请求到服务器，服务器接收请求并分配一个线程处理。 阻塞处理：线程会阻塞等待 I/O 操作完成（如数据库查询、文件读取等）。 执行逻辑：线程执行业务逻辑，处理请求数据。 返回响应：处理完成后，线程将结果返回给客户端。 释放资源：线程释放资源，等待下一个请求。 特点： # 同步阻塞：每个请求需要一个独立的线程，线程在 I/O 操作时会阻塞，导致资源浪费。 并发能力有限：线程数量受限于线程池大小，高并发时容易达到瓶颈。 简单直观：代码逻辑简单，适合低并发、简单业务场景12。 示例： # @RestController public class NonReactiveController { @GetMapping(\u0026#34;/data\u0026#34;) public String getData() { // 阻塞式数据库查询 String result = database.query(); return result; } } 2. 响应式后端服务的处理过程 # 响应式后端服务采用 异步非阻塞模型，其处理请求的过程如下：\n处理流程： # 接收请求：客户端发送请求到服务器，服务器接收请求并分派给事件循环处理。 非阻塞处理：事件循环不会阻塞等待 I/O 操作，而是注册回调函数，继续处理其他请求。 执行逻辑：当 I/O 操作完成时，事件循环触发回调函数，执行业务逻辑。 返回响应：处理完成后，事件循环将结果返回给客户端。 复用资源：事件循环继续处理其他请求，资源利用率高。 特点： # 异步非阻塞：线程不会阻塞在 I/O 操作上，可以处理更多请求。 高并发能力：通过事件驱动模型，支持更高的并发量。 复杂但高效：代码逻辑复杂，但适合高并发、I/O 密集型场景13。 示例： # @RestController public class ReactiveController { @GetMapping(\u0026#34;/data\u0026#34;) public Mono\u0026lt;String\u0026gt; getData() { // 非阻塞式数据库查询 return database.queryReactive(); } } 3. 两者的比较 # 特性 非响应式后端服务 响应式后端服务 模型 同步阻塞 异步非阻塞 线程使用 每个请求需要一个独立线程 一个线程可以处理多个请求 并发能力 低，受限于线程数量 高，支持高并发 资源利用率 低，线程阻塞导致资源浪费 高，线程非阻塞，资源利用率高 代码复杂度 简单，直观 复杂，需要理解异步编程 适用场景 低并发、简单业务逻辑 高并发、I/O 密集型任务 4. 总结 # 非响应式后端服务：适合低并发、简单业务场景，代码简单但性能有限。 响应式后端服务：适合高并发、I/O 密集型场景，性能优异但代码复杂度较高。 根据具体需求选择合适的技术栈，可以显著提升系统的性能和开发效率13。\n可以举一个具体的例子来详细说明吗？一个线程在从处理开始到结束，每个时刻所进行的任务 # 好的！下面通过一个具体的例子，详细说明一个线程在响应式服务中如何从处理开始到结束，每个时刻所执行的任务。我们将使用 Spring WebFlux 作为响应式框架，并结合一个简单的 HTTP 请求处理场景来说明。\n场景描述 # 我们有一个简单的用户服务，提供以下功能：\n根据用户 ID 查询用户信息（/users/{id}）。 查询用户信息时，需要从数据库中异步获取数据。 查询完成后，将结果返回给客户端。 假设我们使用 MongoDB 作为数据库，并通过 ReactiveMongoRepository 实现异步数据库操作。\n代码实现 # @RestController public class UserController { @Autowired private UserRepository userRepository; @GetMapping(\u0026#34;/users/{id}\u0026#34;) public Mono\u0026lt;User\u0026gt; getUserById(@PathVariable String id) { // 1. 接收请求，开始处理 System.out.println(\u0026#34;Thread: \u0026#34; + Thread.currentThread().getName() + \u0026#34; - 开始处理请求\u0026#34;); // 2. 异步查询数据库 Mono\u0026lt;User\u0026gt; userMono = userRepository.findById(id) .doOnNext(user -\u0026gt; System.out.println(\u0026#34;Thread: \u0026#34; + Thread.currentThread().getName() + \u0026#34; - 查询到用户: \u0026#34; + user)); // 3. 返回结果 return userMono .doOnSuccess(user -\u0026gt; System.out.println(\u0026#34;Thread: \u0026#34; + Thread.currentThread().getName() + \u0026#34; - 请求处理完成\u0026#34;)); } } 线程执行过程 # 假设客户端发起一个请求 GET /users/123，以下是一个线程（假设为 Thread-1）在处理该请求时的具体执行过程：\n时刻 1：接收请求 # 线程 Thread-1 接收到客户端请求，开始执行 getUserById 方法。 日志输出： Thread: Thread-1 - 开始处理请求 时刻 2：发起异步数据库查询 # 线程 Thread-1 调用 userRepository.findById(id)，这是一个非阻塞操作。 线程不会等待数据库查询结果，而是立即返回一个 Mono\u0026lt;User\u0026gt; 对象。 数据库查询任务被提交到事件循环中，由底层的异步 I/O 线程池处理。 时刻 3：线程释放 # 线程 Thread-1 完成任务后，立即被释放，可以继续处理其他请求。 此时，Thread-1 不再与当前请求关联，而是可以处理其他客户端请求。 时刻 4：数据库查询完成 # 数据库查询完成后，事件循环将结果传递给 Mono\u0026lt;User\u0026gt; 的订阅者。 日志输出： Thread: nioEventLoopGroup-2-1 - 查询到用户: User(id=123, name=John) 注意：这里的线程是 nioEventLoopGroup-2-1，它是 Netty 的 I/O 线程池中的线程，负责处理异步任务。\n时刻 5：返回结果 # 结果被包装到 Mono\u0026lt;User\u0026gt; 中，返回给客户端。 日志输出： Thread: nioEventLoopGroup-2-1 - 请求处理完成 线程任务总结 # 时刻 线程名称 任务描述 1 Thread-1 接收请求，开始处理。 2 Thread-1 发起异步数据库查询，立即返回 Mono\u0026lt;User\u0026gt;，线程释放。 3 Thread-1 线程被释放，可以处理其他请求。 4 nioEventLoopGroup-2-1 数据库查询完成，处理结果并触发 Mono\u0026lt;User\u0026gt; 的订阅者。 5 nioEventLoopGroup-2-1 将结果返回给客户端，完成请求处理。 关键点 # 非阻塞：线程不会因为等待数据库查询而阻塞，而是立即返回并处理其他请求。 异步 I/O：数据库查询等 I/O 操作由底层的异步线程池（如 Netty 的 EventLoopGroup）处理。 线程复用：一个线程可以同时处理多个请求，提高了并发性能。 事件驱动：通过事件循环机制，任务完成后会自动触发回调，无需线程主动轮询。 总结 # 在这个例子中，一个线程（Thread-1）在接收到请求后，发起异步数据库查询并立即释放，继续处理其他请求。数据库查询完成后，由另一个线程（nioEventLoopGroup-2-1 ）处理结果并返回给客户端。通过这种非阻塞和事件驱动的方式，一个线程可以高效地处理多个请求，显著提升了系统的并发能力。\n在响应式编程中，它的并发量会收到数据库连接池大小的限制，那这不是和阻塞式的服务一样吗 # 在响应式编程中，虽然并发量理论上受到数据库连接池大小的限制，但这与阻塞式服务有本质区别。以下是详细分析：\n1. 响应式编程与阻塞式服务的区别 # 阻塞式服务：\n在阻塞式模型中，每个请求通常会占用一个线程，并且线程在等待数据库查询或其他 I/O 操作完成时会被阻塞。这意味着线程资源被浪费，无法处理其他请求。 当数据库连接池耗尽时，新的请求必须等待，直到有连接被释放。这种等待是同步阻塞的，导致系统吞吐量下降118。 响应式编程：\n响应式模型采用非阻塞和事件驱动的方式。线程不会因为等待 I/O 操作而阻塞，而是可以继续处理其他请求。 当数据库连接池耗尽时，新的请求不会被立即拒绝，而是被放入队列中等待。由于线程是非阻塞的，系统仍然可以处理其他任务（如计算、缓存操作等），直到数据库连接可用1127。 2. 数据库连接池的限制 # 在响应式编程中，数据库连接池的大小确实会影响系统的并发能力。如果连接池过小，可能会导致请求排队等待连接，从而影响响应时间。 但响应式编程的优势在于： 资源高效利用：线程不会被阻塞，可以处理其他任务，而不是空闲等待。 背压机制：响应式框架（如 Reactor）支持背压（Backpressure），可以根据消费者的处理能力动态调整数据流，避免系统过载1827。 异步操作：即使连接池耗尽，响应式服务仍然可以通过异步队列处理请求，而不是直接阻塞1129。 3. 如何优化连接池与响应式编程的结合 # 合理配置连接池：\n根据应用的并发量和数据库性能，设置合适的连接池大小。例如，minimumIdle 和 maximumPoolSize 需要根据实际负载进行调整138。 使用高性能连接池（如 HikariCP）以减少连接获取的开销1。 异步数据库驱动：\n使用支持响应式编程的数据库驱动（如 R2DBC），避免传统 JDBC 的阻塞问题1127。 缓存与负载均衡：\n通过缓存减少对数据库的直接访问，降低连接池的压力。 使用负载均衡将请求分发到多个服务实例，进一步提高并发能力43。 4. 总结 # 虽然响应式编程中数据库连接池的大小限制了并发量，但由于其非阻塞和事件驱动 的特性，系统仍然能够高效利用资源，避免线程浪费。这与阻塞式服务的同步等待有本质区别。通过合理配置连接池、使用异步数据库驱动以及引入缓存和负载均衡，可以进一步优化响应式服务的并发性能1112738 。\n在阻塞式的IO中，数据库的处理线程就是处理请求的那个线程吗 # 在阻塞式IO模型中，数据库的处理线程通常就是处理请求的那个线程。以下是详细说明：\n1. 阻塞式IO的工作机制 # 在阻塞式IO中，线程在执行IO操作（如数据库查询）时会被阻塞，直到操作完成。这意味着：\n当线程发起一个数据库查询请求时，它会一直等待数据库返回结果，期间无法执行其他任务。 处理请求的线程与执行数据库操作的线程是同一个线程146。 2. 具体流程 # 以处理一个HTTP请求为例：\n接收请求：线程接收客户端请求，开始处理。 发起数据库查询：线程向数据库发起查询请求，并进入阻塞状态，等待数据库返回结果。 数据库操作完成：数据库返回查询结果，线程恢复执行。 返回响应：线程将数据库结果封装为响应，返回给客户端4649。 在这个过程中，处理请求的线程和数据库操作的线程是同一个线程。\n3. 阻塞式IO的线程模型 # 在传统的阻塞式IO服务模型中：\n每个请求都会分配一个独立的线程来处理。 如果请求涉及数据库操作，该线程会一直阻塞，直到数据库操作完成3441。 这种模型的缺点是：\n线程在等待数据库操作时会浪费资源，无法处理其他请求。 当并发请求量较大时，线程数量会急剧增加，导致系统资源耗尽3449。 4. 与响应式模型的区别 # 在响应式编程模型中：\n线程不会因为等待数据库操作而阻塞，而是继续处理其他请求。 数据库操作完成后，通过回调机制通知线程处理结果3441。 总结 # 在阻塞式IO中，数据库的处理线程就是处理请求的那个线程 。这种模型虽然简单，但在高并发场景下效率较低，因为线程会因等待IO操作而阻塞，无法充分利用系统资源。相比之下，响应式编程模型通过非阻塞和事件驱动的方式，能够更好地处理高并发请求13441。\n在使用 R2DBC 时，处理数据库操作的线程如何设置 # 在使用 R2DBC（Reactive Relational Database Connectivity）时，处理数据库操作的线程设置主要依赖于非阻塞和事件驱动 的机制，而不是传统的线程池模型。以下是关于如何设置和处理线程的详细说明：\n1. R2DBC 的线程模型 # R2DBC 是基于反应式编程的数据库访问规范，其核心特点是非阻塞和异步。这意味着：\n线程不会因为等待数据库操作而阻塞，而是可以继续处理其他任务。 数据库操作（如查询、更新）由底层的异步 I/O 线程（如 Netty 的 EventLoopGroup）处理，而不是传统的阻塞式线程池。 2. 如何设置线程 # 在 R2DBC 中，线程的设置主要通过以下方式实现：\n(1) 使用连接池配置 # R2DBC 支持连接池（如 r2dbc-pool），可以通过配置连接池参数来优化线程的使用。例如：\n初始连接数：initialSize，设置连接池启动时创建的连接数量。 最大连接数：maxSize，设置连接池允许的最大连接数量。 最大空闲时间：maxIdleTime，设置连接在空闲时的最大存活时间。 获取连接超时时间：maxAcquireTime，设置从连接池获取连接的最大等待时间。 示例配置：\nConnectionPoolConfiguration poolConfiguration=ConnectionPoolConfiguration.builder(connectionFactory) .initialSize(5) // 初始连接数 .maxSize(20) // 最大连接数 .maxIdleTime(Duration.ofMinutes(30)) // 最大空闲时间 .maxAcquireTime(Duration.ofSeconds(10)) // 获取连接超时时间 .build(); ConnectionPool connectionPool=new ConnectionPool(poolConfiguration); 1\n(2) 使用异步 I/O 线程 # R2DBC 依赖于底层的异步 I/O 框架（如 Netty），默认情况下，数据库操作由 Netty 的 EventLoopGroup 线程处理。这些线程是非阻塞的，能够高效处理多个并发请求。\n如果需要调整 Netty 的线程池大小，可以通过以下方式配置：\nEventLoopGroup eventLoopGroup=new NioEventLoopGroup(4); // 设置线程数为 4 ConnectionFactoryOptions options=ConnectionFactoryOptions.builder() .option(EventLoopGroup.class,eventLoopGroup) .build(); 3. 线程处理的流程 # 以下是 R2DBC 处理数据库操作时线程的典型流程：\n接收请求：请求由应用线程（如 WebFlux 的线程）接收。 提交数据库操作：应用线程将数据库操作提交给 R2DBC 的 ConnectionFactory，然后立即释放，继续处理其他请求。 异步执行：数据库操作由 Netty 的 EventLoopGroup 线程执行，结果通过回调机制返回。 返回结果：结果由 Netty 线程返回给客户端。 4. 与传统阻塞式模型的区别 # 阻塞式模型：每个数据库操作会占用一个线程，线程在等待数据库响应时会被阻塞，导致资源浪费。 R2DBC 模型：线程不会被阻塞，数据库操作由异步 I/O 线程处理，线程资源利用率更高。 5. 优化建议 # 合理配置连接池：根据应用的并发量和数据库性能，设置合适的连接池参数（如 maxSize、maxIdleTime 等）1。 使用异步数据库驱动：确保使用支持 R2DBC 的数据库驱动（如 r2dbc-mysql、r2dbc-postgres），以避免阻塞问题13。 监控线程池性能：通过监控工具（如 Micrometer）观察线程池的使用情况，及时调整配置39。 总结 # 在 R2DBC 中，处理数据库操作的线程主要由底层的异步 I/O 线程（如 Netty 的 EventLoopGroup）负责，而不是传统的阻塞式线程池。通过合理配置连接池和优化异步 I/O 线程，可以显著提升系统的并发性能和资源利用率。\nMono # 在java的响应式中，mono是什么 # 在 Java 的响应式编程中，Mono 是 Reactor 库中的一个核心类，用于表示一个 异步的、单值的数据流。它代表了一个可能包含 零个或一个元素 的序列，通常用于处理返回单个结果或没有结果的异步操作。\nMono 的主要特点 # 单值流：Mono 用于表示最多包含一个元素的流，适合处理单个结果或空值的场景。 异步非阻塞：Mono 的操作是非阻塞的，适合处理 I/O 密集型任务，如数据库查询、网络请求等。 丰富的操作符：Mono 提供了多种操作符（如 map、flatMap、filter 等），可以对数据进行转换和处理。 背压支持：Mono 遵循 Reactive Streams 规范，支持背压机制，确保生产者和消费者之间的速率平衡。 Mono 的常见使用场景 # 数据库查询：查询单个记录或返回单个结果的操作。 网络请求：发送 HTTP 请求并接收单个响应。 任务执行：执行异步任务并返回单个结果。 Mono 的示例代码 # 以下是一个简单的 Mono 使用示例：\nimport reactor.core.publisher.Mono; public class MonoExample { public static void main(String[] args) { // 创建一个包含单个值的 Mono Mono\u0026lt;String\u0026gt; mono = Mono.just(\u0026#34;Hello, Mono!\u0026#34;); // 订阅并处理 Mono 中的值 mono.subscribe(value -\u0026gt; System.out.println(\u0026#34;Received: \u0026#34; + value)); } } 在这个示例中，Mono.just 创建了一个包含单个值的 Mono，subscribe 方法用于订阅并处理 Mono 中的值。\nMono 的操作符 # Mono 提供了多种操作符来处理数据，例如：\nmap：对 Mono 中的值进行转换。 flatMap：将 Mono 中的值转换为另一个 Mono。 filter：过滤 Mono 中的值。 示例：\nMono\u0026lt;Integer\u0026gt; mono=Mono.just(10); mono.map(value-\u0026gt;value*2) .subscribe(result-\u0026gt;System.out.println(\u0026#34;Result: \u0026#34;+result)); Mono 与 Flux 的区别 # Mono：用于处理 单个值或空值 的异步序列。 Flux：用于处理 多个值 的异步序列，适合流式数据或集合操作4。 总结 # Mono 是 Java 响应式编程中用于处理 单值异步操作 的核心类，适合处理单个结果或空值的场景。它通过异步非阻塞的机制和丰富的操作符，能够高效地处理 I/O 密集型任务，并支持背压机制，确保系统的稳定性14。\nMono 是如何实现非阻塞的 # Mono 是 Reactor 库中的一个核心类，用于表示一个 异步的、单值的数据流。它通过 事件驱动 和 回调机制 实现了非阻塞的特性。以下是 Mono 实现非阻塞的具体机制：\n1. 事件驱动模型 # Mono 基于 事件驱动模型，其核心思想是：\n事件源：Mono 本身是一个事件源，表示一个可能产生单值或空值的异步操作。 观察者：通过 subscribe 方法订阅 Mono 的观察者，会在事件发生时被通知。 事件循环：Mono 的操作由事件循环驱动，线程不会阻塞在 I/O 操作上，而是继续处理其他任务。 这种模型使得 Mono 能够高效处理异步操作，避免线程阻塞1。\n2. 回调机制 # Mono 通过 回调机制 实现非阻塞：\n订阅触发执行：Mono 的异步操作只有在被订阅时才会执行。例如： Mono.just(\u0026#34;Hello\u0026#34;).subscribe(value -\u0026gt; System.out.println(\u0026#34;Received: \u0026#34; + value)); 这里的 subscribe 方法触发了 Mono 的执行，并通过回调函数处理结果。 异步通知：当 Mono 的异步操作完成时，会通过回调函数通知观察者，线程不会阻塞在等待结果上1。 3. 非阻塞 I/O # Mono 内部的操作是 非阻塞 I/O 的，例如数据库查询、网络请求等：\n异步操作：Mono 将 I/O 操作封装为异步任务，线程不会阻塞在 I/O 操作上。 回调处理：当 I/O 操作完成时，Mono 通过回调机制将结果传递给观察者12。 4. 线程调度 # Mono 使用 Reactor 调度器（Scheduler） 控制任务的执行线程：\n事件循环线程：负责监听事件和分发任务。 工作线程：通过调度器（如 Schedulers.parallel()）执行异步任务。 线程复用：由于线程不会阻塞，少量线程可以高效处理大量并发请求12。 5. 背压支持 # Mono 遵循 Reactive Streams 规范，支持 背压（Backpressure） 机制：\n速率控制：当生产者（Mono）和消费者（观察者）的速率不匹配时，背压机制会调节数据流速率，避免系统过载1。 6. 示例代码 # 以下是一个简单的 Mono 非阻塞示例：\nMono.fromCallable(()-\u0026gt;{ // 模拟一个耗时操作 Thread.sleep(1000); return\u0026#34;Result\u0026#34;; }).subscribeOn(Schedulers.parallel()) // 指定线程池 .subscribe(result-\u0026gt;System.out.println(\u0026#34;Received: \u0026#34;+result)); 在这个示例中：\nfromCallable 封装了一个耗时操作，但不会阻塞线程。 subscribeOn 指定了任务执行的线程池。 subscribe 触发任务执行，并通过回调处理结果12。 总结 # Mono 通过 事件驱动模型、回调机制、非阻塞 I/O 和 线程调度 实现了非阻塞的特性。它的核心设计使得线程不会阻塞在异步操作上，从而高效处理高并发请求，适合 I/O 密集型任务12。\n"},{"id":7,"href":"/post/life/%E6%96%B0%E7%9F%A5/","title":"新知","section":"Life","content":" 新知 # 如果有朋友有心在看这个page，需要提醒您一下，这个页面主要是我对我看的书，视频，电影的回忆，不会校正正确性，可能是不太准确的。\n2025-07-30 # 青铜文明是从中亚传到中国的。牛，羊，小麦也是从中亚传过来的 （简读中国史） 从分封制到郡县制是为了加强皇帝的权利触及到最底层，加强中央集权（简读中国史） 法家思想推行到极致就变成了极端的功利主义，于人民于君主于推崇者都是输的结果（简读中国史） "},{"id":8,"href":"/post/computer-science/monitor/prometheus/","title":"prometheus","section":"Monitor","content":" prometheus # brew # 如果是使用 brew 安装的话，配置文件在这个位置 /opt/homebrew/etc/prometheus.yml\ngrafana # grafana dashboard springboot # SpringBoot + Prometheus + Grafana 实现自定义监控 database # x5y22r/druid-prometheus-monitor "},{"id":9,"href":"/post/computer-science/computer-science-recommend/","title":"推荐","section":"Computer Science","content":" 推荐 # github alex-shpak/hugo-book 这个博客就是用这个项目搭建的 hacker news 有很多关于计算机相关的文章，每天都会更新 资源下载相关 pingf/annie 可以用来下载B站视频 yt-dlp/yt-dlp 下载 youtube 视频 yutto-dev/bilili 下载 bilibili 视频(项目已经归档不再维护,目前还能用，可以使用yutto) yutto-dev/yutto 卡码笔记 代码随想录的网站，里面整理了一些计算机相关的知识点（非算法相关） cdk8s-zelda/IntelliJ-IDEA-Tutorial 介绍一些 idea 的使用技巧的 segment fault cdk8s/cdk8s-team-style 【从开公司到开发全平台产品】4.后端开发的思考、实践-UPUPMO 【从开公司到开发全平台产品】3.软件开发设计阶段的思考、实践-UPUPMO blog # 阮一峰的网络日志 王垠 github # yihong0618 Large Language Model(LLM) # 通义千问 Algorithms # TheAlgorithms/Java "},{"id":10,"href":"/post/computer-science/computer-science-learning-log/","title":"学习记录","section":"Computer Science","content":" 学习记录 # 2025-03-30 Sunday # 分区表的索引如何创建, 请以postgresql举例 postgresql中分区键会自动创建索引吗 kafka如何实现高吞吐量 不同消息队列消息写入方式对比 kafka如何保障顺序消费 Kafka的顺序消费能力与其他消息队列系统相比有何优势 kafka一个分区有多个消费者消费顺序是怎样的 kafka发送失败如何处理 Kafka突然宕机了消息会不会丢失 2025-01-17 # 剑指Offer Book # 剑指Offer 第1章 面试的流程 1 # 1.1 面试官谈面试 1 1.2 面试的三种形式 2 1.2.1 电话面试 2 1.2.2 共享桌面远程面试 3 1.2.3 现场面试 4 1.3 面试的三个环节 5 1.3.1 行为面试环节 5 应聘者的项目经验 6 应聘者掌握的技能 7 回答“为什么跳槽” 8 1.3.2 技术面试环节 10 扎实的基础知识 10 高质量的代码 11 清晰的思路 14 优化效率的能力 15 优秀的综合能力 16 1.3.3 应聘者提问环节 17 1.4 本章小结 18 第2章 面试需要的基础知识 20 # 2.1 面试官谈基础知识 20 2.2 编程语言 22 2.2.1 C++ 22 面试题1：赋值运算符函数 24 经典的解法，适用于初级程序员 25 考虑异常安全性的解法，高级程序员必备 26 2.2.2 C# 27 面试题2：实现Singleton模式 31 不好的解法一：只适用于单线程 31 不好的解法二：可用于多线程但效率不高 32 可行的解法：同步锁前后两次判断 33 推荐的解法一：利用静态构造函数 34 推荐的解法二：按需创建实例 34 解法比较 35 2.3 数据结构 36 2.3.1 数组 36 面试题3：二维数组中的查找 38 2.3.2 字符串 42 面试题4：替换空格 44 O(n2)的解法，不足以拿到Offer 45 O(n)的解法，搞定Offer就靠它 46 2.3.3 链表 49 面试题5：从尾到头打印链表 51 2.3.4 树 53 面试题6：重建二叉树 55 2.3.5 栈和队列 58 面试题7：用两个栈实现队列 59 2.4 算法和数据操作 62 2.4.1 查找和排序 63 面试题8：旋转数组的最小数字 66 2.4.2 递归和循环 71 面试题9：斐波那契数列 73 效率很低的解法，面试官不会喜欢 73 面试官期待的实用解法 74 O(logn)但不够实用的解法 74 解法比较 75 2.4.3 位运算 77 面试题10：二进制中1的个数 78 可能引起死循环的解法 79 常规解法 79 能给面试官带来惊喜的解法 80 2.5 本章小结 82 第3章 高质量的代码 84 # 3.1 面试官谈代码质量 84 3.2 代码的规范性 86 3.3 代码的完整性 87 从3方面确保代码的完整性 87 3种错误处理的方法 88 面试题11：数值的整数次方 90 自以为题目简单的解法 90 全面但不够高效的解法，离Offer已经很近了 90 全面又高效的解法，确保能拿到Offer 92 面试题12：打印1到最大的n位数 94 跳进面试官陷阱 94 在字符串上模拟数字加法 94 把问题转换成数字排列 97 面试题13：在O(1)时间删除链表结点 99 面试题14：调整数组顺序使奇数位于偶数前面 102 只完成基本功能的解法，仅适用于初级程序员 102 考虑可扩展性的解法，能秒杀Offer 104 3.4 代码的鲁棒性 106 面试题15：链表中倒数第k个结点 107 面试题16：反转链表 112 面试题17：合并两个排序的链表 114 面试题18：树的子结构 117 3.5 本章小结 121 第4章 解决面试题的思路 123 # 4.1 面试官谈面试思路 123 面试题19：二叉树的镜像 125 4.2 画图让抽象问题形象化 125 面试题20：顺时针打印矩阵 127 4.3 举例让抽象问题具体化 131 面试题21：包含min函数的栈 132 面试题22：栈的压入、弹出序列 134 面试题23：从上往下打印二叉树 137 面试题24：二叉搜索树的后序遍历序列 140 面试题25：二叉树中和为某一值的路径 143 4.4 分解让复杂问题简单化 146 面试题26：复杂链表的复制 147 面试题27：二叉搜索树与双向链表 151 面试题28：字符串的排列 154 4.5 本章小结 158 第5章 优化时间和空间效率 160 # 5.1 面试官谈效率 160 5.2 时间效率 162 面试题29：数组中出现次数超过一半的数字 163 基于Partition函数的O(n)算法 163 利用数组特点的O(n)算法 165 解法比较 166 面试题30：最小的k个数 167 O(n)的算法，只当可以修改输入数组时可用 167 O(nlogk)的算法，适合处理海量数据 168 解法比较 169 面试题31：连续子数组的最大和 171 举例分析数组的规律 171 应用动态规划法 173 面试题32：从1到n整数中1出现的次数 174 不考虑效率的解法，想拿Offer有点难 174 明显提高效率的解法，让面试官耳目一新 175 面试题33：把数组排成最小的数 177 5.3 时间效率与空间效率的平衡 181 面试题34：丑数 182 逐个判断整数是不是丑数的解法 182 创建数组保存已经找到的丑数的解法 183 面试题35：第一个只出现一次的字符 186 面试题36：数组中的逆序对 189 面试题37：两个链表的第一个公共结点 193 5.4 本章小结 196 第6章 面试中的各项能力 198 # 6.1 面试官谈能力 198 6.2 沟通能力和学习能力 200 沟通能力 200 学习能力 200 善于学习、沟通的人也善于提问 201 6.3 知识迁移能力 203 面试题38：数字在排序数组中出现的次数 204 面试题39：二叉树的深度 207 重复遍历结点的解法，不足以打动面试官 209 只遍历结点一次的解法，正是面试官喜欢的 209 面试题40：数组中只出现一次的数字 211 面试题41：和为s的两个数字VS和为s的连续正数序列 214 面试题42：翻转单词顺序 VS左旋转字符串 218 6.4 抽象建模能力 222 面试题43：n个骰子的点数 223 基于递归求骰子点数，时间效率不够高 223 基于循环求骰子点数，时间性能好 224 面试题44：扑克牌的顺子 226 面试题45：圆圈中最后剩下的数字 228 经典的解法，用循环链表模拟圆圈 229 创新的解法，拿到Offer不在话下 230 6.5 发散思维能力 232 面试题46：求1+2+…+n 233 利用构造函数求解 234 利用虚函数求解 234 利用函数指针求解 235 利用模板类型求解 236 面试题47：不用加减乘除做加法 237 面试题48：不能被继承的类 239 常规的解法：把构造函数设为私有函数 239 新奇的解法：利用虚拟继承 240 6.6 本章小结 241 第7章 两个面试案例 243 # 7.1 案例一：（面试题49）把字符串转换成整数 244 7.2 案例二：（面试题50）树中两个结点的最低公共祖先 252 第8章 英文版新增面试题 261 # 8.1 数组 261 面试题51：数组中重复的数字 261 面试题52：构建乘积数组 263 8.2 字符串 265 面试题53：正则表达式匹配 265 面试题54：表示数值的字符串 267 面试题55：字符流中第一个不重复的字符 269 8.3 链表 270 面试题56：链表中环的入口结点 270 面试题57：删除链表中重复的结点 273 8.4 树 275 面试题58：二叉树的下一个结点 275 面试题59：对称的二叉树 277 面试题60：把二叉树打印成多行 278 面试题61：按之字形顺序打印二叉树 280 面试题62：序列化二叉树 283 面试题63：二叉搜索树的第k个结点 285 面试题64：数据流中的中位数 286 8.5 栈和队列 290 面试题65：滑动窗口的最大值 290 8.6 回溯法 294 面试题66：矩阵中的路径 294 面试题67：机器人的运动范围 296 2025-01-11 # leetcode 刷题 # 面试经典150题 # 面试经典150题 数组/字符串 # 合并两个有序数组 2025-01-12 移除元素 2025-01-11 删除有序数组中的重复项 2025-01-11 没有做出来，看的官方题解 2025-01-11 做完删除有序数组中的重复项 II之后再尝试重新解题完成 删除有序数组中的重复项 II 2025-01-11 多数元素 2025-01-12 轮转数组 2025-01-18 进阶 尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。 你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 买卖股票的最佳时机 2025-01-11 看官方题解做出来的 2025-01-17 review 买卖股票的最佳时机 II 官方题解 理解 2025-01-17 方法一：动态规划 方法二：贪心 跳跃游戏 2025-01-17 官方题解理解 贪心 2025-01-18 跳跃游戏 II 2025-01-18 算法超时了 理解官方题解 2025-01-18 方法一：反向查找出发位置 Solution45.jump2 2025-01-18 方法二：正向查找可达到的最大位置 Solution45.jump3 H 指数 2025-01-18 Tips An easy approach is to sort the array first. What are the possible values of h-index? A faster approach is to use extra space. O(1) 时间插入、删除和获取随机元素 除自身以外数组的乘积 加油站 分发糖果 接雨水 罗马数字转整数 2025-01-12 整数转罗马数字 最后一个单词的长度 2025-01-12 最长公共前缀 2025-01-12 反转字符串中的单词 2025-01-18 进阶 如果字符串在你使用的编程语言中是一种可变数据类型，请尝试使用 O(1) 额外空间复杂度的 原地 解法。 Z 字形变换 找出字符串中第一个匹配项的下标 2025-01-12 文本左右对齐 双指针 # 验证回文串 2025-01-13 判断子序列 2025-01-13 两数之和 II - 输入有序数组 2025-01-13 运行有时候会超过时间限制 盛最多水的容器 三数之和 滑动窗口 # 长度最小的子数组 2025-01-22 无重复字符的最长子串 2025-01-22 串联所有单词的子串 2025-01-22 最小覆盖子串 矩阵 # 有效的数独 2025-01-18 螺旋矩阵 2025-01-18 旋转图像 理解官方题解 2025-01-18 方法一：使用辅助数组 2025-01-18 方法二：原地旋转 有数学公式的推导，需要自己推导一次 2025-01-18 方法三：用翻转代替旋转 有数学公式的推导，需要自己推导一次 矩阵置零 2025-01-18 生命游戏 2025-01-18 进阶 你可以使用原地算法解决本题吗？请注意，面板上所有格子需要同时被更新：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。 本题中，我们使用二维数组来表示面板。原则上，面板是无限的，但当活细胞侵占了面板边界时会造成问题。你将如何解决这些问题？ ✅ 哈希表 # 赎金信 2025-01-13 同构字符串 2025-01-13 单词规律 2025-01-13 有效的字母异位词 2025-01-13 字母异位词分组 2025-01-16 第一遍算法超时，看了官方题解思路后实现通过 两数之和 2025-01-13 快乐数 2025-01-13 存在重复元素 II 2025-01-13 最长连续序列 2025-01-16 看了官方题解后完成 区间 # 栈 # 有效的括号 2025-01-22 简化路径 2025-01-22 最小栈 2025-01-22 理解官方题解 文字描述后完成 2025-01-22 理解官方题解 逆波兰表达式求值 2025-01-22 基本计算器 链表 # 环形链表 2025-01-20 理解官方题解 2025-01-20 方法一：哈希表 方法二：快慢指针 两数相加 2025-01-20 合并两个有序链表 2025-01-20 随机链表的复制 2025-01-20 反转链表 II 2025-01-20 K 个一组翻转链表 删除链表的倒数第 N 个结点 2025-01-20 进阶 2025-01-20 你能尝试使用一趟扫描实现吗？ 删除排序链表中的重复元素 II 2025-01-21 旋转链表 2025-01-20 分隔链表 2025-01-21 LRU 缓存 2025-01-22 理解官方题解 二叉树 # 二叉树的最大深度 2025-01-15 相同的树 2025-01-15 翻转二叉树 2025-01-15 对称二叉树 没做出来，看的官方题解 从前序与中序遍历序列构造二叉树 从中序与后序遍历序列构造二叉树 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表 路径总和 求根节点到叶节点数字之和 二叉树中的最大路径和 二叉搜索树迭代器 完全二叉树的节点个数 二叉树的最近公共祖先 二叉树层次遍历 # 二叉搜索树 # 图 # 图的广度优先搜索 # 字典树 # ✅ 回溯 # 电话号码的字母组合 2025-01-15 组合 2025-01-15 全排列 2025-01-15 组合总和 2025-01-15 N 皇后 II 2025-01-15 括号生成 2025-01-15 单词搜索 2025-01-15 分治 # kadane算法 # 二分查找 # 堆 # 位运算 # 二进制求和 2025-01-16 颠倒二进制位 2025-01-16 没做出来, 参考这篇文章LeetCode 190. 颠倒二进制位 （位运算 分治） 2025-01-17 复习了一遍 2025-01-17 新增了中间值打印的代码在算法中 位1的个数 2025-01-17 只出现一次的数字 2025-01-17 只出现一次的数字 II 2025-01-17 理解了官方题解 方法2 数字范围按位与 2025-01-17 理解了官方题解 方法2 数学 # 回文数 2025-01-17 不将整数转为字符串来解决这个问题 加一 2025-01-17 阶乘后的零 2025-01-17 x 的平方根 2025-01-17 Pow(x, n) 2025-01-17 超时了 2025-01-17 看懂了官方题解 直线上最多的点数 2025-01-17 看了官方题解，但还是不太理解 一维动态规划 # 爬楼梯 2025-01-11 通过 多维动态规划 # 2025-01-09 # ✅ Spring实战 第6版 Book # 第1章 Spring 起步 1.1 什么是Spring 2025-01-09 1.2 初始化 spring 应用 2025-01-09 1.3 编写 Spring 应用 2025-01-09 1.4 俯瞰 Spring 风景线 2025-01-09 第2章 2.1 展现信息 2025-01-09 2.2 处理表单提交 2025-01-09 2.3 校验表单输入 2025-01-09 2.4 使用视图控制器 2025-01-09 2.5 选择视图模板库 2025-01-09 第3章 使用数据 3.1 2025-01-09 3.2 2025-01-11 3.3 2025-01-11 第4章 使用非关系型数据 4.1 2025-01-11 4.2 2025-01-11 第5章 保护Spring 5.1 2025-01-11 5.2 2025-01-11 5.3 2025-01-11 5.4 2025-01-11 5.5 2025-01-12 第6章 使用配置属性 6.1 2025-01-12 6.2 2025-01-12 6.3 2025-01-12 第7章 创建REST服务 7.1 2025-01-12 7.2 2025-01-12 7.3 2025-01-12 第8章 保护REST 8.1 2025-01-12 8.2 2025-01-12 8.3 2025-01-12 8.4 2025-01-12 第9章 发送异步消息 9.1 2025-01-13 9.2 2025-01-13 9.3 2025-01-13 第10章 Spring集成 10.1 2025-01-13 10.2 2025-01-13 10.3 2025-01-13 第11章 理解反应式编程 11.1 2025-01-13 11.2 2025-01-13 11.3 2025-01-13 第12章 开发反应式API 12.1 2025-01-13 12.2 2025-01-13 12.3 2025-01-13 12.4 2025-01-13 12.5 2025-01-13 第13章 反应式持久化数据 13.1 2025-01-14 13.2 2025-01-14 13.3 2025-01-14 第14章 使用RSocket 14.1 2025-01-14 14.2 2025-01-15 14.3 2025-01-15 第15章 部署Spring 15.1 2025-01-15 15.2 2025-01-15 15.3 2025-01-15 15.4 2025-01-15 第16章 管理Spring 16.1 2025-01-15 16.2 2025-01-15 16.3 2025-01-15 第17章 使用JMX监控Spring 17.1 2025-01-15 17.2 2025-01-15 17.3 2025-01-15 第18章 部署Spring 18.1 2025-01-15 18.2 2025-01-15 18.3 2025-01-15 18.4 2025-01-15 18.5 2025-01-15 JavaGuide 文档阅读 # JavaGuide 必看 面试准备 Java 计算机基础 数据库 开发工具 常用框架 Spring\u0026amp;Spring Boot MyBatis常见面试题总结 2025-01-09 太过总结性，需要看一些更基础的文章 Netty常见面试题总结 系统设计 分布式 高性能 高可用 2025-01-08 # 计算机教育中缺失的学期 # 计算机教育中缺失的学期 阮一峰博客阅读 # 阮一峰的网络日志 散文 观点与感想 算法与数学 开发者手册 理解计算机 JavaScript 计算机行业历史 周刊 创业 译文集 2025-01-05 # spring 基础知识点 视频 # B站大学终于把Spring做成动画片了，一周刷爆，2024最新版，学完即可面试，拿走不谢，学不会我退出IT圈！ 1 2025-01-05 Spring 是如何整合MyBatis管理Mapper接口的 2025-01-05 2 2025-01-06 3 2025-01-06 4 2025-01-06 5 2025-01-06 6 2025-01-06 7 2025-01-06 8 2025-01-06 9 2025-01-06 10 2025-01-06 11 (January 6, 2025 at 18:43:04 GMT+8) 12 (January 6, 2025 at 18:50:57 GMT+8) 13 (January 6, 2025 at 18:57:05 GMT+8) 14 (January 6, 2025 at 18:59:15 GMT+8) 15 2025-01-07 16 2025-01-07 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 100 2025-01-03 # 代码随想录 视频 # 代码随想录 数组 # 链表 # 哈希表 # 字符串 # 栈与队列 # 二叉树 # 1 理论基础 2025-01-09 2 递归遍历 (Leetcode 144, 145, 94) 2025-01-09 3 非递归遍历 2025-01-09 4 非递归遍历-中序 2025-01-11 5 层序遍历（广度优先搜索） 6 翻转二叉树 7 对称二叉树 8 二叉树的最大深度 9 二叉树的最小深度 10 完全二叉树节点的数量 11 平衡二叉树 12 二叉树的所有路径 13 左叶子之和 14 找左下角的值 15 路径总和 16 从中序和后序遍历序列构造二叉树 17 最大二叉树 18 合并二叉树 19 二叉搜索树中的搜索 (Leetcode 700) 2025-01-08 20 验证二叉搜索树 (Leetcode 98) 2025-01-08 21 二叉搜索树的最小绝对差 (Leetcode 530) 2025-01-08 22 二叉搜索树中的众数(Leetcode 501) 2025-01-09 23 二叉树的最近公共祖先(Leetcode 236) 2025-01-09 24 二叉搜索树的最近公共祖先 2025-01-09 25 二叉搜索树中的插入操作(Leetcode 701) 2025-01-09 26 删除二叉搜索树中的节点(Leetcode 450) 2025-01-09 27 修剪二叉搜索树 (Leetcode 669) 2025-01-09 28 将有序数组转换为二叉搜索树 (Leetcode 108) 2025-01-09 29 把二叉搜索树转换为累加树(Leetcode 538) 2025-01-09 ✅ 回溯法 # 1 理论篇 2025-01-03 2 组合问题（对应力扣题目：77.组合） 2025-01-03 3 组合问题的剪枝操作（对应力扣题目：77.组合）2025-01-03 4 回溯算法如何剪枝？| LeetCode：216.组合总和III 2025-01-03 5 LeetCode：17.电话号码的字母组合 2025-01-03 6 组合总和（对应「leetcode」力扣题目：39.组合总和） 2025-01-03 7 LeetCode:40.组合总和II 2025-01-03 8 分割回文串 2025-01-04 9 复原IP地址 2025-01-04 10 子集 （Leetcode 78） 2025-01-04 11 子集2（Leetcode 90） 2025-01-04 12 递增子序列（Leetcode 491） 2025-01-04 13 全排列（Leetcode 46） 2025-01-04 14 全排列2（Leetcode 47）2025-01-04 15 N皇后（Leetcode 51） 2025-01-05 16 解数独（Leetcode 37） 2025-01-05 ✅ 贪心算法 # 理论基础 2025-01-05 1 分发饼干 leetcode 455 2025-01-05 2 摆动序列 Leetcode 376 2025-01-05 3 最大子序和 2025-01-06 4 买卖股票最佳时机2 2025-01-06 5 跳跃游戏（Leetcode 55） 2025-01-06 6 跳跃游戏2 （Leetcode 45） 2025-01-06 这道题没听懂 7 K次取反后最大化的数组和 （Leetcode 1005） 2025-01-06 8 加油站（Leetcode 134） 2025-01-06 9 分发糖果（Leetcode 135） 2025-01-06 10 柠檬水找零（Leetcode 860） 2025-01-06 11 根据身高重建队列（Leetcode 406） 2025-01-06 12 用最少数量的箭引爆气球(Leetcode 452) 2025-01-06 13 无重叠区间(Leetcode 435) 2025-01-06 14 划分字母区间 (Leetcode 763) 2025-01-06 15 合并区间 （Leetcode 56） (January 7, 2025 at 15:18:40 GMT+8) 16 单调自增的数字（Leetcode 738）(January 7, 2025 at 15:41:59 GMT+8) 17 监督二叉树（Leetcode 968） (January 7, 2025 at 16:11:51 GMT+8) 动态规划 # 1 理论基础 (January 7, 2025 at 16:34:49 GMT+8) 2 斐波那契数列 （Leetcode 509） (January 7, 2025 at 16:46:54 GMT+8) 3 爬楼梯（Leetcode 70） (January 7, 2025 at 16:57:46 GMT+8) 4 使用最小花费爬楼梯 (Leetcode 746) 2025-01-08 5 不同路径 2025-01-08 6 不同路径2 (Leetcode 63) 2025-01-08 7 整数拆分 (Leetcode 343) 2025-01-08 这道题没太听懂 8 不同的二叉搜索树（Leetcode 96） 9 0-1背包问题理论基础 10 0-1背包问题之滚动数组 11 分割等和子集 12 最后一块石头的重量2 13 目标和 14 一和零 15 完全背包理论基础 16 零钱兑换2 17 组合综合4 18 零钱兑换 19 完全平方数 20 单词拆分 21 打家劫舍 22 打家劫舍2 23 打家劫舍3 24 买卖股票的最佳时机1 25 买卖股票的最佳时机2 26 买卖股票的最佳时机3 27 买卖股票的最佳时机4 28 买卖股票的最佳时机含冷冻期 29 买卖股票的最佳时机含手续费 30 最长递增子序列 31 最长连续递增序列 32 最长重复子数组 33 最长公共子序列 34 不相交的线 35 最大子序和 36 判断子序列 37 不同的子序列 38 两个字符串的删除操作 39 编辑距离 40 回文子串 42 最长回文子序列 单调栈 # 2024-11-14 # What I Wish Someone Told Me About Postgres 介绍了 postgresql 相关的一些知识点，可以看一看 The WIRED Guide to Protecting Yourself From Government Surveillance How a stubborn computer scientist accidentally launched the deep learning boom 可以了解到 辛顿、黄仁勋、李飞飞 的工作是如何推动神经网络的发展的 "},{"id":11,"href":"/post/life/movies-log/","title":"观影记录","section":"Life","content":" 观影记录 # 2025 # 虽然B站有枪版的鬼灭无限之城，但画质确实不太行，等有画质好的在看了 皮诺那么努力但还是在最后一届环法没有拿到一个赛段冠军，突围还是被无情超越了。他有一集里说，他有时候觉得自己配不上自己所得到的关注度，当一次次无法实现自己的目标时，你越来越难以自洽，听着挺感慨的。还有就是莫霍里奇突围得了冠军采访的时候说的那段话，真的不容易。皮德科克下坡超神赢了第一个环法赛段冠军，第二年无法真正担起英力士主将的角色，承受很大压力，但也没办法拿到更好的成绩。 2025-07-27 Sunday 逆风飞驰 S1 E6 2025-07-26 Saturday 逆风飞驰 S2 E8 2025-07-25 Friday 逆风飞驰 S2 E7 2025-07-24 Thursday 逆风飞驰 S2 E6 2025-07-23 Wednesday 逆风飞驰 S2 E5 2025-07-22 Tuesday 逆风飞驰 S2 E4 2025-07-21 Monday 逆风飞驰 S2 E3 2025-07-20 Sunday 逆风飞驰 S2 E2 2025-07-19 逆风飞驰 S2 E1 2025-07-11 我们与恶的距离2 2025-07-06 环法自行车赛：逆风飞驰 第三季 2025-06-06 盗钥匙的方法 一部喜剧，轻松愉快 2025-05-20 百变狸猫 2025-05-18 卧虎藏龙 2025-05-05 斯蒂芬 库里：被低估 2025-05-03 再见瓦城 2025-05-01 妇女参政论者 2025-02-05 全金属外壳 2025-02-04 超完美地狱 2025-02-03 良心护士 2025-02-02 网络谜踪2 2025-01-26 门徒 2025-01-23 东京爱情故事 2025-01-12 敦煌 1 2025-01-12 2 2025-01-15 3 2025-01-16 4 2025-01-18 5 2025-01-20 6 `` 7 `` 8 `` 9 `` 10 `` 2025-01-11 如果国宝会说话 第四季 东京爱情故事 1 2025-01-11 2 2025-01-12 3 2025-01-13 4 2025-01-15 5 2025-01-16 6 2025-01-17 7 2025-01-18 8 2025-01-19 9 2025-01-20 10 2025-01-22 11 `` 2025-01-10 飞屋环游记 2025-01-07 如果国宝会说话 第三季 2025-01-04 如果国宝会说话 第二季 2025-01-03 辛德勒的名单（2） 2025-01-02 四重奏 1 2025-01-02 2 2025-01-03 3 2025-01-04 4 2025-01-05 5 2025-01-06 6 2025-01-07 7 2025-01-08 8 2025-01-09 9 2025-01-10 10 2025-01-10 2025-01-01 如果国宝会说话 第一季 2024 # 2024-12-01 金色梦乡 2024-11-30 Better Call Saul S04E07 2024-11-29 Better Call Saul S04E06 2024-11-28 Better Call Saul S04E05 2024-11-27 Better Call Saul S04E03-04 2024-11-26 Better Call Saul S04E01-02 2024-11-25 Better Call Saul S03E09-10 2024-11-23 热血警探 铁雨 ⭐⭐⭐⭐ 2024-11-18 东邪西毒 终极版 2024-11-17 甲方乙方 2024-11-16 正义回廊 ⭐⭐⭐⭐ 有话好好说 ⭐⭐⭐⭐ 2024-11-15 Better Call Saul S03E07 Better Call Saul S03E08 2024-11-14 Better Call Saul S03E06 2024-11-13 Better Call Saul S03E05 2024-11-12 Better Call Saul S03E04 2024-11-12 Better Call Saul S03E02 Better Call Saul S03E03 2024-10-24 哈利波特与死亡圣器 下 2024-10-23 哈利波特与死亡圣器 上 2024-10-22 哈利波特与混血王子 2024-10-20 哈利波特与凤凰社 哈利波特与火焰杯 哈利波特与阿兹卡班的囚徒 2024-10-19 哈利波特与密室 哈利波特与魔法石 2024-10-07 燃情岁月 ⭐⭐⭐⭐ 抓娃娃 2024-10-06 赛德克巴莱 2024-10-05 名侦探柯南：百万美元的五棱星 2024-10-04 年会不能停 2024-09-17 市场法则 过季 ⭐⭐⭐⭐ 完美的日子 ⭐⭐⭐⭐⭐ 2024-09-15 幽灵公主 鬼灭之刃 那田蜘蛛山篇 鬼灭之刃 柱训练篇 鬼灭之刃 锻刀村篇 2024-09-08 不要抬头 2024-08-18 一部关于咖啡的电影 2024-07-14 鬼灭之刃 游郭篇 鬼灭之刃 无限列车篇 2024-07-07 朗读者 2024-06-15 环法自行车赛：逆风飞驰 第二季 2024-06-09 江湖儿女 2024-05-19 红猪 2024-05-12 繁花 2024-05-04 极速车王 2024-05-03 大佛普拉斯 芝加哥七君子审判 2024-04-22 寻梦环游记 2024-04-21 你想活出怎样的人生 2024-04-06 黄海 逃离乌托邦 2024-04-04 坠落的审判 2024-03-15 周处除三害 2024-03-13 巾帼枭雄之义海豪情 2024-02-20 新闻女王 2024-02-18 飞驰人生2 2024-02-09 阿尔法围棋 哈利波特20周年：回到霍格沃茨 2024-02-08 三大队 2024-01-20 土拨鼠之日 2024-01-10 请回答1988 2023 # 2023年5月2日 婚姻生活 2023年4月29日 惠子，凝视 ⭐⭐⭐⭐ 2023年3月18日 黑暗荣耀 第二季 2023年3月05日 乒乓 2023年2月12日 健听女孩 2023年1月30日 黑匣子 2023年1月29日 巴斯克·斯克鲁格斯的歌谣 2023年1月27日 马拉多纳2019 2023年1月26日 马拉多纳之死 2023年1月26日 打扰伯格曼 2023年1月26日 误杀瞒天记 2023年1月26日 我即闪电 2023年1月25日 风骚律师 第六季 ⭐⭐⭐⭐⭐ 2023年1月25日 宿敌 2023年1月24日 互联网之子 2023年1月22日 互联网之子 2023年1月22日 万圣节的新娘 2023年1月22日 伊卡洛斯 2023年1月22日 老师，您能坐我旁边吗？ 2022 # 2022年10月07日 真相捕捉 第二季 2022年10月03日 黑洞 2022年09月10日 六号车厢 ⭐⭐⭐⭐ 2022年08月10日 我的天才女友 第三季 2022年07月31日 命运喜欢恶作剧 2022年07月30日 人生大事 2022年07月26日 渔业阴谋 2022年02月08日 Tinder诈骗王 2022年02月07日 亢奋 第一季 2022年02月03日 情事 2022年02月03日 火口的两人 2022年02月03日 激情 2022年02月02日 偶然与想象 2022年02月02日 东城梦魇 2022年02月01日 2020去死 2022年01月31日 瀑布 2022年01月31日 天注定 2022年01月30日 T省的 84·85年 2022年01月30日 天道 2022年01月20日 405谋杀案 2022年01月19日 背靠背，脸对脸 2022年01月18日 黑炮事件 2022年01月17日 成瘾剂量 2022年01月09日 驾驶我的车 ⭐⭐⭐⭐ 2022年01月01日 踏雪寻梅 2021 # 2021年12月26日 困在时间里的父亲 2021年11月19日 扬名立万 2021年11月13日 不老奇事 2021年10月31日 沙丘 2021年10月31日 007:无暇赴死 2021年10月16日 长津湖 2021年10月10日 吗啡 2021年09月25日 峰爆 2021年09月22日 教室里的一头牦牛 2021年09月20日 无依之地 2021年09月03日 失控玩家 2021年08月29日 让子弹飞 2021年08月15日 心灵奇旅 2021年08月10日 脸庞，村庄 2021年08月07日 沉默的真相 2021年08月02日 隐秘的角落 2021年07月31日 花束般的恋爱 2021年07月30日 热带往事 2021年07月30日 大阪直美 2021年07月26日 俗女养成记 2021年07月07日 巴萨提的颜色 2021年07月04日 真心半解 2021年06月11日 过把瘾 2021年06月08日 射雕英雄传 2021年05月27日 茶馆 2021年05月16日 人间的条件 5,6 2021年05月15日 人间的条件 3,4 2021年05月14日 热带雨 人间的条件 1,2 2021年05月13日 南海十三郎 2021年05月11日 笨鸟 2021年05月10日 无言的山丘 2021年05月09日 恐怖分子 2021年05月08日 海滩的一日 2021年05月08日 麻将 2021年05月07日 青梅竹马 盲山 万箭穿心 2021年05月06日 倒霉性爱，发狂黄片 2021年05月05日 龙争虎斗 零水日 2021年05月04日 若水 2021年05月04日 剩女 2021-04-13 盗火者：中国教育改革调查 others # 【风骚律师杂谈】我爱你——86年 "},{"id":12,"href":"/post/others/english-learning/","title":"English Learning","section":"Others","content":" English Learning # lite cnn 纯文字版的cnn，没有图片 lite cnn China China Daily 中国官方最大的英语新闻网站？ voa special English 这个网站听 voa special 不用翻墙 rest of world 这个网站很有设计感 China verge Hacker News 技术文章也能学习英语 南华早报 bbc China quora 国外的知乎 log # 2025-01-07 2024-12-14 “羽绒服”英语怎么说？你绝对想不到！ 2025-01-07 2025-01-06 “年会”英文怎么说？“Year Meeting”还是“Annual Party？” 都错啦！ voa special English # voa special English others # 如何利用 AI 更好地学外语 A List Of Text-Only \u0026amp; Minimalist News Sites 2022 # Monkeypox outbreak 猴痘病毒爆发 Russia-Ukraine War November A projected \u0026ldquo;red wave\u0026rdquo; fizzled, as Republicans won a slim majority in the House, and Democrats held control of the United States Senate 随着共和党在众议院赢得微弱多数，民主党控制了美国参议院，预计中的“红色浪潮”落空了 2022-11-09 Why is Apple Rosetta 2 fast? 为什么 Apple Rosetta 2 速度很快？ October Elon Musk took control of Twitter, bringing to the social media giant a brash leadership style – along with thousands of layoffs 埃隆·马斯克 （Elon Musk） 控制了 Twitter，为这家社交媒体巨头带来了傲慢的领导风格——以及数千人的裁员 September Britain\u0026rsquo;s Queen Elizabeth II died in Scotland, at the age of 96. Her son Charles succeeded her as king 英国女王伊丽莎白二世在苏格兰去世，享年 96 岁。她的儿子查理继承了她的国王之位 August The FBI conducted a search of Mar-a-Lago, the home of former president Donald Trump, and found classified materials, including documents labeled \u0026ldquo;top secret.\u0026rdquo; 联邦调查局对前总统唐纳德·特朗普的家马阿拉歌庄园进行了搜查，发现了机密材料，包括标记为“绝密”的文件。 July Former Japanese prime minister Shinzo Abe was assassinated, just two days before that country\u0026rsquo;s parliamentary elections 日本前首相安倍晋三在该国议会选举前两天被暗杀 June The Supreme Court overturned Roe v. Wade, effectively criminalizing abortion in much of the nation 最高法院推翻了罗伊诉韦德案（Roe v. Wade），实际上在全国大部分地区将堕胎定为刑事犯罪。 May A gunman in Uvalde, Texas killed 19 students and two teachers at Robb Elementary School. It was the third-deadliest school shooting in U.S. history 德克萨斯州尤瓦尔迪的一名枪手在罗布小学杀死了 19 名学生和两名教师。这是美国历史上第三致命的校园枪击事件 2021 # December In December, tornadoes ripped through the South and Midwest, killing at least 91 people \u0026hellip; 12 月，龙卷风席卷南部和中西部，造成至少 91 人死亡\u0026hellip;\u0026hellip; October October brought the welcome news that the World Health Organization had endorsed the world\u0026rsquo;s first vaccine against malaria. 10 月带来了一个可喜的消息，即世界卫生组织批准了世界上第一种疟疾疫苗 September September saw the implementation of the Texas Heartbeat Act, which bans abortions after roughly six weeks. The Supreme Court has declined to block the law, saying it\u0026rsquo;s a question for lower courts. 9 月，德克萨斯州心跳法案 （Texas Heartbeat Act） 实施，该法案禁止在大约六周后堕胎。最高法院拒绝阻止这项法律，称这是下级法院的问题 August August saw the withdrawal of American troops from Afghanistan after a two-decade war that took the lives of over 2,400 U.S. service personnel. 8 月，美国军队在经历了二十年的战争后从阿富汗撤军，这场战争夺走了 2,400 多名美国军人的生命 July July brought the 32nd Summer Olympic games to Tokyo, a year after being postponed. The U.S. topped the medal count with 113. 第 32 届夏季奥运会在推迟一年后于 7 月在东京举行。美国以 113 枚奖牌位居榜首 June June saw the partial collapse of a 12-story condominium in Surfside, Florida, killing 98 residents. 6 月，佛罗里达州瑟夫赛德 （Surfside） 的一栋 12 层公寓部分倒塌，造成 98 名居民死亡 March The container ship Ever Given ran aground in the Suez Canal in March, holding up billions in trade. The ship was freed six days later. 3 月，集装箱船 Ever Given 在苏伊士运河搁浅，阻碍了数十亿美元的贸易。六天后，这艘船被释放 February In February, the United States formally re-joined the Paris Climate Agreement, an international treaty aimed at limiting global warming. 今年 2 月，美国正式重新加入旨在限制全球变暖的国际条约《巴黎气候协定》。 Janurary In January Joe Biden was inaugurated as our 46th president … 1 月，乔·拜登就任我们的第 46 任总统\u0026hellip;\u0026hellip; 2020 # The United Kingdom left the European Union; Brexit 2019 # Global SARS-Cov-2 (COVID-19) Pandemic Hong Kong Protests in 2019. 2019 年香港抗议活动 2018 # The Yellow Vests Movement in France 法国巴黎黄背心运动 World\u0026rsquo;s longest sea-crossing bridge: Hong Kong-Zhuhai-Macao Bridge The China-US trade War Started in 2018. 2018 年开始的中美贸易战 2015 # The Legalization of Same-Sex Marriage in the United States 美国同性婚姻合法化 2014 # Catastrophic Aviation Disasters of 2014. 2014 年的灾难性航空灾难 The Annexation of Crimea by Russia 俄罗斯吞并克里米亚 2012 # The “God Particle” Is (Probably) Discovered “上帝粒子”被发现 2011 # Japan’s 2011 Tōhoku Earthquake and Tsunami 日本 2011 年东北地震和海啸 Bin Laden Killed 本·拉登被击毙 2010 # Instagram was launched Apple Inc. releasd the first tablet touch screen computer iPad 2009-2017 # Barack Obama, the 44th U.S. President. The 1st African American President of the United States 2009 # Bitcoin 比特币\n2008 # **The credit and property value bubble collapses, Wall Street and other equities markets crash, demand evaporates, and a global economic recession ensues** 信用和财产价值泡沫破灭，华尔街和其他产权投资金融市场崩盘，因市场需求蒸发，导致全球性的经济衰退 2006 # The International Astronomical Union decides to remove Pluto from the list planets of the solar system 国际天文联会决定将冥王星从太阳系中除名 Twitter was launched 2005 # Facebook Youtube 2003 # USA invades Iraq 2002 # Latin no longer used in UK legal documents USA invades Afghanistan 2001 # Sep. 11 2001 New York City World Trade Center attacked fomer # 2000 International space station 1999 Alibaba 1998 Google 1996 clone 1994 Yahoo European Union 1991 1st web page From 1991 until now. The Information Revolution An era marked by the spread of telecommunications technology, especially with personal computers, the internet, the web-based economy, social media, smart phones, and greater cross-cultural mixing. Late-stage capitalism as inequalities increased. The rise of China. Death cults terrorize the world early in this era, and extremism poses a threat to global security. The threat of global conflict remains as leadership in North Korea, China, and Russia use outdated paradigms to justify policies that prepare their nations for military conflict with neighbors ( Ukraine, Georgia, Taiwan). Anti-democratic nationalist tendencies manifest in the United States (Trump), Brazil, Hungary, Poland, Turkey, the Philippines, China, Russia, Egypt, and elsewhere. But popular people’s movements for the environment, peace, and democracy (e.g., the Arab Spring, anti-global-warming activism, Black Lives Matter, Occupy Wall Street, Anti-Iraq-War) also manifest, and win some victories. Anthropocene global climate catastrophe threatens humanity. Mass extinctions begin. 这个时代代表着电信技术的普及，特别是在个人电脑、网路、电商经济、社交媒体、智能手机、以及更广泛的跨文化融合。晚期资本主义，不平等情况增加。中国的崛起，死亡邪教在这个世界造成。恐惧，极端主义也对全球的安全构成威胁。全球性的威胁冲突仍然存在北韩、中国和俄罗斯的领导阶层，他们使用不符合时代的政策，来证明准备与邻国之间（乌克兰、乔治亚、台湾）所发生的军事冲突的正当性。反民主之民族主义者倾向表现在美国（川普）、巴西、匈牙利、波兰、土耳其、菲律宾、中国、俄罗斯、埃及和其他地方。而民众为了保护环境、和平与民主而开展的运动（例如，阿拉伯之春、反全球暖化的激进主义、黑人的生命问题、占领华尔街和伊拉克战争）也得以体现，并赢得了一些胜利。在人类世，人们正面临着全球性气候灾难的威胁，这也是大灭绝的开始。 1991 1st Gulf War, USA invades Iraq following invasion of Kuwait 第一次波斯湾战争，美国攻击伊拉克接著入侵科威特 USSR collapse 苏联体制崩溃解体 Union of Soviet Socialist Republics 苏维埃社会主义共和国联盟 1990 Hubble space telescope 哈伯太空望远镜 1989 USSR quits Eastern Europe 苏联撤离东欧 Berlin wall falls 1988 USSR quits Afghanistan 1987 DNA convicts criminals 用DNA检测方式证明罪犯的罪行 1986 Shuttle Tragedy 航天飞机悲剧 1985 Ozone layer \u0026ldquo;hole\u0026rdquo; discovered 发现臭氧层破洞 1984 String Theory accepted as a possible unifying theory in physics 弦理论被接受的原因在于它有可能会成为物理中的大统一理论 1983 The Internet is Born 互联网诞生 1981 AIDS identified 辨认出爱滋病 Acquired Immunodeficiency Syndrome 获得性免疫缺陷综合征 1979 USSR invades Afghanistan China attacks Vietnam, but is repelled 1977 MRI 核磁共振摄影 Magnetic Resonance Imaging 1973 Roe v. Wade 罗诉韦德案 1972 Nixon Goes To China 尼克松访问中国 1970 String Theory \u0026ldquo;born\u0026rdquo; 1969 1st moon walk 人类首次登陆月球 1968 King Assassinated 马丁·路德·金遇刺 1967 Arab-Israeli \u0026ldquo;6-day war\u0026rdquo; 阿拉伯和以色列之间的“六日战争\u0026quot; 1966 Martin Luther King assassination 1963 John F. Kennedy Assassinated 肯尼迪遇刺 1962 Cuban Missile Crisis 古巴导弹危机 1961 Berlin Wall Built 柏林墙建成 1958 US Launches First Satellite 美国发射第一颗卫星 1953 The Dawn of DNA 1950 Credit cards 1949 Germany divided into East \u0026amp; West 1948 State of Israel founded First transistor 晶体管 1945 USA bombs Japan with two Atomic bombs UN founded 1939-1945 World War II 1935 Spanish Civil War 西班牙内战 Mao\u0026rsquo;s long march 长征 1932 Von Neumann develops foundation for Quantum Mechanics 冯・诺伊曼建立了量子力学的基础 1931 Empire State Building Completed 帝国大厦竣工 1927 Heisenberg, Uncertainty Principle 海森堡的不确定性原理 1920-1933 U.S. Prohibition 美国禁酒时期 1920 Schrödinger Equation, Quantum Theory emerges in modern form 薛定谔方程式，为现在量子力学中的基本方程式 1914-1918 World War I From 1912 end of Imperial China and start of Balkan wars to 1991, the end of the Cold War. The Age of Conflict 冲突时代 从西元1912年中国大情帝国衰亡和巴尔干战争开始，到西元1991年的冷战结束。 An era marked by the Mexican Revolution, the Russian Revolution, the Great War (1914-1918), the Great Influenza Pandemic, the Warlord Era in China, The War of Japanese Imperial Conquest, the Second World War, the Maoist Revolution in China, various anti-colonial wars, the Cold War, and all this while technology leaped ahead with computer-controlled machine tools carrying automation to new levels. Rudimentary automobiles and aircraft of the previous era transformed to a point where humans went to the moon. Air conditioning and television and radio changed culture as people spent more time indoors. Urbanization transformed society as fewer people lived on farms in rural areas. Electrification and the demand for power created a surge in the construction of power plants and infrastructure to extract fossil fuels and Uranium ores from the earth. 这个时代看到了墨西哥革命、俄罗斯革命、第一次世界大战（西元1914-1918年）、流感大流行、中国的军阀时代、日本的帝国战争、第二次世界大战、中国的毛派革命、 各种反殖民战争、冷战，在同时科技飞速的发展，提升到用电脑控制的自动化机器的新的水平。上一个时代，基本生活里的汽车和飞机，已转变为人类有能力登陆月球。随着冷气机、电视机和广播的普及，人们花费更多的时间待在室内。城市化改变了社会，因为在农村地区居住的人口减少了。电气化和对电力的需求，掀起一股建设发电厂的热潮，和从地球上开采化石燃料和铀矿石的基础设施。 "},{"id":13,"href":"/post/life/bilibili/","title":"bilibili","section":"Life","content":" bilibili # movies # 木鱼水心 电影广角镜 world # Yooupi食途 星球研究所 世茹很如意 digital # 那岩KJMX TESTV官方频道 黄杨ME cycling # Contayu_Cycling 道长说车 club100 周四青年 艾慕葡萄 table tennis # -我是派派- computer science # TheCW PegasusWang 神州数码云基地 Koala聊开源 JavaEE之Spring框架 开源社KAIYUANSHE 美团技术团队 技术胖 代码随想录 张老师和杜老师编程课 photography # 影视飓风 music # 94不曈 bilibili-knowledge # 量子位 柴知道 other # M2档案 "},{"id":14,"href":"/post/computer-science/java/concurrent/","title":"concurrent","section":"Java","content":" concurrent # synchronized # synchronized 的底层原理是什么？ # 基于 jvm 的 Monitor 机制 通过进入和退出 Monitor 对象来实现方法和代码块的同步 字节码指令 monitorenter 获取 Monitor 的所有权 monitorexit 释放 Monitor 的所有权 同步方法的实现 ACC_SYNCHRONIZED 标志：当方法被 synchronized 修饰时，JVM 会在方法常量池中设置 ACC_SYNCHRONIZED 标志。 调用方法时，JVM 检查该标志。如果设置了，线程必须先获取 Monitor 才能执行方法，执行完成后释放 Monitor 锁的优化 为了提升性能，JVM 对 synchronized 进行了优化，包括 偏向锁（Biased Locking）：当锁始终由同一线程持有时，JVM 会将锁标记为偏向锁，减少锁获取的开销 轻量级锁（Lightweight Locking）：当存在多个线程交替执行时，JVM 会将锁升级为轻量级锁，通过 CAS 操作减少阻塞 重量级锁（Heavyweight Locking）：当锁竞争激烈时，JVM 会将锁升级为重量级锁，依赖于操作系统的互斥量（Mutex）实现 自旋锁（Spin Locking）：当线程无法获取锁时，会进行有限次数的自旋尝试，避免直接进入阻塞状态 ConcurrentHashMap # ConcurrentLinkedHashMap # 比较 ConcurrentHash 和 ConcurrentLinkedHashMap # 在ConcurrentHashMap的基础上，增加了双向链表来维护插入顺序或访问顺序 支持LRU缓存淘汰策略，通过Weigher计算存储单元数，自动清理最近最少使用的数据 线程池 # 线程池的核心参数 # 核心线程数 corePoolSize 最大线程数 maximumPoolSize 空闲线程存活时间 keepAliveTime 时间单位 unit 任务队列 workQueue ArrayBlockingQueue 基于数组的有界队列 LinkedBlockingQueue 基于链表的无界队列 SynchronousQueue 不存储元素的队列，直接交给线程处理 PriorityBlockingQueue 支持优先级的无界队列 线程工厂 threadFactory 拒绝策略 handler AbortPolicy 抛弃任务并抛出异常 RejectedExecutionException DiscardPolicy 抛弃任务但不抛出异常 CallerRunsPolicy 由提交任务的线程自己执行任务 DiscardOldestPolicy 抛弃优先级最低的任务 线程池的关键参数，比如核心线程数、等待队列、拒绝策略，在创建的时候做什么考虑 # 核心线程数 任务类型 CPU密集型: CPU核数 + 1 IO密集型: CPU核数 * 2 最大线程数 默认设置为与核心线程数一致，减少创建线程和销毁线程的开销 等待队列 无界队列: 任务量稳定的场景, 但可能导致内存溢出 有界队列: 任务量波动的场景 同步队列: 适合任务量较少的场景 拒绝策略 任务重要性: 如果任务不能丢弃，使用 CallerRunsPolicy(由提交任务的线程自己执行任务) 系统容错性: 如果任务可以丢弃, 使用 DiscardPolicy(抛弃任务但不抛出异常) 和 DiscardOldestPolicy(抛弃优先级最低的任务) 线程空闲时间 任务波动性: 如果任务波动较大，可以设置较短的空闲时间，及时回收线程 如果在出现任务峰值的时候，创建线程锁产生的开销要如何处理？ 线程工厂 线程命名: 自定义线程名称，便于监控与查询问题 线程优先级: 根据任务重要性设置线程优先级 线程池拒绝策略有哪些，你项目通常选用哪个，遇到重要场景触发拒绝策略必须需要处理任务你如何处理 # 线程池拒绝策略 AbortPolicy 抛异常 CallerRunsPolicy DiscardPolicy 不抛异常 DiscardOldestPolicy 项目中常用哪个？ 可以容忍丢失的情况 DiscardPolicy DiscardOldestPolicy 不允许有丢弃的情况：CallerRunsPolicy 重要场景触发拒绝策略的处理方法 使用 CallerRunsPolicy 自定义拒绝策略：增加自定义异常处理器，将拒绝的任务添加到外部的消息队列中，后续再进行提交 动态调整线程池的参数 监控线程池的状态，动态调整 corePoolSize, maximumPoolSize, queueCapacity, 以应对突发流量 如何实现动态线程池？ # 通过线程池的方法设置核心线程数、最大线程数、最大空闲时间 JDK 创建线程池有哪些方式 # 通过 Executors 工厂类创建 newFixedThreadPool newCachedThreadPool newSingleThreadExecutor newScheduledThreadPool newSingleThreadScheduledExecutor newWorkStealingPool 通过 ThreadPoolExecutor 手动指定参数创建 进程间通信 # 管道 Pipe 消息队列 Message Queue 共享内存 Shared Memory 信号 Signal kill 信号量 Semaphore 套接字 Socket 文件 File 内存映射文件 Memory-Mapped File 远程过程调用 RPC, Remote Procedure Call JUC # java.util.concurrent JUC 包下的7大类 # 原子变量类（java.util.concurrent.atomic 包） 用于实现无锁的线程安全操作，基于CAS（Compare and Swap）机制： AtomicInteger：原子操作的整型变量。 AtomicLong：原子操作的长整型变量。 AtomicBoolean：原子操作的布尔变量。 AtomicReference\u0026lt;V\u0026gt;：原子操作的引用类型变量。 AtomicStampedReference\u0026lt;V\u0026gt;：带版本戳的原子引用，解决ABA问题。 锁和同步器类（java.util.concurrent.locks 包） 提供更灵活的锁机制，替代传统的synchronized关键字： ReentrantLock：可重入锁，支持公平锁和非公平锁。 ReentrantReadWriteLock：读写锁，支持读多写少的场景。 StampedLock：基于邮戳的锁，提供乐观读锁。 Condition：条件变量，用于线程间的等待和唤醒。 并发集合类（java.util.concurrent 包） 线程安全的集合类，优化了高并发场景下的性能： ConcurrentHashMap：线程安全的哈希表，采用分段锁或CAS机制。 CopyOnWriteArrayList：写时复制的线程安全列表，适合读多写少的场景。 ConcurrentLinkedQueue：无界的线程安全队列，基于CAS实现。 同步工具类 用于线程间的协作和同步： CountDownLatch：计数器门闩，等待一组线程完成。 CyclicBarrier：循环栅栏，等待一组线程到达同步点。 Semaphore：信号量，控制同时访问资源的线程数量。 Phaser：更灵活的同步器，支持动态注册线程和多次同步。 线程池框架（java.util.concurrent 包） 用于管理线程的生命周期和任务调度： ExecutorService：线程池接口，提供任务提交、关闭等功能。 ThreadPoolExecutor：可自定义的线程池实现。 ScheduledExecutorService：支持定时任务和周期任务的线程池。 ForkJoinPool：用于分治算法和并行流的线程池。 阻塞队列类（java.util.concurrent 包） 线程安全的阻塞队列，用于生产者-消费者模型： ArrayBlockingQueue：基于数组的有界阻塞队列。 LinkedBlockingQueue：基于链表的无界阻塞队列。 PriorityBlockingQueue：支持优先级的无界阻塞队列。 其他工具类 Future\u0026lt;V\u0026gt;：表示异步计算的结果。 CompletableFuture\u0026lt;V\u0026gt;：支持异步编程的增强版Future。 Exchanger\u0026lt;V\u0026gt;：用于线程间交换数据的工具。 ThreadLocal # ThreadLocal 原理 # 每一个线程都维护一个对象副本，每个线程独立地访问和操作各自的副本 数据是保存在 Thread 父类的 ThreadLocalMap 中 锁 # Java里的锁有哪些 # 锁的类型 synchronized 内置锁 ReentrantLock 可重入锁 ReadWriteLock 读写锁 StampedLock 邮戳锁 Condition 条件锁 与ReentrantLock 配合使用，实现线程间的等待和唤醒 类似于 Object.wait() 和 Object.notify()，但更灵活 LockSupport Semaphore 信号量 CountDownLatch 倒计时锁 CyclicBarrier 循环屏障 Phaser 阶段锁 不同的锁的使用场景 简单场景：使用 synchronized 复杂场景：使用 ReentrantLock、ReadWriteLock 或 StampedLock 线程协作：使用 Condition、CountDownLatch、CyclicBarrier 或 Phaser 资源限制：使用 Semaphore 锁升级 # 锁升级的过程 # 锁机制根据竞争情况自动或手动调整锁的粒度和强度的过程，目的是在保证线程安全的同时优化性能 在Java中，锁升级特指synchronized关键字的优化机制。JDK 1.6后，为了减少锁操作的开销，JVM引入了偏向锁、轻量级锁、重量级锁三种状态，锁状态只能从低到高单向升级，不可降级 锁升级的4个阶段是什么？ # 无锁状态 共享对象没有被任何线程锁定 偏向锁 首次通过 synchronized 获取锁时，JVM讲锁标记为偏向锁 轻量级锁 当多线程竞争偏向锁时，JVM讲锁由偏向锁转换为轻量级锁 通过CAS实现 重量级锁 轻量级锁自旋失败（如自旋次数超过阈值）或高并发竞争激烈时 依赖操作系统的互斥量 Mutex 公平、非公平 # 什么是公平锁、非公平锁？ # 公平锁：线程根据申请锁的顺序获取锁 非公平锁：允许线程直接获取锁，而不用考虑申请锁的顺序 synchronized 是公平的还是不公平的？ # 不公平的 ReentrantLock 公平性 # 可以在构造可重入锁时指定是公平锁还是非公平锁 AQS AbstractQueuedSynchronizer的队列机制 FairSync 维护一个 FIFO 的队列 CAS # 什么是CAS # 一个原子性的硬件指令 compare and swap 比较并交换。多线程的场景下，只有一个线程能比较成功并交换值，其他线程比较失败不执行交换 AQS # 什么是AQS # AbstractQueuedSynchronizer 用于构造锁和同步器类的基础类 ReentrantLock Semaphore CountDownLatch AQS的核心概念是什么？ # 同步状态 等待队列 AQS的模板方法有哪些？ # tryAcquire tryRelease tryAcquireShared tryAcquireReleased ABA 问题 # ABA问题产生的原因是什么？ # 使用 CAS 实现无锁数据结构，因为CAS只关注数据是否一致，没有关注数据是否更改过 如何解决ABA问题？ # 使用版本号, 比如使用原子变量类AtomicStampedReference JDK提供的原子变量类会存在ABA问题吗？ # "},{"id":15,"href":"/post/life/cycling/","title":"cycling","section":"Life","content":" cycling # my log # 环滇池 # 9 2024-09-15 8 2023-11-11 7 2023-10-28 6 2023-10-22 5 2023-05-21 4 2022-12-31 3 2022-06-05 2 2022-03-20 1 2021-11-27 昆洛路-\u0026gt;彩云中路爬坡-\u0026gt;彩云北路 # 8 2025-01-07 7 2024-12-19 6 2024-12-18 5 2024-12-17 4 2024-12-13 3 2024-12-10 2 2024-12-06 1 2024-11-29 2024 # 2024-05-01 149.44km 阳宗海 2024-03-16 169.81km 环两湖失败 2023 # 2023-07-15 136.21km 梁王山 2023-04-30 150.06km 抚仙湖折返 2022 # 2022-05-28 131.56km 梁王山 2022-04-30 202.94km 抚仙湖 骑行路线 # 昆明 # 环滇池 宝花路 爬至小亭子 梁王山上坡 西山后山爬坡 松花坝水库爬坡 昭通 # 凤凰山 athlete # Tadej Pogacar # strava 2024-09-29 世锦赛冠军 2024-07-21 环法 stage 21 赛段冠军 2024-07-20 stage 20 赛段冠军 reference # pro cycling stats 自行车职业赛数据及积分排行查询 strava my_strava veloviewer "},{"id":16,"href":"/post/sports/cycling/","title":"cycling","section":"Sports","content":" pro cycling stats 自行车职业赛数据及积分排行查询 videos # 【2025 Donostia San Sebastian Klasikoa（圣塞巴斯蒂安） "},{"id":17,"href":"/post/computer-science/database/database/","title":"database","section":"Database","content":" database # 索引 index # 什么是聚集索引、非聚集索引？ # 聚集索引：数据行的物理存储顺序与索引的逻辑顺序一致 非聚集索引：数据行的物理存储顺序与索引的逻辑顺序不一致 为什么只能有一种聚集索引？ # 因为数据物理的存储顺序只能有一种，因此只能有一种聚集索引 默认的聚集索引是什么？ # 主键 什么是回表？ # 当查询条件使用普通索引并且查询的列不包含在索引中，就需要查询完普通索引后再去查询聚集索引的树拿到完整的行数据 当底层建了abc的联合索引，底层会建a,ab, abc这3个索引么？ # 不会，只创建一个联合索引树 联合索引（abc)，当查询ab, ac会走索引么？ # ab 走索引 ac 只走 a 索引 order by 和 group by 如何创建索引？ # order by 单列 直接创建 多列 创建联合索引, 索引顺序要和 order by 的顺序一致 不一致索引会失效 group by group by 实际上是先进行排序，再进行分组。所以遵循 order by 的索引机制 MySQL索引失效的20种场景 # MySQL索引失效的20种场景 1 查询条件未使用索引列 SELECT * FROM users WHERE non_indexed_column = 'example' 2 查询条件对索引列使用了函数或表达式 SELECT * FROM users WHERE LEFT(name, 3) = 'Ali' 3 数据类型不一致引发隐式类型转换 SELECT * FROM users WHERE phone = 1234567890; -- phone 是 VARCHAR 4 联合索引使用时的范围查询阻断 SELECT * FROM users WHERE name = 'Alice' AND age \u0026gt; 30 AND city = 'New York' 5 如果 OR 条件中有字段未使用索引，会导致整体索引失效 SELECT * FROM users WHERE name = 'Alice' OR age = 30; 解决方法：拆分查询，用 UNION 替代 SELECT * FROM users WHERE name = 'Alice' UNION SELECT * FROM users WHERE age = 30; 6 LIKE 查询中使用前置通配符 % 时，无法利用索引 SELECT * FROM users WHERE name LIKE '%Alice'; 解决方法 替换为后置通配符 LIKE \u0026lsquo;Alice%\u0026rsquo; 使用全文索引 ALTER TABLE users ADD FULLTEXT(name); SELECT * FROM users WHERE MATCH(name) AGAINST('Alice'); 7 不等值操作符 != \u0026lt;\u0026gt; 通常会导致索引失效 SELECT * FROM users WHERE age != 30; 解决方法：改写为范围查询 SELECT * FROM users WHERE age \u0026lt; 30 OR age \u0026gt; 30; 8 IN 子句中参数过多时，索引可能失效 SELECT * FROM users WHERE id IN (1, 2, ..., 10000) 解决方法：分批查询或控制 IN 参数数量 SELECT * FROM users WHERE id BETWEEN 1 AND 5000 9 某些情况下对NULL值的查询可能导致索引失效 SELECT * FROM users WHERE email IS NULL; 解决方法：避免使用 NULL，改为特定占位值 10 ORDER BY 和 GROUP BY 不符合索引顺序 select * from users order by age, name; 索引顺序为(name,age) 解决方法：调整查询或索引顺序一致 11 索引列未覆盖查询字段 select age from users where name = 'Alice' 解决方法：创建覆盖索引 alter table users add index(name, age) 12 表统计信息过期 表的统计信息不准确时，MySQL优化器可能错误选择全表扫描 解决方法：定期更新统计信息 ANALYZE TABLE users 13 数据分布不均 select * from users where gender = 'M' -- gender 列 90% 的值相同 解决方法：优化查询字段或调整数据分布 14 子查询未优化 子查询结果集过大时，索引失效 SELECT * FROM users WHERE id IN (SELECT user_id FROM orders WHERE total \u0026gt; 100) 解决方法：改为 JOIN 查询 SELECT u.* FROM users u JOIN orders o ON u.id = o.user_id WHERE o.total \u0026gt; 100 15 锁机制干扰 间隙锁 描述：间隙锁可能阻止索引的高效使用 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE 解决方法：降低事务隔离级别至 Read Committed(读已提交) 可重复读加上间隙锁防止幻读 16 索引被动态调整 MySQL优化器动态调整索引，可能选择非最佳索引或直接全表扫描 SELECT * FROM users FORCE INDEX (idx_name) WHERE name = 'Alice' 17 聚合函数未走索引 使用聚合函数(如 COUNT, SUM) 时，索引可能无法被利用 SELECT COUNT(*) FROM users WHERE age \u0026gt; 30 解决方法：利用覆盖索引 ALTER TABLE users ADD INDEX(age) 18 使用了非等值JOIN select * from users u join orders o on u.id \u0026gt; o.user_id 优化连接条件，尽量使用等值连接 19 小表全表扫描替代索引扫描 对于非常小的表，MySQL优化器可能选择全表扫描而非索引 SELECT * FROM small_table WHERE id = 1; 解决方法：无需优化，小表全表扫描的代价通常可以忽略 20 分区表查询不走全局索引 分区表的查询条件不覆盖分区键时，全局索引可能无法生效 SELECT * FROM partitioned_users WHERE city = 'New York' 解决方法：在分区键上创建局部索引 分区表的索引如何创建 # 分区 # 分表和分区在物理存储上有什么区别？ # 在数据库中一张表对应磁盘中的2个文件，拓展名为idb的文件和拓展名为frm的文件，idb文件存储表中的记录，frm存储表的结构信息 进行分表的话有几张表就有几个对应的文件，进行分区就只有一个frm文件和若干个idb文件，一个分区对应一个idb文件 分区能提升大表的读写性能就是因为根据分区规则仅仅扫描对应分区的磁盘文件，而不用进行全表扫描 一张表最多可以分多少个区？ # 1024 事务 # 数据隔离级别 # 读未提交 Read Uncommitted 读已提交 Read Committed 脏读：同一个事务中，多次读取同一数据的结果不同 可重复读 Repeatable Read 幻读：同一个事务中，相同的查询条件读取到的数据条数不一样 串行化 Serializable MVCC # MVCC 的全称是什么？ # Multi-Version Concurrency Control 多版本并发控制 MySQL的事务引擎仅仅使用行级锁吗？ # 不是，它结合了行级锁+MVCC(多版本并发控制) MVCC适用于哪些隔离级别？ # 适用于 REPEATED READ 和 READ COMMITTED 不适用于 READ UNCOMMITTED "},{"id":18,"href":"/post/computer-science/distributed-system/distributed-system/","title":"distributed system","section":"Distributed System","content":" distributed system # 微服务和分布式的比较 # 微服务架构和分布式架构是现代软件系统中两种重要的设计模式 分布式架构 分布式架构是指将系统组件部署在不同的物理或虚拟节点上，通过网络协作完成任务。其核心目标是解决性能、可扩展性、容错性等问题，例如通过负载均衡、数据分片等技术提升系统吞吐能力 典型场景：分布式数据库（如Cassandra）、分布式计算（如Spark） 适合需要高性能、高可用性的场景，如大规模数据处理、高并发请求 微服务架构 微服务是一种将单体应用拆分为多个小型、独立服务的架构风格，每个服务围绕特定业务功能构建，通过轻量级通信（如HTTP/REST、gRPC）交互。核心目标是提升开发效率、灵活性和可维护性，解决业务复杂度问题 典型场景：电商平台（订单、库存等独立服务）。 适合业务复杂、需快速迭代的系统，尤其是多团队协作开发时 分布式是手段：通过物理分散提升系统能力 微服务是策略：通过逻辑拆分优化开发和维护 选择依据： 若需解决性能瓶颈，优先考虑分布式 若需应对业务复杂性，选择微服务 "},{"id":19,"href":"/post/computer-science/database/druid/","title":"druid","section":"Database","content":" druid # Spring Boot 整合 Druid 指南 SpringBoot——开启Druid监控统计功能(SQL监控、慢SQL记录、Spring监控、去广告) SpringBoot - 开启Druid监控统计功能教程（SQL监控、慢SQL记录、去广告） 这个有用，配置要全部加上，不能漏了 "},{"id":20,"href":"/post/computer-science/front-end/echarts/","title":"echarts","section":"Front End","content":" echarts # PPChart "},{"id":21,"href":"/post/computer-science/database/elasticsearch/","title":"elasticsearch","section":"Database","content":" ElasticSearch # 使用场景 # 场景1 全文搜索Elasticsearch 凭借其强大、可扩展和快速的搜索功能，在全文搜索场景中表现出色。它允许用户以近乎实时的响应执行复杂的查询 场景2 实时分析Elasticsearch 能够实时执行分析，因此适用于跟踪实时数据（如用户活动、交易或传感器输出）的仪表板 场景3 机器学习通过在 X-Pack 中添加机器学习功能，Elasticsearch 可以自动检测数据中的异常、模式和趋势 场景4 地理数据应用程序Elasticsearch 通过地理空间索引和搜索功能支持地理数据。这对于需要管理和可视化地理信息的应用程序（如地图和基于位置的服务）非常有用 场景5 日志和事件数据分析组织使用 Elasticsearch 来聚合、监控和分析来自各种来源的日志和事件数据。它是 ELK 堆栈（Elasticsearch、Logstash、Kibana）的关键组件，用于管理系统和应用程序日志以识别问题和监控系统运行状况 场景6 安全信息和事件管理 （SIEM）Elasticsearch 可用作 SIEM 工具，帮助组织实时分析安全事件 "},{"id":22,"href":"/post/computer-science/github/","title":"github","section":"Computer Science","content":" github # Github Action # GitHub Actions 入门教程 repository # torvalds/linux CesiumGS/cesium CesiumJS is a JavaScript library for creating 3D globes and 2D maps in a web browser without a plugin. It uses WebGL for hardware-accelerated graphics, and is cross-platform, cross-browser, and tuned for dynamic-data visualization. ohmyzsh/ohmyzsh Oh My Zsh is an open source, community-driven framework for managing your zsh configuration. duanluan/zutil 追求更快更全的 Java 工具类 文档 binarywang/Linux-Tutorial Java 程序员眼中的 Linux algorithm-practice # algorithm-practice dataStructure # com.penruins.dataStructure PriorityQueueDemo # demo1 PriorityQueue 默认为最小堆 如果 PriorityQueue 中没有元素了，则返回 null demo2 自定义一个比较器实现最大堆 follow # oldratlee algorithm practice 剑指 offer # 第1章 整数 # 1.1 整数的基础知识 # 面试题1：整数除法 # 1.2 二进制 # 面试题2：二进制加法 # 面试题3：前n个数字二进制形式中1的个数 # 简单计算每个整数的二进制形式中1的个数 # 根据“i\u0026amp;（i-1）”计算i的二进制形式中1的个数 # 根据“i/2”计算i的二进制形式中1的个数 # 面试题4：只出现一次的数字 # 面试题5：单词长度的最大乘积 # 用哈希表记录字符串中出现的字符 # 用整数的二进制数位记录字符串中出现的字符 # 1.3 本章小结 # 第2章 数组 # 2.1 数组的基础知识 # 2.2 双指针 # 面试题6：排序数组中的两个数字之和 # 面试题7：数组中和为0的3个数字 # 面试题8：和大于或等于k的最短子数组 # 面试题9：乘积小于k的子数组 # 2.3 累加数组数字求子数组之和 # 面试题10：和为k的子数组 # 面试题11：0和1个数相同的子数组 # 面试题12：左右两边子数组的和相等 # 面试题13：二维子矩阵的数字之和 # 2.4 本章小结 # 第3章 字符串 # 3.1 字符串的基础知识 # 3.2 双指针 # 面试题14：字符串中的变位词 # 面试题15：字符串中的所有变位词 # 面试题16：不含重复字符的最长子字符串 # 需要多次遍历整个哈希表的解法 # 避免多次遍历整个哈希表的解法 # 面试题17：包含所有字符的最短字符串 # 3.3 回文字符串 # 面试题18：有效的回文 # 面试题19：最多删除一个字符得到回文 # 面试题20：回文子字符串的个数 # 3.4 本章小结 # 第4章 链表 # 4.1 链表的基础知识 # 4.2 哨兵节点 # 用哨兵节点简化链表插入操作 # 用哨兵节点简化链表删除操作 # 4.3 双指针 # 面试题21：删除倒数第k个节点 # 面试题22：链表中环的入口节点 # 需要知道环中节点数目的解法 # 不需要知道环中节点数目的解法 # 面试题23：两个链表的第1个重合节点 # 4.4 反转链表 # 面试题24：反转链表 # 面试题25：链表中的数字相加 # 面试题26：重排链表 # 面试题27：回文链表 # 4.5 双向链表和循环链表 # 面试题28：展平多级双向链 # 面试题29：排序的循环链表 # 4.6 本章小结 # 第5章 哈希表 # 5.1 哈希表的基础知识 # 5.2 哈希表的设计 # 5.3 哈希表的应用 # 5.4 本章小结 # 第6章 栈 # 6.1 栈的基础知识 # 6.2 栈的应用 # 面试题36：后缀表达式 # 面试题37：小行星碰撞 # 面试题38：每日温度 # 面试题39：直方图最大矩形面积 # 蛮力法 # 分治法 # 单调栈法 # 面试题40：矩阵中的最大矩形 # 6.3 本章小结 # 第7章 队列 # 7.1 队列的基础知识 # 7.2 队列的应用 # 面试题41：滑动窗口的平均值 # 面试题42：最近请求次数 # 7.3 二叉树的广度优先搜索 Solution0703001 # 广度优先搜索 # public List\u0026lt;Integer\u0026gt; bfs(TreeNode root){ Queue\u0026lt;TreeNode\u0026gt; queue=new LinkedList\u0026lt;\u0026gt;(); if(root!=null){ queue.offer(root); } List\u0026lt;Integer\u0026gt; result=new ArrayList\u0026lt;\u0026gt;(); while(!queue.isEmpty()){ TreeNode node=queue.poll(); result.add(node.val); if(node.left!=null) queue.offer(node.left); if(node.right!=null) queue.offer(node.right); } return result; } 面试题43：在完全二叉树中添加节点 # // CBT Complete Binary Tree class CBTInserter { private Queue\u0026lt;TreeNode\u0026gt; queue; private TreeNode root; public CBTInserter(TreeNode root) { this.root = root; queue = new LinkedList\u0026lt;\u0026gt;(); while (queue.peek().left != null \u0026amp;\u0026amp; queue.peek().right != null) { TreeNode node = queue.poll(); queue.offer(node.left); queue.offer(node.right); } } public int insert(int v) { TreeNode parent = queue.peek(); TreeNode node = new TreeNode(v); if (parent.left == null) { parent.left = node; } else { parent.right = node; queue.poll(); queue.offer(parent.left); queue.offer(parent.right); } return parent.val; } public TreeNode get_root() { return this.root; } } 面试题44：二叉树中每层的最大值 # 用一个队列实现二叉树的广度优先搜索 # public List\u0026lt;Integer\u0026gt; largestValues(TreeNode root){ int current=0; int next=0; Queue\u0026lt;TreeNode\u0026gt; queue=new LinkedList\u0026lt;\u0026gt;(); if(root!=null){ queue.offer(root); current=1; } List\u0026lt;Integer\u0026gt; result=new LinkedList\u0026lt;\u0026gt;(); int max=Integer.MIN_VALUE; while(!queue.isEmpty()){ TreeNode node=queue.poll(); current--; max=Math.max(max.node.val); if(node.left!=null){ queue.offer(node.left); next++; } if(node.right!=null){ queue.offer(node.right); next++; } if(current==0){ result.add(max); max=Integer.MIN_VALUE; current=next; next=0; } } return result; } 用两个队列实现二叉树的广度优先搜索 # public List\u0026lt;Integer\u0026gt; largestValues(TreeNode root){ Queue\u0026lt;TreeNode\u0026gt; queue1=new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2=new LinkedList\u0026lt;\u0026gt;(); if(root!=null){ queue1.offer(root); } List\u0026lt;Integer\u0026gt; result=new LinkedList\u0026lt;\u0026gt;(); int max=Math.max(max,node.val); if(node.left!=null){ queue2.offer(node.left); } if(node.right!=null){ queue2.offer(node.right); } if(queue1.isEmpty()){ result.add(max); max=Integer.MIN_VALUE; queue1=queue2; queue2=new LinkedList\u0026lt;\u0026gt;(); } return result; } 面试题45：二叉树最低层最左边的值 # public int findBottomLeftValue(TreeNode root){ Queue\u0026lt;TreeNode\u0026gt; queue1=new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2=new LinkedList\u0026lt;\u0026gt;(); queue1.offer(root); int bottomLeft=root.val; while(!queue.isEmpty()){ TreeNode node=queue1.poll(); if(node.left!=null){ queue2.offer(node.left); } if(node.right!=null){ queue2.offer(node.right); } if(queue1.isEmpty()){ queue1=queue2; queue2=new LinkedList\u0026lt;\u0026gt;(); if(!queue1.isEmpty()){ bottomLeft=queue1.peek().val; } } } return bottomLeft; } 面试题46：二叉树的右侧视图 # public List\u0026lt;Integer\u0026gt; rightSideView(TreeNode root){ List\u0026lt;Integer\u0026gt; view=new LinkedList\u0026lt;\u0026gt;(); if(root==null){ return view; } Queue\u0026lt;TreeNode\u0026gt; queue1=new LinkedList\u0026lt;\u0026gt;(); Queue\u0026lt;TreeNode\u0026gt; queue2=new LinkedList\u0026lt;\u0026gt;(); queue1.offer(root); while(!queue1.isEmpty()){ TreeNode node=queue1.poll(); if(node.left!=null){ queue2.offer(node.left); } if(node.right!=null){ queue2.offer(node.right); } if(queue1.isEmpty()){ view.add(node.val); queue1=queue2; queue2=new LinkedList\u0026lt;\u0026gt;(); } } return view; } 7.4 本章小结 # 第8章 树 # 8.1 树的基础知识 # public class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } 8.2 二叉树的深度优先搜索 # 中序遍历 # public List\u0026lt;Integer\u0026gt; inorderTraversal(){ List\u0026lt;Integer\u0026gt; nodes=new LinkedList\u0026lt;\u0026gt;(); dfs(root,nodes); return nodes; } private void dfs(TreeNode root,List\u0026lt;Integer\u0026gt; nodes){ if(root!=null){ dfs(root.left,nodes); nodes.add(root.val); dfs(root.right,nodes); } } 迭代 # // left -\u0026gt; current -\u0026gt; right public List\u0026lt;Integer\u0026gt; inorderTraversal(TreeNode root){ List\u0026lt;Integer\u0026gt; nodes=new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack=new Stack\u0026lt;\u0026gt;(); TreeNode cur=root; while(cur!=null||!stack.isEmpty()){ while(cur!=null){ stack.push(cur); cur=cur.left; } cur=stack.pop(); nodes.add(cur.val); // current node cur=cur.right; } return nodes; } 前序遍历 # public List\u0026lt;Integer\u0026gt; preorderTraversal(TreeNode root){ List\u0026lt;Integer\u0026gt; nodes=new LinkedList\u0026lt;\u0026gt;(); dfs(root,nodes); return nodes; } private void dfs(TreeNode root,List\u0026lt;Integer\u0026gt; nodes){ if(root!=null){ nodes.add(root.val); dfs(node.left,nodes); dfs(node.right,nodes); } } 迭代 # // current -\u0026gt; left -\u0026gt; right public List\u0026lt;Integer\u0026gt; preorderTraversal(TreeNode root){ List\u0026lt;Integer\u0026gt; result=new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack=new Stack\u0026lt;\u0026gt;(); TreeNode cur=root; if(cur!=null||!stack.isEmpty()){ while(cur!=null){ result.add(cur.val); // current node stack.push(cur); cur=cur.left; } cur=stack.pop(); cur=cur.right; } return result; } 后序遍历 # 迭代 # public List\u0026lt;Integer\u0026gt; postorderTraversal(TreeNode root){ List\u0026lt;Integer\u0026gt; result=new LinkedList\u0026lt;\u0026gt;(); Stack\u0026lt;TreeNode\u0026gt; stack=new Stack\u0026lt;\u0026gt;(); TreeNode cur=root; TreeNode prev=null; while(cur!=null||!stack.isEmpty()){ while(cur!=null){ stack.push(cur); cur=cur.left; } cur=stack.peek(); if(cur.right!=null\u0026amp;\u0026amp;cur.right!=prev){ }else{ stack.pop(); result.add(cur.val); prev=cur; cur=null; } } return result; } 3种遍历方法小结 # 面试题47：二叉树剪枝 # public TreeNode pruneTree(TreeNode root){ if(root==null){ return root; } root.left=pruneTree(root.left); root.right=pruneTree(root.right); if(root.left==null\u0026amp;\u0026amp;root.right==null\u0026amp;\u0026amp;root.val==0){ return null; } return root; } 面试题48：序列化和反序列化二叉树 # 序列化 # public String serialize(TreeNode root){ if(root==null){ return\u0026#34;#\u0026#34;; } String leftStr=serialize(root.left); String right=serialize(root.right); return String.valueOf(root.val)+\u0026#34;,\u0026#34;+leftStr+\u0026#34;,\u0026#34;+rightStr; } 反序列化 # public TreeNode deserialize(String data){ String[]nodeStrs=data.split(\u0026#34;,\u0026#34;); int[]i={0}; return dfs(nodeStrs,i); } private TreeNode dfs(String[]strs,int[]i){ String str=strs[i[0]]; i[0]++; if(str.equals(\u0026#34;#\u0026#34;)){ return null; } TreeNode node=new TreeNode(Integer.valueOf(str)); node.left=dfs(strs,i); node.right=dfs(strs,i); return node; } 面试题49：从根节点到叶节点的路径数字之和 # public int sumNumbers(TreeNode root){ return dfs(root,0); } private int dfs(TreeNode root,int path){ if(root==null){ return 0; } path=path*10+root.val; if(root.left==null\u0026amp;\u0026amp;root.right==null){ return path; } return dfs(root.left,path)+dfs(root.right,path); } 面试题50：向下的路径节点值之和 # public int pathSum(TreeNode root,int sum){ Map\u0026lt;Integer, Integer\u0026gt; map=new HashMap\u0026lt;\u0026gt;(); map.put(0,1); return dfs(root,sum,map,0); } private int dfs(TreeNode root,int sum, Map\u0026lt;Integer, Integer\u0026gt; map,int path){ if(root==null){ return 0; } path+=root.val; int count=map.getOrDefault(path-sum,0); } 面试题51：节点值之和最大的路径 # 8.3 二叉搜索树 # 面试题52：展平二叉搜索树 # 面试题53：二叉搜索树的下一个节点 # 时间复杂度O(n)的解法 # 时间复杂度O(h)的解法 # 面试题54：所有大于或等于节点的值之和 # 面试题55：二叉搜索树迭代器 # 面试题56：二叉搜索树种两个节点的值之和 # 利用哈希表，空间复杂度为O（n）的解法 # 应用双指针，空间复杂度为O（h）的解法 # 8.4 TreeSet和TreeMap的应用 # 面试题57：值和下标之差都在给定的范围内 # 时间复杂度为O（nlogk）的解法 # 时间复杂度为O（n）的解法 # 面试题58：日程表 # 8.5 本章小结 # 第9章 堆 # 9.1 堆的基础知识 # 9.2 堆的应用 # ✅ 面试题59：数据流的第k大数字 JZOffer59.java # ✅ 面试题60：出现频率最高的k个数字 JZOffer60.java # ✅ 面试题61：和最小的k个数对 JZOffer61.java # 使用最大堆 # 使用最小堆 # kSmallestPairs 9.3 本章小结 # 第10章 前缀树 # 10.1 前缀树的基础知识 # ✅ 面试题62：实现前缀树 JZOffer62.java # 10.2 前缀树的应用 # ✅ 面试题63：替换单词 JZOffer63.java # 面试题64：神奇的字典 # 面试题65：最短的单词编码 # 面试题66：单词之和 # 面试题67：最大的异或 # 10.3 本章小结 # 第11章 二分查找 # 11.1 二分查找的基础知识 # ✅ 二分查找算法 com.penruins.JZOffer.BinarySearch.java # 11.2 在排序数组中二分查找 # 面试题68：查找插入位置 # 面试题69：山峰数组的顶部 # 面试题70：排序数组中只出现一次的数字 com.penruins.JZOffer.JZOffer70.java # singleNonDuplicate 用异或运算的方式实现 面试题71：按权重生成随机数 # 11.3 在数值范围内二分查找 # 面试题72：求平方根 # 面试题73：狒狒吃香蕉 # 11.4 本章小结 # 第12章 排序 # 12.1 排序的基础知识 # 面试题74：合并区间 # 12.2 计数排序 # 面试题75：数组相对排序 # 12.3 快速排序 # 快速排序算法 com.penruins.JZOffer.QuickSort # 面试题76：数组中第k大的数字 # 12.4 归并排序 # 面试题77：链表排序 # 面试题78：合并排序链表 # 利用最小堆选取值最小的节点 # 按照归并排序的思路合并链表 # 12.5 本章小结 # 第13章 回溯法 # 13.1 回溯法的基础知识 # 13.2 集合的组合、排列 # 13.3 回溯法解决其他类型问题 # 13.4 本章小结 # 第14章 动态规划 # 14.1 动态规划的基础知识 # 14.2 单序列问题 # 14.3 双序列问题 # 14.4 矩阵路径问题 # 面试题98：路径的数目 # 分析确定状态转移方程 # 根据状态转移方程写递归代码 # 递归代码 # 优化空间效率 # 面试题99：最小路径之和 # 面试题100：三角形中最小路径之和 # 14.5 背包问题 # 0-1 背包问题 多重背包问题 完全背包问题 面试题101：分割等和子集 # 分析确定状态转移方程 # 根据状态转移方程写递归代码 # 根据状态转移方程写迭代代码 # 优化空间效率 # 面试题102：加减的目标值 # 面试题103：最小的硬币数目 # 分析确定状态转移方程 # 根据状态转移方程写代码 # 另一种思路 # 面试题104：排列的数目 # int[] nums = new int[1 2 3]; i = 3; f(i) = f(i - nums[0]) + f(i - nums[1]) + f(i - nums[2]); f(0) = 1; f(1) = f(0) + f(-1) + f(-2) = 1; f(2) = f(1) + f(0) + f(-1) = 2; f(3) = f(2) + f(1) + f(0) = 4; f(2) {1,1} {2} f(1) {1} f(0) {} 14.6 本章小结 # 第15章 图 305 # 15.1 图的基础知识 305 # 15.2 图的搜索 307 # 15.3 拓扑排序 333 # 15.4 并查集 342 # 15.5 本章小结 354 # 剑指offer这本书中每一道面试题对应leetcode的题目 # 《剑指Offer》是一本经典的编程面试书籍，其中包含了许多高质量的编程题目。很多题目与LeetCode上的题目有对应关系。以下是一些《剑指Offer》中的题目及其在LeetCode上的对应题目：\n1. 数组中重复的数字 # 剑指Offer题目：找出数组中重复的数字。 LeetCode对应题目：287. 寻找重复数 2. 二维数组中的查找 # 剑指Offer题目：在一个二维数组中查找某个数是否存在。 LeetCode对应题目：240. 搜索二维矩阵 II 3. 替换空格 # 剑指Offer题目：将字符串中的空格替换为\u0026quot;%20\u0026quot;。 LeetCode对应题目：剑指 Offer 05. 替换空格 4. 从尾到头打印链表 # 剑指Offer题目：从尾到头打印链表。 LeetCode对应题目：剑指 Offer 06. 从尾到头打印链表 5. 重建二叉树 # 剑指Offer题目：根据前序遍历和中序遍历的结果重建二叉树。 LeetCode对应题目 ：105. 从前序与中序遍历序列构造二叉树 6. 二叉树的下一个节点 # 剑指Offer题目：给定二叉树中的一个节点，找到中序遍历的下一个节点。 LeetCode对应题目：剑指 Offer 08. 二叉树的下一个节点 7. 用两个栈实现队列 # 剑指Offer题目：用两个栈实现队列。 LeetCode对应题目：232. 用栈实现队列 8. 斐波那契数列 # 剑指Offer题目：求斐波那契数列的第n项。 LeetCode对应题目：509. 斐波那契数 9. 旋转数组的最小数字 # 剑指Offer题目：在一个旋转数组中查找最小的数字。 LeetCode对应题目：153. 寻找旋转排序数组中的最小值 10. 矩阵中的路径 # 剑指Offer题目：在矩阵中查找是否存在某条路径。 LeetCode对应题目：79. 单词搜索 11. 机器人的运动范围 # 剑指Offer题目：计算机器人能够到达的格子数。 LeetCode对应题目：剑指 Offer 13. 机器人的运动范围 12. 剪绳子 # 剑指Offer题目：将绳子剪成若干段，使得乘积最大。 LeetCode对应题目：343. 整数拆分 13. 二进制中1的个数 # 剑指Offer题目：统计一个整数的二进制表示中1的个数。 LeetCode对应题目：191. 位1的个数 14. 数值的整数次方 # 剑指Offer题目：实现函数计算数值的整数次方。 LeetCode对应题目：50. Pow(x, n) 15. 打印从1到最大的n位数 # 剑指Offer题目：打印从1到最大的n位数。 LeetCode对应题目：剑指 Offer 17. 打印从1到最大的n位数 16. 删除链表的节点 # 剑指Offer题目：在O(1)时间内删除链表节点。 LeetCode对应题目：237. 删除链表中的节点 17. 正则表达式匹配 # 剑指Offer题目：实现正则表达式匹配。 LeetCode对应题目：10. 正则表达式匹配 18. 表示数值的字符串 # 剑指Offer题目：判断字符串是否表示数值。 LeetCode对应题目：剑指 Offer 20. 表示数值的字符串 19. 调整数组顺序使奇数位于偶数前面 # 剑指Offer题目：调整数组顺序，使奇数位于偶数前面。 LeetCode对应题目：905. 按奇偶排序数组 20. 链表中倒数第k个节点 # 剑指Offer题目：找到链表中倒数第k个节点。 LeetCode对应题目：剑指 Offer 22. 链表中倒数第k个节点 21. 反转链表 # 剑指Offer题目：反转链表。 LeetCode对应题目：206. 反转链表 22. 合并两个排序的链表 # 剑指Offer题目：合并两个排序的链表。 LeetCode对应题目：21. 合并两个有序链表 23. 树的子结构 # 剑指Offer题目：判断一棵树是否是另一棵树的子结构。 LeetCode对应题目：剑指 Offer 26. 树的子结构 24. 二叉树的镜像 # 剑指Offer题目：求二叉树的镜像。 LeetCode对应题目：226. 翻转二叉树 25. 对称的二叉树 # 剑指Offer题目：判断一棵二叉树是否是对称的。 LeetCode对应题目：101. 对称二叉树 26. 顺时针打印矩阵 # 剑指Offer题目：顺时针打印矩阵。 LeetCode对应题目：54. 螺旋矩阵 27. 包含min函数的栈 # 剑指Offer题目：实现一个包含min函数的栈。 LeetCode对应题目：155. 最小栈 28. 栈的压入、弹出序列 # 剑指Offer题目：判断一个序列是否是栈的弹出序列。 LeetCode对应题目：946. 验证栈序列 29. 从上到下打印二叉树 # 剑指Offer题目：从上到下打印二叉树。 LeetCode对应题目：102. 二叉树的层序遍历 30. 二叉搜索树的后序遍历序列 # 剑指Offer题目：判断一个序列是否是二叉搜索树的后序遍历序列。 LeetCode对应题目 ：剑指 Offer 33. 二叉搜索树的后序遍历序列 31. 二叉树中和为某一值的路径 # 剑指Offer题目：找到二叉树中路径和等于某个值的路径。 LeetCode对应题目：113. 路径总和 II 32. 复杂链表的复制 # 剑指Offer题目：复制复杂链表。 LeetCode对应题目：138. 复制带随机指针的链表 33. 二叉搜索树与双向链表 # 剑指Offer题目：将二叉搜索树转换为双向链表。 LeetCode对应题目 ：426. 将二叉搜索树转化为排序的双向链表 34. 序列化二叉树 # 剑指Offer题目：实现二叉树的序列化和反序列化。 LeetCode对应题目：297. 二叉树的序列化与反序列化 35. 字符串的排列 # 剑指Offer题目：输出字符串的所有排列。 LeetCode对应题目：剑指 Offer 38. 字符串的排列 36. 数组中出现次数超过一半的数字 # 剑指Offer题目：找到数组中出现次数超过一半的数字。 LeetCode对应题目：169. 多数元素 37. 最小的k个数 # 剑指Offer题目：找到数组中最小的k个数。 LeetCode对应题目：剑指 Offer 40. 最小的k个数 38. 连续子数组的最大和 # 剑指Offer题目：找到连续子数组的最大和。 LeetCode对应题目：53. 最大子数组和 39. 1～n整数中1出现的次数 # 剑指Offer题目：统计1～n整数中1出现的次数。 LeetCode对应题目：233. 数字 1 的个数 40. 数字序列中某一位的数字 # 剑指Offer题目：找到数字序列中某一位的数字。 LeetCode对应题目：400. 第 N 位数字 41. 把数组排成最小的数 # 剑指Offer题目：把数组排成最小的数。 LeetCode对应题目：剑指 Offer 45. 把数组排成最小的数 42. 把数字翻译成字符串 # 剑指Offer题目：把数字翻译成字符串。 LeetCode对应题目：91. 解码方法 43. 礼物的最大价值 # 剑指Offer题目：在矩阵中寻找礼物的最大价值。 LeetCode对应题目：剑指 Offer 47. 礼物的最大价值 44. 最长不含重复字符的子字符串 # 剑指Offer题目：找到最长不含重复字符的子字符串。 LeetCode对应题目：3. 无重复字符的最长子串 45. 丑数 # 剑指Offer题目：找到第n个丑数。 LeetCode对应题目：264. 丑数 II 46. 第一个只出现一次的字符 # 剑指Offer题目：找到第一个只出现一次的字符。 LeetCode对应题目：387. 字符串中的第一个唯一字符 47. 数组中的逆序对 # 剑指Offer题目：统计数组中的逆序对。 LeetCode对应题目：剑指 Offer 51. 数组中的逆序对 48. 两个链表的第一个公共节点 # 剑指Offer题目：找到两个链表的第一个公共节点。 LeetCode对应题目：160. 相交链表 49. 在排序数组中查找数字 # 剑指Offer题目：在排序数组中查找某个数字出现的次数。 LeetCode对应题目 ：剑指 Offer 53 - I. 在排序数组中查找数字 I 50. 0～n-1中缺失的数字 # 剑指Offer题目：找到0～n-1中缺失的数字。 LeetCode对应题目：268. 丢失的数字 51. 二叉搜索树的第k大节点 # 剑指Offer题目：找到二叉搜索树的第k大节点。 LeetCode对应题目：剑指 Offer 54. 二叉搜索树的第k大节点 52. 二叉树的深度 # 剑指Offer题目：求二叉树的深度。 LeetCode对应题目：104. 二叉树的最大深度 53. 平衡二叉树 # 剑指Offer题目：判断一棵二叉树是否是平衡二叉树。 LeetCode对应题目：110. 平衡二叉树 54. 数组中数字出现的次数 # 剑指Offer题目：找到数组中只出现一次的两个数字。 LeetCode对应题目：260. 只出现一次的数字 III 55. 数组中唯一只出现一次的数字 # 剑指Offer题目：找到数组中唯一只出现一次的数字。 LeetCode对应题目：137. 只出现一次的数字 II 56. 和为s的两个数字 # 剑指Offer题目：找到数组中两个数字，使得它们的和等于s。 LeetCode对应题目：剑指 Offer 57. 和为s的两个数字 57. 和为s的连续正数序列 # 剑指Offer题目：找到所有和为s的连续正数序列。 LeetCode对应题目 ：剑指 Offer 57 - II. 和为s的连续正数序列 58. 翻转单词顺序 # 剑指Offer题目：翻转句子中单词的顺序。 LeetCode对应题目：151. 反转字符串中的单词 59. 左旋转字符串 # 剑指Offer题目：左旋转字符串。 LeetCode对应题目：剑指 Offer 58 - II. 左旋转字符串 60. 滑动窗口的最大值 # 剑指Offer题目：找到滑动窗口中的最大值。 LeetCode对应题目：239. 滑动窗口最大值 61. 扑克牌中的顺子 # 剑指Offer题目：判断扑克牌是否是顺子。 LeetCode对应题目：剑指 Offer 61. 扑克牌中的顺子 62. 圆圈中最后剩下的数字 # 剑指Offer题目：圆圈中最后剩下的数字（约瑟夫环问题）。 LeetCode对应题目 ：剑指 Offer 62. 圆圈中最后剩下的数字 63. 股票的最大利润 # 剑指Offer题目：计算股票的最大利润。 LeetCode对应题目：121. 买卖股票的最佳时机 64. 求1+2+…+n # 剑指Offer题目：求1+2+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 LeetCode对应题目：剑指 Offer 64. 求1+2+…+n 65. 不用加减乘除做加法 # 剑指Offer题目：不用加减乘除做加法。 LeetCode对应题目：371. 两整数之和 66. 构建乘积数组 # 剑指Offer题目：构建乘积数组。 LeetCode对应题目：238. 除自身以外数组的乘积 67. 把字符串转换成整数 # 剑指Offer题目：把字符串转换成整数。 LeetCode对应题目：8. 字符串转换整数 (atoi) 68. 树中两个节点的最低公共祖先 # 剑指Offer题目：找到树中两个节点的最低公共祖先。 LeetCode对应题目：236. 二叉树的最近公共祖先 以上是《剑指Offer》中部分题目与LeetCode上对应题目的对照表。由于LeetCode的题目库不断更新，可能会有新的题目与《剑指Offer》中的题目对应。建议在准备面试时，结合两本书的题目进行练习。\n面试经典 150 题 # 数组 / 字符串 # ✅ 88 合并两个有序数组 # ✅ 27 移除元素 # ✅ 26 删除有序数组中的重复项 # ✅ 80 删除有序数组中的重复项 II # ✅ 169 多数元素 # ✅ 189 轮转数组 # ✅ 121 买卖股票的最佳时机 # 122 买卖股票的最佳时机 II # ✅ 55 跳跃游戏 # ✅ 45 跳跃游戏 II # ✅ 274 H 指数 # O(1) 时间插入、删除和获取随机元素 # 除自身以外数组的乘积 # 加油站 # 分发糖果 # 接雨水 # ✅ 13 罗马数字转整数 # 整数转罗马数字 # ✅ 58 最后一个单词的长度 # ✅ 14 最长公共前缀 # ✅ 151 反转字符串中的单词 # Z 字形变换 # ✅ 28 找出字符串中第一个匹配项的下标 # 文本左右对齐 # 双指针 # ✅ 125 验证回文串 # ✅ 392 判断子序列 # ✅ 167 两数之和 II - 输入有序数组 # 盛最多水的容器 # 三数之和 # 滑动窗口 # ✅ 长度最小的子数组 # ✅ 无重复字符的最长子串 # ✅ 串联所有单词的子串 # 最小覆盖子串 # 矩阵 # ✅ 有效的数独 # ✅ 螺旋矩阵 # 旋转图像 # ✅ 矩阵置零 # ✅ 生命游戏 # 哈希表 # ✅ 383 赎金信 # ✅ 205 同构字符串 # ✅ 290 单词规律 # ✅ 242 有效的字母异位词 # ✅ 49 字母异位词分组 # ✅ 1 两数之和 # ✅ 202 快乐数 # ✅ 219 存在重复元素 II # ✅ 128 最长连续序列 # 区间 # 汇总区间 # 合并区间 # 插入区间 # 用最少数量的箭引爆气球 # # 栈 # ✅ 20 有效的括号 # ✅ 71 简化路径 # ✅ 155 最小栈 # ✅ 150 逆波兰表达式求值 # 基本计算器 # 链表 # ✅ 141 环形链表 # ✅ 2 两数相加 # ✅ 21 合并两个有序链表 # ✅ 138 随机链表的复制 # ✅ 92 反转链表 II # K 个一组翻转链表 # ✅ 19 删除链表的倒数第 N 个结点 # ✅ 82 删除排序链表中的重复元素 II # ✅ 61 旋转链表 # ✅ 86 分隔链表 # ✅ 146 LRU 缓存 # 二叉树 # ✅ 104 二叉树的最大深度 # 104. 二叉树的最大深度 ✅ 100 相同的树 # 100. 相同的树 ✅ 226 翻转二叉树 # 226. 翻转二叉树 ✅ 101 对称二叉树 # 101. 对称二叉树 ✅ 105 从前序与中序遍历序列构造二叉树 # 105. 从前序与中序遍历序列构造二叉树 ✅ 106 从中序与后序遍历序列构造二叉树 # 106. 从中序与后序遍历序列构造二叉树 ✅ 117 填充每个节点的下一个右侧节点指针 II # 117. 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表 # ✅ 路径总和 # 求根节点到叶节点数字之和 # 二叉树中的最大路径和 # 二叉搜索树迭代器 # 完全二叉树的节点个数 # 二叉树的最近公共祖先 # 二叉树层次遍历 # ✅ 199 二叉树的右视图 # 199.二叉树的右视图 ✅ 637 二叉树的层平均值 # 637. 二叉树的层平均值 ✅ 二叉树的层序遍历 # ✅ 二叉树的锯齿形层序遍历 # 103.二叉树的锯齿形层序遍历 ✅ 二叉搜索树 # ✅ 二叉搜索树的最小绝对差 # ✅ 二叉搜索树中第 K 小的元素 # 验证二叉搜索树 # 图 # ✅ 200 岛屿数量 # 200.岛屿数量 被围绕的区域 # 克隆图 # 除法求值 # 课程表 # 课程表 II # 图的广度优先搜索 # 909 蛇梯棋 # 909 蛇梯棋 官方题解\nclass Solution { public int snakesAndLadders(int[][] board) { int n = board.length; boolean[] vis = new boolean[n * n + 1]; // 广度优先使用队列 Queue\u0026lt;int[]\u0026gt; queue = new LinkedList\u0026lt;int[]\u0026gt;(); // int[0] cell的序号 // int[1] 到达这个cell所需要的步数 queue.offer(new int[]{1, 0}); while (!queue.isEmpty()) { int[] p = queue.poll(); // 遍历6个可能下棋的位置 for (int i = 1; i \u0026lt;= 6; ++i) { int nxt = p[0] + i; if (nxt \u0026gt; n * n) { // 超出边界 break; } int[] rc = id2rc(nxt, n); // 得到下一步的行列 if (board[rc[0]][rc[1]] \u0026gt; 0) { // 存在蛇或梯子 nxt = board[rc[0]][rc[1]]; } if (nxt == n * n) { // 到达终点 return p[1] + 1; } if (!vis[nxt]) { vis[nxt] = true; queue.offer(new int[]{nxt, p[1] + 1}); // 扩展新状态 } } } return -1; } public int[] id2rc(int id, int n) { int r = (id - 1) / n, c = (id - 1) % n; if (r % 2 == 1) { c = n - 1 - c; } return new int[]{n - 1 - r, c}; } } 最小基因变化 # 最小基因变化 方法一：广度优先搜索 # 官方题解\nclass Solution { public int minMutation(String start, String end, String[] bank) { Set\u0026lt;String\u0026gt; cnt = new HashSet\u0026lt;String\u0026gt;(); Set\u0026lt;String\u0026gt; visited = new HashSet\u0026lt;String\u0026gt;(); char[] keys = {\u0026#39;A\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;T\u0026#39;}; for (String w : bank) { cnt.add(w); } if (start.equals(end)) { return 0; } if (!cnt.contains(end)) { return -1; } Queue\u0026lt;String\u0026gt; queue = new ArrayDeque\u0026lt;String\u0026gt;(); queue.offer(start); visited.add(start); int step = 1; while (!queue.isEmpty()) { int sz = queue.size(); for (int i = 0; i \u0026lt; sz; i++) { String curr = queue.poll(); for (int j = 0; j \u0026lt; 8; j++) { for (int k = 0; k \u0026lt; 4; k++) { // 24种变异 if (keys[k] != curr.charAt(j)) { StringBuffer sb = new StringBuffer(curr); sb.setCharAt(j, keys[k]); String next = sb.toString(); if (!visited.contains(next) /*没有遍历过*/ \u0026amp;\u0026amp; cnt.contains(next) /*在基因库中*/) { if (next.equals(end)) { return step; } // 在基因库中，但不是目标值 queue.offer(next); visited.add(next); } } } } } step++; } return -1; } } 方法二：预处理优化 # 官方题解\nclass Solution { public int minMutation(String start, String end, String[] bank) { int m = start.length(); int n = bank.length; List\u0026lt;Integer\u0026gt;[] adj = new List[n]; for (int i = 0; i \u0026lt; n; i++) { adj[i] = new ArrayList\u0026lt;Integer\u0026gt;(); } int endIndex = -1; for (int i = 0; i \u0026lt; n; i++) { // 记录目标基因序列在基因库中的下标 if (end.equals(bank[i])) { endIndex = i; } for (int j = i + 1; j \u0026lt; n; j++) { int mutations = 0; for (int k = 0; k \u0026lt; m; k++) { if (bank[i].charAt(k) != bank[j].charAt(k)) { mutations++; } if (mutations \u0026gt; 1) { break; } } // 记录基因库中每个基因序列可以进行的有效基因变异 if (mutations == 1) { adj[i].add(j); adj[j].add(i); } } } // 目标基因序列不再基因库中 if (endIndex == -1) { return -1; } Queue\u0026lt;Integer\u0026gt; queue = new ArrayDeque\u0026lt;Integer\u0026gt;(); boolean[] visited = new boolean[n]; int step = 1; for (int i = 0; i \u0026lt; n; i++) { int mutations = 0; for (int k = 0; k \u0026lt; m; k++) { if (start.charAt(k) != bank[i].charAt(k)) { mutations++; } if (mutations \u0026gt; 1) { break; } } // 如果执行到这里，说明初始基因序列可以通过一次有效变异为当前遍历的基因库序列 // 队列记录的是一次有效变异可变的基因序列下标（在基因库中的下标） if (mutations == 1) { queue.offer(i); visited[i] = true; } } while (!queue.isEmpty()) { int sz = queue.size(); for (int i = 0; i \u0026lt; sz; i++) { int curr = queue.poll(); if (curr == endIndex) { return step; } for (int next : adj[curr]) { if (visited[next]) { continue; } visited[next] = true; queue.offer(next); } } step++; } return -1; } } 单词接龙 # ✅ 字典树 # ✅ 208 实现 Trie (前缀树) # 208 实现 Trie (前缀树) ✅ 211 添加与搜索单词 - 数据结构设计 # 211 添加与搜索单词 - 数据结构设计 ✅ 212 单词搜索 II # 212 单词搜索 II ✅ 回溯 # ✅ 电话号码的字母组合 # ✅ 组合 # ✅ 全排列 # ✅ 组合总和 # ✅ N 皇后 II # ✅ 括号生成 # ✅ 单词搜索 # 分治 # ✅ 108 将有序数组转换为二叉搜索树 # 108 将有序数组转换为二叉搜索树 148 排序链表 # 148 排序链表 建立四叉树 # 合并 K 个升序链表 # Kadane 算法 # 最大子数组和 # 环形子数组的最大和 # 二分查找 # 搜索插入位置 # 搜索二维矩阵 # 寻找峰值 # 搜索旋转排序数组 # 在排序数组中查找元素的第一个和最后一个位置 # 寻找旋转排序数组中的最小值 # 寻找两个正序数组的中位数 # 堆 # 数组中的第K个最大元素 # IPO # 查找和最小的 K 对数字 # 数据流的中位数 # 位运算 # 二进制求和 # 颠倒二进制位 # 位1的个数 # 只出现一次的数字 # 只出现一次的数字 II # 数字范围按位与 # 数学 # ✅ 9 回文数 # ✅ 66 加一 # ✅ 172 阶乘后的零 # ✅ 69 x 的平方根 # 50 Pow(x, n) # 149 直线上最多的点数 # 一维动态规划 # ✅ 爬楼梯 # 打家劫舍 # 单词拆分 # 零钱兑换 # 最长递增子序列 # 多维动态规划 # 三角形最小路径和 # 最小路径和 # 不同路径 II # 最长回文子串 # 交错字符串 # 编辑距离 # 买卖股票的最佳时机 III # 买卖股票的最佳时机 IV # 最大正方形 # graph(com.penruins.graph) # com.penruins.graph 广度优先搜索(com.penruins.graph.GraphSearch.bfs) # com.penruins.graph.GraphSearch.bfs 二维图的广度优先搜索 8个方向 从标志数组的打印可以看出来是广度优先搜索 "},{"id":23,"href":"/post/computer-science/big-data/hadoop/","title":"hadoop","section":"Big Data","content":" hadoop # Hadoop生态系统是一个由Apache基金会维护的开源软件集合，用于处理和分析大规模数据集。经过多年发展，Hadoop已从最初的HDFS和MapReduce两个核心组件扩展为一个包含众多工具和框架的完整生态系统 核心基础组件 HDFS (Hadoop Distributed File System) Hadoop的分布式文件系统，用于存储超大规模数据集 采用主从架构：NameNode(主节点)管理元数据，DataNode(从节点)存储实际数据块 特点：高容错性、高吞吐量、适合部署在廉价硬件上 YARN (Yet Another Resource Negotiator) Hadoop 2.0引入的资源管理和作业调度框架 包含ResourceManager(集群资源管理)和NodeManager(节点资源监控) 支持多种计算框架(MapReduce、Spark等)共享集群资源 MapReduce 分布式计算框架，采用\u0026quot;分而治之\u0026quot;思想 包含Map(数据分解)和Reduce(结果汇总)两个阶段 适合处理大规模离线批处理任务 数据存储组件 HBase 分布式列式NoSQL数据库，基于Google BigTable设计 构建在HDFS之上，提供实时读写能力 适合存储海量结构化数据 Hive 数据仓库工具，提供类SQL查询语言(HiveQL) 将SQL转换为MapReduce/Tez/Spark作业执行 适合数据汇总、即席查询和分析 Pig 高级数据流语言(Pig Latin)和执行框架 简化MapReduce编程，适合ETL流程 支持结构化/半结构化数据处理 数据采集与传输组件 Sqoop 关系型数据库与Hadoop间数据传输工具 支持从MySQL、Oracle等导入数据到HDFS/Hive/HBase 也支持将Hadoop数据导出到关系数据库 Flume 分布式日志收集系统 适合采集、聚合和移动大量日志数据到HDFS 包含Source(数据源)、Channel(传输通道)和Sink(目的地)三个组件 协调与管理组件 Zookeeper 分布式协调服务 提供统一命名服务、配置管理、集群同步等 解决分布式环境下的数据一致性问题 Oozie 工作流调度系统 用于编排Hadoop作业(MapReduce、Pig、Hive等) 支持定时和依赖触发 Ambari Hadoop集群管理工具 提供Web界面监控、配置和管理Hadoop集群 支持大多数Hadoop组件 高级计算框架 Spark 内存计算框架，比MapReduce快10-100倍 支持批处理、流处理、机器学习和图计算 可与HDFS、HBase等集成 Flink 流处理框架，支持事件时间和精确一次处理 适合实时数据分析场景 与Hadoop生态系统兼容 Mahout 机器学习算法库 提供聚类、分类、推荐等算法实现 可扩展至大规模数据集 其他重要组件 Kafka 分布式消息队列系统 高吞吐量、低延迟 常用于实时数据管道 Tez 优化后的MapReduce执行引擎 减少中间结果写入磁盘，提高性能 被Hive、Pig等采用 Avro 数据序列化系统 提供紧凑的二进制数据格式 支持RPC通信 "},{"id":24,"href":"/post/computer-science/big-data/hbase/","title":"hbase","section":"Big Data","content":" hbase # HBase 是一个面向列式存储的分布式数据库，其设计思想来源于 Google 的 BigTable 论文 HBase 底层存储基于 HDFS 实现，集群的管理基于 ZooKeeper 实现 HBase 良好的分布式架构设计为海量数据的快速存储、随机访问提供了可能，基于数据副本机制和分区机制可以轻松实现在线扩容、缩容和数据容灾，是大数据领域中 Key-Value 数据结构存储最常用的数据库方案 hbase vs elasticsearch # HBase是基于Hadoop生态的分布式列式数据库，源自Google BigTable设计，擅长海量结构化/半结构化数据的存储和高吞吐写入 Elasticsearch是基于Lucene的分布式搜索引擎，专注于全文检索、复杂查询和实时分析，采用文档型数据模型 数据模型与灵活性 HBase采用列式存储模型，数据按\u0026quot;行键(RowKey)+列族(Column Family)+列限定符(Qualifier)\u0026ldquo;组织，适合结构化或半结构化数据。虽然schema-free设计允许灵活添加列，但列族需要预先定义 Elasticsearch采用文档型模型，数据以JSON格式存储，天然支持非结构化数据。字段可以动态添加，无需预定义schema，更适合多变的数据结构 查询能力对比 HBase查询能力相对有限 主要支持基于RowKey的精确查询和范围扫描(Scan) 复杂查询需要借助二级索引或Phoenix等SQL层 无内置全文检索能力，需结合Solr等搜索引擎 Elasticsearch提供丰富的查询功能 支持全文搜索、模糊查询、分词查询、聚合分析等高级特性 提供强大的DSL查询语言和SQL接口 内置倒排索引，亿级数据下仍能保持秒级响应 典型场景：HBase适合\u0026quot;已知RowKey查明细\u0026rdquo;，ES适合\u0026quot;根据内容特征找文档\u0026quot; 性能与扩展性 写入性能 两者都基于LSM树结构，理论写入性能相当 实际场景中HBase写入更高效，因为ES需要构建倒排索引等额外开销 HBase单集群可支持每天TB级数据写入 查询性能 ES在复杂查询和全文检索方面性能显著优于HBase HBase在简单键值查询和范围扫描上延迟更低 扩展能力 HBase天生为海量数据设计，通过Region分裂实现水平扩展 ES通过分片(Shard)机制扩展，但数据量极大时可能需要业务层干预 存储成本与资源消耗 存储效率 HBase采用列式存储+压缩，存储效率更高，适合长期保存海量数据 ES因维护索引和副本，存储开销通常比HBase高30%-50% 资源消耗 ES的CPU和内存消耗更高（分词、索引构建等） HBase更注重I/O优化，适合资源受限环境 维护复杂度 HBase依赖完整的Hadoop生态(HDFS/ZooKeeper等)，组件多，运维复杂度高 Elasticsearch自成体系，部署和维护相对简单，但集群调优需要专业知识 实时性与一致性 HBase采用强一致性模型(基于2PC协议)，适合对一致性要求高的场景 Elasticsearch采用最终一致性，查询实时性更好但可能短暂不一致 典型应用场景推荐 适合选择HBase的场景 海量时序数据存储：如设备监控数据、日志流水(每日5G以上) 高吞吐写入：需要持续写入TB级结构化数据的场景 简单查询为主：已知主键的快速查询或固定模式的范围扫描 长期数据归档：需要低成本长期保存的历史数据 案例：某埋点系统每天100G数据通过Kafka写入HBase，稳定运行 适合选择Elasticsearch的场景 全文检索需求：如商品搜索、内容检索、日志分析 复杂查询分析：需要多条件组合、聚合统计的业务 实时数据分析：如应用监控、安全分析等需要秒级响应的场景 灵活的数据结构：字段频繁变化或无法预定义schema的情况 混合架构方案 对于同时需要海量存储和复杂查询的场景，可考虑ES+HBase组合架构 HBase作为主存储，保证数据持久性和高吞吐写入 ES作为索引层，提供丰富的查询能力 通过数据同步工具保持两者数据一致 百亿级数据架构案例：使用ES处理复杂查询，HBase保证可靠存储，两者协同工作 选型决策关键因素 数据规模：日增5GB以下ES更简单，TB级选HBase 查询复杂度：简单查询HBase足够，复杂搜索选ES 数据结构：固定结构用HBase，多变结构用ES 资源预算：资源有限优先HBase，可接受较高成本选ES 团队技能：熟悉Hadoop选HBase，无大数据经验ES更易上手 总结建议 Elasticsearch是搜索和复杂查询的首选，特别适合日志分析、内容检索等需要灵活查询的场景 HBase是海量数据存储的可靠选择，特别适合时序数据、用户行为记录等高吞吐写入场景 HBase与RDBMS的区别 # 存储方式：HBase为列式存储，RDBMS为行式存储 扩展性：HBase支持水平扩展，RDBMS通常垂直扩展 事务：HBase仅支持单行事务，RDBMS支持多行复杂事务 HBase与Hive的区别 # 用途：HBase是实时数据库，Hive是离线数据仓库 查询性能：HBase支持毫秒级查询，Hive依赖MapReduce，延迟高 数据存储结构 # Region：表的水平分区，按RowKey范围划分 MemStore：写缓存，满时刷盘生成HFile HFile：底层存储文件，基于HDFS的列族数据块 hbase 的特点 # 易扩展 海量存储 列式存储 高可靠性 稀疏性 模块组成 # HBase 可以将数据存储在本地文件系统，也可以存储在 HDFS 文件系统。在生产环境中，HBase 一般运行在 HDFS 上，以 HDFS 作为基础的存储设施。HBase 通过 HBase Client 提供的 Java API 来访问 HBase 数据库，以完成数据的写入和读取。HBase 集群主由HMaster、Region Server 和 ZooKeeper 组成 HMaster 负责管理 RegionServer，实现其负载均衡 管理和分配 Region，比如在 Region split时分配新的 Region，在 RegionServer 退出时迁移其内的 Region 到其他 RegionServer上 管理namespace和table的元数据（实际存储在HDFS上） 权限控制（ACL） RegionServer 存放和管理本地 Region 读写HDFS，管理Table中的数据 Client 从 HMaster 中获取元数据，找到 RowKey 所在的 RegionServer 进行读写数据 ZooKeeper 存放整个 HBase集群的元数据以及集群的状态信息 实现HMaster主从节点的failover RowKey设计原则 # 长度：建议≤16字节，避免内存和存储浪费 散列性：高位散列（如哈希前缀）防止热点问题 唯一性：必须保证RowKey唯一标识数据 应用场景 # 适用场景 半结构化/非结构化数据（如日志、用户行为） 高并发实时读写（如电商订单、社交消息） HBase是根据谷歌的BigTable设计的。典型的应用场景就是不断插入新的信息（谷歌的情况下就是互联网上新生成的网页），而不怎么修改。比如现在Facebook的messenger就是用HBase实现的 Facebook Facebook用HBase存储在线消息，每天数据量近百亿，每月数据量250 ~ 300T， HBase读写比基本在1:1，吞吐量150w qps 小米 10+在线HBase集群，好几百台服务器，米聊历史数据，消息push系统等多个重要应用系统都建立在HBase基础之上 网易 哨兵监控系统，云信历史数据，日志归档数据等一系列重要应用底层都由HBase提供服务 写密集型应用，每天写入量巨大，而相对读数量较小的应用，比如IM的历史消息，游戏的日志等等 不需要复杂查询条件来查询数据的应用，HBase只支持基于rowkey的查询，对于HBase来说，单条记录或者小范围的查询是可以接受的，大范围的查询由于分布式的原因，可能在性能上有点影响，而对于像SQL的join等查询，HBase无法支持 对性能和可靠性要求非常高的应用，由于HBase本身没有单点故障，可用性非常高 数据量较大，而且增长量无法预估的应用，HBase支持在线扩展，即使在一段时间内数据量呈井喷式增长，也可以通过HBase横向扩展来满足功能 不适用场景 需要复杂事务或多表关联查询的业务 Reference # 什么是HBase？终于有人讲明白了 "},{"id":25,"href":"/post/life/hiking/","title":"hiking","section":"Life","content":" hiking # 2024-10-13 金铜盆 "},{"id":26,"href":"/post/computer-science/big-data/hive/","title":"hive","section":"Big Data","content":" hive # Apache Hive是一个基于Hadoop的数据仓库基础设施，主要用于处理和分析存储在Hadoop分布式文件系统(HDFS)中的大规模数据集。它由Facebook开发并开源，旨在为大数据分析提供类SQL的查询能力，使得非程序员也能方便地进行海量数据处理 "},{"id":27,"href":"/post/computer-science/tools/idea/","title":"IDEA","section":"Tools","content":" IDEA # 索引 # 如果IDE一直对构建目录(例如target)进行索引，可以将这个目录设置为 Excluded，这样就不会对这个目录进行索引了 右键目录 Mark Directory as -\u0026gt; Excluded "},{"id":28,"href":"/post/computer-science/operating-system/ios/","title":"ios","section":"Operating System","content":" ios # 一日一技：iOS抓包最简单方案 Charles 有 iOS 版本，app store 上就能下载，使用下来还不错 轻听英语 # Kiwix # 众山小笔记 # 微信输入法 # 很清爽，但是输入的体验不太好（自动补全不智能，这点还是搜狗输入法好用。。） Picsew # 长截图工具 Net # Shadowrocket # Strides # Charles # Caenets - Jupyter # Actions # LocalSend # Data Jar # HashPhotos # a-Shell # GitHub # 大陆的 App Store 已经下载不到了 下载好了之后可以不用 magic 就能使用，比web 的网络稳定性更好 可以查看action的执行情况 working copy # 目前用下来最好的 git 客户端 现在在中国大陆的 app store 上架的app要备案，因为这个app的开发者是国外大哥，不要因为政策下架呀。。 Freeform # 苹果原生的白板应用，很流畅，添加很多图片也不会卡顿。现在还没有创建文件夹的功能，希望尽快有这个功能，白板多了不好管理文件。2025-07-30 bark # Finb/Bark Bark is a push notification tool app. It\u0026rsquo;s free, simple, and secure, leveraging APNs without draining device battery. document Bark-Java-SDK Day One # Obsidian # ios 端最好用的 markdown 编辑器，可以把笔记存到 obsidian 的云服务上，也可以存到 icloud上。我是配合 working copy push到github，然后配合github的action，自动构建更新我的博客（比如这段话我就是在手机上用obsidian编辑的） 实在受不了都 ios 18，apple notes还是那么极简，没有目录，不支持markdown，还是坚持不下来使用 IFTTT # 3 个非常规 Day One 使用场景 触发你的智能生活：IFTTT 入门 RSS # Inoreader Feedly "},{"id":29,"href":"/post/computer-science/job/","title":"job","section":"Computer Science","content":" job # 应届生的简历 "},{"id":30,"href":"/post/computer-science/java/jvm/","title":"jvm","section":"Java","content":" jvm # JMM # Java的JVM内存模型 Java Memory Model # 主内存 Main Memory 工作内存 Working Memory JMM 的核心问题 # 可见性 原子性 有序性 内存机制 # JVM的内存机制是怎样的？ # jvm 的内存区域 程序计数器 Program Counter 记录当前线程的指令地址，用于记录线程恢复运行状态后执行指令的地址 虚拟机栈 Java Virtual Machine Stack 用于记录方法调用链 本地方法栈 Native Method Stack 类似于Java虚拟机栈，用于记录本地方法的调用链 堆 Heap 用于保存实例化的对象 方法区 Method Area 记录加载到内存中的类相关的信息 直接内存 Direct Memory 非阻塞式的IO操作的内存分配 垃圾回收机制 标记-清除算法 标记存活对象，清除未标记对象，但会产生内存碎片 标记-复制算法 将存活对象复制到另一个内存区域，适用于新生代，效率高但内存利用率低 标记-整理算法 标记存活对象后，将对象向一端移动，整理内存空间，适用于老年代 分代收集算法 根据对象生命周期将堆分为新生代和老年代，分别采用不同的回收算法 JVM的内存模型中哪些是线程私有的？ # 程序计数器 Program Counter Java 虚拟机栈 Java Virtual Stack 本地方法栈 Native Method Stack 垃圾回收 # 垃圾回收算法有哪些 # 标记-清除算法 标记-复制算法 标记-整理算法 Reference\n《深入理解Java虚拟机》 3.3 垃圾收集算法\n如何判断对象是否可以被回收 # 引用计数 可达性分析 类加载 # java类加载流程 # 加载 获取字节流 转换数据结构 生成Class对象 连接 验证 准备 静态变量分配默认值 解析 常量池的符号引用(类名、方法名)替换为直接引用(内存地址或偏移量) 初始化 执行类的静态代码块和复制操作 classloader 的种类 # 启动类加载器 拓展类加载器 应用类加载器 自定义类加载器 什么是双亲委派？ # 对类的加载任务会不断请求父加载器完成，当父加载器不进行加载时，才由本级加载器完成加载 为了解决的问题 避免类的重复加载 保证程序的安全性 防止类加载器加载核心类，出现潜在的安全风险 维护类的唯一性 "},{"id":31,"href":"/post/computer-science/distributed-system/message-queue/kafka/","title":"kafka","section":"Message Queue","content":" kafka # kafka vs rocketmq # Kafka 和 RocketMQ 之性能对比 kafka如何实现高吞吐量的？ # 顺序读写 零拷贝 分区与并行处理 批量发送 数据压缩 页缓存 高效的日志存储(将消息分段、并建立索引文件、支持快速定位与消息读取) Kafka突然宕机了消息会不会丢失 # 消息的持久化机制 消息会存储到日志文件中，宕机后不会丢失 副本机制 一个分区可以建立副本，确保数据不丢失 生产者确认机制 刷盘机制 同步刷盘, 每次写入消息就将写入到磁盘中, 但损失了效率 异步刷盘 kafka如何保障顺序消费 # 分区内的顺序性 将分区键与业务ID进行绑定，保证相同业务的消息都发送到对应分区进行顺序消费 kafka重平衡的触发条件是什么？ # 消费者组成员发生变化 消费者的加入、退出或崩溃 订阅主题分区数发生变化 主题分区增加或减少 订阅主题发生变化 使用正则表达式订阅主题时，新的主题被匹配 kafka发送失败如何处理 # 同步发送模式 捕获异常 异步发送模式 在回调方法中捕获异常 重试机制 设置重试次数 错误分类处理 可恢复错误 网络超时 不可恢复错误 无效的主题 调整生产者配置 设置acks, 可以设置为all，确保所有副本都确认才返回成功 使用死信队列 将发送失败的消息加入到死信队列中，以便后续处理 kafka的分区分配策略有哪些？ # RangeAssignor RoundRobinAssignor StickerAssignor CooperativeStickerAssignor kafka默认的分区策略是什么？ # DefaultPartitioner 指定分区 基于key分配 轮询分配 "},{"id":32,"href":"/post/computer-science/llm/2025-03-30-7-kafka%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA%E6%9C%89%E5%A4%9A%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/","title":"kafka一个分区有多个消费者消费顺序是怎样的","section":"Computer Science","content":" kafka一个分区有多个消费者消费顺序是怎样的 # 在 Kafka 中，一个分区（Partition）只能被同一个消费者组（Consumer Group）内的一个消费者（Consumer）消费，这是 Kafka 设计的基本原则。以下是详细分析：\n1. 单分区与消费者组的消费规则 # 一个分区仅由一个消费者消费：\n在同一个消费者组内，每个分区会被分配给组内的唯一消费者。例如，如果一个 Topic 有 3 个分区，消费者组有 3 个消费者，则每个消费者负责一个分区，消息按分区顺序消费29。\n消费者数量 \u0026gt; 分区数：多余的消费者会处于空闲状态，无法消费任何分区的消息。 消费者数量 ≤ 分区数：每个消费者可能分配到一个或多个分区，但一个分区始终只对应一个消费者29。 分区内消息严格有序：\n单个分区内的消息按生产者写入的顺序存储和消费，消费者按偏移量（Offset）递增顺序处理消息1317。\n2. 多消费者消费同一分区的特殊情况 # 不同消费者组：\n多个消费者组可以独立消费同一个分区的消息（每个组内仍遵循单消费者规则），但不同组之间的消费进度（Offset）互不影响。例如：\n消费者组 A 的 Consumer 1 消费分区 0； 消费者组 B 的 Consumer 1 也消费分区 029。 注意：这种场景下，消息会被重复消费，且各组消费顺序独立。 同一消费者组内多线程消费：\n若一个消费者启动多线程处理同一分区的消息，需自行保证线程间的顺序性（如单线程消费或业务层排序），否则可能乱序11。\n3. 分区分配策略的影响 # Kafka 默认的分区分配策略（如 RangeAssignor 或 RoundRobinAssignor）会影响消费者与分区的对应关系，但不会改变单分区单消费者的核心规则13。例如：\nRangeAssignor：按分区范围顺序分配，可能导致分区分配不均。 RoundRobinAssignor：轮询分配，更均衡但可能打乱业务相关性13。 4. 总结与建议 # 顺序性保障： 单分区内消息天然有序，但需确保消费者组内单线程消费17。 跨分区顺序需通过相同 Key 路由到同一分区实现局部有序117。 扩展性权衡：\n增加分区数可提升并行度，但需避免消费者数量不足导致负载不均。 若需多消费者并发处理同一分区的消息且保持顺序，需引入外部排序机制（如优先级队列）或改用单消费者多线程模式11。\n"},{"id":33,"href":"/post/computer-science/llm/2025-03-30-8-kafka%E5%8F%91%E9%80%81%E5%A4%B1%E8%B4%A5%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/","title":"kafka发送失败如何处理","section":"Computer Science","content":" kafka发送失败如何处理 # 当 Kafka 生产者发送消息失败时，可以通过以下方法进行排查和处理，结合错误类型和业务需求选择合适策略：\n一、常见失败原因及解决方案 # 网络故障\n现象：生产者无法连接 Broker，或发送超时。 解决： 检查网络连通性（如防火墙、DNS 解析）。 增加生产者参数 retries（重试次数）和 retry.backoff.ms（重试间隔）114。 分区副本不可用\n现象：目标分区 Leader 副本宕机或正在重分配。 解决： 检查 Broker 和分区状态（如 kafka-topics.sh --describe）。 配置 acks=all 确保所有副本确认写入，避免数据丢失114。 主题不存在\n现象：发送到未创建的主题。 解决： 提前创建主题，或启用 auto.create.topics.enable=true（生产环境慎用）1。 消息大小超限\n现象：消息超过 max.request.size 或 Broker 限制。 解决： 增大 max.request.size 或拆分大消息114。 生产者配置错误\n现象：bootstrap.servers 配置错误或序列化器不匹配。 解决： 检查 bootstrap.servers 地址和序列化配置（如 StringSerializer）。 二、发送失败的处理策略 # 同步发送模式\n调用 send().get() 阻塞等待发送结果，捕获异常后重试或记录日志222。 try { RecordMetadata metadata = producer.send(record).get(); } catch (Exception e) { // 重试或记录失败 } 异步发送模式\n通过回调（Callback）处理失败，例如重试或存入死信队列2。 producer.send(record, (metadata, exception) -\u0026gt; { if (exception != null) { // 异步处理失败 } }); 启用自动重试\n配置 retries=3（默认0）和 retry.backoff.ms=1000，应对瞬时错误（如网络抖动）2。 幂等性与事务\n设置 enable.idempotence=true 避免重复消息；事务消息需配置 transactional.id。 监控与报警\n监控生产者指标（如 record-error-rate），对持续失败触发报警。 三、高级优化建议 # 调整批量参数\n增大 batch.size 和 linger.ms 提升吞吐，但可能增加延迟22。 压缩消息\n配置 compression.type=snappy/lz4 减少网络传输量22。 备份与容灾\n确保 replication.factor≥2，避免单点故障导致数据不可用114。 四、总结 # 瞬时错误：通过重试和异步回调处理。 持久错误：检查配置、资源限制或 Broker 状态。 关键业务：结合同步发送、幂等性和事务保证可靠性12。 若问题持续，建议结合 Broker 日志（如 kafka-server.log）和生产者日志进一步定位。\n"},{"id":34,"href":"/post/computer-science/llm/2025-03-30-5-kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E9%9A%9C%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9/","title":"kafka如何保障顺序消费","section":"Computer Science","content":" kafka如何保障顺序消费 # Kafka 通过其独特的分区机制和消费者组设计来保障消息的顺序消费，但需注意其仅能保证单分区内的顺序性，跨分区的全局顺序需额外设计。以下是具体实现方法和原理：\n一、单分区顺序性保障 # 分区内消息严格有序\nKafka 的每个分区（Partition）是一个有序的、不可变的日志序列，消息按生产者发送的顺序追加到分区末尾，消费者按相同顺序读取11825。 关键设计：分区内的消息通过偏移量（Offset）标识顺序，消费者按 Offset 递增消费18。 生产者配置\n相同 Key 路由到同一分区：生产者通过消息 Key 的哈希值确定分区，相同 Key 的消息始终进入同一分区，确保业务相关的消息顺序12539。 // 示例：发送相同Key的消息到同一分区 ProducerRecord\u0026lt;String, String\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;topic\u0026#34;, \u0026#34;order-123\u0026#34;, \u0026#34;message\u0026#34;); producer.send(record); 限制并发请求：设置 max.in.flight.requests.per.connection=1，防止生产者因重试导致消息乱序3125。 消费者配置\n单线程消费：每个分区仅由一个消费者线程处理，避免并发消费破坏顺序18。 手动提交 Offset：确保消息处理完成后再提交 Offset，防止重复消费或漏消费。 二、全局顺序性实现（跨分区） # 单分区策略\n将 Topic 设置为单分区，所有消息集中到一个分区，但会牺牲吞吐量和扩展性242532。 适用场景：低吞吐但强顺序要求的场景（如金融交易流水）24。 基于 Key 的分区路由\n将需顺序处理的消息（如同一订单 ID）通过相同 Key 路由到固定分区，实现局部顺序139。 局限性：若 Key 分布不均，可能导致分区负载倾斜24。 应用层排序\n消费者拉取多分区消息后，通过优先级队列（如按时间戳或业务ID排序）实现全局顺序。 示例： PriorityQueue\u0026lt;ConsumerRecord\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;(Comparator.comparing(ConsumerRecord::timestamp)); 三、高级配置与优化 # 幂等生产者\n设置 enable.idempotence=true，避免重试导致消息重复或乱序，同时允许 max.in.flight.requests.per.connection\u0026gt;1 提升吞吐31。 消费者组与分区数平衡\n消费者组内实例数 ≤ 分区数，确保每个分区仅由一个消费者处理1838。 分区分配策略： RangeAssignor：按分区范围分配，适合分区数固定的场景38。 RoundRobin：轮询分配，均衡负载但可能打乱业务顺序38。 避免消费者重平衡\n消费者频繁加入/退出会触发分区重分配，可能导致短暂乱序。可通过 session.timeout.ms 调整心跳检测时间。 四、适用场景与权衡 # 高吞吐 vs 顺序性：Kafka 默认优先保证吞吐，全局顺序需牺牲性能2431。 推荐方案： 局部顺序：Key 分区 + 单线程消费（如订单状态变更）139。 全局顺序：单分区或应用层排序（如日志时间序列）25。 总结 # Kafka 的顺序消费能力依赖于合理配置生产者的分区策略、消费者的并发控制及业务逻辑设计。单分区顺序是原生支持的，而全局顺序需结合业务需求权衡性能与一致性182431。\n"},{"id":35,"href":"/post/computer-science/llm/2025-03-30-3-kafka%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F/","title":"kafka如何实现高吞吐量","section":"Computer Science","content":" kafka如何实现高吞吐量 # Kafka 实现高吞吐量的核心机制基于其多层次的优化设计，包括存储、网络、并行处理和资源利用等方面。以下是关键实现原理及技术细节：\n1. 顺序写入与页缓存技术 # 顺序写入磁盘：Kafka 将消息追加到分区日志文件末尾，避免随机磁盘寻址。顺序写入的吞吐量接近内存读写速度（可达数百MB/s），远高于随机写入11222。 页缓存（Page Cache）：消息首先写入操作系统的页缓存（内存），由操作系统异步刷盘。这减少了直接磁盘I/O的开销，同时利用内存加速读写11223。 2. 零拷贝（Zero-Copy）技术 # sendfile 系统调用：消费者读取数据时，Kafka 通过 sendfile 直接将页缓存的数据发送到网卡，跳过用户态与内核态之间的数据拷贝，减少CPU消耗和上下文切换15153。 mmap 内存映射：生产者写入时通过内存映射文件（mmap）将磁盘文件映射到内存，避免数据复制1251。 3. 分区与并行处理 # 分区机制：Topic 分为多个 Partition，每个 Partition 独立处理读写请求，支持水平扩展。分区数越多，并行度越高，吞吐量线性增长34。 消费者组：多个消费者并行消费不同分区，避免单点瓶颈。例如，6个分区的Topic可由6个消费者同时处理，提升整体消费速率。 4. 批量处理与压缩 # 生产者批量发送：Producer 累积消息到批次（如100ms或1MB阈值）后一次性发送，减少网络和磁盘I/O次数1232。 消息压缩：支持 Snappy、GZIP 等压缩算法，减少网络传输数据量（尤其对文本数据压缩率可达80%）1222。 5. 高效的存储与索引 # 稀疏索引：每个 Partition 的日志分段（Segment）附带索引文件，通过偏移量快速定位消息，避免全量扫描3223。 日志分段清理：定期删除过期数据或合并小文件，保持存储高效。 6. 网络与协议优化 # 二进制协议：自定义紧凑的二进制通信协议，减少解析开销32。 长轮询与拉取模式：消费者主动拉取消息（Pull），根据处理能力控制流量，避免Broker过载。 总结 # Kafka 的高吞吐量是多项技术协同作用的结果：\n存储层：顺序写入+页缓存+零拷贝最大化I/O效率； 架构层：分区+并行处理实现水平扩展； 传输层：批量+压缩+高效协议降低网络开销。 实际应用中，需根据业务调整分区数、批次大小和压缩算法等参数以进一步优化性能112。\n"},{"id":36,"href":"/post/computer-science/llm/2025-03-30-6-kafka%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B%E4%B8%8E%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%B3%BB%E7%BB%9F%E7%9B%B8%E6%AF%94%E6%9C%89%E4%BD%95%E4%BC%98%E5%8A%BF/","title":"Kafka的顺序消费能力与其他消息队列系统相比有何优势","section":"Computer Science","content":" Kafka的顺序消费能力与其他消息队列系统相比有何优势 # Kafka 在顺序消费能力上与其他主流消息队列系统（如 RabbitMQ、RocketMQ）相比，具有独特的优势和适用场景。以下是详细对比分析：\n一、Kafka 顺序消费的核心优势 # 分区内严格有序\nKafka 通过分区（Partition）机制天然保证同一分区内的消息顺序性，消息按写入顺序存储和消费，适用于高吞吐场景下的局部有序需求（如订单流水、日志流）1。 对比：RabbitMQ 默认不保证顺序，需通过单队列单消费者或复杂的分组逻辑实现；RocketMQ 虽支持队列内有序，但需依赖队列分配策略。 高性能与扩展性\nKafka 的分区设计允许水平扩展，通过增加分区数提升吞吐量，同时保持分区内顺序。例如，10个分区的 Topic 可支持10个消费者并行消费，每个消费者处理一个分区的有序消息128。 对比：RabbitMQ 单队列模式无法扩展，吞吐量受限；RocketMQ 虽支持多队列，但全局有序需牺牲队列数（单队列）47。 生产者控制灵活\n通过消息 Key 的哈希路由，Kafka 可将需顺序处理的消息（如相同订单ID）固定到同一分区，兼顾顺序性与并行能力28。 对比：RabbitMQ 需业务层实现分组逻辑；RocketMQ 类似但需显式配置 MessageQueueSelector47。 零拷贝与批量处理\nKafka 的零拷贝技术和批量发送机制减少 I/O 开销，在高吞吐场景下仍能保持低延迟的顺序消费129。 对比：RabbitMQ 的推送模型和内存优先策略在吞吐量上逊色1。 二、与其他消息队列的对比 # 特性 Kafka RocketMQ RabbitMQ 顺序性保证 分区内有序，分区间无序 队列内有序，队列间无序 默认无序，需单队列单消费者 全局有序实现 单分区主题（牺牲吞吐）或 Key 分区 单队列主题或 Key 选择队列 单队列单消费者或消息分组 并行能力 高（多分区并行） 高（多队列并行） 低（单队列限制）40 适用场景 日志聚合、流处理、高吞吐局部有序 金融交易、分布式事务 低吞吐、简单顺序需求1 三、Kafka 的局限性 # 全局有序成本高\n需将 Topic 设为单分区，严重限制吞吐量，仅适合低并发场景2847。 对比：RocketMQ 同样需单队列，但提供顺序消息 API 简化实现47。 消费者复杂度\n需手动管理 Offset 和分区分配，多线程消费时需避免破坏顺序（如使用阻塞队列排序）28。 对比：RabbitMQ 的简单队列模型更易实现单线程消费40。 延迟消息不支持\nKafka 原生不支持延迟消息，需业务层实现，而 RocketMQ 和 RabbitMQ 提供内置支持1。 四、总结与选型建议 # 选择 Kafka：\n适合高吞吐、分区级顺序场景（如日志流、事件溯源），需利用分区和 Key 路由平衡顺序与性能129。 选择 RocketMQ：\n需兼顾顺序性、事务和高并发的金融场景（如订单状态变更）47。 选择 RabbitMQ：\n低吞吐、简单顺序需求（如任务队列），或需灵活路由的场景40。 Kafka 的顺序消费优势在于其分区机制与高吞吐设计的结合，而其他系统在特定场景（如事务、延迟）可能更适用。实际选型需综合业务需求和性能权衡1。\n"},{"id":37,"href":"/post/computer-science/llm/2025-03-30-9-kafka%E7%AA%81%E7%84%B6%E5%AE%95%E6%9C%BA%E4%BA%86%E6%B6%88%E6%81%AF%E4%BC%9A%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1/","title":"Kafka突然宕机了消息会不会丢失","section":"Computer Science","content":" Kafka突然宕机了消息会不会丢失 # Kafka 在突然宕机时是否会导致消息丢失，取决于其副本机制、生产者配置、刷盘策略等多个因素。以下是具体分析：\n一、可能导致消息丢失的场景 # 生产者未启用高可靠性配置\n若生产者设置 acks=0 或 acks=1，且消息未完全同步到副本时 Leader 宕机，消息会丢失： acks=0：生产者不等待 Broker 确认，直接发送下一条消息，宕机时丢失风险最高111。 acks=1：仅 Leader 写入本地日志即返回成功，若 Follower 未同步且 Leader 宕机，消息丢失1118。 Broker 刷盘策略为异步\nKafka 默认先将消息写入操作系统的 PageCache，异步刷盘。若服务器宕机，PageCache 中未刷盘的消息会丢失1118。 副本同步不足\n若 min.insync.replicas=1（默认），且仅 Leader 持有消息时宕机，即使设置 acks=all 也可能丢失消息1823。 二、避免消息丢失的配置 # 生产者端\n设置 acks=all：确保所有 ISR（同步副本）均写入消息后才返回成功1118。 启用幂等性（enable.idempotence=true）和重试机制（retries\u0026gt;0），防止重复发送和网络抖动导致丢失143。 Broker 端\n提高 min.insync.replicas（如设置为 2），确保至少两个副本同步成功1823。 同步刷盘（log.flush.interval.messages=1），但会显著降低性能，仅适用于金融等高可靠性场景1118。 Topic 配置\n设置 replication.factor≥3，多副本冗余存储，即使一台 Broker 宕机，其他副本仍可提供服务23。 三、Kafka 的可靠性保障机制 # ISR 机制 只有与 Leader 同步的副本（ISR）才能参与选举，避免数据不一致1823。 自动故障恢复 Leader 宕机后，Controller 会从 ISR 中选举新 Leader，继续提供服务23。 持久化设计 消息以追加日志（append-only）形式写入磁盘，即使消费者已消费，数据仍保留（可配置保留时间）。 四、总结 # 可能丢失：若配置为 acks=0/1、异步刷盘或副本不足时，宕机会导致消息丢失。 不会丢失：若配置 acks=all、同步刷盘且 min.insync.replicas≥2，即使单台 Broker 宕机，消息仍可从其他副本恢复111823。 建议：根据业务重要性权衡性能与可靠性，金融级场景建议同步刷盘 + 多副本 + 事务支持（transactional.id）43。\n"},{"id":38,"href":"/post/life/life-recommend/","title":"life recommand","section":"Life","content":" life recommend # sspai 数码相关内容，还有一些偏硬核的科普，技术文章 movies # 绝命毒师 Breaking Bad 风骚律师 Better Call Saul 权力的游戏 灿烂人生 无言的山丘 人间的条件 赤足小子 婚姻生活 article # 互联网是人类历史的一段弯路吗 每天通勤骑车60公里身体会不会累垮？ books # 社会心理学 戴维迈尔斯 西方哲学史讲演录 赵林 为什么学生不喜欢上学 送你一颗子弹 刘瑜 resources # zlibrary bilibili # movies 木鱼水心 质量很高，第一个关注的电影解说up 电影广角镜 绝命毒师和风骚律师 解说的很棒 digital 那岩KJMX 科技美学 cycling 道长说车 CLUB100 Contayu_Cycling world Yooupi食途 星球研究所 economy 小Lin说 software # ios # a-Shell working copy Documents Shadowrocket Obsidian ServerCat Github 搜狗输入法 彩云天气 Actions DataJar ShellFish nPlayer HashPhotos Soor Shortcuts 小宇宙 让听播客回归简单——即刻团队新作「小宇宙」体验报告 mac # windows # wallpaper # 4k wallpapers philosophy # Philosophia 哲学社 2020-03-16 种族歧视错在哪儿 F1 # 指北集EP.01——简明Formula One观赛指北 motto # you don\u0026rsquo;t give up, then there\u0026rsquo;s no limitation.\n真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。\n梦里不知身是客，一晌贪欢\n夫夷以近，则游者众；险以远，则至者少。而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也。有志矣，不随以止也，然力不足者，亦不能至也。有志与力，而又不随以怠，至于幽暗昏惑而无物以相之，亦不能至也。然力足以至焉，于人为可讥，而在己为有悔；尽吾志也而不能至者，可以无悔矣，其孰能讥之乎？此余之所得也！\n2024-06-12\n艾柯：將來，教育目的是教人“篩選”這種藝術。再沒必要教加德滿都在哪裏，或者查理大帝之後誰是第一個法蘭西國王，因為我們隨處找到答案。不過，我們應該叫學生考查十五個網絡頁面，讓他們自己判斷哪個最差。需要教會他們“比較”這種技巧。\n2023-10-24\n"},{"id":39,"href":"/post/computer-science/operating-system/linux/","title":"linux","section":"Operating System","content":" linux # resources # 鸟哥的Linux私房菜：基础学习篇 第四版 tail # tail -f xxxx sed # sed命令详解 nmon # nmon 系统性能监控工具的使用 HomePage yazi # sxyazi/yazi 官方仓库 docs 【命令行必备】Yazi：最强文件管理器 TheCW "},{"id":40,"href":"/post/computer-science/operating-system/mac/","title":"mac","section":"Operating System","content":" mac # 如何像极客一样使用你的Mac？分享下我的Mac工作流 icloud # 文件APP不同步-iCloud云盘延迟同步解决方法 killall bird killall cloudd brew # 查看 brew 服务运行状态 brew services list mysql # 启动 brew services start mysql@8.0 使用命令行连接 mysql mysql -u root reference Macbook通过brew安装mysql8.0 mongodb # mongodb 安装 brew tap mongodb/brew brew update brew install mongodb-community@8.0 启动 mongodb brew services start mongodb-community@8.0 停止 mongodb brew services stop mongodb-community@8.0 mongodb 配置文件位置 vim /opt/homebrew/etc/mongod.conf 窗口管理 # AltTab # 官网 相比起系统自带的 command + tab 它提供相同应用的窗口切换（例如浏览器打开了多个窗口，系统自带的是不能指定某一个窗口进行切换的） 可以设置UI的样式，用列表的方式来展示窗口，文字设置的小一点 Yabai # 用Mac不用它，你的Mac白买了 —— 平铺式窗口管理器yabai ffmpeg # 安装 brew install ffmpeg postgresql # Homebrew 安装 postgresql yazi # docs git # lazygit # jesseduffield/lazygit zen·工作环境搭建之git篇之Lazygit LazyGit 使用教程：简化 Git 操作的终端工具 yt-dlp # yt-dlp/yt-dlp 安装 brew install yt-dlp output-template yt-dlp -N 20 https://www.youtube.com/@xiaodaodalang --merge-output-format mp4 # 后台下载 nohup yt-dlp -N 20 https://www.youtube.com/@xiaodaodalang --merge-output-format mp4 \u0026amp; # 加上日期前缀 yt-dlp -N 20 -o \u0026#34;%(upload_date\u0026gt;%Y-%m-%d)s-%(title)s.%(ext)s\u0026#34; https://www.youtube.com/@xiaodaodalang --merge-output-format mp4 player # Mac下最好的视频播放器 IINA orbstack # orbstack skechybar # skechybar install homerow # 模拟点击 Hammerspoon # 脚本工具 免费又强大的 macOS 自动化工具，Hammerspoon 可以让你少买很多 App HomePage arc # dia # folo # Folo: 你的一站式信息订阅平台（可同时订阅B站、油管、X等多个平台的博主） reference # 如何评价Orbstack（在Mac上低开销地运行容器和Linux）？ 登录虚拟机 # orb -m ubuntu -u xiangliu disk # DaisyDisk Hidden space 隐藏空间 如何用命令弹出硬盘 查询硬盘挂载路径 df -h 取消挂载 diskutil unmount xxxxx transmit 文件传输工具 Raycast # 最强macOS生产力软件：Raycast AeroSpace # 我用AeroSpace替代了yabai+skhd Apple Music # 一日一技 | 如何用命令行将音乐转码到 iTunes Plus AAC battery # Powerflow：轻巧好用的 macOS 电源与充电状态监控神器 vladkens/macmon altente mac 上抓取应用的https的包 # 在Mac上抓取应用的HTTPS流量，你需要使用网络分析工具，如Wireshark、Charles Proxy或MITMproxy。由于HTTPS加密了数据传输，直接抓包无法查看具体内容，因此通常需要设置一个代理服务器来进行中间人攻击（Man-in-the-Middle, MITM）来解密和检查HTTPS流量。\n以下是使用Charles Proxy作为例子来说明如何进行HTTPS流量的抓取：\n安装Charles Proxy:\n下载并安装Charles Proxy应用程序到你的Mac电脑上。 配置Charles SSL代理:\n打开Charles，前往Proxy -\u0026gt; SSL Proxying Settings。 在SSL Proxying标签中点击Enable SSL Proxying。 添加你想要监控的应用程序使用的域名端口对，例如对于大多数Web流量是443端口。 安装Charles的SSL证书:\n为了让Charles能够解密HTTPS流量，你需要信任它的SSL证书。 在Charles中前往Help -\u0026gt; SSL Proxying -\u0026gt; Install Charles Root Certificate。 按照提示完成证书安装，并确保系统信任此证书。 配置设备或应用以使用Charles代理:\n如果你想抓取的是Mac本地应用的流量，你需要配置该应用使用Charles作为HTTP/HTTPS代理。 对于某些应用程序，这可能需要更改系统的网络设置，或者在应用内部设置代理服务器地址为localhost或127.0.0.1，端口号通常是8888（默认的Charles监听端口）。 如果是移动设备上的应用，你需要设置设备的Wi-Fi连接使用手动HTTP代理指向运行Charles的Mac的局域网IP地址和端口。 开始抓包:\n现在你可以启动目标应用程序并开始与它交互，所有的HTTPS流量应该会通过Charles被截获，并且如果你正确设置了SSL代理，你应该能看到解密后的流量。 过滤和分析流量:\n使用Charles提供的过滤器和搜索功能来定位你感兴趣的特定请求和响应。 请注意，抓取和解密HTTPS流量可能涉及到隐私问题以及违反服务条款的风险。务必确保你有合法的权利去监视和分析这些流量。如果你是在测试自己的应用，确保遵循公司的政策和法律要求。如果你试图分析第三方应用的流量，请确保你有权这样做。\ncharles # Mac使用Charles进行HTTPS抓包 高颜值抓包工具Charles，实现Mac和IOS端抓取https请求 Configure Charles Root certificate on Mac 需要在keychains里信任证书 Charles Proxy for Mobile apps that use SSL Pinning 8 Ways to Bypass SSL Pinning in iOS tools # neofetch # mac 安装 brew install neofetch ubuntu 安装 sudo apt install neofetch mess # 我的Mac效率设置和软件（2024） 10款好用的Mac系统监控软件推荐 建模太阳磁场、运行本地大模型！为什么学生都爱用Macbook Air？ questions # 2024-11-15 指纹识别及录入问题 M1 macbookPro 指纹不是识别及其慢就是识别不了，没有反应 电脑插电会有影响，不插电指纹功能是正常的 2025-02-08 Is there a way to download Screen Time data from iPhone or other Apple devices? Timing "},{"id":41,"href":"/post/computer-science/distributed-system/message-queue/message-queue/","title":"Message Queue","section":"Message Queue","content":" Message Queue # 消息队列如何选型？ # 高吞吐量、大数据场景：Kafka 金融交易、高可靠场景：RocketMQ 支持事务消息和高可用性 易于使用、功能丰富：RabbitMQ 云原生、多租户场景：Pulsar 适合需要高扩展性和分层存储的场景 简单轻量、定制开发场景：NSQ 适合 Golang技术栈 "},{"id":42,"href":"/post/computer-science/java/mybatis/","title":"Mybatis","section":"Java","content":" mybatis是怎么进行事务管理的 2025-02-08 # MyBatis 通过集成外部事务管理器（如 Spring 或 Java EE 容器）或使用内置的 JDBC 事务管理机制来管理事务。以下是 MyBatis 事务管理的主要方式：\n1. 使用 JDBC 事务管理 # MyBatis 默认使用 JDBC 的事务管理，通过 java.sql.Connection 实现。具体步骤如下：\n开启事务：调用 Connection.setAutoCommit(false) 关闭自动提交。 提交事务：调用 Connection.commit() 提交事务。 回滚事务：调用 Connection.rollback() 回滚事务。 示例代码：\nSqlSession sqlSession = sqlSessionFactory.openSession(); try{ // 执行数据库操作 sqlSession. insert(\u0026#34;insertUser\u0026#34;,user); sqlSession. update(\u0026#34;updateUser\u0026#34;,user); // 提交事务 sqlSession. commit(); }catch( Exception e){ // 回滚事务 sqlSession. rollback(); }finally{ // 关闭 SqlSession sqlSession. close(); } 2. 集成 Spring 事务管理 # MyBatis 通常与 Spring 集成，利用 Spring 的事务管理功能。Spring 提供了声明式和编程式事务管理。\n2.1 声明式事务管理 # 通过 @Transactional 注解或 XML 配置实现事务管理。\n示例代码：\n@Service public class UserService { @Autowired private UserMapper userMapper; @Transactional public void addUser(User user) { userMapper.insertUser(user); userMapper.updateUser(user); } } 2.2 编程式事务管理 # 通过 TransactionTemplate 或 PlatformTransactionManager 手动管理事务。\n示例代码：\n@Service public class UserService { @Autowired private UserMapper userMapper; @Autowired private PlatformTransactionManager transactionManager; public void addUser(User user) { TransactionDefinition def = new DefaultTransactionDefinition(); TransactionStatus status = transactionManager.getTransaction(def); try { userMapper.insertUser(user); userMapper.updateUser(user); transactionManager.commit(status); } catch (Exception e) { transactionManager.rollback(status); throw e; } } } 3. 使用 Java EE 容器的事务管理 # 在 Java EE 环境中，MyBatis 可以通过 JTA（Java Transaction API）与容器的事务管理器集成，通常通过 UserTransaction 或容器提供的其他机制管理事务。\n总结 # JDBC 事务管理：MyBatis 默认使用 JDBC 事务管理，手动控制事务。 Spring 事务管理：与 Spring 集成时，推荐使用 Spring 的事务管理，支持声明式和编程式事务。 Java EE 事务管理：在 Java EE 环境中，可通过 JTA 与容器的事务管理器集成。 选择合适的事务管理方式取决于应用场景和框架集成需求。\n我使用springboot框架，我在一个方法中使用mybatis提供的mapper方法插入了一条数据，但是我没有在方法上使用@Transactional注解，这种情况下有事务吗 2025-02-08 # 在 Spring Boot 中使用 MyBatis 时，如果你在一个方法中调用了 MyBatis 的 Mapper 方法插入数据，但没有在方法上使用 @Transactional 注解，那么默认情况下是没有事务管理的。具体表现如下：\n1. 没有事务的情况 # 如果没有 @Transactional 注解，Spring 不会为该方法开启事务。 每次调用 MyBatis 的 Mapper 方法时，MyBatis 会使用默认的 JDBC 行为，即自动提交（auto-commit）。 这意味着每次执行 SQL 语句（如插入、更新、删除）后，数据库会立即提交该操作，无法回滚。 2. 可能的风险 # 数据不一致：如果方法中有多个数据库操作（例如插入多条数据），其中一个操作失败，前面的操作已经提交，无法回滚，可能导致数据不一致。 缺乏事务控制：无法保证操作的原子性。 3. 如何验证没有事务 # 你可以通过以下方式验证：\n在方法中故意抛出异常，观察数据是否被插入。 如果没有事务，即使抛出异常，已经插入的数据也会被提交到数据库。 示例代码：\n@Service public class UserService { @Autowired private UserMapper userMapper; public void addUser(User user) { userMapper.insertUser(user); // 插入数据 throw new RuntimeException(\u0026#34;模拟异常\u0026#34;); // 抛出异常 } } 运行后，检查数据库，会发现 user 数据已经被插入，即使抛出了异常。\n4. 如何启用事务 # 如果你希望方法中的操作在一个事务中执行，可以通过以下方式启用事务管理：\n4.1 使用 @Transactional 注解 # 在方法上添加 @Transactional 注解，Spring 会为该方法开启事务。\n示例代码：\n@Service public class UserService { @Autowired private UserMapper userMapper; @Transactional public void addUser(User user) { userMapper.insertUser(user); // 插入数据 throw new RuntimeException(\u0026#34;模拟异常\u0026#34;); // 抛出异常 } } 运行后，检查数据库，会发现 user 数据没有被插入，因为事务回滚了。\n4.2 配置事务管理器 # 确保 Spring Boot 项目中已经配置了事务管理器（通常使用 DataSourceTransactionManager）。Spring Boot 会自动配置事务管理器，只要你引入了相关依赖（如 spring-boot-starter-data-jpa 或 mybatis-spring-boot-starter）。\n5. 总结 # 没有 @Transactional 注解：默认没有事务，每次 SQL 操作会立即提交。 需要事务：在方法上添加 @Transactional 注解，确保方法中的多个操作在同一个事务中执行，保证原子性。 验证事务：通过抛出异常的方式验证事务是否生效。 如果你希望方法中的操作具有事务性，务必使用 @Transactional 注解。\n什么是乐观锁、悲观锁 2025-02-08 # 乐观锁和悲观锁是并发控制中常用的两种策略，用于解决多个事务或线程同时访问和修改同一数据时可能引发的数据不一致问题。它们的核心区别在于对并发冲突的处理方式。\n1. 悲观锁（Pessimistic Locking） # 悲观锁假设并发冲突很可能发生，因此在访问数据时直接加锁，确保其他事务或线程无法修改数据，直到当前操作完成。\n实现方式 # 在数据库中，通常通过 SELECT ... FOR UPDATE 或 SELECT ... LOCK IN SHARE MODE 实现。 在代码中，可以通过 synchronized 关键字或 ReentrantLock 实现。 特点 # 优点：保证数据强一致性，适合写操作多的场景。 缺点：加锁会降低并发性能，可能导致死锁。 适用场景 # 写操作频繁，且并发冲突概率高的场景。 例如：银行转账、库存扣减等。 示例 # -- 数据库中使用悲观锁 BEGIN; SELECT * FROM account WHERE id = 1 FOR UPDATE; -- 加锁 UPDATE account SET balance = balance - 100 WHERE id = 1; COMMIT; 2. 乐观锁（Optimistic Locking） # 乐观锁假设并发冲突很少发生，因此在访问数据时不会加锁，而是在提交时检查数据是否被其他事务修改过。如果发现冲突，则回滚或重试。\n实现方式 # 通常通过版本号（Version）或时间戳（Timestamp）实现。 在数据库中，可以为表添加一个 version 字段，每次更新时检查版本号是否一致。 特点 # 优点：不加锁，提高并发性能，适合读操作多的场景。 缺点：冲突时需要回滚或重试，可能增加业务逻辑复杂度。 适用场景 # 读操作频繁，写操作较少的场景。 例如：电商库存、评论系统等。 示例 # -- 数据库中使用乐观锁 -- 表结构 CREATE TABLE product ( id INT PRIMARY KEY, name VARCHAR(50), stock INT, version INT -- 版本号字段 ); -- 更新操作 UPDATE product SET stock = stock - 1, version = version + 1 WHERE id = 1 AND version = 5; -- 检查版本号 在代码中，可以通过以下方式实现乐观锁：\npublic boolean updateProduct(Product product) { int rows = productMapper.updateProduct( product.getId(), product.getStock(), product.getVersion() ); if (rows == 0) { throw new OptimisticLockException(\u0026#34;数据已被修改，请重试\u0026#34;); } return true; } 3. 对比总结 # 特性 悲观锁 乐观锁 加锁时机 访问数据时立即加锁 提交时检查冲突 性能 低（加锁影响并发） 高（不加锁，冲突时回滚） 适用场景 写操作多，冲突概率高 读操作多，冲突概率低 实现复杂度 简单 较复杂（需处理冲突） 数据一致性 强一致性 最终一致性 4. 如何选择 # 如果业务场景中写操作频繁，且对数据一致性要求高，选择悲观锁。 如果业务场景中读操作频繁，且冲突概率低，选择乐观锁。 5. 实际应用中的注意事项 # 悲观锁：注意死锁问题，避免长时间持有锁。 乐观锁：需要设计重试机制，处理冲突时的回滚或重试逻辑。 通过合理选择锁机制，可以在保证数据一致性的同时，最大化系统的并发性能。\nmybatis 框架使用了哪些设计模式 # MyBatis 框架在其设计和实现中使用了多种设计模式，以下是主要的设计模式及其应用场景：\n1. Builder模式 # 应用场景：MyBatis 在初始化过程中，使用 SqlSessionFactoryBuilder 构建 SqlSessionFactory，并通过 XMLConfigBuilder、XMLMapperBuilder 等类解析配置文件，构建核心对象 Configuration。这些 Builder 类负责将复杂的配置解析和对象构建过程分离124。 示例：SqlSessionFactoryBuilder 根据不同的输入参数构建 SqlSessionFactory 对象12。 2. 工厂模式 # 应用场景：MyBatis 使用工厂模式创建核心对象，如 SqlSessionFactory 负责创建 SqlSession，MapperProxyFactory 负责创建 Mapper 接口的代理对象124。 示例：SqlSessionFactory 的 openSession() 方法根据不同的参数创建 SqlSession 对象12。 3. 单例模式 # 应用场景：MyBatis 中的 ErrorContext 和 LogFactory 使用了单例模式，确保全局唯一实例。ErrorContext 用于记录线程执行环境的错误信息，LogFactory 用于获取日志对象124。 示例：LogFactory 提供了一个全局的日志工厂，用于获取配置好的日志对象24。 4. 代理模式 # 应用场景：MyBatis 的核心功能之一是通过动态代理实现 Mapper 接口与 SQL 语句的绑定。MapperProxy 是 Mapper 接口的代理类，负责将接口方法调用转换为 SQL 执行124。 示例：MapperProxy 使用 JDK 动态代理为 Mapper 接口创建代理对象14。 5. 装饰器模式 # 应用场景：MyBatis 的缓存模块使用了装饰器模式，通过 BlockingCache、FifoCache、LruCache 等装饰类为缓存添加不同的功能，如阻塞、日志、同步等34。 示例：LruCache 装饰 PerpetualCache，实现最近最少使用缓存策略34。 6. 模板方法模式 # 应用场景：MyBatis 的 BaseExecutor 和 BaseTypeHandler 使用了模板方法模式，定义了操作的骨架，具体实现由子类完成。例如，BaseExecutor 实现了 SQL 执行的通用逻辑，子类如 SimpleExecutor 负责具体实现134。 示例：BaseTypeHandler 定义了类型处理的模板方法，子类如 IntegerTypeHandler 负责具体实现34。 7. 适配器模式 # 应用场景：MyBatis 的日志模块使用适配器模式，将不同的日志框架（如 Log4j、JDK Logging）适配到统一的 Log 接口14。 示例：Log 接口适配了多种日志框架的实现14。 8. 组合模式 # 应用场景：MyBatis 的 SqlNode 及其子类（如 ChooseSqlNode）使用了组合模式，将多个 SQL 节点组合成复杂的 SQL 语句1。 示例：SqlNode 及其子类共同构建动态 SQL 语句1。 9. 迭代器模式 # 应用场景：MyBatis 的 PropertyTokenizer 使用了迭代器模式，用于解析属性表达式的迭代1。 示例：PropertyTokenizer 迭代解析属性表达式1。 总结 # MyBatis 通过灵活运用多种设计模式，实现了配置解析、对象创建、SQL 执行、缓存管理等核心功能。这些设计模式不仅提高了代码的复用性和可维护性，还使得框架更加灵活和可扩展。\n"},{"id":43,"href":"/post/computer-science/java/mybatis-plus/","title":"Mybatis Plus","section":"Java","content":" document 条件构造器 "},{"id":44,"href":"/post/computer-science/database/mycat/","title":"mycat","section":"Database","content":" mycat # 那些年非常火的MyCAT是什么？ MyCat(看这一篇就够了） 应用场景 MySQL读写分离 分库分表 数据库路由器 整合数据源 当一个项目需要用到多种数据源如Oracle, MySQL, SQL Server, PostgreSQL时，可以利用Mycat进行整合，只需访问Mycat这一个数据源就行 逻辑库 schema 业务开发人员通常在实际应用中并不需要知道中间件的存在，只需要关注数据库，所以数据库中间件可以被当做一个或多个数据库集群构成的逻辑库 逻辑表 table 既然有逻辑库，就会有逻辑表。在分布式数据库中，对于应用来说，读写数据的表就是逻辑表。逻辑表可以分布在一个或多个分片库中，也可以不分片 Mycat的原理最重要的一个动词是拦截，它拦截用户发送过来的SQL语句 Mycat 如何实现高可用 # 基于keepalived的MyCat高可用技术 Keepalived通过VRRP协议实现虚拟IP(VIP)的自动漂移，当主节点故障时，VIP会自动切换到备用节点，实现MyCat服务的高可用 HAProxy+Keepalived实现高可用与负载均衡 HAProxy实现MyCat多节点的负载均衡 Keepalived实现HAProxy自身的高可用 同时解决了MyCat的负载均衡器的高可用问题 "},{"id":45,"href":"/post/computer-science/database/mysql/","title":"mysql","section":"Database","content":" mysql # binlog # redo log 和 binlog日志 # redo log 重做日志 Redo log是InnoDB存储引擎特有的物理日志，主要保证事务的持久性和崩溃恢复能力(crash-safe)。当MySQL实例意外宕机时，InnoDB可以通过redo log恢复已提交但未写入数据文件的事务，确保数据不会丢失 Redo log采用\u0026quot;预写日志(WAL, Write-Ahead Logging)\u0026ldquo;机制：在数据页修改前，先记录日志到redo log buffer，再根据策略刷盘到redo log文件 刷盘策略 通过innodb_flush_log_at_trx_commit 参数控制 0：每秒刷盘一次，事务提交时不刷盘(可能丢失1秒数据) 1：每次事务提交都刷盘(默认，最安全) 2：写入OS缓存，不立即刷盘(仅MySQL崩溃安全，服务器宕机可能丢失数据) bin log 二进制日志 Binlog是MySQL Server层维护的逻辑日志，记录所有引起数据变更的SQL语句或行变更 主要用于 主从复制：从库通过重放主库的binlog实现数据同步 时间点恢复：结合全量备份和binlog可实现任意时间点的数据恢复 数据归档：记录数据库所有变更历史 三种格式 STATEMENT：记录SQL原文(默认)，可能因函数(如NOW())导致主从不一致 ROW：记录行数据变更(最安全)，但日志量大 MIXED：混合模式，根据语句自动选择格式 刷盘控制 通过 sync_binlog 参数控制 0：由系统决定刷盘时机 1：每次事务提交都刷盘(最安全) N：每N个事务刷盘一次(平衡性能与安全性) 两阶段提交：保证日志一致性 Prepare阶段：写入redo log并标记为prepare状态 写入binlog Commit阶段：将redo log标记为commit状态 读写分离 # SpringBoot+Mybatis-Plus实现mysql读写分离方案 在 Spring Boot 中优雅地实现读写分离 【读写分离】SpringBoot整合多数据源实现读写分离（一） Reference # MySQL 架构原理 "},{"id":46,"href":"/post/life/learning-others-log/","title":"other learning","section":"Life","content":" other learning # 经济学原理 # 经济学原理 1 微观部分 什么是经济学 2 什么是经济学 3 像经济学家一样思考 1 4 像经济学家一样思考 2 5 经济相互依存性和贸易的好处 1 6 经济相互依存性和贸易的好处 2 7 供给与需求 1 8 供给与需求 2 9 供给与需求 3 10 弹性及其应用 1 11 弹性及其应用 2 12 弹性及其应用 3 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 2025-01-04 # 清华韩秀云精品课（第一季，64集） # 清华韩秀云精品课（第一季，64集） ✅ 第一期：国外宏观经济形势 # 1 美国央行大放水 2025-01-04 2 负债率的欧洲和日本 2025-01-04 3 政府发钱刺激经济 2025-01-04 ✅ 第二期：通胀来了，该如何配置资产 # 4 通胀来了怎么办 2025-01-05 5 如何配置你的资产？2025-01-05 6 投资房产考虑什么？2025-01-05 7 投资黄金有必要吗？2025-01-06 8 炒股要注意什么？2025-01-06 ✅ 第三期：我国宏观政策走向 # 9 政府救市与共同富裕 2025-01-06 10 2022年政策与行业机会 2025-01-07 ✅ 第四期：黄金 # 11 黄金的前世今生 2025-01-07 12 美元和黄金挂钩与脱钩 2025-01-07 13 黄金的避险功能 2025-01-08 14 全世界的金库在哪里 2025-01-08 15 投资黄金该注意什么 2025-01-08 ✅ 第五期：石油 # 16 石油的前世今生 2025-01-09 17 洛克菲勒与标准石油 2025-01-09 18 美国石油反垄断 2025-01-09 19 油价为何总在波动 2025-01-11 20 欧佩克的转变 2025-01-11 21 石油的用途 2025-01-11 22 油价为何是负的 2025-01-12 23 什么是石油期货的 2025-01-12 ✅ 第六期：楼市 # 24 房价的成长史的 2025-01-12 25 楼市中看不见的手的 2025-01-13 26 市场决定资源配置的 2025-01-13 27 买房要选稀缺的 2025-01-13 28 买住宅怎么选 2025-01-15 29 买商铺和写字楼 2025-01-15 30 买房看机会成本 2025-01-15 31 买房要注意几件事 2025-01-16 32 买房还是租房好 2025-01-16 33 政府何为要调控楼市 2025-01-16 34 楼市调控还会继续吗？ 2025-01-17 35 房地产税会退出吗？ 2025-01-17 36 房地产税推出后，房价会下跌吗？ 2025-01-17 37 买房防止变成资产 2025-01-19 38 警惕房地产泡沫 2025-01-19 39 全球楼市涨跌互见 2025-01-19 第七期：股市 # 40 炒股要懂经济学 2025-01-20 41 股票是如何诞生的？ 2025-01-20 42 东印度公司的第一张股票 2025-01-20 43 英美为什么发股票 2025-01-21 44 荷兰证券交易所的诞生 2025-01-21 45 纽约证券交易所的由来 2025-01-21 46 道琼斯指数的故事 2025-01-21 47 股票价格与股价指数 2025-01-21 48 股市的投资理念 2025-01-21 49 炒股应该注意什么？2025-02-09 50 参与股市的几种方式 2025-02-09 51 郁金香泡沫 2025-02-09 52 密西西比泡沫 2025-02-10 53 南海泡沫 2025-02-10 54 美国1929年股灾 2025-02-10 55 中国2007年股市暴涨 2025-02-11 56 中国2015年股灾 2025-02-11 57 教你判断股市趋势 2025-02-11 第八期：汇市 # 58 汇率的基本知识 2025-02-13 59 人民币汇率 2025-02-13 60 美元的霸权 2025-02-13 61 欧元的诞生 2025-02-15 62 人民币国际化 2025-02-15 "},{"id":47,"href":"/post/life/podcast/","title":"podcast","section":"Life","content":" podcast # 小宇宙 # 码农姐妹 经济新闻每日速递 纵横说 "},{"id":48,"href":"/post/life/politics/","title":"politics","section":"Life","content":" politics # 茶党 # \u0026ldquo;茶党\u0026rdquo;（Tea Party）通常指的是美国的一个政治运动，这个运动始于2009年，主要由保守派共和党支持者组成，强调减少政府开支、降低税收、限制政府权力以及遵守美国宪法。茶党的名字来源于1773年的波士顿茶叶事件，这是一个反对英国殖民统治和高税收的历史事件，象征着对政府过度干预的抗议。\n茶党成员经常组织示威活动，尤其是在经济政策和财政责任方面。他们在2010年的中期选举中对美国政治产生了显著影响，支持了多位共和党候选人的当选，这些候选人随后在美国国会中代表了更加保守的立场。\n随着时间的发展，茶党的影响力有所减弱，但它仍然是美国政治中一个重要的保守力量。如果你有关于茶党的更具体问题，欢迎继续提问。\n茶党和共和党建制派的区别是什么 # 茶党和共和党建制派是美国共和党内两个不同的政治派别，它们在政治立场、策略和目标上存在一些显著差异：\n政治立场：\n茶党：茶党通常被视为共和党内的激进派，强调极端保守的经济政策，比如大幅减税、削减政府开支、反对政府干预市场、减少债务和赤字。此外，茶党成员往往强烈反对奥巴马政府时期的医疗保健改革（即“奥巴马医改”）等政策。 共和党建制派：相比之下，建制派共和党人虽然也支持保守政策，但他们的立场相对温和，愿意与民主党合作以实现政治目标。建制派更倾向于维护共和党的传统利益，包括与大企业和精英阶层的关系。 策略和方法：\n茶党：茶党成员倾向于采取更为激进的策略，包括组织大规模抗议活动、支持极端保守的候选人、反对妥协。他们通常认为现有的政治体系已经腐败，需要彻底改革。 共和党建制派：建制派共和党人更倾向于通过传统政治渠道实现目标，如立法谈判、建立联盟和政治筹款。他们更注重保持共和党的整体稳定和长期利益。 目标：\n茶党：茶党的目标是推动共和党向更加保守的方向发展，减少政府规模和干预，保护个人自由和财产权。 共和党建制派：建制派的目标是保持共和党的主流地位，通过务实的政治策略赢得选举，维护共和党的长期利益和权力。 支持者基础：\n茶党：茶党的支持者通常是中下层中产阶级，他们对经济困境和政府过度干预感到不满，希望通过政治行动表达自己的诉求。 共和党建制派：建制派的支持者更多来自大企业和精英阶层，他们希望通过共和党的政策维护自身的经济利益。 总结来说，茶党和共和党建制派在政治立场、策略和目标上存在明显的差异，茶党更激进、更强调基层动员，而建制派则更温和、更注重政治稳定和长期利益。\n"},{"id":49,"href":"/post/computer-science/database/postgresql/","title":"postgresql","section":"Database","content":" postgresql # "},{"id":50,"href":"/post/computer-science/llm/2025-03-30-2-postgresql%E4%B8%AD%E5%88%86%E5%8C%BA%E9%94%AE%E4%BC%9A%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E5%90%97/","title":"postgresql中分区键会自动创建索引吗","section":"Computer Science","content":" postgresql中分区键会自动创建索引吗 # 在PostgreSQL中，分区键不会自动创建索引。以下是详细说明和相关建议：\n1. 分区键与索引的关系 # PostgreSQL的分区表机制本身不会自动为分区键创建索引。分区键仅用于数据路由（决定数据存储在哪个分区），但不会自动优化基于该列的查询性能1。 如果需要对分区键进行高效查询（尤其是范围查询或等值查询），必须手动创建索引。例如： -- 在分区表上显式创建分区键索引 CREATE INDEX idx_logdate ON log_history (logdate); -- 自动在所有子分区上创建相同索引 从PostgreSQL 11开始，在父表上创建的索引会自动传播到所有子分区16。 2. 为什么需要手动创建索引？ # 分区剪枝（Partition Pruning）依赖分区键：虽然查询时PostgreSQL会根据分区键过滤不需要的分区，但如果查询条件还包含其他非分区键列，仍需额外索引来加速126。 唯一约束的限制：若要在分区表上创建主键或唯一约束，必须包含分区键列，否则无法保证全局唯一性16。例如： -- 正确做法：包含分区键 ALTER TABLE sales ADD PRIMARY KEY (order_id, sale_date); -- sale_date是分区键 3. 自动索引传播的特性 # 从PostgreSQL 11开始，在父表上创建的索引（包括唯一索引）会自动在所有子分区上创建相同结构的索引16。 但需注意： 并发创建索引（CONCURRENTLY）：无法直接在父表上并发创建索引，需逐个分区操作29。 索引类型一致性：所有分区的索引必须与父表索引类型相同（如B-tree、Hash等）。 4. 最佳实践建议 # 显式为高频查询的分区键创建索引，即使它已用于分区剪枝126。 结合查询模式设计索引：若查询常使用分区键 + 其他列，可创建复合索引。 定期监控索引使用情况：删除未使用的索引以减少维护开销。 总结 # PostgreSQL的分区键本身不会自动创建索引，需手动添加。合理设计分区键和索引（尤其是包含分区键的复合索引）能显著提升查询性能116。\n"},{"id":51,"href":"/post/computer-science/distributed-system/message-queue/rabbitmq/","title":"rabbitmq","section":"Message Queue","content":" rabbitmq # main # RabbitMQ RabbitMQ Tutorials Hello World Work Queues Distributing tasks among workers 一个生产者，多个消费者 Publish/Subscribe Sending messages to many consumers at once 一个消息，每个消费者都能接收到 Routing 多个消费者订阅同一个生产者的消息, 通过路由键，选择性消费 Topics 通过匹配的方式来选择性接收 RPC rabbitmq有哪几种模式 # 简单模式（Simple Mode） 描述：一个生产者（Producer）和一个消费者（Consumer），消息直接发送到队列中，不需要交换机（Exchange）。 特点：消息只能被一个消费者处理，适合简单的点对点通信。 应用场景：简单的任务队列，如日志收集。 工作队列模式（Work Queue Mode） 描述：一个生产者和多个消费者，消息分发到多个消费者，但每个消息只能被一个消费者处理。 特点：默认采用轮询机制分发消息，支持手动确认（ack）以确保消息处理成功。 应用场景：任务分发，如多个消费者处理不同的任务。 发布/订阅模式（Publish/Subscribe Mode） 描述：生产者将消息发送到交换机（Exchange），交换机将消息广播到所有绑定的队列，每个队列可以有多个消费者。 特点：使用 fanout 类型的交换机，消息会被所有消费者接收。 应用场景：消息广播，如通知多个系统或用户。 路由模式（Routing Mode） 描述：生产者将消息发送到交换机，交换机根据路由键（Routing Key）将消息分发到匹配的队列。 特点：使用 direct 类型的交换机，支持精确的路由规则。 应用场景：根据特定规则分发消息，如按日志级别分类。 主题模式（Topics Mode） 描述：类似于路由模式，但支持更灵活的路由规则，使用通配符（如 * 和 #）匹配路由键。 特点：使用 topic 类型的交换机，支持复杂的路由逻辑。 应用场景：需要灵活匹配和过滤消息的场景，如多维度消息分发。 RPC 模式（Remote Procedure Call Mode） 描述：生产者发送消息后，等待消费者处理并返回结果，类似于远程过程调用。 特点：通过回调队列实现请求和响应的匹配。 应用场景：需要同步返回结果的场景，如远程调用。 发布确认模式（Publisher Confirms Mode） 描述：生产者在发送消息后，等待 RabbitMQ 的确认，确保消息被成功接收。 特点：提高消息的可靠性，避免消息丢失。 应用场景：需要高可靠性的消息传递，如金融交易。 Header 模式（Headers Mode） 描述：根据消息的头部信息（Headers）进行路由，而不是依赖路由键。 特点：使用 headers 类型的交换机，支持复杂的匹配规则。 应用场景：需要根据消息属性进行路由的场景。 rabbitmq有哪些类型的路由键 # 在 RabbitMQ 中，路由键（Routing Key） 是用于决定消息如何被路由到队列的关键字。路由键的具体使用方式取决于 交换机类型，不同类型的交换机对路由键的处理方式不同。以下是 RabbitMQ 中常见的交换机类型及其对应的路由键使用方式：\n直连交换机（Direct Exchange） 路由键规则：路由键必须与 绑定键（Binding Key） 完全匹配。 特点：消息会被精确地路由到绑定键与路由键完全匹配的队列。 示例：如果队列绑定键为 error，则只有路由键为 error 的消息会被路由到该队列。 主题交换机（Topic Exchange） 路由键规则：路由键支持通配符匹配。 * 匹配一个单词（如 quick.orange.rabbit 匹配 quick.orange.*）。 # 匹配零个或多个单词（如 lazy.# 匹配 lazy.orange.rabbit 和 lazy.dog）。 特点：支持灵活的路由规则，适用于复杂的消息分发场景。 示例：路由键 quick.orange.rabbit 会匹配绑定键 quick.orange.* 和 *.rabbit 的队列。 扇出交换机（Fanout Exchange） 路由键规则：忽略路由键。 特点：将消息广播到所有绑定到该交换机的队列，路由键对消息路由没有影响。 示例：无论路由键是什么，消息都会被发送到所有绑定队列。 头交换机（Headers Exchange） 路由键规则：不使用路由键，而是根据消息的 头部属性（Headers） 进行匹配。 特点：通过键值对匹配消息和队列，适用于需要基于消息属性进行路由的场景。 示例：如果队列绑定规则要求消息头部包含 type=error，则只有满足该条件的消息会被路由到该队列。 总结 直连交换机：完全匹配路由键和绑定键。 主题交换机：支持通配符匹配，灵活性高。 扇出交换机：忽略路由键，广播消息。 头交换机：基于消息头部属性匹配，不使用路由键。 核心组件 # Broker（服务器） 负责接收和分发消息的应用，RabbitMQ Server 就是 Message Broker。 Virtual Host（虚拟主机） 用于逻辑隔离，类似于网络中的 namespace 概念。多个用户可以共享同一个 RabbitMQ Server，但每个用户在自己的 vhost 中创建 exchange、queue 等。 Connection（连接） 生产者（Producer）和消费者（Consumer）与 Broker 之间的 TCP 连接。 Channel（信道） 在 Connection 内部建立的逻辑连接，用于执行 AMQP 操作。每个线程通常对应一个 Channel，以减少 TCP 连接的开销。 Exchange（交换机） 消息到达 Broker 的第一站，根据分发规则将消息路由到队列。常见的类型包括 direct、topic 和 fanout。 Queue（队列） 消息最终被送到队列中，等待消费者取走。 Binding（绑定） 交换机和队列之间的虚拟连接，binding 中可以包含 routing key，用于消息的分发依据。 Message（消息） 由生产者发送并通过交换机路由到队列的数据单元，通常由头部（元数据）和正文（负载数据）组成。 Producer（生产者） 创建并发布消息的应用程序，负责将消息发送到 RabbitMQ。 Consumer（消费者） 从队列中获取并处理消息的应用程序。 AMQP（高级消息队列协议） RabbitMQ 使用的通信协议，确保不同系统间的互操作性。 这些组件共同构成了 RabbitMQ 的核心架构，使其能够高效地处理消息传递任务。\nRabbit可以实现高吞吐量吗 # 是的，RabbitMQ 可以实现高吞吐量，但其性能表现取决于具体的配置和使用场景。以下是一些关键点和优化策略，可以帮助 RabbitMQ 实现更高的吞吐量： RabbitMQ 的吞吐量表现 RabbitMQ 的吞吐量通常在 万级到十万级消息每秒，虽然相比 Kafka 和 RocketMQ（十万级到百万级）稍低，但在大多数场景下已经足够高效。 其性能受多种因素影响，包括硬件配置、网络带宽、消息大小、持久化设置等。 优化 RabbitMQ 吞吐量的策略 使用 Direct Exchange** Direct Exchange 的吞吐率比 Topic Exchange 快约 2 倍，因为它不需要复杂的路由匹配。 2. 自动确认（Auto ACK） 自动确认比手动确认的吞吐率快约 2 倍，因为减少了确认操作的开销。但自动确认可能会丢失消息，需根据业务需求权衡。 3. 批量消费与确认 在高吞吐量场景下，建议使用 channel.Qos 设置预取数量（prefetchCount），结合缓冲区处理和批量确认（channel.Ack 的 multiple 参数），以减少单条确认的开销。 4. 惰性队列（Lazy Queue） 惰性队列将消息直接存储到磁盘，避免了内存过载和间歇性的 page-out 操作，适合处理大量消息堆积的场景。 5. 集群和镜像模式 镜像模式（Mirror Mode）可以保证数据的高可靠性，同时通过多节点分担负载提高吞吐量。 6. 优化硬件和网络 使用高性能的硬件（如 SSD）和充足的网络带宽，可以显著提升 RabbitMQ 的吞吐量。 7. 消息大小和持久化 较小的消息大小和合理的持久化设置（如仅在必要时启用）可以提高吞吐量。 RabbitMQ 的吞吐量虽然不及 Kafka 和 RocketMQ，但在 低延迟 和 灵活性 方面表现更优，适合需要复杂路由和消息顺序性保证的场景。 4. 实际应用建议 # 如果业务场景对吞吐量要求极高（如日志收集、大数据处理），可以考虑 Kafka 或 RocketMQ。 如果业务场景更注重低延迟、灵活路由和易用性，RabbitMQ 是一个不错的选择，并通过上述优化策略提升其吞吐量。 集群模式 # 主备模式（Warren 模式） 描述：主备模式是一种简单的高可用方案，通常用于并发量和数据量不高的场景。主节点提供读写服务，而备节点仅作为备份，不提供读写服务。当主节点宕机时，备节点会自动切换为主节点，继续提供服务。 特点： - 主节点提供读写，备节点仅备份。 - 配置简单，适合中小规模应用。 应用场景：中小型系统，对高可用性要求不高的场景。 镜像模式（Mirror 模式） 描述：镜像模式是 RabbitMQ 最常用的集群模式，确保数据的高可靠性。在这种模式下，队列中的消息会在多个节点之间同步，即使某个节点宕机，数据也不会丢失。 特点： - 消息和元数据在所有节点间同步。 - 通常需要 2-3 个节点来实现数据同步，保证 100% 数据不丢失。 - 适合对数据可靠性要求高的场景。 应用场景：互联网大厂、金融系统等对数据可靠性要求极高的场景。 多活模式（Federation 模式） 描述：多活模式用于实现异地数据复制，适合跨地域的 RabbitMQ 集群。通过 Federation 插件，可以在不同数据中心之间复制消息，实现高可用性和负载均衡。 特点： - 支持跨地域的消息复制。 - 配置复杂，但可以实现高可用性和负载均衡。 - 适合需要异地灾备和多中心部署的场景。 应用场景：跨地域的分布式系统，如全球化的电商平台。 远程模式（Shovel 模式） 描述：远程模式用于将消息从本地集群复制到远程集群，适合处理高负载场景。通过 Shovel 插件，可以将部分消息路由到远程集群进行处理。 特点： - 支持异步消息复制。 - 配置较为复杂，适合处理高负载场景。 - 目前已较少使用，多被多活模式替代。 应用场景：早期的高负载处理场景。 默认集群模式（普通集群模式） 描述：默认集群模式下，RabbitMQ 仅同步元数据（如队列、交换机、绑定关系等），而不会同步队列中的消息内容。消息仅存储在创建队列的节点上，其他节点只保存元数据和指向该节点的指针。 特点： - 消息不复制，节省存储空间。 - 节点故障时，消息可能丢失。 - 适合对消息可靠性要求不高的场景。 应用场景：测试环境或对消息可靠性要求较低的场景。 RabbitMQ的集群模式在实际项目中如何选型 # 中小规模系统，对高可用性要求不高 推荐模式：主备模式（Warren 模式） 特点： - 配置简单，易于维护。 - 主节点提供读写服务，备节点作为备份。 - 当主节点宕机时，备节点自动切换为主节点。 适用场景： - 中小型系统，消息量不大。 - 对高可用性要求不高，允许短暂的服务中断。 对数据可靠性要求高，需要消息不丢失 推荐模式：镜像模式（Mirror 模式） 特点： - 消息和元数据在所有节点间同步，保证数据不丢失。 - 通常需要 2-3 个节点来实现数据同步。 - 适合对数据可靠性要求极高的场景。 适用场景： - 金融、支付等对数据可靠性要求高的系统。 - 互联网大厂的核心业务系统。 跨地域部署，需要异地灾备和多中心高可用 推荐模式：多活模式（Federation 模式） 特点： - 支持跨地域的消息复制，实现异地灾备。 - 配置复杂，但可以实现高可用性和负载均衡。 - 适合需要异地灾备和多中心部署的场景。 适用场景： - 全球化的电商平台或分布式系统。 - 需要跨地域高可用的业务。 高负载场景，需要分担消息处理压力 推荐模式：远程模式（Shovel 模式） 特点： - 将部分消息路由到远程集群进行处理，分担负载。 - 配置较为复杂，目前已较少使用，多被多活模式替代。 适用场景： - 早期的高负载处理场景。 - 需要分担消息处理压力的系统。 测试环境或对消息可靠性要求较低 推荐模式：默认集群模式（普通集群模式） 特点： - 仅同步元数据（如队列、交换机、绑定关系等），消息不复制。 - 节点故障时，消息可能丢失。 - 配置简单，适合测试环境或对消息可靠性要求较低的场景。 适用场景： 开发测试环境。 对消息可靠性要求较低的业务。 需要灵活的路由和消息分发 推荐模式：镜像模式 + 多活模式 特点： - 结合镜像模式的高可靠性和多活模式的跨地域能力。 - 实现灵活的路由和消息分发，同时保证数据可靠性。 适用场景： - 复杂的分布式系统，需要灵活的消息路由和高可靠性。 需要高吞吐量和低延迟 推荐模式：镜像模式 + 优化配置 特点： - 通过镜像模式保证数据可靠性，同时优化配置（如 Direct Exchange、自动确认、批量处理等）提升吞吐量。 - 适合对吞吐量和延迟要求较高的场景。 适用场景： - 高并发的消息处理系统，如实时交易系统。 rabbitmq可以像kafka一样把消费者平均分配到所有broker上吗 # RabbitMQ 和 Kafka 在消费者分配机制上有显著差异，RabbitMQ 并不能像 Kafka 一样将消费者平均分配到所有 Broker 上。以下是两者的具体对比： RabbitMQ 的消费者分配机制 在 RabbitMQ 中，消费者是直接绑定到队列的，而队列是创建在特定的 Broker 上的。因此，消费者的分配取决于队列的分布： 队列分布：一个队列只能存在于一个 Broker 上，即使是在集群模式下，队列也不会自动分布在多个 Broker 上。 消费者分配：消费者连接到队列所在的 Broker，因此消费者的分布取决于队列的位置。如果一个队列在一个 Broker 上，那么所有消费该队列的消费者都会连接到这个 Broker。 镜像队列：为了提高可用性，RabbitMQ 支持镜像队列（Mirrored Queue），将队列复制到多个 Broker 上。但这只是数据的冗余备份，消费者的连接仍然集中在主队列所在的 Broker 上。 Kafka 的消费者分配机制 在 Kafka 中，消费者是基于分区（Partition）进行分配的，而分区可以分布在多个 Broker 上： 分区分布：一个主题（Topic）可以分为多个分区，每个分区可以分布在不同的 Broker 上。 消费者分配：消费者组中的消费者会分配到不同的分区，从而实现负载均衡。Kafka 会自动将分区均匀地分配给消费者组中的消费者。 动态扩展：Kafka 支持动态增加分区和消费者，从而实现横向扩展。 RabbitMQ 与 Kafka 的对比\n特性 RabbitMQ Kafka 消费者分配 消费者绑定到队列，队列位于单个 Broker 上 消费者分配到分区，分区分布在多个 Broker 上 负载均衡 需要手动配置镜像队列或多队列实现负载均衡 自动将分区均匀分配给消费者组 扩展性 扩展性有限，依赖于队列的分布 支持动态增加分区和消费者，扩展性强 适用场景 适合低延迟、复杂路由的场景 适合高吞吐量、流数据处理的场景 如何实现 RabbitMQ 的负载均衡 虽然 RabbitMQ 不能像 Kafka 那样自动将消费者分配到所有 Broker 上，但可以通过以下方式实现负载均衡： 多队列策略：为同一个主题创建多个队列，并将消费者分布到不同的队列上。 镜像队列：使用镜像队列提高可用性，但消费者的连接仍然集中在主队列所在的 Broker 上。 客户端负载均衡：在客户端实现逻辑，将消费者均匀地分配到不同的 Broker 上。 rabbitmq 为什么不能保证消息的顺序性 # 多个消费者并发消费同一个队列 问题：当多个消费者同时消费同一个队列时，RabbitMQ 会将消息分发给不同的消费者。由于每个消费者的处理速度不同，可能会导致消息的消费顺序与发送顺序不一致。 示例：如果消息 A、B、C 按顺序进入队列，消费者 1 拿到消息 A，消费者 2 拿到消息 B，但消费者 2 处理速度更快，导致消息 B 先于消息 A 被处理。 消费者内部多线程处理 问题：即使一个队列只有一个消费者，如果消费者内部使用多线程处理消息，不同线程的执行顺序也可能导致消息的消费顺序错乱。 示例：消费者内部将消息 A 和 B 分配给不同的线程处理，线程 2 先处理消息 B，线程 1 后处理消息 A，导致顺序错乱。 网络延迟或重试机制 问题：消息在传输过程中可能因网络延迟或消费者处理失败而触发重试机制，导致消息的到达顺序与发送顺序不一致。 复杂的交换器和队列配置 问题：使用复杂的交换器配置（如 Topic Exchange）可能会将消息路由到不同的队列中，这些队列的消费顺序无法保证。 RabbitMQ 的设计机制 RabbitMQ 的设计目标是高吞吐量和高可用性，而不是严格的消息顺序性。它通过并发消费和负载均衡来提高性能，但这也会导致消息顺序的不可控。 如果需要保证消息顺序性，可以通过以下方式解决： 单一消费者模式：一个队列只绑定一个消费者。 消息分区策略：将相关消息路由到同一个队列，确保顺序性。 消费者内部排序：在消费者端使用内存队列对消息进行排序。 如果只有一个生产者一个消费者，消费者是单线程的，能保证消息的顺序性吗 # 是的，如果只有一个生产者、一个消费者，并且消费者是单线程的，RabbitMQ 可以保证消息的顺序性。以下是具体原因和机制： 生产者发送顺序 生产者将消息顺序发送到 RabbitMQ 的队列中。RabbitMQ 的队列是先进先出（FIFO）的，因此消息会按照发送顺序存储在队列中。 消费者单线程消费 消费者是单线程的，意味着它一次只处理一条消息，处理完一条消息后才会从队列中取出下一条消息。这种方式确保了消息按照队列中的顺序被消费。 队列的 FIFO 特性 RabbitMQ 的队列本身是 FIFO 数据结构，只要消费者是单线程的，消息就会按照进入队列的顺序被处理。 注意事项 网络延迟：虽然生产者和消费者是单线程的，但在极端情况下（如网络延迟或重试机制），可能会导致消息到达队列的顺序与发送顺序不一致。这种情况非常罕见，但在高要求场景下仍需注意。 消费者内部逻辑：如果消费者在处理消息时引入了异步操作（如多线程或异步回调），可能会破坏消息的顺序性。 "},{"id":52,"href":"/post/computer-science/operating-system/raspberrypi/","title":"raspberry pi","section":"Operating System","content":" raspberry pi # reference # 树莓派文档 clash # reference 为什么全局代理后， CMD 依然 Ping 不通 Google？ 树莓派 Clash 透明代理(TProxy) 在 Raspberry Pi 上运行 Clash 作为透明代理 解决 Clash Meta 中TUN模式无法上网的问题：正确配置DNS设置 解决 树莓派ping: baidu.com: 域名解析暂时失败 树莓派安装clash，实现科学上网 在 Raspberry Pi 上运行 Clash 作为透明代理 http://yacd.haishan.me yt-dlp # 使用这个工具，可以下载 youtube 视频\n后台下载命令 nohup yt-dlp -N 20 {{video_url}} --merge-output-format mp4 \u0026amp; 实时查看后台下载进度 tail -f nohup.out 停止下载 查询后台进程号 ps -aux | grep yt-dlp 杀死进程 kill -9 {{进程号}} tomcat # 树莓派安装Tomcat wget https://archive.apache.org/dist/tomcat/tomcat-9/v9.0.36/bin/apache-tomcat-9.0.36.tar.gz tar zxvf apache-tomcat-9.0.36.tar.gz cd ~/apache-tomcat-9.0.36/bin sudo ./startup.sh dd # dd 命令是一个非常强大的工具，可以用来复制和转换文件。通过创建一个临时文件并测量其读写速度，可以测试存储介质的性能。\n打开终端：您可以通过SSH连接到您的树莓派，或者直接在树莓派上打开终端。\n测试写入速度：\n创建一个 1GB 的临时文件，并测量写入速度： sudo dd if=/dev/zero of=testfile bs=1M count=1024 conv=fdatasync 解释： if=/dev/zero：从 /dev/zero 读取数据（这是一个无限的零流）。 of=testfile：将数据写入名为 testfile 的文件。 bs=1M：每次读写 1MB 的数据块。 count=1024：写入 1024 个 1MB 的数据块，总共 1GB。 conv=fdatasync：确保所有数据都写入磁盘后再结束命令。 测试读取速度：\n读取刚刚创建的文件，并测量读取速度： sudo dd if=testfile of=/dev/null bs=1M 解释： if=testfile：从 testfile 文件读取数据。 of=/dev/null：将数据写入 /dev/null（丢弃数据）。 bs=1M：每次读取 1MB 的数据块。 删除测试文件：\n测试完成后，删除 testfile 以释放空间： sudo rm testfile iwlist # sudo iwlist wlan0 scan sudo iwlist wlan0 scan | grep SSID 定时任务 # 查看当前的定时任务 crontab -l 编辑定时任务 crontab -e 外网登录 # 如何从外网登录访问树莓派Raspberry Pi holer Wisdom wisdom-projects/holer 方式一：使用公开的holer映射或者开通holer服务，通过holer客户端软件经holer服务器实现公网访问 方式二：使用holer服务端软件搭建holer服务，通过holer客户端软件经自己服务器实现公网访问， Holer端口映射软件使用教程 cpolar # cpolar 3.3 将隧道配置为后台服务 Cpolar快速入门教程：树莓派系列 后台管理页面 http://localhost:9200 zsh: corrupt history file /home/me/.zsh_history # 怎样修复zsh历史记录错误：zsh: corrupt history file /home/me/.zsh_history cd ~ mv .zsh_history .zsh_history_bad strings -eS .zsh_history_bad \u0026gt; .zsh_history fc -R .zsh_history "},{"id":53,"href":"/post/computer-science/redis/","title":"redis","section":"Computer Science","content":" redis # redis基本数据类型, 使用场景 # 5大基本类型 String 字符串 常用场景： 缓存：存储用户信息、配置信息等。 计数器：如文章阅读量、点赞数等。 分布式锁：通过 SETNX 命令实现。 Hash 哈希 常用场景： 存储用户信息：如用户 ID 作为 key，用户属性（姓名、年龄等）作为 field-value 对。 存储商品信息：如商品 ID 作为 key，商品详情（价格、库存等）作为 field-value 对。 List 列表 常用场景： 消息队列：通过 LPUSH 和 RPOP 实现简单的消息队列。 最新消息列表：如微博的时间线、朋友圈动态等。 Set 集合 常用场景： 标签系统：如文章标签、用户兴趣标签等。 去重：如统计独立 IP 访问量。 Sorted Set 有序集合 常用场景： 排行榜：如游戏积分排行榜、热搜榜等。 延迟队列：通过分数存储时间戳，按时间顺序处理任务。 什么是缓存击穿 缓存穿透 缓存雪崩 # 缓存击穿 Cache Breakdown 热点数据过期的同时有大量的请求访问该热点数据，导致数据库负载突然增加 解决办法 使用互斥锁，同时只能一个线程读取数据库中的数据后保存到缓存中，其他线程等待读取缓存中的值 缓存穿透 Cache Penetration 查询的数据在缓存和数据库中都不存在 解决办法 缓存空值 布隆过滤器 参数校验 简单动态字符串 # 链表 # 字典 # 跳跃表 # 整数集合 # 压缩列表 # 对象 # 数据库 # redis 集群 # redis 的集群模式有哪些？ # 主从模式 主节点负责写操作，从节点负责读操作，实现读写分离 哨兵模式 在主从复制的基础上，增加了自动故障转移功能。哨兵节点监控主从节点的状态，当主节点故障时，自动选举从节点为主节点 cluster模式 通过数据分片（Sharding）实现分布式存储，支持自动故障转移和负载均衡 redis 数据如何进行分片？ # 槽位计算：通过 CRC16(key) % 16384 计算键（key）所属的槽位 槽位分配：每个节点负责维护一部分槽位，槽位分布均匀，支持动态扩容和缩容 数据路由：客户端请求时，先计算 key 的槽位，然后根据槽位找到对应的节点 分片的实现方案有哪些？ # 客户端分片 Redis-rb Predis 代理分片（客户端与Redis节点之间增加代理层 Twemproxy） 增加了系统的复杂性和延迟 主从 # Reference 《Redis设计与实现》 第15章 复制 在Redis中，用户可以通过执行SLAVEOF命令或者设置slaveof选项，让一个服务器去复制（replicate）另一个服务器，我们称呼被复制的服务器为主服务器（master），而对主服务器进行复制的服务器则被称为从服务器（slave） 进行复制中的主从服务器双方的数据库将保存相同的数据，概念上将这种现象称作“数据库状态一致”，或者简称“一致”。 旧版复制功能的实现 # 同步 sync 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 步骤 1）从服务器向主服务器发送SYNC命令。 2）收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令。 3）当主服务器的BGSAVE命令执行完毕时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。 4）主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。 命令传播 command propagate 命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器的数据库重新回到一致状态 旧版复制功能的缺陷 # 在Redis中，从服务器对主服务器的复制可以分为以下两种情况 初次复制：从服务器以前没有复制过任何主服务器，或者从服务器当前要复制的主服务器和上一次复制的主服务器不同 对于初次复制来说，旧版复制功能能够很好地完成任务 断线后重复制：处于命令传播阶段的主从服务器因为网络原因而中断了复制，但从服务器通过自动重连接重新连上了主服务器，并继续复制主服务器 对于断线后重复制来说，旧版复制功能虽然也能让主从服务器重新回到一致状态，但效率却非常低 SYNC命令是一个非常耗费资源的操作 1）主服务器需要执行BGSAVE命令来生成RDB文件，这个生成操作会耗费主服务器大量的CPU、内存和磁盘I/O资源。 2）主服务器需要将自己生成的RDB文件发送给从服务器，这个发送操作会耗费主从服务器大量的网络资源（带宽和流量），并对主服务器响应命令请求的时间产生影响。 3）接收到RDB文件的从服务器需要载入主服务器发来的RDB文件，并且在载入期间，从服务器会因为阻塞而没办法处理命令请求。 因为SYNC命令是一个如此耗费资源的操作，所以Redis有必要保证在真正有需要时才执行SYNC命令。 新版复制功能的实现 # 为了解决旧版复制功能在处理断线重复制情况时的低效问题，Redis从2.8版本开始，使用PSYNC命令代替SYNC命令来执行复制时的同步操作 PSYNC命令具有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式 其中完整重同步用于处理初次复制情况：完整重同步的执行步骤和SYNC命令的执行步骤基本一样，它们都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步 而部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态 部分重同步的实现 # 部分重同步功能由以下三个部分构成： 主服务器的复制偏移量（replication offset）和从服务器的复制偏移量 执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量 主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量的值加上N 从服务器每次收到主服务器传播来的N个字节的数据时，就将自己的复制偏移量的值加上N 通过对比主从服务器的复制偏移量，程序可以很容易地知道主从服务器是否处于一致状态 如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同的 相反，如果主从服务器两者的偏移量并不相同，那么说明主从服务器并未处于一致状态 主服务器的复制积压缓冲区（replication backlog） 复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB 和普通先进先出队列随着元素的增加和减少而动态调整长度不同，固定长度先进先出队列的长度是固定的，当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列 当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面 主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量 当从服务器重新连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作 如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作 相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作 根据需要调整复制积压缓冲区的大小 Redis为复制积压缓冲区设置的默认大小为1MB，如果主服务器需要执行大量写命令，又或者主从服务器断线后重连接所需的时间比较长，那么这个大小也许并不合适 如果复制积压缓冲区的大小设置得不恰当，那么PSYNC命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要 如果复制积压缓冲区的大小设置得不恰当，那么PSYNC命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要 其中second为从服务器断线后重新连接上主服务器所需的平均时间（以秒计算） 而write_size_per_second则是主服务器平均每秒产生的写命令数据量（协议格式的写命令的长度总和） 例如，如果主服务器平均每秒产生1 MB的写数据，而从服务器断线之后平均要5秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于5MB。 为了安全起见，可以将复制积压缓冲区的大小设为2secondwrite_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理 服务器的运行ID（run ID） 每个Redis服务器，不论主服务器还是从服务，都会有自己的运行ID 运行ID在服务器启动时自动生成，由40个随机的十六进制字符组成 当从服务器对主服务器进行初次复制时，主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来 当从服务器断线并重新连上一个主服务器时，从服务器将向当前连接的主服务器发送之前保存的运行ID 如果从服务器保存的运行ID和当前连接的主服务器的运行ID相同，那么说明从服务器断线之前复制的就是当前连接的这个主服务器，主服务器可以继续尝试执行部分重同步操作 相反地，如果从服务器保存的运行ID和当前连接的主服务器的运行ID并不相同，那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器，主服务器将对从服务器执行完整重同步操作 PSYNC 命令的实现 # 复制的实现 # 心跳检测 # Sentinel # Sentinel（哨岗、哨兵）是Redis的高可用性（high availability）解决方案：由一个或多个Sentinel实例（instance）组成的Sentinel系统（system）可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求 集群 # Redis集群是Redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供复制和故障转移功能 节点 # 一个Redis集群通常由多个节点（node）组成，在刚开始的时候，每个节点都是相互独立的，它们都处于一个只包含自己的集群当中，要组建一个真正可工作的集群，我们必须将各个独立的节点连接起来，构成一个包含多个节点的集群 槽指派 # Redis集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽（slot），数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点可以处理0个或最多16384个槽 当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok）；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态（fail） 在集群中执行命令 # 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己 如果键所在的槽正好就指派给了当前节点，那么节点直接执行这个命令 如果键所在的槽并没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令 重新分片 # Redis集群的重新分片操作可以将任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点），并且相关槽所属的键值对也会从源节点被移动到目标节点。 重新分片操作可以在线（online）进行，在重新分片的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求 ASK错误 # 复制与故障转移 # Redis集群中的节点分为主节点（master）和从节点（slave），其中主节点用于处理槽，而从节点则用于复制某个主节点，并在被复制的主节点下线时，代替下线主节点继续处理命令请求 消息 # 集群中的各个节点通过发送和接收消息（message）来进行通信，我们称发送消息的节点为发送者（sender），接收消息的节点为接收者（receiver） 节点发送的消息主要有以下五种 MEET PING PONG FAIL PUBLISH "},{"id":54,"href":"/post/computer-science/security/","title":"security","section":"Computer Science","content":" security # man-in-the-middle attack 中间人攻击 # SSL Pinning is a technique we use on the client side to avoid a man-in-the-middle attack by validating the server certificates. The developers embed (or pin) a list of trustful certificates in the client application during development and use them to compare against the server certificates during runtime.\nIf there is a mismatch between the server and the local copy of certificates, the connection will be disrupted, and no further user data will be sent to that server. This enforcement ensures that user devices communicate only with dedicated, trustful servers.\nSSL Pinning prevents a man-in-the-middle attack, which means an attacker can not intercept the traffic and modify the data. If an attacker can not intercept the traffic, the application automatically prevents many server-side vulnerabilities. Because an attacker can not perform API-level test cases, implementing SSL is very important.\nSSL pinning # reference Charles Proxy for Mobile apps that use SSL Pinning 8 Ways to Bypass SSL Pinning in iOS "},{"id":55,"href":"/post/computer-science/distributed-system/sentinel/","title":"Sentinel","section":"Distributed System","content":" Sentinel # 性能压测 # “引入Sentinel带来的性能损耗非常小，只有在业务单机量级超过25万QPS的时候才会有一些显著的影响（5%～10%左右），单机QPS不太大的时候损耗几乎可以忽略不计。”这是Sentinel官方文档中的一句话，本节将通过基准测试验证这句话。 SPI在Sentinel中的应用 # SPI机制在阿里巴巴集团开源的项目中被广泛使用，如Dubbo，RocketMQ与Sentinel都使用了SPI机制 除了Dubbo外，RocketMQ与Sentinel使用的都是Java提供的SPI机制 Dubbo使用的是自实现的一套SPI——Dubbo SPI，与Java SPI的配置方式不同，Dubbo SPI使用Key-Value方式配置，目的是实现自适应扩展机制 Java SPI实现原理与适用场景 SPI（Service Provider Interface，服务提供者接口）是一种服务发现机制，是Java的一个内置标准，可以保障不同的开发者实现某个特定的服务 SPI的本质是将接口实现类的全限定名配置在文件中，由服务加载器读取配置文件、加载实现类并创建实例。使用SPI机制能够实现运行时从配置文件中读取接口的实现类并创建实例 ServiceLoader.load() SPI机制的适用场景 适合适用策略模式、责任链模式的场景都可以使用SPI机制 Java SPI在Sentinel中的应用 我们可以直接替换Sentinel提供的默认SlotChainBuilder，使用自定义的SlotChainBuilder为资源构造自己的ProcessorSlotChain，以实现修改ProcessorSlot排列顺序、增加或移除ProcessorSlot的功能 责任链模式在Sentinel中的应用 # 我们将Sentinel提供的所有ProcessorSlot分为两类 一类是负责完成资源指标数据统计的ProcessorSlot 一类是实现限流、熔断等流量控制功能的ProcessorSlot Sentinel使用责任链模式将注册的所有ProcessorSlot按照一定的顺序串成一个单向链表 实现资源指标数据统计的ProcessorSlot必须在实现流量控制功能的ProcessorSlot的前面，原因很简单，限流、熔断降级等都需要依赖资源的实时指标数据做判断 Reference # 实战Alibaba Sentinel：深度解析微服务高并发流量治理 "},{"id":56,"href":"/post/computer-science/database/shardingsphere/","title":"shardingsphere","section":"Database","content":" shardingsphere # 官网 概览 # 什么是 shardingsphere # Apache ShardingSphere 是一款分布式的数据库生态系统， 可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力对原有数据库进行增强 Apache ShardingSphere 设计哲学为 Database Plus，旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。 它站在数据库的上层视角，关注它们之间的协作多于数据库自身 ShardingSphere-JDBC ShardingSphere-JDBC 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务 ShardingSphere-Proxy ShardingSphere-Proxy 定位为透明化的数据库代理端，通过实现数据库二进制协议，对异构语言提供支持 ShardingSphere-JDBC # ShardingSphere-Proxy # 启动手册 二进制发布包 使用 docker 构建 GraalVM Native Image(Alpha) 高性能数据库集群 # 第一种：读写分离 # 主库负责处理事务性的增删改操作，从库负责处理查询操作 能够有效的避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善 读写分离是根据SQL语义的分析，将读操作和写操作分别路由至主库与从库 两种方式 一主多从 多主多从 第二种：数据库分片 # 传统的将数据集中存储至单一节点的解决方案，在性能、可用性和运维成本这三方面已经难于满足海量数据的场景 性能 由于关系型数据库大多采用 B+ 树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降； 同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈 可用性 从可用性的方面来讲，服务化的无状态性，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。 而单一的数据节点，或者简单的主从架构，已经越来越难以承担。数据库的可用性，已成为整个系统的关键。 运维成本 从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，对于 DBA 的运维压力就会增大。 数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围 在传统的关系型数据库无法满足互联网场景需要的情况下，将数据存储至原生支持分布式的 NoSQL 的尝试越来越多。 但 NoSQL 对 SQL 的不兼容性以及生态圈的不完善，使得它们在与关系型数据库的博弈中始终无法完成致命一击，而关系型数据库的地位却依然不可撼动 什么是数据分片？ 按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中以达到提升性能瓶颈以及可用性的效果。 数据分片的有效手段是对关系型数据库进行分库和分表。 分库和分表均可以有效的避免由数据量超过可承受阈值而产生的查询瓶颈。 除此之外，分库还能够用于有效的分散对数据库单点的访问量； 分表虽然无法缓解数据库压力，但却能够提供尽量将分布式事务转化为本地事务的可能，一旦涉及到跨库的更新操作，分布式事务往往会使问题变得复杂。 使用多主多从的分片方式，可以有效的避免数据单点，从而提升数据架构的可用性。 读写分离分散了数据库读写操作的压力，但是没有分散存储的压力，为了满足业务数据存储的需求，就需要将存储分散到多台数据库服务器上 数据分片的有效手段是对关系型数据库进行分库和分表 数据分片的拆分方式 垂直分片 水平分片 垂直分片 # 什么是垂直分片？ 按照业务拆分的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务 而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库 垂直分片的问题 垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。 专库专用 例如将商城库拆分为订单库、用户库、库存库 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理 垂直分表适合将表中某些不常用的列，或者是占了大量空间的列拆分出去 水平分片 # 什么是水平分片 水平分片又称为横向拆分。 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分 例如：根据主键分片，偶数主键的记录放入 0 库（或表），奇数主键的记录放入 1 库（或表） 水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是数据分片的标准解决方案 水平分表 单表切分为多表之后，新的表即使在同一个数据库服务器中，也可能带来可观的性能提升，如果性能能够满足业务要求，可以不拆分到多台数据库服务器，毕竟业务分库也会引入很多复杂性 水平分库 如果单表拆分为多表后，单台服务器依然无法满足性能要求，那就需要将多个表分散在不同的数据库服务器中 数据分片的挑战 # 面对如此散乱的分片之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。 他们需要知道数据需要从哪个具体的数据库的子表中获取 另一个挑战则是，能够正确的运行在单节点数据库中的 SQL，在分片之后的数据库中并不一定能够正确运行。 例如，分表导致表名称的修改，或者分页、排序、聚合分组等操作的不正确处理。 跨库事务也是分布式的数据库集群要面对的棘手事情 合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。 在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。 而基于 XA 的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。 目标 # 尽量透明化分库分表所带来的影响，让使用方尽量像使用一个数据库一样使用水平分片之后的数据库集群，是 Apache ShardingSphere 数据分片模块的主要设计目标 CAP理论中的C在实践中是不可能完美实现的，在数据复制的过程中，节点N1和节点N2的数据并不一致（强一致性）。即使无法做到强一致性，但应用可以采用合适的方式达到最终一致性 基本可用 软引用 最终一致性 阿里巴巴Java开发手册 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表 如果预计3年后的数据量根本达不到这个级别，请不要在创建表时就分库分表 读写分离和数据分片具体的视线方式有两种 程序代码封装 在代码中抽象一个数据访问层（中间层封装），实现读写操作分离和数据库服务器连接的管理 Apache ShardingSphere ShardingSphere-JDBC 程序代码封装 ShardingSphere-Proxy 中间件封装 中间件封装 独立一套系统处理，实现读写操作分离和数据库服务器连接的管理。对于业务服务器来说，访问中间件和访问数据库没有区别，在业务服务器看来，中间件就是一个数据库服务器 MyCat 主从同步原理 # slave会从master读取binlog来进行数据同步 1 master将数据改变记录到bin log中 2 当 slave 上执行 start slave 命令之后，slave会创建一个IO连接用来连接master，请求master中的binlog 3 当 slave 连接 master 时，master 会创建一个 log dump 线程，用于发送 bin log 的内容。在读取 binlog 的内容的操作中，会对主节点中的binlog加锁，当读取完成并发送给从服务器后解锁 4 IO 线程接收主节点 binlog dump 进程发来的更新之后，保存到中继日志 relay log 中 5 slave 的 SQL 线程，读取 relay log 日志，并解析成具体操作，从而实现主从操作一直，最终数据一致 MyCat与ShardingSphere深度对比 # 如果是从传统单体结构迁移，且只需要基本的分库分表功能，MyCat可能更合适 如果是新建的云原生系统或微服务架构，ShardingSphere是更好的选择 考虑到技术演进和社区支持，新项目建议优先考虑ShardingSphere 某些场景可以组合使用-用ShardingSphere-JDBC处理应用内分片，用MyCat/ShardingShpere-Proxy处理遗留系统访问 分布式事务 # 在单一数据节点中，事务仅限于对单一数据库资源的访问控制，称之为本地事务。 几乎所有的成熟的关系型数据库都提供了对本地事务的原生支持。 但是在基于微服务的分布式应用环境下，越来越多的应用场景要求对多个服务的访问及其相对应的多个数据库资源能纳入到同一个事务当中，分布式事务应运而生 关系型数据库虽然对本地事务提供了完美的 ACID 原生支持。 但在分布式的场景下，它却成为系统性能的桎梏。 如何让数据库在分布式场景下满足 ACID 的特性或找寻相应的替代方案，是分布式事务的重点工作 挑战 # 强一致的事务与柔性事务的 API 和功能并不完全相同，在它们之间并不能做到自由的透明切换。 在开发决策阶段，就不得不在强一致的事务和柔性事务之间抉择，使得设计和开发成本被大幅增加 基于 XA 的强一致事务使用相对简单，但是无法很好的应对互联网的高并发或复杂系统的长事务场景； 柔性事务则需要开发者对应用进行改造，接入成本非常高，并且需要开发者自行实现资源锁定和反向补偿 原理介绍 # ShardingSphere 对外提供 begin/commit/rollback 传统事务接口，通过 LOCAL，XA，BASE 三种模式提供了分布式事务的能力 LOCAL事务 # LOCAL 模式基于 ShardingSphere 代理的数据库 begin/commit/rolllback 的接口实现， 对于一条逻辑 SQL，ShardingSphere 通过 begin 指令在每个被代理的数据库开启事务，并执行实际 SQL，并执行 commit/rollback。 由于每个数据节点各自管理自己的事务，它们之间没有协调以及通信的能力，也并不互相知晓其他数据节点事务的成功与否。 在性能方面无任何损耗，但在强一致性以及最终一致性方面不能够保证。 XA事务 # XA 事务采用的是 X/OPEN 组织所定义的 DTP 模型 所抽象的 AP（应用程序）, TM（事务管理器）和 RM（资源管理器） 概念来保证分布式事务的强一致性。 其中 TM 与 RM 间采用 XA 的协议进行双向通信，通过两阶段提交实现。 与传统的本地事务相比，XA 事务增加了准备阶段，数据库除了被动接受提交指令外，还可以反向通知调用方事务是否可以被提交。 TM 可以收集所有分支事务的准备结果，并于最后进行原子提交，以保证事务的强一致性 XA 事务建立在 ShardingSphere 代理的数据库 xa start/end/prepare/commit/rollback/recover 的接口上 对于一条逻辑 SQL，ShardingSphere 通过 xa begin 指令在每个被代理的数据库开启事务，内部集成 TM，用于协调各分支事务，并执行 xa commit/rollback 基于 XA 协议实现的分布式事务，由于在执行的过程中需要对所需资源进行锁定，它更加适用于执行时间确定的短事务。 对于长事务来说，整个事务进行期间对数据的独占，将会对并发场景下的性能产生一定的影响 BASE事务 # 如果将实现了 ACID 的事务要素的事务称为刚性事务的话，那么基于 BASE 事务要素的事务则称为柔性事务 BASE 是基本可用、柔性状态和最终一致性这三个要素的缩写 基本可用（Basically Available）保证分布式事务参与方不一定同时在线 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够察觉 最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性 在 ACID 事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。 通过放宽对强一致性要求，来换取系统吞吐量的提升 基于 ACID 的强一致性事务和基于 BASE 的最终一致性事务都不是银弹，只有在最适合的场景中才能发挥它们的最大长处。 Apache ShardingSphere 集成了 SEATA 作为柔性事务的使用方案 应用场景 # 在单机应用场景中，依赖数据库提供的事务即可满足业务上对事务 ACID 的需求。但是在分布式场景下，传统数据库解决方案缺乏对全局事务的管控能力，用户在使用过程中可能遇到多个数据库节点上出现数据不一致的问题 ShardingSphere 分布式事务，为用户屏蔽了分布式事务处理的复杂性，提供了灵活多样的分布式事务解决方案，用户可以根据自己的业务场景在 LOCAL，XA，BASE 三种模式中，选择适合自己的分布式事务解决方案 ShardingSphere LOCAL 事务使用场景 对于 LOCAL 事务，在分布式环境下，不保证各个数据库节点之间数据的一致性和隔离性，需要业务方自行处理可能出现的不一致问题。适用于用户希望自行处理分布式环境下数据一致性问题的业务场景 ShardingSphere XA 事务使用场景 对于 XA 事务，提供了分布式环境下，对数据强一致性的保证。但是由于存在同步阻塞问题，对性能会有一定影响。适用于对数据一致性要求非常高且对并发性能要求不是很高的业务场景 ShardingSphere BASE 事务使用场景 对于 BASE 事务，提供了分布式环境下，对数据最终一致性的保证。由于在整个事务过程中，不会像 XA 事务那样全程锁定资源，所以性能较好。适用于对并发性能要求很高并且允许出现短暂数据不一致的业务场景 YMAL配置 # YMAL配置 读写分离 # 核心概念 # 核心概念 主库 添加、更新以及删除数据操作所使用的数据库，目前仅支持单主库 从库 查询数据操作所使用的数据库，可支持多从库 主从同步 将主库的数据异步的同步到从库的操作。 由于主从同步的异步性，从库与主库的数据会短时间内不一致 负载均衡策略 通过负载均衡策略将查询请求疏导至不同从库 使用限制 不处理主库和从库的数据同步 不处理主库和从库的数据同步延迟导致的数据不一致 不支持主库多写 不处理主从库间的事务一致性。主从模型中，事务中的数据读写均用主库。 数据库网关 # 背景 随着数据库碎片化趋势的不可逆转，多种类型数据库的共存已渐成常态。使用一种 SQL 方言访问异构数据库的场景在不断增加 挑战 多样化的数据库的存在，使访问数据库的 SQL 方言难于标准化，工程师需要针对不同种类的数据库使用不同的方言，缺乏统一化的查询平台 将不同类型的数据库方言自动翻译为后端数据库所使用的方言，让工程师可以使用任意一种数据库方言访问所有的后端异构数据库，可以极大的降低开发和维护成本 目标 SQL 方言的自动翻译，是 Apache ShardingSphere 数据库网关希望达成的主要目标 应用场景 随着业务场景的多元化，企业内部的数据库产品也呈现多元化的趋势，业务应用与不同数据库产品的对接也变得异常复杂，ShardingSphere 数据库网关可以屏蔽业务应用与底层多元化数据库之间连接，同时为不同的业务场景提供统一的访问协议和语法体系，能够帮助企业快速打造统一的数据访问平台。 使用限制 Apache ShardingSphere 的 SQL 方言翻译处于实验阶段 目前仅支持 MySQL/PostgreSQL 的方言自动翻译，工程师可以使用 MySQL 的方言和协议，访问 PostgreSQL 数据库，反之亦然 流量治理 # 数据迁移 # 挑战 在迁移过程中，不应该对正在运行的业务造成影响。尽可能减少迁移时数据不可用的时间窗口，是数据迁移的第一个挑战 其次，数据迁移不应该对现有的数据造成影响，如何保证数据的正确性，是数据迁移的第二个挑战 应用场景 假如一个应用系统在使用传统单体数据库，单表数据量达到了1亿并且还在快速增长，单体数据库负载持续在高位，成为系统瓶颈。一旦数据库成为瓶颈，对应用服务器扩容是无效的，需要对数据库进行扩容 数据加密 # 数据脱敏 # 影子库 # 背景 在基于微服务的分布式应用架构下，业务需要多个服务是通过一系列的服务、中间件的调用来完成，所以单个服务的压力测试已无法代表真实场景。 在测试环境中，如果重新搭建一整套与生产环境类似的压测环境，成本过高，并且往往无法模拟线上环境的复杂度以及流量。 因此，业内通常选择全链路压测的方式，即在生产环境进行压测，这样所获得的测试结果能够准确地反应系统真实容量和性能水平 可观察性 # 如何观测集群的运行状态，使运维人员可以快速掌握当前系统现状，并进行进一步的维护工作，是分布式系统的全新挑战 登录到具体服务器的点对点运维方式，无法适用于面向大量分布式服务器的场景 通过对系统可观察性数据的遥测是分布式系统推荐的运维方式。 Tracing（链路跟踪）、 Metrics（指标监控）和 Logging （日志）是系统运行状况的可观察性数据重要的获取手段 APM（应用性能监控） 是通过对系统可观察性数据进行采集、存储和分析，进行系统的性能监控与诊断，主要功能包括性能指标监控、调用链分析，应用拓扑图等 Apache ShardingSphere 并不负责如何采集、存储以及展示应用性能监控的相关数据，而是为应用监控系统提供必要的指标数据 换句话说，Apache ShardingSphere 仅负责产生具有价值的数据，并通过标准协议或插件化的方式递交给相关系统 Tracing 用于获取 SQL 解析与 SQL 执行的链路跟踪信息。Apache ShardingSphere 默认提供了对 OpenTelemetry，SkyWalking 的支持，也支持用户通过插件化的方式开发自定义的 Tracing 组件 使用 OpenTelemetry OpenTelemetry 在 2019 年由 OpenTracing 和 OpenCencus 合并而来。 使用这种方式，只需要在 agent 配置文件中，根据 OpenTelemetry SDK 自动配置说明 ，填写合适的配置即可。可以导出数据到 Jaeger，Zipkin 使用 SkyWalking 需要在 agent 配置中配置启用对应插件，并且需要同时配置使用 SkyWalking 的 apm-toolkit 工具 使用 SkyWalking 的内置自动探针 Apache ShardingSphere 团队与 Apache SkyWalking 团队共同合作，在 SkyWalking 中实现了 Apache ShardingSphere 自动探针，可以将相关的应用性能数据自动发送到 SkyWalking 中。注意这种方式的自动探针不能与 Apache ShardingSphere 插件探针同时使用 Metrics 则用于收集和展示整个集群的统计指标。Apache ShardingSphere 默认提供了对 Prometheus 的支持 联邦查询 # 背景 当用户使用数据分片对海量数据进行水平拆分时，虽然能够有效解决数据库性能瓶颈，但业务上也因此带来了一些新的问题。 例如以下场景：跨节点关联查询、子查询、分页、排序、聚合查询。在进行业务实现时需要注意查询 SQL 的使用范围，尽量避免跨数据库实例查询，这使得业务层面的功能受到了数据库的限制 ShardingSphere的分布式事务功能具体是如何实现的？ # XA事务（强一致性） # 实现原理 基于XA协议的两阶段提交(2PC) 使用ShardingSphere的XATransactionManager作为事务管理器 工作流程 准备阶段 事务协调器向所有参与者发送prepare请求 各参与者执行事务但不提交，记录undo/redo日志 参与者返回准备就绪或失败响应 提交/回滚阶段 如果所有参与者都准备就绪，发送commit请求 如果任一参与者准备失败，发送rollback请求 参与者根据指令完成最终操作 Seata事务（柔性事务/AT模式） # 整合Seata的AT(Automatic Transaction)模式 基于全局锁+分支事务的补偿机制 工作流程 第一阶段 业务SQL被Seata拦截解析 RM生成undo log记录修改前数据 执行业务SQL并提交本地事务 向TC注册分支事务并报告状态 第二阶段 成功时：异步删除undo log 失败时：基于 undo log 进行补偿回滚 BASE事务（Saga模式） # 基于Saga模式的长事务解决方案 每个子事务都有对应的补偿操作 最终一致性模型 执行模式 正向流程：按顺序执行所有子事务 补偿流程：出现失败时，逆序执行补偿操作 生产实践建议 # 金融核心系统：优先考虑XA事务 普通交易系统：推荐Seata AT模式 跨系统长流程：考虑Saga模式 Reference # 官方文档 这个很好，优先看这个 shardingsphere分库分表示例（逻辑表，真实表，绑定表，广播表，单表），分页性能测试 ShardingSphere学习（超详细） 为什么几乎所有的开源数据库中间件都是国内公司开源的？并且几乎都停止了更新？ - 张亮的回答 - 知乎 "},{"id":57,"href":"/post/computer-science/java/spring/spring/","title":"spring","section":"Spring","content":" Spring # huanzi-qch/springBoot SpringBoot系列Demo代码 什么是Spring # Spring是一个java开发框架 它的核心特性是 控制反转 依赖注入 面向切面编程 声明式事务管理 模块化设计 Spring MVC # Spring MVC 流程 # 流程 用户发送请求 DispatcherServlet 调用 HandlerMapping DispatcherServlet 调用 HandlerAdapter Controller 处理请求 DispatcherServlet 调用 ViewResolver 视图渲染 ModelAndView -\u0026gt; ViewResolver -\u0026gt; View 返回响应 核心组件 DispatcherServlet：前端控制器，负责请求的分发和协调 HandlerMapping：根据请求 URL 查找对应的 Handler HandlerAdapter：适配并执行 Handler Controller：处理具体的业务逻辑 ViewResolver：解析视图名称，生成具体的 View 对象 View：负责视图的渲染 Bean # Bean的生命周期 # Bean的实例化 通过反射调用 Bean 的构造函数，创建Bean的实例 填充属性（依赖注入） Spring根据配置文件或注解，将依赖的Bean注入到当前Bean中 调用Aware接口 如果Bean实现了Spring的Aware接口，Spring会调用对应的回调方法 BeanPostProcessor 的前置处理 Spring调用所有BeanPostProcessor的postProcessBeforeInitialization()方法 执行初始化方法 Spring会调用Bean的初始化方法。 @PostConstruct BeanPostProcessor的后置处理 Spring调用所有BeanPostProcessor的postProcessAfterInitialization()方法。 Bean初始化完成 Bean已经完全初始化，可以被其他Bean使用。 Bean的使用 Bean的销毁 Bean的作用域 # Singleton（单例） 默认作用域，单例模式 Prototype（原型） 每次请求创建新实例 Request（请求） 每个 HTTP 请求创建一个实例 Session（会话） 每个 HTTP Session 创建一个实例 Application（应用） 整个 ServletContext 生命周期内有效 WebSocket WebSocket 会话生命周期内有效 spring 循环依赖如何解决？ # 三级缓存 singletonObjects：一级缓存，存储经历了完整生命周期的Bean对象 earlySingletonObjects：二级缓存，存储提前暴露出来的Bean对象，其生命周期未结束，属性未完全填充 singletonFactories：三级缓存，存储生成Bean的工厂 IOC # 什么是IOC # IOC是控制反转的意思，在一个程序中对象的创建与管理由一个容器负责，对象之间的引用通过注入(属性填充)的方式从容器中获取，降低了代码之间的耦合度 IOC 的核心概念是什么？ # 依赖注入 控制反转 IOC容器 举一个 Spring 的容器？ # BeanFactory ApplicationContext WebApplicationContext IOC 的优势是什么？ # 降低耦合度 提高可测试性 注入模拟对象进行测试 增强可扩展性 优化资源管理 容器管理对象的创建和销毁，避免资源浪费 AOP # 什么是AOP？ # AOP 是一种编程范式, 通过将横切关注点与业务代码分离，提高代码的可维护性与可重用性 AOP的核心概念是什么？ # 切面 Aspect 连接点 Join Point 程序执行过程中可以插入切面的点（方法的调用或异常的处理） 通知 Advice 切面在连接点执行的操作 @Before @After @Around 切入点 Pointcut 定义在哪些连接点上应用通知，通常通过表达式来匹配 织入 Weaving 将切面应用到目标对象并创建代理对象的过程，可以在编译期、类加载期或运行期进行 AOP的应用场景 # 日志记录 事务管理 权限控制 性能监控 记录方法执行时间 AOP的实现方式 # JDK动态代理 实现了接口的类 CGLIB代理 未实现接口的类 事务 # "},{"id":58,"href":"/post/computer-science/java/springboot/","title":"spring boot","section":"Java","content":" spring boot # AOP # 为什么要使用AOP？ # AOP的术语和流程 # AOP开发详解 # 确定拦截目标 需要拦截什么类的什么方法 开发切面 @Aspect 注解的一个类 @Before @After @AfterReturning @AfterThrowing 定义切点 环绕通知 # 一般而言，只有在需要大幅度修改原有目标对象的服务逻辑时才使用它，一般情况下尽量不要使用它。环绕通知是一个取代整个流程的通知，当然它也提供了回调原有流程的能力 引入 # 通知获取参数 # 织入 # 织入是一个生成动态代理对象并且将切面和目标对象方法编入约定流程的过程 本书中采用先声明接口再提供一个实现类的形式来提供服务类，这也是Spring推荐的方式，但是是否拥有接口并不是AOP的强制要求 在Java中，当前有多种方式实现动态代理，我们之前谈到的CGLIB只是其中的一种，业界比较流行的还有JDK和Javassist等。Spring采用了JDK和CGLIB，对于JDK动态代理的要求是被代理的目标对象必须拥有接口，而对于CGLIB动态代理则不做要求。因此，在默认的情况下，Spring会按照这样的一条规则处理：当需要使用AOP的类拥有接口时，它会以JDK动态代理的方式运行，否则以CGLIB动态代理的方式运行 多个切面 # 数据库事务 # JDBC的数据库事务 # Spring声明式事务的使用 # 声明式事务是使用注解@Transactional进行标注的，这个注解可以标注在类或者方法上，当它标注在类上时，表示这个类所有公共的(public)非静态的方法都将启用事务功能 Spring事务管理器 # 在Spring中，事务管理器的顶层接口为 TransactionManager，这个接口没有任何方法定义，这是因为这个接口下又可以划分两大类事务管理器 响应式编程的事务管理器 非响应式编程的事务管理器 PlatformTransactionManager getTransaction 获取事务，返回事务状态 commit 提交事务 rollback 回滚事务 在Spring Boot中，添加Maven依赖mybatis-spring-boot-starter之后，会自动创建JdbcTransactionManager对象作为事务管理器 如果依赖spring-boot-starter-data-jpa，则会自动创建JpaTransactionManager对象作为事务管理器 隔离级别 # 在企业的生产实践中，选择隔离级别一般会以读写提交为主，它能够防止脏读，但不能避免不可重复读和幻读 传播行为 # 执行一个批量任务，它会处理很多的交易，绝大部分交易可以顺利完成，但是也有极少数的交易因为特殊原因不能完成而发生异常，这时我们不应该因为极少数的交易不能完成而回滚批量任务调用的其他交易，使得那些本能完成的交易也不能完成了 在执行一个批量任务的过程中，调用多个交易时，如果有一些交易发生异常，只回滚那些出现异常的交易，而不回滚整个批量任务，这样就能够使得那些没有问题的交易顺利完成，而有问题的交易则不做任何事情 在Spring中，当一个方法调用另一个方法时，可以让事务采取不同的策略工作，如新建事务或者挂起当前事务等，这便是事务的传播行为 7种传播行为 REQUIRED 需要事务，它是默认传播行为。如果当前存在事务，就沿用当前事务；否则新建一个事务运行该方法 SUPPORTS 支持事务。如果当前存在事务，就沿用当前事务；否则继续采用无事务的方式运行该方法 MANDATORY 必须使用事务。如果当前没有事务，则会抛出异常；如果存在当前事务，则沿用当前事务运行该方法￼ REQUIRES_NEW 无论当前事务是否存在，都会创建新事务运行该方法，这样新事务就可以拥有新的锁和隔离级别等特性，与当前事务相互独立￼ e.g. 在进行数据同步的时候，不用将整个同步过程都设置为一个事务 NOT_SUPPORTED 不支持事务，当前存在事务时，将挂起事务，运行方法 NEVER 不支持事务，如果当前存在事务，则抛出异常，否则继续采用无事务的方式运行该方法￼ NESTED 在当前方法调用方法时，如果被调用的方法发生异常，只回滚被调用的方法运行过的SQL语句，而不回滚当前方法的事务 原理 在大部分的数据库中，一段SQL语句中可以设置一个标志位，运行后面的SQL语句时如果有问题，只回滚到这个标志位的数据状态，而不会让这个标志位之前的SQL语句也回滚。这个标志位在数据库概念中被称为保存点(save point)。从加粗日志部分可以看到，Spring生成了nested事务，也可以看到保存点的释放，可见Spring也是使用保存点技术来完成让子事务回滚而不致使当前事务回滚的工作。 注意，并不是所有数据库都支持保存点技术，因此Spring内部有这样的规则：当数据库支持保存点技术时，就启用保存点技术；如果不能支持，就新建一个事务来运行代码，即等价于REQUIRES_NEW传播行为 NESTED 和 REQUIRES_NEW 的区别 NESTED传播行为和REQUIRES_NEW传播行为是有区别的：NESTED传播行为会沿用当前事务，以保存点技术为主；REQUIRES_NEW传播行为则创建新的事务，事务的提交和回滚也是独立的，它拥有独立上下文（例如隔离级别和超时时间等），这是在应用中需要注意的地方。 占用事务时间过长 # @Transactional自调用失效问题 # spring-data-redis # Reference 《深入迁出 Spring Boot 3.x》7.1 spring-data-redis项目简介 Lettuce vs Jedis # 在Java中有很多种与Redis连接的驱动，目前使用比较广泛的是Lettuce和Jedis，它们是类似的，不过自Spring Boot 2.0发布以来，默认使用的是Lettuce Lettuce是基于Netty框架的事件驱动的Redis客户端，其方法调用是异步的，其API也是线程安全的，因此多个线程可以操作单个Lettuce连接来完成各种操作，并且Lettuce支持连接池。Lettuce线程可以被多个请求公用，且不会产生频繁创建和关闭Lettuce连接的开销，因此比较适合应用于高并发网站。 Jedis是同步的，不支持异步，Jedis客户端连接不是线程安全的，需要为每个请求创建和关闭一个Jedis连接，所以一般通过连接池来使用Jedis客户端连接。Jedis不太适合在高并发网站使用，当遇到高并发场景时，Jedis连接池无法避免频繁创建和关闭Jedis连接，因为这会造成十分大的系统开销 RedisTemplate和 StringRedisTemplate # StringRedisTemplate是RedisTemplate的子类，从名称就可以看出，StringRedisTemplate专门用于操作字符串 RedisTemplate，它是一个强大的类，会自动从RedisConnectionFactory工厂中获取连接，然后执行对应的Redis命令，最后还会关闭Redis的连接。这些操作都被封装在RedisTemplate中，所以开发者并不需要关注Redis连接的闭合问题 Spring对Redis数据类型操作的封装 # ValueOperations 字符串操作接口 HashOperations 哈希操作接口 ListOperations 列表（链表）操作接口 SetOperations 集合操作接口 ZSetOperations 有序集合操作接口 // 获取字符串操作接口 redisTemplate.opsForValue(); // 获取哈希操作接口 redisTemplate.opsForHash(); // 获取列表（链表）操作接口 redisTemplate.opsForList(); // 获取集合操作接口 redisTemplate.opsForSet(); // 获取有序集合操作接口 redisTemplate.opsForZSet(); SessionCallback 和 RedisCallback 接口 # Redis事务 # 使用 Redis 流水线 # 在默认的情况下，Redis客户端把命令逐条发送到Redis服务器，这样做显然性能不高。在关系数据库中我们可以批量运行语句，也就是只有需要运行SQL语句时，才一次性地发送所有SQL语句去运行，这样性能就提高了许多。类似地，Redis也可以批量执行命令，这便是流水线(pipeline)技术，在很多情况下并不是Redis性能不佳，而是网络传输的速度慢造成瓶颈，使用流水线技术可以在需要执行很多命令时大幅度地提升Redis的性能 使用 Redis发布 / 订阅 # 使用 Lua 脚本 # 在Redis中运行Lua脚本具备原子性，且Lua脚本具备更加强大的计算能力，在高并发环境中需要保证数据一致性时，使用Lua脚本方案比使用Redis自身提供的事务更好 Redis提供了两种运行Lua的方法 一种是直接发送Lua脚本到Redis服务器运行 另一种是先把Lua脚本发送给Redis服务器，Redis服务器对Lua脚本进行缓存，然后返回一个32位的SHA1编码，之后只需要发送SHA1和相关参数给Redis服务器便可以运行了。 这里需要解释为什么会存在通过32位编码运行Lua脚本的方法。如果Lua脚本很长，那么就需要通过网络传递脚本给Redis服务器运行，而现实的情况是网络的传递速度往往跟不上Redis的运行速度，因此网络速度就会成为Redis运行的瓶颈。如果只传递32位编码和参数，那么需要通过网络传输的消息就少了许多，这样就可以提高系统的性能 使用 Spring 缓存注解操作 Redis # @CachePut 将方法返回的结果存储到缓存中 @Cacheable 先通过定义的键从缓存中查询，如果可以查询到数据则返回，否则运行该方法，返回数据，并且将返回的结果存储到缓存中 @CacheEvict 通过定义的键移除缓存 缓存注解自调用失效问题 # 自定义缓存管理器 # 异步线程池 # 异步消息 RabbitMQ # 定时任务 # Spring-boot-monitor # 好久没维护了，服务有上下文资源会请求不到，这。。。。。。。 单机监控SpringBoot应用指标 官网 "},{"id":59,"href":"/post/computer-science/distributed-system/spring-cloud/","title":"Spring Cloud","section":"Distributed System","content":" Spring Cloud # 服务注册与发现 # Eureka # Netflix 开源的服务注册中心，采用 AP 架构（高可用性），通过心跳机制检测服务状态 包含 Eureka Server（注册中心）和 Eureka Client（服务提供者/消费者） 注：Eureka 2.x 已停止维护，建议新项目使用 Nacos Nacos # Spring Cloud Alibaba 的核心组件，兼具服务注册中心和配置中心功能，支持 CP/AP 模式切换 提供动态服务发现、健康检查、配置管理等功能，适用于云原生场景 服务调用与负载均衡 # Feign # 声明式的 REST 客户端，通过动态代理简化服务间 HTTP 调用，整合了 Ribbon 实现负载均衡 Ribbon # 客户端负载均衡组件，支持轮询、随机、权重等算法，需配合 Eureka/Nacos 使用 注：Ribbon 已进入维护阶段，Spring Cloud LoadBalancer 是新一代替代方案 Dubbo # Spring Cloud Alibaba 支持的 RPC 框架，适用于高性能服务调用，替代 Feign+Ribbon 的组合 服务容错与熔断 # Hystrix # Netflix 开源的熔断器，通过熔断、降级、隔离机制防止服务雪崩 注：Hystrix 已停止维护，推荐使用 Sentinel Sentinel # Alibaba 开源的流量控制组件，支持熔断、限流、系统自适应保护，提供实时监控 服务网关 # Zuul # Netflix 的 API 网关，负责路由、过滤、负载均衡，但性能较低 注：Zuul 1.x 已停止维护，Zuul 2.x 未集成到 Spring Cloud Spring Cloud Gateway # 基于 Reactor 的高性能网关，支持动态路由、限流、集成 Sentinel 配置中心 # Spring Cloud Config # 集中化管理配置，支持 Git、本地存储等，但需配合 Bus 实现动态刷新 Nacos Config # 与 Nacos 注册中心无缝集成，支持配置动态更新和版本管理 消息总线与事件驱动 # Spring Cloud Bus # 通过消息队列（如 RabbitMQ、Kafka）广播配置变更，实现配置热更新 Spring Cloud Stream # 统一消息中间件抽象层，支持 Kafka、RocketMQ 等 分布式链路追踪 # Sleuth + Zipkin # 追踪微服务调用链路，生成请求依赖图，便于故障排查 SkyWalking # 更强大的 APM 工具，支持分布式追踪、性能监控 分布式事务 # Seata # Alibaba 开源的分布式事务解决方案，支持 AT、TCC、SAGA 模式 其他组件 # Spring Cloud Security # OAuth2、JWT 等安全认证 Spring Cloud OpenFeign # Feign 的增强版，支持 Spring MVC 注解 Reference # "},{"id":60,"href":"/post/computer-science/distributed-system/spring-cloud-alibaba/","title":"Spring Cloud Alibaba","section":"Distributed System","content":" Spring Cloud Alibaba # Spring Cloud Alibaba Spring Cloud VS Spring Cloud Alibaba # 现在学spring cloud alibaba 还是spring cloud? 以下是 Spring Cloud 和 Spring Cloud Alibaba 的详细对比，从技术定位、核心组件、适用场景等维度综合分析，并结合实际应用场景提供选型建议：\n功能 Spring Cloud Spring Cloud Alibaba 优势对比 服务注册与发现 Eureka（AP，已停更） Nacos（AP/CP 双模，高性能） Nacos 支持动态配置管理，性能提升 50%+ 配置中心 Config Server（基于 Git） Nacos Config（可视化界面） Nacos 支持实时推送和多环境配置 流量控制与熔断 Hystrix（维护模式） Sentinel（动态规则、实时监控） Sentinel 支持精细化流量控制和系统保护 分布式事务 无官方方案（依赖第三方） Seata（原生集成 AT/TCC 模式） Seata 简化分布式事务开发 消息队列 无（依赖 RabbitMQ） RocketMQ（高吞吐、事务消息） RocketMQ 适合高并发和削峰填谷场景 "},{"id":61,"href":"/post/computer-science/database/sql/","title":"SQL","section":"Database","content":" sql # 2502 设计内存分配器 # ✅ 175 组合两个表 # 175. 组合两个表 需要展示的字段 姓 LastName 名 FirstName 城市 City 州 State 如果 personId 的地址不再 Address 表中，则报告为 null 使用左连接 select FirstName, LastName, City, State from Person left join on Person.PersonId = Address.PersonId; 176 第二高的薪水 # 176. 第二高的薪水 Create table If Not Exists Employee ( id int, salary int ); Truncate table Employee; insert into Employee (id, salary) values (\u0026#39;1\u0026#39;, \u0026#39;100\u0026#39;); insert into Employee (id, salary) values (\u0026#39;2\u0026#39;, \u0026#39;200\u0026#39;); insert into Employee (id, salary) values (\u0026#39;3\u0026#39;, \u0026#39;300\u0026#39;); insert into Employee (id, salary) values (\u0026#39;4\u0026#39;, \u0026#39;400\u0026#39;); insert into Employee (id, salary) values (\u0026#39;5\u0026#39;, \u0026#39;500\u0026#39;); insert into Employee (id, salary) values (\u0026#39;6\u0026#39;, \u0026#39;600\u0026#39;); insert into Employee (id, salary) values (\u0026#39;7\u0026#39;, \u0026#39;700\u0026#39;); Employee 表： +-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | salary | int | +-------------+------+ id 是这个表的主键。 表的每一行包含员工的工资信息。 select distinct Salary as SecondHighestSalary from Employee order by Salary desc limit 1 offset 1 然而，如果没有第 2 高的薪资，即表里可能只有一条记录，这个解答会被评测为 \u0026lsquo;Wrong Answer\u0026rsquo; 。为了克服这个问题，我们可以将其作为临时表。\nSELECT (SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1 OFFSET 1) AS SecondHighestSalary ; 177 第N高的薪水 # 177 第N高的薪水 create function getNthHighestSalary(N int) returns int begin declare M int; set M = N - 1; return (select distinct salary from Employee order by salary desc limit M, 1); end 178 分数排名 # 178 分数排名 Create table If Not Exists Scores ( id int, score DECIMAL(3, 2) ); Truncate table Scores; insert into Scores (id, score) values (\u0026#39;1\u0026#39;, \u0026#39;3.5\u0026#39;); insert into Scores (id, score) values (\u0026#39;2\u0026#39;, \u0026#39;3.65\u0026#39;); insert into Scores (id, score) values (\u0026#39;3\u0026#39;, \u0026#39;4.0\u0026#39;); insert into Scores (id, score) values (\u0026#39;4\u0026#39;, \u0026#39;3.85\u0026#39;); insert into Scores (id, score) values (\u0026#39;5\u0026#39;, \u0026#39;4.0\u0026#39;); insert into Scores (id, score) values (\u0026#39;6\u0026#39;, \u0026#39;3.65\u0026#39;); 表: Scores +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | score | decimal | +-------------+---------+ id 是该表的主键（有不同值的列）。 该表的每一行都包含了一场比赛的分数。Score 是一个有两位小数点的浮点值。 方法 1：DENSE_RANK # select s.score, dense_rank() over ( order by S.score desc ) as \u0026#39;rank\u0026#39; from Scores S; 窗口函数 # 方法 2: 使用 COUNT(DISTINCT \u0026hellip;) 的相关子查询 # select S1.score, (select count(distinct S2.score) from Scores S2 where S2.score \u0026gt;= S1.score) as \u0026#39;rank\u0026#39; from Scores S1 order by S1.score desc; 方法 3：使用 INNER JOIN 和 COUNT(DISTINCT\u0026hellip;) # select S.score, count(distinct T.score) as \u0026#39;rank\u0026#39; from Scores S inner join Scores T on S.score \u0026lt;= T.score group by S.id, S.socre order by S.score desc; 数据库表自身进行内连接的结果是什么 # 数据库表自身进行内连接（Self-Join）的结果是将表中的每一行与同一表中的其他行进行匹配，基于指定的连接条件。如果连接条件满足，则返回匹配的行组合。\n具体说明：\n连接条件：通常使用主键、外键或其他相关列作为连接条件。 结果：返回满足条件的行组合，未匹配的行将被排除。 示例：\n假设有一个表 Employees：\nEmployeeID Name ManagerID 1 Alice 3 2 Bob 3 3 Charlie NULL 4 David 2 执行以下自连接查询：\nSELECT e1.Name AS Employee, e2.Name AS Manager FROM Employees e1 INNER JOIN Employees e2 ON e1.ManagerID = e2.EmployeeID; 结果：\nEmployee Manager Alice Charlie Bob Charlie David Bob 解释：\nAlice 和 Bob 的 ManagerID 为 3，与 Charlie 的 EmployeeID 匹配。 David 的 ManagerID 为 2，与 Bob 的 EmployeeID 匹配。 Charlie 没有 ManagerID，因此不参与匹配。 总结：\n自连接的结果是表中满足连接条件的行组合，常用于处理层次结构或递归关系的数据。\n180 连续出现的数字 # 180 连续出现的数字 Create table If Not Exists Logs ( id int, num int ); Truncate table Logs; insert into Logs (id, num) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;4\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;5\u0026#39;, \u0026#39;1\u0026#39;); insert into Logs (id, num) values (\u0026#39;6\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;7\u0026#39;, \u0026#39;2\u0026#39;); insert into Logs (id, num) values (\u0026#39;8\u0026#39;, \u0026#39;2\u0026#39;); 表：Logs +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | num | varchar | +-------------+---------+ 在 SQL 中，id 是该表的主键。 id 是一个自增列。 select distinct l1.Num as ConsecutiveNums from Logs l1, Logs l2, Logs l3 where l1.Id = l2.Id - 1 and l2.Id = l3.Id - 1 and l1.Num = l2.Num and l2.Num = l3.Num and l1.Num = l3.Num; ✅ 181 超过经理收入的员工 # 181 超过经理收入的员工 Create table If Not Exists Employee2 ( id int, name varchar(255), salary int, managerId int ); Truncate table Employee2; insert into Employee2 (id, name, salary, managerId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;3\u0026#39;); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;4\u0026#39;); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, NULL); insert into Employee2 (id, name, salary, managerId) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, NULL); 表：Employee +-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | name | varchar | | salary | int | | managerId | int | +-------------+---------+ id 是该表的主键（具有唯一值的列）。 该表的每一行都表示雇员的ID、姓名、工资和经理的ID。 select e1.name as \u0026#39;Employee\u0026#39; from Employee e1 inner join Employee e2 on e1.managerId = e2.Id where e1.salary \u0026gt; e2.salary; 182 查找重复的电子邮箱 # 182 查找重复的电子邮箱 Create table If Not Exists Person ( id int, email varchar(255) ); Truncate table Person; insert into Person (id, email) values (\u0026#39;1\u0026#39;, \u0026#39;a@b.com\u0026#39;); insert into Person (id, email) values (\u0026#39;2\u0026#39;, \u0026#39;c@d.com\u0026#39;); insert into Person (id, email) values (\u0026#39;3\u0026#39;, \u0026#39;a@b.com\u0026#39;); 方法一：使用 GROUP BY 和临时表 # select Email from (select Email, count(Email) as num from Person group by Email) as statistics where num \u0026gt; 1; 方法二：使用 GROUP BY 和 HAVING 条件 # select Email from Person group by Email having count(Email) \u0026gt; 1; ✅ 183 从不订购的客户 # 183 从不订购的客户 Create table If Not Exists Customers ( id int, name varchar(255) ); Create table If Not Exists Orders ( id int, customerId int ); Truncate table Customers; insert into Customers (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;); insert into Customers (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;); insert into Customers (id, name) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;); insert into Customers (id, name) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;); Truncate table Orders; insert into Orders (id, customerId) values (\u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;); insert into Orders (id, customerId) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;); -- 实现方法1 select c.name as Customers from Customers c left join Orders o on c.id = o.customerId where o.id is null; -- 实现方法2 select name as \u0026#39;Customers\u0026#39; from Customers where id not in (select distinct(customerId) from Orders); ✅ 184 部门工资最高的员工 # 184 部门工资最高的员工 Create table If Not Exists Employee3 ( id int, name varchar(255), salary int, departmentId int ); Create table If Not Exists Department ( id int, name varchar(255) ); Truncate table Employee3; insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;2\u0026#39;, \u0026#39;Jim\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;3\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;4\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee3 (id, name, salary, departmentId) values (\u0026#39;5\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); Truncate table Department; insert into Department (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;IT\u0026#39;); insert into Department (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Sales\u0026#39;); select Department.name as \u0026#39;Department\u0026#39;, Employee.name as \u0026#39;Employee\u0026#39;, Salary from Employee join Department on Employee.DepartmentId = Department.Id where (Employee.DepartmentId, Salary) in (select DepartmentId, max(Salary) from Employee group by DepartmentId) ; 185 部门工资前三高的所有员工 # 185 部门工资前三高的所有员工 drop table Employee; Create table If Not Exists Employee ( id int, name varchar(255), salary int, departmentId int ); drop table Department; Create table If Not Exists Department ( id int, name varchar(255) ); Truncate table Employee; insert into Employee (id, name, salary, departmentId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, \u0026#39;2\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;5\u0026#39;, \u0026#39;Janet\u0026#39;, \u0026#39;69000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;6\u0026#39;, \u0026#39;Randy\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;); insert into Employee (id, name, salary, departmentId) values (\u0026#39;7\u0026#39;, \u0026#39;Will\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;1\u0026#39;); Truncate table Department; insert into Department (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;IT\u0026#39;); insert into Department (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Sales\u0026#39;); 196 删除重复的电子邮箱 # 196 删除重复的电子邮箱 delete p1 from Person p1, Person p2 where p1.Email = p2.Email and p1.Id \u0026gt; p2.Id; 197 上升的温度 # 197 上升的温度 select a.id from Weather a, Weather b where datediff(a.recordDate, b.recordDate) = 1 and a.Temperature \u0026gt; b.Temperature; 262 行程和用户 # 511 游戏玩法分析 I # 511 游戏玩法分析 I 方法 1：分组并提取最小值 # select player_id, min(event_date) as first_login from Activity group by player_id; 方法 2：窗口函数 # rank() # select X.player_id, X.event_date as first_login from (select A.player_id, A.event_date rank() over ( partition by A.player_id group by A.event_date ) as rnk from Activity A) X where X.rnk = 1; first_value() # --- 必须使用 distinct SELECT DISTINCT A.player_id, FIRST_VALUE(A.event_date) OVER ( PARTITION BY A.player_id ORDER BY A.event_date ) AS first_login FROM Activity A; 512 游戏玩法分析 II # 534 游戏玩法分析 III # 550 游戏玩法分析 IV # 550. 游戏玩法分析 IV select player_id, date_add(min(event_date), interval 1 day) as second_date from Activity group by player_id 在sql中，from后面用逗号写了多张表，这样属于什么连接 # 在 SQL 中，如果在 FROM 子句中使用逗号分隔多张表，例如：\nFROM table1, table2 这属于 隐式连接（Implicit Join），也称为 笛卡尔连接（Cartesian Join）或 交叉连接（Cross Join）。它的行为是将两张表的所有行进行组合，生成一个笛卡尔积。\n隐式连接的特点：\n没有明确的连接条件：\n如果没有在 WHERE 子句中指定连接条件，结果将是两张表的笛卡尔积。 例如，table1 有 3 行，table2 有 4 行，结果将返回 (3 \\times 4 = 12) 行。 连接条件需要在 WHERE 子句中指定：\n如果需要特定的连接逻辑（如内连接），必须在 WHERE 子句中明确写出连接条件。 例如： FROM table1, table2 WHERE table1.id = table2.table1_id; 可读性较差：\n隐式连接的语法不够直观，尤其是在涉及多张表或复杂连接条件时，容易出错或难以维护。 示例：\n假设有两张表：\ntable1:\nid name 1 Alice 2 Bob table2:\nid table1_id value 1 1 100 2 2 200 3 1 300 隐式连接（无 WHERE 条件）： SELECT * FROM table1, table2; 结果（笛卡尔积）：\nid name id table1_id value 1 Alice 1 1 100 1 Alice 2 2 200 1 Alice 3 1 300 2 Bob 1 1 100 2 Bob 2 2 200 2 Bob 3 1 300 隐式连接（带 WHERE 条件）： SELECT * FROM table1, table2 WHERE table1.id = table2.table1_id; 结果（内连接效果）：\nid name id table1_id value 1 Alice 1 1 100 1 Alice 3 1 300 2 Bob 2 2 200 显式连接 vs 隐式连接：\n显式连接（推荐）：\n使用 JOIN 关键字（如 INNER JOIN、LEFT JOIN 等）。 连接条件写在 ON 子句中。 语法清晰，易于维护。 示例： SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.table1_id; 隐式连接（不推荐）：\n使用逗号分隔表。 连接条件写在 WHERE 子句中。 可读性差，容易出错。 总结：\n在 FROM 子句中使用逗号分隔多张表属于 隐式连接。如果没有指定 WHERE 条件，结果将是笛卡尔积；如果指定了 WHERE 条件，可以实现类似内连接的效果。但出于可读性和可维护性的考虑，建议使用显式连接（JOIN）。\n569 员工薪水中位数 # 570 至少有5名直接下属的经理 # 571 给定数字的频率查询中位数 # 574 当选者 # 577 员工奖金 # 578 查询回答率最高的问题 # 579 查询员工的累计薪水 # 580 统计各专业学生人数 # 584 寻找用户推荐人 # 585 2016年的投资 # 586 订单最多的客户 # 595 大的国家 # 596 超过 5 名学生的课 # 597 好友申请 I：总体通过率 # 601 体育馆的人流量 # 602 好友申请 II ：谁有最多的好友 # 603 连续空余座位 # 607 销售员 # 608 树节点 # 610 判断三角形 # 612 平面上的最近距离 # 613 直线上的最近距离 # 614 二级关注者 # 615 平均工资：部门与公司比较 # 618 学生地理信息报告 # 619 只出现一次的最大数字 # 620 有趣的电影 # 626 换座位 # 627 变更性别 # 1045 买下所有产品的客户 # 1050 合作过至少三次的演员和导演 # 1068 产品销售分析 I # 1069 产品销售分析 II # mac2025 mysql # leetcode # "},{"id":62,"href":"/post/sports/table-tennis/","title":"table tennis","section":"Sports","content":" 张继科（日）原片 "},{"id":63,"href":"/post/computer-science/front-end/vue/","title":"vue","section":"Front End","content":" vue # vuejs.org 文档 vue2 教程 Vue 2.0 在 2023 年 12 月 31 日停止更新 vue3 教程 快速上手 # 安装 node.js 使用 brew 安装 brew install node 检查 node 是否安装成功 node -v npm -v 创建 vue 项目 npm create vue@latest cd my-vue-project 修改镜像源 reference npm、yarn、pnpm 最新国内镜像源设置和常见问题解决 npm install npm run dev Local http://localhost:5173 Vue DevTools http://localhost:5173/__devtools__/ reference 如何在 macOS 上安装 Node.js "},{"id":64,"href":"/post/computer-science/java/xxl-job/","title":"xxl job","section":"Java","content":" xuxueli/xxl-job 文档 什么情况下使用 springboot自带的schedule，什么时候应该使用 xxl job # 在分布式系统和定时任务调度场景中，选择 Spring Boot 自带的 @Scheduled 还是分布式任务调度框架（如 XXL-JOB）取决于业务需求和技术架构。以下是详细的对比和决策建议：\n1. Spring Boot 自带的 @Scheduled # 适用场景：\n单机环境：任务只需在单个节点运行，无需分布式协调。 简单任务：轻量级、短时间执行的定时任务（如本地缓存刷新、日志清理）。 开发效率：快速集成，无需额外部署中间件。 强一致性要求低：任务重复执行或偶尔遗漏对业务影响较小（如非关键统计报表）。 优势：\n零依赖，与 Spring 生态无缝集成。 注解驱动（@Scheduled），配置简单（支持 cron 表达式、固定速率/延迟）。 局限性：\n无分布式协调：多实例部署时任务会重复执行（需自行加锁，如 @SchedulerLock）。 无可视化管控：任务状态、日志需自行实现。 缺乏弹性调度：不支持动态调整、故障转移、分片等高级特性。 示例代码：\n@Scheduled(cron = \u0026#34;0 0/5 * * * ?\u0026#34;) public void refreshCache() { // 单机任务逻辑 } 2. XXL-JOB # 适用场景：\n分布式环境：需要任务在多个节点间协调（如唯一执行、分片处理）。 复杂任务：长耗时任务（需超时控制）、需动态启停或修改调度策略。 高可靠性：要求任务失败重试、故障自动转移、报警通知。 运维需求：需要可视化任务管理、执行日志追踪、用户权限控制。 优势：\n分布式调度：通过中心化调度器（如数据库、Redis）避免任务重复执行。 任务分片：将大数据任务拆分到多个节点并行处理（如批量处理百万条数据）。 运维友好：提供管理界面，支持动态配置、日志查看、报警推送。 扩展性：支持 GLUE 脚本（动态修改代码）、跨语言任务（通过 HTTP 调用）。 局限性：\n需要额外部署调度中心（Admin）和执行器（Executor），增加架构复杂度。 依赖中间件（如 MySQL），存在性能瓶颈风险（高频任务需优化）。 示例配置：\n@XxlJob(\u0026#34;demoJobHandler\u0026#34;) public void execute() { // 分布式任务逻辑（支持分片参数） int shardIndex = XxlJobHelper.getShardIndex(); int shardTotal = XxlJobHelper.getShardTotal(); } 决策树：如何选择？ # 是否多实例部署？\n是 → 选择 XXL-JOB（避免任务重复）。 否 → 考虑 @Scheduled。 是否需要任务高可用/弹性？\n是（如支付对账、订单补单）→ XXL-JOB。 否（如本地日志清理）→ @Scheduled。 是否需要动态管理？\n是（如频繁调整 cron 表达式）→ XXL-JOB。 否（固定任务）→ @Scheduled。 任务是否分片/并行？\n是（如大数据处理）→ XXL-JOB。 否 → @Scheduled。 3. 其他替代方案 # Quartz：适合需要数据库持久化但无需复杂管理的场景（需自行封装分布式锁）。 Elastic-Job：基于 ZooKeeper 的分布式调度，适合分片需求高的场景（已停更，可考虑 ShedLock）。 Kubernetes CronJob：若应用部署在 K8s 中，可直接使用原生 CronJob 实现单次任务调度。 总结 # Spring Boot @Scheduled：简单、单机、轻量级任务。 XXL-JOB：分布式、高可靠、需运维管控的复杂任务。 根据团队规模、运维能力和业务需求权衡，避免为简单场景过度设计，也不要在分布式环境下强用单机方案。\n"},{"id":65,"href":"/post/computer-science/llm/2025-03-30-4-%E4%B8%8D%E5%90%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%B6%88%E6%81%AF%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94/","title":"不同消息队列消息写入方式对比","section":"Computer Science","content":" 不同消息队列消息写入方式对比 # 以下是主流消息队列（Kafka、RocketMQ、RabbitMQ、Pulsar、ActiveMQ）在消息写入方式上的对比，结合性能、可靠性和适用场景进行综合分析：\n1. Kafka # 写入方式： 顺序追加写入：消息以追加（Append-only）方式写入分区日志文件，利用磁盘顺序I/O的高性能特性11528。 批量发送：生产者（Producer）将消息累积到批次（如1MB或100ms阈值）后批量发送，减少网络和磁盘I/O次数28。 异步刷盘：默认异步刷盘（依赖页缓存），通过参数可配置同步刷盘（牺牲性能换可靠性）28。 特点： 高吞吐（10万级/秒），适合日志、大数据场景115。 不支持延迟消息，仅保证分区内有序1628。 2. RocketMQ # 写入方式： 顺序写+索引：消息追加到CommitLog文件（顺序写），同时构建索引文件（ConsumeQueue）加速查询42。 同步/异步刷盘：支持同步刷盘（强一致性）和异步刷盘（高性能）4243。 事务消息：通过“半消息”机制实现分布式事务，先暂存消息，本地事务提交后再确认写入42。 特点： 兼顾高吞吐（10万级/秒）和功能完备性（延迟消息、事务支持）1628。 适合电商、金融等业务场景142。 3. RabbitMQ # 写入方式： 内存+磁盘混合：默认优先写入内存，通过持久化队列（Durable Queue）将消息同步到磁盘128。 Exchange路由：消息通过Exchange根据路由规则（Direct/Topic/Fanout）分发到队列116。 特点： 实时性高（微秒级延迟），但吞吐量较低（万级/秒）28。 支持复杂路由和消息确认机制，适合中小规模业务116。 4. Pulsar # 写入方式： 分层存储：消息先写入Broker的内存层，再异步持久化到BookKeeper集群（计算与存储分离）116。 分片（Segment）存储：Topic分区划分为Segment，分散存储提高扩展性1。 特点： 支持秒级延迟消息和多租户，适合云原生和异地容灾场景116。 吞吐量接近Kafka，但架构更复杂1。 5. ActiveMQ # 写入方式： 内存/KahaDB/JDBC：默认KahaDB（基于日志的存储），支持JDBC持久化到数据库。 同步刷盘可选：通过配置选择是否同步刷盘。 特点： 功能全面但吞吐量最低（万级/秒），适合传统企业应用28。 社区活跃度低，逐渐被替代28。 对比总结 # 特性 Kafka RocketMQ RabbitMQ Pulsar ActiveMQ 写入性能 最高（顺序I/O+批量） 高（顺序写+索引） 低（内存优先） 高（分层存储） 最低 可靠性 异步刷盘可能丢数据 支持同步刷盘 依赖持久化配置 高（BookKeeper） 依赖配置 延迟消息 不支持 支持 支持（插件） 支持秒级 支持 适用场景 日志/大数据 电商/金融 中小规模业务 云原生/异地容灾 传统企业应用 参考资料：115162842\n"},{"id":66,"href":"/post/computer-science/llm/2025-03-30-1-%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E7%B4%A2%E5%BC%95%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA-%E8%AF%B7%E4%BB%A5postgresql%E4%B8%BE%E4%BE%8B/","title":"分区表的索引如何创建，请以postgresql举例","section":"Computer Science","content":" 分区表的索引如何创建，请以postgresql举例 # PostgreSQL分区表索引创建指南 # PostgreSQL中分区表索引的创建方法与普通表有所不同，需要特别注意分区表的特性。以下是详细的创建方法和示例：\n一、基本索引创建方法 # 1. 自动分区索引（PostgreSQL 11+） # 从PostgreSQL 11开始，可以直接在父表上创建索引，系统会自动为所有子分区创建对应的索引1247。\n-- 创建分区表 CREATE TABLE sales ( id SERIAL PRIMARY KEY, product VARCHAR, sale_date DATE ) PARTITION BY RANGE (sale_date); -- 创建子分区 CREATE TABLE sales_2021_01_01 PARTITION OF sales FOR VALUES FROM (\u0026#39;2021-01-01\u0026#39;) TO (\u0026#39;2021-01-02\u0026#39;); CREATE TABLE sales_2021_01_02 PARTITION OF sales FOR VALUES FROM (\u0026#39;2021-01-02\u0026#39;) TO (\u0026#39;2021-01-03\u0026#39;); -- 在父表上创建索引，会自动应用到所有分区 CREATE INDEX idx_product ON sales (product); 2. 手动创建分区索引（PostgreSQL 10及以下） # 在PostgreSQL 10及以下版本，需要为每个分区单独创建索引：\n-- 为每个分区单独创建索引 CREATE INDEX sales_2021_01_01_product_idx ON sales_2021_01_01 (product); CREATE INDEX sales_2021_01_02_product_idx ON sales_2021_01_02 (product); 二、特殊索引类型 # 1. 唯一索引和主键 # PostgreSQL 11+支持在分区表上创建唯一约束和主键，但必须包含分区键47：\n-- 创建包含分区键的唯一索引 CREATE TABLE rtable(c1 INT, c2 VARCHAR(10)) PARTITION BY RANGE(c1); ALTER TABLE rtable ADD CONSTRAINT pk_rtable PRIMARY KEY(c1); 2. 局部索引(Partial Index) # 可以只为满足特定条件的行创建索引，节省空间并提高查询效率25：\n-- 只为活跃客户创建索引 CREATE INDEX idx_customer_inactive ON customer(active) WHERE active = 0; 3. 全局索引(Global Index) # PostgreSQL支持全局索引，可以跨分区查询而不需要包含分区键2743：\n-- 创建全局索引 CREATE INDEX idx_global ON employees(email) GLOBAL; 三、在线创建索引的注意事项 # PostgreSQL不支持直接在分区表上并发创建索引(CONCURRENTLY)，但可以通过以下方法实现类似效果17：\n在每个分区上并发创建索引 在父表上以非并发方式创建索引 -- 错误方法（会报错） CREATE INDEX CONCURRENTLY idx_product ON sales (product); -- 正确方法 -- 1. 在每个分区上并发创建索引 CREATE INDEX CONCURRENTLY sales_2021_01_01_product_idx ON sales_2021_01_01 (product); CREATE INDEX CONCURRENTLY sales_2021_01_02_product_idx ON sales_2021_01_02 (product); -- 2. 在父表上创建索引 CREATE INDEX idx_product ON sales (product); 四、索引类型选择 # PostgreSQL支持多种索引类型，应根据查询需求选择合适的类型4041：\nB-tree：默认索引类型，适合范围查询和等值查询 Hash：只支持等值查询，但性能更好 GIN：适合全文搜索和数组查询 GiST：适合空间数据和复杂数据类型 BRIN：适合大型有序数据集，占用空间小 -- 创建GIN索引示例 CREATE INDEX idx_gin ON documents USING gin (content gin_trgm_ops); 五、最佳实践建议 # 索引应包含查询条件中的常用列1 对于分区表，考虑查询是否使用分区键来决定索引类型27 定期分析索引使用情况，删除不必要的索引 对于大型分区表，考虑使用BRIN索引减少空间占用40 唯一约束必须包含分区键列47 通过合理设计分区表索引，可以显著提高PostgreSQL数据库的查询性能和管理效率。\n"},{"id":67,"href":"/post/life/goal/","title":"goal","section":"Life","content":" goal # 2025-01-12 # 过年前完成(1月24日内) 面试经典150题(一天完成5道题, 应该完成70道题左右) Spring实战 第6版 Book (读完这本书) 清华韩秀云精品课（第一季，64集）(大概应该看到56集) 美国困局：“新右翼” 的兴起与挑战 (读完这本书) OAuth 2 in Action Microservices Security in Action API Security in Action ActiveMQ in Action RabbitMQ in Depth（Manning，2017年） Alvaro Videla和Jason J.W. Williams合著的RabbitMQ in Action（Manning，2012年） Kafka in Action （Manning，2017年） Enterprise Integration Patterns（Addison-Wesley，2003年） Functional Programming in Java（Manning，2017年） Grokking Functional Programming（Manning，2021年） "},{"id":68,"href":"/post/life/coffee/","title":"coffee","section":"Life","content":" coffee # 咖啡碎碎念#1 一次探店2家上海“天花板”咖啡馆？！喝到一半老板直接开始上课？#上海VLOG（上） 科普丨意式咖啡傻傻分不清？10分钟带你全部看懂 马克西姆咖啡机 马克西姆使用评测（上）3000+价位段最值得入手半自动意式咖啡机一体机 马克西姆咖啡机评测（下）使用成本低是最好的入手理由 马克西姆咖啡机用了一年，总结出5个使用技巧 马克西姆半自动家用咖啡机，如何调试和定量出品，掌握核心2点，控制好粉重和粉液比 "},{"id":69,"href":"/post/computer-science/algorithm/","title":"Algorithm","section":"Computer Science","content":" Algorithm # 代码随想录 Tips # 如果我要创建一个列表，并且需要一直在列表的开头插入元素，我要怎么实现代码保证效率 # 在 Java 中，如果你需要频繁在列表的开头插入元素，使用 LinkedList 会比 ArrayList 更高效。因为 LinkedList 在列表开头插入元素的时间复杂度是 O(1)，而 ArrayList 在开头插入元素的时间复杂度是 O(n)，需要移动所有元素。\n使用 LinkedList 的示例代码：\nimport java.util.LinkedList; import java.util.List; public class Main { public static void main(String[] args) { // 创建一个 LinkedList List\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 在列表开头插入元素 list.add(0, 1); // 插入元素 1 list.add(0, 2); // 插入元素 2 list.add(0, 3); // 插入元素 3 // 输出列表 System.out.println(list); // 输出: [3, 2, 1] } } 为什么 LinkedList 更高效？\nLinkedList 是基于双向链表实现的，插入和删除操作只需要调整节点的指针，时间复杂度为 O(1)。 ArrayList 是基于动态数组实现的，插入和删除操作需要移动元素，时间复杂度为 O(n)。 总结：\n如果你需要频繁在列表开头插入元素，优先选择 LinkedList 以保证效率。\nLinkedList 在任意位置插入和删除节点，时间复杂度都是O(1)吗？ # 不是的，LinkedList 在任意位置插入和删除节点的时间复杂度并不总是 O(1)。具体的时间复杂度取决于操作的位置。\nLinkedList 的时间复杂度分析：\n在头部或尾部插入/删除节点：\n时间复杂度是 O(1)，因为 LinkedList 是双向链表，直接操作头节点或尾节点即可。 在任意位置插入/删除节点：\n时间复杂度是 O(n)，因为需要从头节点或尾节点开始遍历链表，找到目标位置后才能进行操作。 为什么任意位置插入/删除是 O(n)？\nLinkedList 是基于双向链表实现的，虽然插入和删除操作本身只需要调整指针（O(1)），但找到目标位置需要遍历链表。 平均情况下，遍历链表的时间复杂度是 O(n/2) ≈ O(n)。 示例代码：\nimport java.util.LinkedList; public class Main { public static void main(String[] args) { LinkedList\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(1); list.add(2); list.add(3); // 在索引 1 处插入元素（需要遍历到索引 1） list.add(1, 10); // 时间复杂度 O(n) // 删除索引 2 处的元素（需要遍历到索引 2） list.remove(2); // 时间复杂度 O(n) System.out.println(list); // 输出: [1, 10, 3] } } 总结：\nLinkedList 在头部或尾部插入/删除节点的时间复杂度是 O(1)。 在任意位置插入/删除节点的时间复杂度是 O(n)，因为需要遍历链表找到目标位置。 如果你需要频繁在任意位置插入或删除节点，并且希望时间复杂度更低，可以考虑使用其他数据结构（如 ArrayList 或自定义数据结构），具体选择取决于你的使用场景。\n如果我要不断往list的末尾添加元素，是使用LinkedList还是ArrayList？ # 如果你需要不断往列表的末尾添加元素，使用 ArrayList 会比 LinkedList 更高效。以下是原因和详细分析：\nArrayList 的优势 时间复杂度： 在末尾添加元素的平均时间复杂度是 O(1)。 只有在数组容量不足时，ArrayList 需要扩容（创建一个新的更大的数组并复制元素），此时时间复杂度是 O(n)。但扩容操作是分摊的，平均下来仍然是 O(1)。 空间效率： ArrayList 是基于数组实现的，内存连续，存储效率高，没有额外的指针开销。 缓存友好： 数组的内存布局是连续的，对 CPU 缓存更友好，访问速度更快。 LinkedList 的劣势 时间复杂度： 在末尾添加元素的时间复杂度是 O(1)，但每次添加都需要创建一个新的节点对象，并调整指针。 空间效率： LinkedList 是基于双向链表实现的，每个节点需要额外的空间存储前驱和后继指针，内存开销更大。 缓存不友好： 链表的内存布局是分散的，对 CPU 缓存不友好，访问速度较慢。 性能对比 ArrayList： 添加元素时，大多数情况下是 O(1)，偶尔扩容时是 O(n)。 内存连续，访问速度快。 LinkedList： 添加元素时，每次都是 O(1)，但需要创建节点对象和调整指针。 内存分散，访问速度慢。 代码示例 使用 ArrayList：\nimport java.util.ArrayList; import java.util.List; public class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 不断往末尾添加元素 for (int i = 0; i \u0026lt; 1000000; i++) { list.add(i); // 平均时间复杂度 O(1) } System.out.println(\u0026#34;ArrayList 添加完成\u0026#34;); } } 使用 LinkedList：\nimport java.util.LinkedList; import java.util.List; public class Main { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 不断往末尾添加元素 for (int i = 0; i \u0026lt; 1000000; i++) { list.add(i); // 时间复杂度 O(1)，但性能不如 ArrayList } System.out.println(\u0026#34;LinkedList 添加完成\u0026#34;); } } 实测性能 在实际测试中，ArrayList 的性能通常优于 LinkedList，尤其是在大量添加元素时。以下是一个简单的性能对比：\n操作 ArrayList 耗时 LinkedList 耗时 添加 100 万个元素 ~50 ms ~100 ms 添加 1000 万个元素 ~500 ms ~1200 ms 总结 如果你需要不断往列表末尾添加元素，优先选择 ArrayList。 它的时间复杂度更低（平均 O(1)）。 它的内存效率更高，访问速度更快。 只有在需要频繁在列表头部或中间插入/删除元素时，才考虑使用 LinkedList。 希望这个解答对你有帮助！如果还有其他问题，欢迎随时提问！\n如果我想要构造一个字符串，我会不断往字符串头部添加字符，我该怎么编码保证效率 # 如果你需要不断往字符串的头部添加字符，直接使用 Java 的 String 或 StringBuilder 会导致性能问题，因为它们的底层实现不适合频繁在头部插入操作。以下是原因和高效解决方案：\n为什么 String 和 StringBuilder 不适合？ String： String 是不可变的，每次修改都会创建一个新的字符串对象，频繁在头部插入字符会导致大量对象创建和复制，性能极差。 StringBuilder： StringBuilder 是可变的，适合在尾部添加字符（时间复杂度 O(1)），但在头部插入字符的时间复杂度是 O(n)，因为需要移动所有现有字符。 高效解决方案 为了高效地在字符串头部添加字符，可以使用以下数据结构：\n方案 1：使用 LinkedList\u0026lt;Character\u0026gt;\nLinkedList 在头部插入元素的时间复杂度是 O(1)，非常适合频繁在头部添加字符的场景。 插入完成后，可以将 LinkedList 转换为字符串。 方案 2：使用 Deque\u0026lt;Character\u0026gt;（双端队列）\nDeque 是基于双向链表实现的，支持在头部和尾部高效插入和删除元素。 插入完成后，可以将 Deque 转换为字符串。 代码实现 方案 1：使用 LinkedList\u0026lt;Character\u0026gt;\nimport java.util.LinkedList; public class Main { public static void main(String[] args) { // 创建一个 LinkedList 来存储字符 LinkedList\u0026lt;Character\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); // 不断往头部添加字符 list.addFirst(\u0026#39;a\u0026#39;); // 添加字符 \u0026#39;a\u0026#39; list.addFirst(\u0026#39;b\u0026#39;); // 添加字符 \u0026#39;b\u0026#39; list.addFirst(\u0026#39;c\u0026#39;); // 添加字符 \u0026#39;c\u0026#39; // 将 LinkedList 转换为字符串 StringBuilder sb = new StringBuilder(); for (char c : list) { sb.append(c); } String result = sb.toString(); System.out.println(result); // 输出: cba } } 方案 2：使用 Deque\u0026lt;Character\u0026gt;\nimport java.util.Deque; import java.util.LinkedList; public class Main { public static void main(String[] args) { // 创建一个 Deque 来存储字符 Deque\u0026lt;Character\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); // 不断往头部添加字符 deque.addFirst(\u0026#39;a\u0026#39;); // 添加字符 \u0026#39;a\u0026#39; deque.addFirst(\u0026#39;b\u0026#39;); // 添加字符 \u0026#39;b\u0026#39; deque.addFirst(\u0026#39;c\u0026#39;); // 添加字符 \u0026#39;c\u0026#39; // 将 Deque 转换为字符串 StringBuilder sb = new StringBuilder(); for (char c : deque) { sb.append(c); } String result = sb.toString(); System.out.println(result); // 输出: cba } } 性能分析 时间复杂度： 在头部插入字符的时间复杂度是 O(1)。 转换为字符串的时间复杂度是 O(n)，其中 n 是字符的数量。 空间复杂度： 使用 LinkedList 或 Deque 会额外存储每个字符的节点信息（前驱和后继指针），空间开销略高于 StringBuilder。 为什么不直接使用 StringBuilder？ StringBuilder 在头部插入字符的时间复杂度是 O(n)，因为需要移动所有现有字符。 示例： StringBuilder sb = new StringBuilder(); sb.insert(0, \u0026#39;a\u0026#39;); // O(n) sb.insert(0, \u0026#39;b\u0026#39;); // O(n) sb.insert(0, \u0026#39;c\u0026#39;); // O(n) System.out.println(sb.toString()); // 输出: cba 这种方法在频繁插入时性能较差。 总结 如果需要不断往字符串头部添加字符，推荐使用 LinkedList\u0026lt;Character\u0026gt; 或 Deque\u0026lt;Character\u0026gt;。 它们在头部插入字符的时间复杂度是 O(1)，性能最优。 插入完成后，可以将其转换为字符串。 如果插入操作较少，或者主要在尾部添加字符，可以使用 StringBuilder。 希望这个解答对你有帮助！如果还有其他问题，欢迎随时提问！\n面试经典150题 # 面试经典150题 数组/字符串 # 移除元素 # 2025-01-11 击败3.36% class Solution { public int removeElement(int[] nums, int val) { Arrays.sort(nums); int flagIndex = -1; int count = 0; for (int i = 0; i \u0026lt; nums.length; i++) { if (nums[i] == val \u0026amp;\u0026amp; count == 0) { flagIndex = i; count++; } else if (nums[i] == val) { count++; } } if (flagIndex != -1 \u0026amp;\u0026amp; count != 0) { for (int i = flagIndex; i \u0026lt; flagIndex + count; i++) { nums[i] = nums[nums.length - (i - flagIndex) - 1]; } } return nums.length - count; } } 一维动态规划 # 爬楼梯 # 2025-01-11 击败100% class Solution { public int climbStairs(int n) { if (n == 0) return 0; if (n == 1) return 1; if (n == 2) return 2; int[] dp = new int[n + 1]; dp[0] = 0; dp[1] = 1; dp[2] = 2; for (int i = 3; i \u0026lt;= n; i++) { dp[i] = dp[i - 1] + dp[i - 2]; } return dp[n]; } } 面试经典150题 # 面试经典150题 数组/字符串 # 合并两个有序数组 # 合并两个有序数组 2025-01-12 public class Solution88 { public static void merge(int[] nums1, int m, int[] nums2, int n) { if (n == 0) return; int nIndex = 0; for (int i = m; i \u0026lt; m + n; i++) { nums1[i] = nums2[nIndex++]; } Arrays.sort(nums1); } public static void main(String[] args) { int[] nums1 = {1, 2, 3, 0, 0, 0}; int m = 3; int[] nums2 = {2, 5, 6}; int n = 3; merge(nums1, m, nums2, n); for (int i : nums1) { System.out.print(i + \u0026#34; \u0026#34;); } } } 移除元素 # 移除元素 2025-01-11 删除有序数组中的重复项 # 删除有序数组中的重复项 2025-01-11 没有做出来，看的官方题解 2025-01-11 做完删除有序数组中的重复项 II之后再尝试重新解题完成 public class Solution26 { public static int removeDuplicates(int[] nums) { if (nums.length \u0026lt;= 1) return nums.length; int slow = 1; int fast = 1; while (slow \u0026lt;= fast \u0026amp;\u0026amp; fast \u0026lt; nums.length) { if (nums[fast] != nums[fast - 1]) { nums[slow] = nums[fast]; slow++; } fast++; } return slow; } public static void main(String[] args) { int[] nums = {0, 0, 1, 1, 1, 2, 2, 3, 3, 4}; for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(removeDuplicates(nums)); for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } } } 删除有序数组中的重复项 II # 删除有序数组中的重复项 II 2025-01-11 public class Solution80 { public static int removeDuplicates(int[] nums) { if (nums.length \u0026lt;= 2) return nums.length; int slow = -1; int fast = 1; int count = 1; while (slow \u0026lt;= fast \u0026amp;\u0026amp; fast \u0026lt; nums.length) { if (nums[fast] == nums[fast - 1]) { count++; if (count \u0026gt; 2 \u0026amp;\u0026amp; slow == -1) { slow = fast; } else if (count \u0026lt;= 2 \u0026amp;\u0026amp; slow != -1) { nums[slow] = nums[fast]; slow++; } } else if (nums[fast] != nums[fast - 1]) { if (slow != -1) { nums[slow] = nums[fast]; slow++; } count = 1; } fast++; } return slow == -1 ? nums.length : slow; } public static void main(String[] args) { //int[] nums = {0,0,1,1,1,1,2,3,3}; //int[] nums = {1,2,2}; int[] nums = {1, 1, 1, 2, 2, 2, 3, 3}; for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } System.out.println(); System.out.println(removeDuplicates(nums)); for (int num : nums) { System.out.print(num + \u0026#34; \u0026#34;); } } } 多数元素 # 多数元素 2025-01-12 轮转数组 # 轮转数组 2025-01-18 进阶 尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。 你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 买卖股票的最佳时机 # 买卖股票的最佳时机 2025-01-11 看官方题解做出来的 2025-01-17 review 买卖股票的最佳时机 II # 买卖股票的最佳时机 II 官方题解 理解 2025-01-17 方法一：动态规划 方法二：贪心 跳跃游戏 # 跳跃游戏 2025-01-17 官方题解理解 贪心 2025-01-18 跳跃游戏 II # 跳跃游戏 II 2025-01-18 算法超时了 理解官方题解 2025-01-18 方法一：反向查找出发位置 Solution45.jump2 2025-01-18 方法二：正向查找可达到的最大位置 Solution45.jump3 H 指数 # H 指数\n2025-01-18 Tips An easy approach is to sort the array first. What are the possible values of h-index? A faster approach is to use extra space. O(1) 时间插入、删除和获取随机元素\n除自身以外数组的乘积\n加油站\n分发糖果\n接雨水\n罗马数字转整数\n2025-01-12 整数转罗马数字\n最后一个单词的长度\n2025-01-12 最长公共前缀\n2025-01-12 反转字符串中的单词\n2025-01-18 进阶 如果字符串在你使用的编程语言中是一种可变数据类型，请尝试使用 O(1) 额外空间复杂度的 原地 解法。 Z 字形变换\n找出字符串中第一个匹配项的下标\n2025-01-12 文本左右对齐\n双指针 # 验证回文串 # 验证回文串 2025-01-13 判断子序列 # 判断子序列 2025-01-13 两数之和 II - 输入有序数组 # 两数之和 II - 输入有序数组\n2025-01-13 运行有时候会超过时间限制 盛最多水的容器\n三数之和\n滑动窗口 # 长度最小的子数组 # 长度最小的子数组 2025-01-22 无重复字符的最长子串 # 无重复字符的最长子串 2025-01-22 串联所有单词的子串 # 串联所有单词的子串 2025-01-22 最小覆盖子串 # 最小覆盖子串 矩阵 # 有效的数独 # 有效的数独 2025-01-18 螺旋矩阵 # 螺旋矩阵 2025-01-18 旋转图像 # 旋转图像 理解官方题解 2025-01-18 方法一：使用辅助数组 2025-01-18 方法二：原地旋转 有数学公式的推导，需要自己推导一次 2025-01-18 方法三：用翻转代替旋转 有数学公式的推导，需要自己推导一次 矩阵置零 # 矩阵置零 2025-01-18 生命游戏 # 生命游戏 2025-01-18 进阶 你可以使用原地算法解决本题吗？请注意，面板上所有格子需要同时被更新：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。 本题中，我们使用二维数组来表示面板。原则上，面板是无限的，但当活细胞侵占了面板边界时会造成问题。你将如何解决这些问题？ ✅ 哈希表 # ✅ 赎金信 # 赎金信 2025-01-13 ✅ 同构字符串 # 同构字符串 2025-01-13 ✅ 单词规律 # 单词规律 2025-01-13 ✅ 有效的字母异位词 # 有效的字母异位词 2025-01-13 ✅ 字母异位词分组 # 字母异位词分组 2025-01-16 第一遍算法超时，看了官方题解思路后实现通过 ✅ 两数之和 # 两数之和 2025-01-13 ✅ 快乐数 # 快乐数 2025-01-13 ✅ 存在重复元素 II # 存在重复元素 II 2025-01-13 ✅ 最长连续序列 # 最长连续序列 2025-01-16 看了官方题解后完成 区间 # 栈 # 有效的括号 # 有效的括号 2025-01-22 简化路径 # 简化路径 2025-01-22 最小栈 # 最小栈 2025-01-22 理解官方题解 文字描述后完成 2025-01-22 理解官方题解 逆波兰表达式求值 # 逆波兰表达式求值 2025-01-22 基本计算器 # 基本计算器 链表 # ✅ 环形链表 # 环形链表 2025-01-20 理解官方题解 2025-01-20 方法一：哈希表 方法二：快慢指针 ✅ 两数相加 # 两数相加 2025-01-20 ✅ 合并两个有序链表 # 合并两个有序链表 2025-01-20 ✅ 随机链表的复制 # 随机链表的复制 2025-01-20 ✅ 反转链表 II # 反转链表 II 2025-01-20 K 个一组翻转链表 # K 个一组翻转链表 ✅ 删除链表的倒数第 N 个结点 # 删除链表的倒数第 N 个结点 2025-01-20 进阶 2025-01-20 你能尝试使用一趟扫描实现吗？ ✅ 删除排序链表中的重复元素 II # 删除排序链表中的重复元素 II 2025-01-21 ✅ 旋转链表 # 旋转链表 给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。 2025-01-20 public class Solution61 { public static ListNode rotateRight(ListNode head, int k) { if (head == null || head.next == null) return head; ListNode _head = head; int nodeCount = 1; while (_head.next != null) { _head = _head.next; nodeCount++; } _head.next = head; _head = head; for (int i = 0; i \u0026lt; (nodeCount - k % nodeCount) - 1; i++) { _head = _head.next; } head = _head.next; _head.next = null; return head; } public static void main(String[] args) { test002(); test001(); } public static void test001() { ListNode node0 = new ListNode(1); ListNode node1 = new ListNode(2); ListNode node2 = new ListNode(3); ListNode node3 = new ListNode(4); ListNode node4 = new ListNode(5); node0.next = node1; node1.next = node2; node2.next = node3; node3.next = node4; ListNode listNode = rotateRight(node0, 2); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } public static void test002() { ListNode node0 = new ListNode(0); ListNode node1 = new ListNode(1); ListNode node2 = new ListNode(2); node0.next = node1; node1.next = node2; ListNode listNode = rotateRight(node0, 4); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } static public class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } } ✅ 分隔链表 # 分隔链表 2025-01-21 public class Solution86 { public static ListNode partition(ListNode head, int x) { ListNode solder = new ListNode(-1); solder.next = head; ListNode insertPreNode = solder; ListNode insertNode = insertPreNode.next; while (insertNode != null \u0026amp;\u0026amp; insertNode.val \u0026lt; x) { insertPreNode = insertNode; insertNode = insertNode.next; } ListNode preNode = insertPreNode; ListNode currentNode = preNode.next; ListNode nextNode = currentNode != null ? currentNode.next : null; while (currentNode != null) { if (currentNode.val \u0026lt; x) { preNode.next = nextNode; insertPreNode.next = currentNode; currentNode.next = insertNode; insertPreNode = currentNode; } else { preNode = currentNode; } currentNode = nextNode; nextNode = currentNode != null ? currentNode.next : null; } return solder.next; } public static void main(String[] args) { test002(); test001(); } public static void test001() { ListNode node0 = new ListNode(1); ListNode node1 = new ListNode(4); ListNode node2 = new ListNode(3); ListNode node3 = new ListNode(2); ListNode node4 = new ListNode(5); ListNode node5 = new ListNode(2); node0.next = node1; node1.next = node2; node2.next = node3; node3.next = node4; node4.next = node5; ListNode listNode = partition(node0, 3); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } public static void test002() { ListNode node0 = new ListNode(2); ListNode node1 = new ListNode(1); node0.next = node1; ListNode listNode = partition(node0, 2); while (listNode != null) { System.out.print(listNode.val + \u0026#34; \u0026#34;); listNode = listNode.next; } System.out.println(); } static public class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } } ✅ LRU 缓存 # LRU 缓存 2025-01-22 理解官方题解 二叉树 # 二叉树的最大深度 # 二叉树的最大深度 2025-01-15 相同的树 # 相同的树 2025-01-15 翻转二叉树 # 翻转二叉树 2025-01-15 对称二叉树 # 对称二叉树 没做出来，看的官方题解 从前序与中序遍历序列构造二叉树 # 从前序与中序遍历序列构造二叉树 从中序与后序遍历序列构造二叉树 # 从中序与后序遍历序列构造二叉树 填充每个节点的下一个右侧节点指针 II # 填充每个节点的下一个右侧节点指针 II 二叉树展开为链表 # 二叉树展开为链表 路径总和 # 路径总和 求根节点到叶节点数字之和 # 求根节点到叶节点数字之和 二叉树中的最大路径和 # 二叉树中的最大路径和 二叉搜索树迭代器 # 二叉搜索树迭代器 完全二叉树的节点个数 # 完全二叉树的节点个数 二叉树的最近公共祖先 # 二叉树的最近公共祖先 二叉树层次遍历 # 二叉搜索树 # 图 # 图的广度优先搜索 # 字典树 # ✅ 回溯 # ✅ 电话号码的字母组合 # 电话号码的字母组合 2025-01-15 ✅ 组合 # 组合 2025-01-15 ✅ 全排列 # 全排列 2025-01-15 ✅ 组合总和 # 组合总和 2025-01-15 ✅ N 皇后 II # N 皇后 II 2025-01-15 ✅ 括号生成 # 括号生成 2025-01-15 ✅ 单词搜索 # 单词搜索 2025-01-15 分治 # kadane算法 # 二分查找 # 堆 # 位运算 # 二进制求和 # 给你两个二进制字符串 a 和 b ，以二进制字符串的形式返回它们的和。 示例 1： 输入:a = \u0026ldquo;11\u0026rdquo;, b = \u0026ldquo;1\u0026rdquo; 输出：\u0026ldquo;100\u0026rdquo; 示例 2： 输入：a = \u0026ldquo;1010\u0026rdquo;, b = \u0026ldquo;1011\u0026rdquo; -输出：\u0026ldquo;10101\u0026rdquo; 提示： 1 \u0026lt;= a.length, b.length \u0026lt;= 104 a 和 b 仅由字符 \u0026lsquo;0\u0026rsquo; 或 \u0026lsquo;1\u0026rsquo; 组成 字符串如果不是 \u0026ldquo;0\u0026rdquo; ，就不含前导零 二进制求和 2025-01-16 public class Solution67 { public static String addBinary(String a, String b) { StringBuilder sb = new StringBuilder(); int aIndex = a.length() - 1; int bIndex = b.length() - 1; int flag = 0; while (true) { int count = (aIndex \u0026lt; 0 ? \u0026#39;0\u0026#39; : a.charAt(aIndex)) - \u0026#39;0\u0026#39; + (bIndex \u0026lt; 0 ? \u0026#39;0\u0026#39; : b.charAt(bIndex)) - \u0026#39;0\u0026#39; + flag; sb.insert(0, count % 2); flag = count / 2; aIndex--; bIndex--; if (aIndex \u0026lt; 0 \u0026amp;\u0026amp; bIndex \u0026lt; 0 \u0026amp;\u0026amp; flag == 0) break; } return sb.toString(); } public static void main(String[] args) { System.out.println(addBinary(\u0026#34;11\u0026#34;, \u0026#34;1\u0026#34;)); System.out.println(addBinary(\u0026#34;1010\u0026#34;, \u0026#34;1011\u0026#34;)); } } 颠倒二进制位 # 颠倒二进制位 2025-01-16 没做出来, 参考这篇文章LeetCode 190. 颠倒二进制位 （位运算 分治） 2025-01-17 复习了一遍 2025-01-17 新增了中间值打印的代码在算法中 位1的个数 # 位1的个数 2025-01-17 只出现一次的数字 # 只出现一次的数字 2025-01-17 只出现一次的数字 II # 只出现一次的数字 II 2025-01-17 理解了官方题解 方法2 数字范围按位与 # 数字范围按位与 2025-01-17 理解了官方题解 方法2 数学 # 回文数 # 回文数 2025-01-17 不将整数转为字符串来解决这个问题 public class Solution9 { public static boolean isPalindrome(int x) { String numberString = String.valueOf(x); int left = 0; int right = numberString.length() - 1; while (left \u0026lt;= right) { if (numberString.charAt(left) != numberString.charAt(right)) { return false; } left++; // 左边指针向右移动一个位置 right--; // 右边指针向左边移动一个位置 } return true; } public static void main(String[] args) { System.out.println(isPalindrome(121)); System.out.println(isPalindrome(-121)); //负数肯定不是回文数 System.out.println(isPalindrome(10)); } } 加一 # 给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。 最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。 你可以假设除了整数 0 之外，这个整数不会以零开头。 示例 1： 输入：digits = [1,2,3] 输出：[1,2,4] 解释：输入数组表示数字 123。 示例 2： 输入：digits = [4,3,2,1] 输出：[4,3,2,2] 解释：输入数组表示数字 4321。 示例 3： 输入：digits = [9] 输出：[1,0] 解释：输入数组表示数字 9。 加 1 得到了 9 + 1 = 10。 因此，结果应该是 [1,0]。 加一 2025-01-17 public class Solution66 { public static int[] plusOne(int[] digits) { ArrayList\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int digit : digits) { list.add(digit); } int flag = 0; // 表示进位 int number = list.get(list.size() - 1); // 最右边一位 int _number = number; number = (_number + 1) % 10; flag = (_number + 1) / 10; list.set(list.size() - 1, number); if (list.size() \u0026gt;= 2) { // 原数字位数大于1 for (int i = list.size() - 2; i \u0026gt;= 0; i--) { int numberTmp = list.get(i); list.set(i, (numberTmp + flag) % 10); flag = (numberTmp + flag) / 10; } } if (flag != 0) { // 如果还有一个进位，就在最左边新增一位 list.add(0, 1); } // 构造一个整数数组返回结果 int[] result = new int[list.size()]; for (int i = 0; i \u0026lt; list.size(); i++) { result[i] = list.get(i); } return result; } public static void main(String[] args) { int[] result = plusOne(new int[]{9, 9}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{9}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{1, 2, 3}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); result = plusOne(new int[]{4, 3, 2, 1}); for (int number : result) { System.out.print(number + \u0026#34; \u0026#34;); } System.out.println(); } } 阶乘后的零 # 给定一个整数 n ，返回 n! 结果中尾随零的数量。 提示 n! = n * (n - 1) * (n - 2) * \u0026hellip; * 3 * 2 * 1 示例 1： 输入：n = 3 输出：0 解释：3! = 6 ，不含尾随 0 示例 2： 输入：n = 5 输出：1 解释：5! = 120 ，有一个尾随 0 示例 3： 输入：n = 0 输出：0 提示：0 \u0026lt;= n \u0026lt;= 10^4 阶乘后的零 2025-01-17 version 1 # public class Solution172 { // 因式分解 public static int trailingZeroes(int n) { int result = 0; int[] countArr = new int[]{0, 0}; for (int i = n; i \u0026gt;= 1; i--) { int number = i; while (number % 10 == 0) { result++; number /= 10; } while (number % 5 == 0) { countArr[1]++; number /= 5; } while (number % 2 == 0) { countArr[0]++; number /= 2; } int min = Math.min(countArr[0], countArr[1]); if (min != 0) { countArr[0] -= min; countArr[1] -= min; result += min; } } return result; } public static void main(String[] args) { for (int i = 5; i \u0026lt; 10000; i++) { System.out.println(i + \u0026#34; : \u0026#34; + trailingZeroes(i)); } } } version 2 # 只需要因式分解 2 和 5 就行了，不用分解 10（已经包含了 2 和 5 ） class Solution { public static int trailingZeroes(int n) { int result = 0; int[] countArr = new int[]{0, 0}; for (int i = n; i \u0026gt;= 1; i--) { int number = i; while (number % 5 == 0) { countArr[1]++; number /= 5; } while (number % 2 == 0) { countArr[0]++; number /= 2; } int min = Math.min(countArr[0], countArr[1]); if (min != 0) { countArr[0] -= min; countArr[1] -= min; result += min; } } return result; } } x 的平方根 # 给你一个非负整数 x ，计算并返回 x 的 算术平方根 由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 示例 1： 输入：x = 4 输出：2 示例 2： 输入：x = 8 输出：2 解释：8 的算术平方根是 2.82842\u0026hellip;, 由于返回类型是整数，小数部分将被舍去。 提示： 0 \u0026lt;= x \u0026lt;= 2^31 - 1 x 的平方根 2025-01-17 package com.penruins.leetcode; public class Solution69 { public static int mySqrt(int x) { long xLong = Long.valueOf(x).longValue(); if (xLong == 0) return 0; if (xLong == 1) return 1; for (long i = 1; i \u0026lt; xLong; i++) { if (i * i == xLong || (i * i \u0026lt; xLong \u0026amp;\u0026amp; (i + 1) * (i + 1) \u0026gt; xLong)) { return (int) i; } } return -1; } public static void main(String[] args) { System.out.println(mySqrt(2147483647)); System.out.println(2147483647); System.out.println(46340 * 46340); System.out.println(46341l * 46341l); // for (int i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { // System.out.println(i + \u0026#34; : \u0026#34; + mySqrt(i)); // } } } Pow(x, n) # 实现 pow(x, n) ，即计算 x 的整数 n 次幂函数（即，x^n ）。 示例 1： 输入：x = 2.00000, n = 10 输出：1024.00000 示例 2： 输入：x = 2.10000, n = 3 输出：9.26100 示例 3： 输入：x = 2.00000, n = -2 输出：0.25000 解释：2-2 = 1/22 = 1/4 = 0.25 提示： -100.0 \u0026lt; x \u0026lt; 100.0 -2^31 \u0026lt;= n \u0026lt;= 2^31-1 n 是一个整数 要么 x 不为零，要么 n \u0026gt; 0 -10^4 \u0026lt;= xn \u0026lt;= 10^4 Pow(x, n) 2025-01-17 超时了 2025-01-17 看懂了官方题解 直线上最多的点数 # 直线上最多的点数 2025-01-17 看了官方题解，但还是不太理解 一维动态规划 # 爬楼梯 2025-01-11 通过 多维动态规划 # 排序 sort # 基础排序算法 # 冒泡排序 Bubble Sort # 选择排序 Selection Sort # 插入排序 Insertion Sort # 高效排序算法 # 快速排序 Quick Sort # com.penruins.JZOffer.sort.QuickSort 剑指Offer 12.3 归并排序 Merge Sort # 剑指Offer 12.4 迭代实现 # 递归实现 # 堆排序 Heap Sort # 希尔排序 Shell Sort # 特殊场景排序算法 # 基数排序 Radix Sort # 计数排序 Counting Sort # com.penruins.JZOffer.sort.CountingSort 剑指Offer 12.2 桶排序 Bucket Sort # "},{"id":70,"href":"/post/computer-science/database/mongodb/","title":"Penruins","section":"Database","content":" mongodb # "},{"id":71,"href":"/post/blog/2025/2025-03-31-shardingsphere-prometheus-%E9%85%8D%E7%BD%AE/","title":"2025 03 31 Shardingsphere Prometheus 配置","section":"Posts","content":" 2025-03-31-Shardingsphere-prometheus-配置 # 把 shardingsphere proxy 搭建好之后，想要把监测数据放到 grafana里面进行监测，但是按照找到的资料来配置好像都不太行，自己研究了一下启动脚本，现在可以正常获取到指标数据了，所以花点时间把这个问题记录一下\n下载了官网提供的 shardingsphere-proxy 的包之后，里面其实已经包含了 agent 相关的 jar 包以及插件相关的 jar 包，其实不需要再下载一个 shardingsphere-agent\n我们需要配置一下agent.yaml里面的内容，文件的位置在 apache-shardingsphere-5.5.2-shardingsphere-proxy-bin/agent/conf/agent.yaml，现在只需要配置 prometheus，所以如下所示\nplugins: metrics: Prometheus: host: \u0026#34;localhost\u0026#34; port: 9000 props: jvm-information-collector-enabled: \u0026#34;true\u0026#34; 在 prometheus 的配置文件中需要加上 9000 的指标接口（如果是使用 brew 安装的话，配置文件在这个位置 /opt/homebrew/etc/prometheus.yml）\nscrape_configs: - job_name: \u0026#39;shardingsphere\u0026#39; static_configs: - targets: [\u0026#39;localhost:9000\u0026#39;] 网上查到的这篇文章 Apache ShardingSphere Agent 可观察性实用指南 提到需要修改脚本文件，其实是不用修改的，只需要夹一个参数 --agent 就可以\n需要注意的是运行的目录需要在 shardingsphere-proxy 的根目录下，因此命令如下所示\nsh bin/start.sh 5555 --agent 查看日志 vim logs/stdout.log 打印的应该如下所示\nMar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-metrics-prometheus-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-tracing-opentelemetry-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-metrics-core-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-plugin-core-5.5.2.jar Mar 31, 2025 6:07:37 PM org.apache.shardingsphere.agent.core.plugin.jar.PluginJarLoader load INFO: Loaded jar: shardingsphere-agent-logging-file-5.5.2.jar [INFO ] 2025-03-31 18:07:38.772 [main] o.a.s.d.p.c.l.PipelineContextManagerLifecycleListener - mode type is not Cluster, mode type=\u0026#39;Standalone\u0026#39;, ignore [INFO ] 2025-03-31 18:07:38.786 [main] o.a.s.p.v.ShardingSphereProxyVersion - Database type is `MySQL`, version is `8.0.41`, database name is `sharding_db` [INFO ] 2025-03-31 18:07:38.786 [main] o.a.s.p.frontend.ssl.ProxySSLContext - Proxy frontend SSL/TLS is not enabled. [INFO ] 2025-03-31 18:07:38.836 [main] o.a.s.p.frontend.ShardingSphereProxy - ShardingSphere-Proxy Standalone mode started successfully 这个时候需要查询一下数据库，agent才会把服务启起来\n[INFO ] 2025-03-31 18:08:14.258 [nioEventLoopGroup-3-1] o.a.s.a.c.p.PluginLifecycleServiceManager - Start plugin: Prometheus [INFO ] 2025-03-31 18:08:14.290 [nioEventLoopGroup-3-1] o.a.s.a.p.m.p.PrometheusPluginLifecycleService - Prometheus metrics HTTP server `localhost:9000` start success. 日志如上打印之后，agent就真正启动了。访问 http://localhost:9000/metrics 可以看到返回了指标数据\nReference # 可观察性的使用 官方文档 Apache ShardingSphere Agent 可观察性实用指南 "},{"id":72,"href":"/post/computer-science/cloud/","title":"Cloud","section":"Computer Science","content":"cloud\n"},{"id":73,"href":"/post/computer-science/hugo/","title":"Hugo","section":"Computer Science","content":" 在 Hugo 中配置 TOC 从一级标题开始显示 # 要在 Hugo 中让侧边栏的目录(TOC)从一级标题(h1)开始显示，你可以通过以下几种方法实现：\n方法一：修改 config.toml # 在你的 Hugo 配置文件(通常是 config.toml 或 config.yaml)中添加或修改以下设置：\n[markup] [markup.tableOfContents] startLevel = 1 endLevel = 6 或者对于 YAML 格式：\nmarkup: tableOfContents: startLevel: 1 endLevel: 6 方法二：模板中指定 # 如果你在模板中调用 TOC，可以这样指定：\n{{ .TableOfContents }} 默认情况下，Hugo 会从二级标题(h2)开始显示 TOC。要修改这个行为，你需要使用方法一中的配置。\n方法三：使用自定义 CSS # 如果配置修改后仍然不符合预期，你可以添加自定义 CSS 来隐藏不需要的层级：\n/* 隐藏除一级标题外的其他层级 */ #TableOfContents ul ul { display: none; } 方法四：使用 Goldmark 配置 # 如果你使用的是 Goldmark 渲染器(默认)，确保配置正确：\n[markup.goldmark] [markup.goldmark.parser] [markup.goldmark.parser.attribute] block = true title = true 注意事项 # 确保你的内容中确实有一级标题(# 或 \u0026lt;h1\u0026gt;) 某些主题可能会覆盖默认的 TOC 行为，你可能需要检查主题文档 清除缓存(hugo --gc)有时能解决显示问题 如果你使用的是特定主题，可能需要查看该主题的文档，因为有些主题会提供自己的 TOC 配置选项。\n"},{"id":74,"href":"/post/computer-science/micro-service/nacos/","title":"Nacos","section":"Micro Service","content":" 关于 Nacos 配置更新后避免 HikariCP 连接断开的问题 # 解决方案 # 使用 @RefreshScope(proxyMode = ScopedProxyMode.NO) 排除数据源 # @Configuration @RefreshScope(proxyMode = ScopedProxyMode.NO) public class DataSourceConfig { // 数据源配置 } 自定义 RefreshScope 排除数据源相关配置 # @Bean public RefreshScope refreshScope() { RefreshScope scope = new RefreshScope(); scope.setExcludeNames(new String[]{\u0026#34;dataSource\u0026#34;, \u0026#34;hikariDataSource\u0026#34;}); return scope; } 在 bootstrap.yml 中排除特定配置的刷新 # spring: cloud: nacos: config: refresh-enabled: true refreshable-data-sources: none # 不刷新数据源配置 使用 @RefreshScope 但不刷新数据源 # @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource.hikari\u0026#34;) @RefreshScope(proxyMode = ScopedProxyMode.NO) public HikariDataSource dataSource() { return DataSourceBuilder.create().type(HikariDataSource.class).build(); } 最佳实践 # 分离配置：将数据库配置和其他频繁变动的配置分开，放在不同的配置文件中 版本控制：对数据库配置的修改应该通过版本控制和应用重启来完成，而不是热更新 监控：即使解决了这个问题，也应该监控数据库连接池状态 注意事项 # 这些解决方案可能会因 Spring Boot/Cloud 版本不同而有所差异 在生产环境实施前应在测试环境充分验证 如果确实需要动态修改数据库配置，建议使用更优雅的方式如多数据源切换 "},{"id":75,"href":"/post/others/economy/","title":"Economy","section":"Others","content":" 2025 反内卷 # 本轮反内卷法治化与市场化结合，上一轮去产能主要以行政主导模式 #财经-2025-16 上一轮去产能，中央设定产能淘汰硬指标（如钢铁去产能1.5亿吨），纳入地方政府考核体系，通过“一刀切”关停、限产实现快速出清。 本轮“反内卷”政策，具有一系列明确的法律约束，即新修订的《反不正当竞争法》明确禁止“低于成本价倾销”，建立公平竞争审查制度。 同时，更为注重市场引导：通过产能置换指标交易（如水泥行业每新增1吨产能需退出1.5吨旧产能）、行业协会自律倡议（如光伏企业集体减产30%）实现渐进式出清。 同时，上一轮去产能主要为国企主导实施。国有企业承担80%钢铁去产能任务，政策执行刚性强。本轮行业“反内卷”，新兴行业（如光伏、汽车等）民企占比超70%，政策更依赖行业自发协调（如中汽协倡议统一供应商账期）而非行政命令。 同时，面对的行业也不一样。本轮“反内卷”所对应的是部分先进制造业。由于部分先进制造业出海，前期按照全球需求进行产能布局，外需回落或暂时的贸易壁垒才加剧了供需错配压力。 本轮行业“反内卷”面临总需求疲软，通货紧缩的宏观背景；上一轮去产能时，需求端支撑，价格传导顺畅。 对一些工业和制造业行业而言，“反内卷”也势必将导致一定程度的“去产能”。但不意味着以“去产能”为核心目的来推动“反内卷”，更不适合刚性的以产量和投资下降等产能去化指标来衡量“反内卷”效果。由于本轮调整的行业范围与性质较上一轮更为复杂，“反内卷”必须坚持以纠正市场失灵，建立公平竞争的市场秩序为最终目标的改革思路，而不能变成新一轮的行政性“去产能”。本轮行业反内卷的核心是提质，走高质量发展道路，而非简单的“去产能”。 mess # 沿海地区高歌猛进的人工智能、大模型、具身智能、物联网、工业互联网等等，必将给内地相对传统的产业进一步赋能，带来进一步的效率提升 "},{"id":76,"href":"/post/blog/2025/2025-%E5%B9%BF%E5%B7%9E-%E6%89%BE%E5%B7%A5%E4%BD%9C/","title":"2025 广州 找工作","section":"Posts","content":" 2025 广州 找工作 # 面试记录 # 2025-03-21 网易游戏商城-充值 第一面 未通过 # 在生产环境下如何给一张表添加索引？ 数据库的ACID有了解吗？ kafka如何保证消息的有序性？ redis的集群模式有哪些？ 2025-03-19 探迹科技-后台开发python 技术复试 通过 # 开发的模块的QPS是多少？ Netty的线程模式是怎样的？(简历中提到了使用了Netty作为tcp连接的框架) 如果商城中有10亿个商品，每天的活跃用户平均有1000w，每个用户平均每天会浏览10个商品，如何在数据库中保存浏览记录？ 你的职业规划是怎样的？ 反问 为什么要是属于python作为后台开发的语言？ 2025-03-12 探迹科技-后台开发python 技术初面 通过 # 开发的模块的QPS是多少？ 有一个很长的整数数组，给定一个整数total，返回2个下标，使得下标对应的两个元素相加等于total，要怎么实现？ HashMap 底层的数据结构是怎样的？ HashMap 是线程安全的吗？如何保证它线程安全？ 主从数据库是如何进行数据同步的？ 有没有关注什么新技术？ "},{"id":77,"href":"/post/life/article/","title":"article","section":"Life","content":" 2025-03-31-Shardingsphere-prometheus-配置 2025-广州-找工作 2025-03-29 教育到底怎么了？ 2025-03-16 能找到工作吗？ "},{"id":78,"href":"/post/computer-science/artificial-intelligence/","title":"Artificial Intelligence","section":"Computer Science","content":" Artificial Intelligence # Cherry Studio # 面向新手的MCP使用教程：在Cherry Studio中配置和使用模型上下文协议 "},{"id":79,"href":"/post/computer-science/crawler/","title":"crawler","section":"Computer Science","content":" crawler # 针对豆瓣反爬问题的讨论 从豆瓣的反爬说说自建代理池 "},{"id":80,"href":"/post/others/f1/","title":"F1","section":"Others","content":" Chester117 合集·F1分钟小知识 我亲手搓了一条F1轮胎 "},{"id":81,"href":"/post/computer-science/git/","title":"git","section":"Computer Science","content":" branches # git checkout main #切换到 main 分支 git branch #查看本地分支 git branch -a #查看所有分支（包括远程） git branch -r #仅查看远程分支 "},{"id":82,"href":"/post/computer-science/ci-cd/gitlab/","title":"Gitlab","section":"CI/CD","content":" Gitlab 安装和配置 "},{"id":83,"href":"/post/books/computer-science/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/","title":"Java并发编程实战","section":"Computer Science","content":" Java并发编程实战 第1章 简介 # 1.1 并发简史 # 1.2 线程的优势 # 1.3 线程带来的风险 # 1.4 线程无处不在 # 开发线程安全的类比开发非线程安全的类要更加谨慎和细致 每个Java应用程序都会使用线程 当JVM启动时，它将为JVM的内部任务（例如，垃圾收集、终结操作等）创建后台线程，并创建一个主线程来运行main方法。 AWT（Abstract Window Toolkit，抽象窗口工具库）和Swing的用户界面框架将创建线程来管理用户界面事件。 Timer将创建线程来执行延迟任务。 一些组件框架，例如Servlet和RMI，都会创建线程池并调用这些线程中的方法。 当某个框架在应用程序中引入并发性时，通常不可能将并发性仅局限于框架代码，因为框架本身会回调（Callback）应用程序的代码，而这些代码将访问应用程序的状态。 对线程安全性的需求也不能局限于被调用的代码，而是要延伸到需要访问这些代码所访问的程序状态的所有代码路径。因此，对线程安全性的需求将在程序中蔓延开来。 第2章 线程安全性 # 要编写线程安全的代码，其核心在于要对状态访问操作进行管理，特别是对共享的（Shared）和可变的（Mutable）状态的访问。 “共享”意味着变量可以由多个线程同时访问，而“可变”则意味着变量的值在其生命周期内可以发生变化。 一个对象是否需要是线程安全的，取决于它是否被多个线程访问 当多个线程访问某个状态变量并且其中有一个线程执行写入操作时，必须采用同步机制来协同这些线程对变量的访问。 Java中的主要同步机制是关键字synchronized，它提供了一种独占的加锁方式，但“同步”这个术语还包括volatile类型的变量，显式锁（Explicit Lock）以及原子变量。 2.1 什么是线程安全性 # 在线程安全性的定义中，最核心的概念就是正确性。如果对线程安全性的定义是模糊的，那么就是因为缺乏对正确性的清晰定义。 正确性的含义是，某个类的行为与其规范完全一致。在良好的规范中通常会定义各种不变性条件（Invariant）来约束对象的状态，以及定义各种后验条件（Postcondition）来描述对象操作的结果。 线程安全性：当多个线程访问某个类时，这个类始终都能表现出正确的行为，那么就称这个类是线程安全的。 当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 在线程安全类中封装了必要的同步机制，因此客户端无须进一步采取同步措施。 无状态对象一定是线程安全的 大多数Servlet都是无状态的，从而极大地降低了在实现Servlet线程安全性时的复杂性。只有当Servlet在处理请求时需要保存一些信息，线程安全性才会成为一个问题。 2.2 原子性 # 在并发编程中，这种由于不恰当的执行时序而出现不正确的结果是一种非常重要的情况，它有一个正式的名字：竞态条件（Race Condition） 2.2.1 竞态条件 # 当某个计算的正确性取决于多个线程的交替执行时序时，那么就会发生竞态条件。换句话说，就是正确的结果要取决于运气 “先检查后执行”：首先观察到某个条件为真（例如文件X不存在），然后根据这个观察结果采用相应的动作（创建文件X），但事实上，在你观察到这个结果以及开始创建文件之间，观察结果可能变得无效（另一个线程在这期间创建了文件X），从而导致各种问题（未预期的异常、数据被覆盖、文件被破坏等）。 2.2.2 示例：延迟初始化中的竞态条件 # 延迟初始化的目的是将对象的初始化操作推迟到实际被使用时才进行，同时要确保只被初始化一次。 假定线程A和线程B同时执行getInstance。A看到instance为空，因而创建一个新的ExpensiveObject实例。B同样需要判断instance是否为空。此时的instance是否为空，要取决于不可预测的时序，包括线程的调度方式，以及A需要花多长时间来初始化ExpensiveObject并设置instance。如果当B检查时，instance为空，那么在两次调用getInstance时可能会得到不同的结果，即使getInstance通常被认为是返回相同的实例。 2.2.3 复合操作 # 要避免竞态条件问题，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或之后读取和修改状态，而不是在修改状态的过程中。 假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。 原子操作是指，对于访问同一个状态的所有操作（包括该操作本身）来说，这个操作是一个以原子方式执行的操作。 在java.util.concurrent.atomic包中包含了一些原子变量类，用于实现在数值和对象引用上的原子状态转换。通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问操作都是原子的。 当在无状态的类中添加一个状态时，如果该状态完全由线程安全的对象来管理，那么这个类仍然是线程安全的 当状态变量的数量由一个变为多个时，并不会像状态变量数量由零个变为一个那样简单 在实际情况中，应尽可能地使用现有的线程安全对象（例如AtomicLong）来管理类的状态。与非线程安全的对象相比，判断线程安全对象的可能状态及其状态转换情况要更为容易，从而也更容易维护和验证线程安全性。 2.3 加锁机制 # 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。 2.3.1 内置锁 # Java提供了一种内置的锁机制来支持原子性：同步代码块（Synchronized Block）。 以关键字synchronized来修饰的方法就是一种横跨整个方法体的同步代码块，其中该同步代码块的锁就是方法调用所在的对象。静态的synchronized方法以Class对象作为锁。 每个Java对象都可以用做一个实现同步的锁，这些锁被称为内置锁（Intrinsic Lock）或监视器锁（Monitor Lock） 2.3.2 重入 # 当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞 由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。“重入”意味着获取锁的操作的粒度是“线程”，而不是“调用” 重入的一种实现方法是，为每个锁关联一个获取计数值和一个所有者线程。 当计数值为0时，这个锁就被认为是没有被任何线程持有。当线程请求一个未被持有的锁时，JVM将记下锁的持有者，并且将获取计数值置为1。如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为0时，这个锁将被释放。 2.4 用锁来保护状态 # 对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁，在这种情况下，我们称状态变量是由这个锁保护的。 之所以每个对象都有一个内置锁，只是为了免去显式地创建锁对象。 每个共享的和可变的变量都应该只由一个锁来保护，从而使维护人员知道是哪一个锁。 一种常见的加锁约定是，将所有的可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径进行同步，使得在该对象上不会发生并发访问。 并非所有数据都需要锁的保护，只有被多个线程同时访问的可变数据才需要通过锁来保护。 2.5 活跃性与性能 # 不良并发（Poor Concurrency）应用程序：可同时调用的数量，不仅受到可用处理资源的限制，还受到应用程序本身结构的限制。 当实现某个同步策略时，一定不要盲目地为了性能而牺牲简单性（这可能会破坏安全性）。 无论是执行计算密集的操作，还是在执行某个可能阻塞的操作，如果持有锁的时间过长，那么都会带来活跃性或性能问题。 当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。 第3章 对象的共享 # 同步还有另一个重要的方面：内存可见性（Memory Visibility）。我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态，而且希望确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 3.1 可见性 # 在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。 3.1.1 失效数据 # 3.1.2　非原子的64位操作 # 当线程在没有同步的情况下读取变量时，可能会得到一个失效值，但至少这个值是由之前某个线程设置的值，而不是一个随机值。这种安全性保证也被称为最低安全性（out-of-thin-air safety） 最低安全性适用于绝大多数变量，但是存在一个例外：非volatile类型的64位数值变量（double和long，请参见3.1.4节）。Java内存模型要求，变量的读取操作和写入操作都必须是原子操作，但对于非volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位￼。因此，即使不考虑失效数据问题，在多线程程序中使用共享且可变的long和double等类型的变量也是不安全的，除非用关键字volatile来声明它们，或者用锁保护起来。 3.1.3　加锁与可见性 # 加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。 3.1.4　Volatile变量 # Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。 在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制。 在当前大多数处理器架构上，读取volatile变量的开销只比读取非volatile变量的开销略高一些。 我们并不建议过度依赖volatile变量提供的可见性。如果在代码中依赖volatile变量来控制状态的可见性，通常比使用锁的代码更脆弱，也更难以理解。 仅当volatile变量能简化代码的实现以及对同步策略的验证时，才应该使用它们。 如果在验证正确性时需要对可见性进行复杂的判断，那么就不要使用volatile变量。 volatile的语义不足以确保递增操作（count++）的原子性，除非你能确保只有一个线程对变量执行写操作。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。 当且仅当满足以下所有条件时，才应该使用volatile变量 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁。 调试小提示：对于服务器应用程序，无论在开发阶段还是在测试阶段，当启动JVM时一定都要指定-server命令行选项。server模式的JVM将比client模式的JVM进行更多的优化，例如将循环中未被修改的变量提升到循环外部，因此在开发环境（client模式的JVM）中能正确运行的代码，可能会在部署环境（server模式的JVM）中运行失败。例如，如果在程序清单3-4中“忘记”把asleep变量声明为volatile类型，那么server模式的JVM会将asleep的判断条件提升到循环体外部（这将导致一个无限循环），但client模式的JVM不会这么做。在解决开发环境中出现无限循环问题时，解决这个问题的开销远小于解决在应用环境出现无限循环的开销。 3.2 发布与逸出 # “发布（Publish）”一个对象的意思是指，使对象能够在当前作用域之外的代码中使用。 将一个指向该对象的引用保存到其他代码可以访问的地方，或者在某一个非私有的方法中返回该引用，或者将引用传递到其他类的方法中。在许多情况中，我们要确保对象及其内部状态不被发布。而在某些情况下，我们又需要发布某个对象，但如果在发布时要确保线程安全性，则可能需要同步。发布内部状态可能会破坏封装性，并使得程序难以维持不变性条件。例如，如果在对象构造完成之前就发布该对象，就会破坏线程安全性。当某个不应该发布的对象被发布时，这种情况就被称为逸出（Escape）。 发布对象的最简单方法是将对象的引用保存到一个公有的静态变量中，以便任何类和线程都能看见该对象 一般来说，如果一个已经发布的对象能够通过非私有的变量引用和方法调用到达其他的对象，那么这些对象也都会被发布。 当某个对象逸出后，你必须假设有某个类或线程可能会误用该对象。这正是需要使用封装的最主要原因：封装能够使得对程序的正确性进行分析变得可能，并使得无意中破坏设计约束条件变得更难。 安全的对象构造过程 不要在构造过程中使this引用逸出 在构造过程中使this引用逸出的一个常见错误是，在构造函数中启动一个线程。当对象在其构造函数中创建一个线程时，无论是显式创建（通过将它传给构造函数）还是隐式创建（由于Thread或Runnable是该对象的一个内部类），this引用都会被新创建的线程共享。在对象尚未完全构造之前，新的线程就可以看见它。 在构造函数中创建线程并没有错误，但最好不要立即启动它，而是通过一个start或initialize方法来启动 在构造函数中调用一个可改写的实例方法时（既不是私有方法，也不是终结方法），同样会导致this引用在构造过程中逸出。 如果想在构造函数中注册一个事件监听器或启动线程，那么可以使用一个私有的构造函数和一个公共的工厂方法（Factory Method），从而避免不正确的构造过程 3.3 线程封闭 # Swing应用程序的许多并发错误都是由于错误地在另一个线程中使用了这些被封闭的对象。 线程封闭是在程序设计中的一个考虑因素，必须在程序中实现。 3.3.1 Ad-hoc线程封闭 # 在volatile变量上存在一种特殊的线程封闭。只要你能确保只有单个线程对共享的volatile变量执行写入操作，那么就可以安全地在这些共享的volatile变量上执行“读取-修改-写入”的操作。在这种情况下，相当于将修改操作封闭在单个线程中以防止发生竞态条件，并且volatile变量的可见性保证还确保了其他线程能看到最新的值。 由于Ad-hoc线程封闭技术的脆弱性，因此在程序中尽量少用它，在可能的情况下，应该使用更强的线程封闭技术（例如，栈封闭或ThreadLocal类）。 3.3.2 栈封闭 # 栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。 由于任何方法都无法获得对基本类型的引用，因此Java语言的这种语义就确保了基本类型的局部变量始终封闭在线程内。 3.3.3 ThreadLocal 类 # ThreadLocal对象通常用于防止对可变的单实例变量（Singleton）或全局变量进行共享。 假设你需要将一个单线程应用程序移植到多线程环境中，通过将共享的全局变量转换为ThreadLocal对象（如果全局变量的语义允许），可以维持线程安全性。 3.4 不变性 # 如果某个对象在被创建后其状态就不能被修改，那么这个对象就称为不可变对象。 不可变对象一定是线程安全的 虽然在Java语言规范和Java内存模型中都没有给出不可变性的正式定义，但不可变性并不等于将对象中所有的域都声明为final类型，即使对象中所有的域都是final类型的，这个对象也仍然是可变的，因为在final类型的域中可以保存对可变对象的引用。 当满足以下条件时，对象才是不可变的： 对象创建以后其状态就不能修改。 对象的所有域都是final类型。 对象是正确创建的（在对象的创建期间，this引用没有逸出）。 3.4.1 Final域 # 关键字final可以视为C++中const机制的一种受限版本，用于构造不可变性对象。final类型的域是不能修改的（但如果final域所引用的对象是可变的，那么这些被引用的对象是可以修改的）。 即使对象是可变的，通过将对象的某些域声明为final类型，仍然可以简化对状态的判断，因此限制对象的可变性也就相当于限制了该对象可能的状态集合。 正如“除非需要更高的可见性，否则应将所有的域都声明为私有域”[EJ Item 12]是一个良好的编程习惯，“除非需要某个域是可变的，否则应将其声明为final域”也是一个良好的编程习惯。 3.4.2 示例：使用volatile类型来发布不可变对象 # 通过使用包含多个状态变量的容器对象来维持不变性条件，并使用一个volatile类型的引用来确保可见性，使得Volatile Cached Factorizer在没有显式地使用锁的情况下仍然是线程安全的 3.5 安全发布 # 3.5.1 不正确的发布：正确的对象被破坏 # 你不能指望一个尚未被完全创建的对象拥有完整性。某个观察该对象的线程将看到对象处于不一致的状态，然后看到对象的状态突然发生变化，即使线程在对象发布后还没有修改过它。 3.5.2 不可变对象与初始化安全性 # 我们已经知道，即使某个对象的引用对其他线程是可见的，也并不意味着对象状态对于使用该对象的线程来说一定是可见的。为了确保对象状态能呈现出一致的视图，就必须使用同步。 任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。 在没有额外同步的情况下，也可以安全地访问final类型的域。然而，如果final类型的域所指向的是可变对象，那么在访问这些域所指向的对象的状态时仍然需要同步。 3.5.3 安全发布的常用模式 # 可变对象必须通过安全的方式来发布，这通常意味着在发布和使用该对象的线程时都必须使用同步。 要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见 在静态初始化函数中初始化一个对象引用。 将对象的引用保存到volatile类型的域或者AtomicReferance对象中。 将对象的引用保存到某个正确构造对象的final类型域中。 将对象的引用保存到一个由锁保护的域中。 在线程安全容器内部的同步意味着，在将对象放入到某个容器，例如Vector或synchronizedList时，将满足上述最后一条需求。如果线程A将对象X放入一个线程安全的容器，随后线程B读取这个对象，那么可以确保B看到A设置的X状态，即便在这段读/写X的应用程序代码中没有包含显式的同步。 线程安全库中的容器类提供了以下的安全发布保证 通过将一个键或者值放入Hashtable、synchronizedMap或者ConcurrentMap中，可以安全地将它发布给任何从这些容器中访问它的线程（无论是直接访问还是通过迭代器访问）。 通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、synchronizedList或synchronizedSet中，可以将该元素安全地发布到任何从这些容器中访问该元素的线程。 通过将某个元素放入BlockingQueue或者ConcurrentLinkedQueue中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。 要发布一个静态构造的对象，最简单和最安全的方式是使用静态的初始化器 public static Holder holder=new Holder（42） 静态初始化器由JVM在类的初始化阶段执行。由于在JVM内部存在着同步机制，因此通过这种方式初始化的任何对象都可以被安全地发布 3.5.4 事实不可变对象 # 如果对象在发布后不会被修改，那么对于其他在没有额外同步的情况下安全地访问这些对象的线程来说，安全发布是足够的。 如果对象从技术上来看是可变的，但其状态在发布后不会再改变，那么把这种对象称为“事实不可变对象（Effectively Immutable Object）” 通过使用事实不可变对象，不仅可以简化开发过程，而且还能由于减少了同步而提高性能。 例如，Date本身是可变的￼，但如果将它作为不可变对象来使用，那么在多个线程之间共享Date对象时，就可以省去对锁的使用 3.5.5 可变对象 # 如果对象在构造后可以修改，那么安全发布只能确保“发布当时”状态的可见性。对于可变对象，不仅在发布对象时需要使用同步，而且在每次对象访问时同样需要使用同步来确保后续修改操作的可见性。 在并发程序中使用和共享对象时，可以使用一些实用的策略，包括： 线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。 3.5.6 安全地共享对象 # 第4章 对象的组合 # 4.1 设计线程安全的类 # 4.2 实例封闭 # 4.3 线程安全性的委托 # 4.4 在现有的线程安全类中添加功能 # 4.5 将同步策略文档化 # 第5章 基础构建模块 # 5.1 同步容器类 # 5.2 并发容器 # 5.3 阻塞队列和生产者-消费者模式 # 5.4 阻塞方法与中断方法 # 5.5 同步工具类 # 5.6 构建高效且可伸缩的结果缓存 # 第6章 任务执行 # 6.1 在线程中执行任务 # 6.2 Executor框架 # 6.3 找出可利用的并行性 # 第7章 取消与关闭 # 7.1 任务取消 # 7.2 停止基于线程的服务 # 7.3 处理非正常的线程终止 # 7.4 JVM关闭 # 第8章 线程池的使用 # 8.1 在任务与执行策略之间的隐性耦合 # 8.2 设置线程池的大小 # 8.3 配置ThreadPoolExecutor # 8.4 扩展ThreadPoolExecutor # 8.5 递归算法的并行化 # 第9章 图形用户界面应用程序 # 9.1 为什么GUI是单线程的 # 9.2 短时间的GUI任务 # 9.3 长时间的GUI任务 # 9.4 共享数据模型 # 9.5 其他形式的单线程子系统 # 第10章 避免活跃性危险 # 10.1 死锁 # 10.2 死锁的避免与诊断 # 10.3 其他活跃性危险 # 第11章 性能与可伸缩性 # 11.1 对性能的思考 # 11.2 Amdahl定律 # 11.3 线程引入的开销 # 11.4 减少锁的竞争 # 11.5 示例：比较Map的性能 # 11.6 减少上下文切换的开销 # 第12章 并发程序的测试 # 12.1 正确性测试 # 12.2 性能测试 # 12.3 避免性能测试的陷阱 # 12.4 其他的测试方法 # 第13章 显式锁 # 13.1 Lock与ReentrantLock # 13.2 性能考虑因素 # 13.3 公平性 # 13.4 在synchronized和ReentrantLock之间进行选择 # 13.5 读-写锁 # 第14章 构建自定义的同步工具 # 14.1 状态依赖性的管理 # 14.2 使用条件队列 # 14.3 显式的Condition对象 # 14.4 Synchronizer剖析 # 14.5 AbstractQueuedSynchronizer # 14.6 java.util.concurrent同步器类中的AQS # 第15章 原子变量与非阻塞同步机制 # 15.1 锁的劣势 # 15.2 硬件对并发的支持 # 15.3 原子变量类 # 15.4 非阻塞算法 # 第16章 Java内存模型 # 16.1 什么是内存模型，为什么需要它 # 16.2 发布 # 16.3 初始化过程中的安全性 # "},{"id":84,"href":"/post/computer-science/ci-cd/jenkins/","title":"Jenkins","section":"CI/CD","content":" Jenkins # docs docker macOS macOS Installer for Jenkins LTS Install the latest LTS version: brew install jenkins-lts Start the Jenkins service: brew services start jenkins-lts Restart the Jenkins service: brew services restart jenkins-lts Update the Jenkins version: brew upgrade jenkins-lts Using Jenkins password # jenkins publish over SSH中SSH sever密码存放位置 记录 从jenkins配置文件中解密密码 reference # 在Jenkins中拉取GitHub上的代码包（超详细) jenkins配置全局凭据 结合gitlab jenkins部署github项目 "},{"id":85,"href":"/post/life/law/","title":"law","section":"Life","content":" 最高法举行《最高人民法院关于审理劳动争议案件适用法律问题的解释（二）》新闻发布会 01新劳动争议司法解释回应竞业等热点问题 "},{"id":86,"href":"/post/computer-science/ci-cd/maven/","title":"maven","section":"CI/CD","content":" plugin # 从Maven中的命令行参数跳过exec-Maven插件 reference # 利用码云gitee搭建个人maven仓库 "},{"id":87,"href":"/post/computer-science/ci-cd/nexus/","title":"Nexus","section":"CI/CD","content":" Nexus # docker sonatype/nexus3 install docker run -d -p 8081:8081 --name nexus sonatype/nexus3 "},{"id":88,"href":"/post/computer-science/python/","title":"Python","section":"Computer Science","content":" Python # yutto # "},{"id":89,"href":"/post/books/computer-science/python%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","title":"Python神经网络编程","section":"Computer Science","content":" 第1章 神经网络如何工作 # "},{"id":90,"href":"/post/computer-science/reddison/","title":"reddison","section":"Computer Science","content":" 什么情况下使用 redistemplate 什么时候使用 reddison # 在 Java 项目中，选择 RedisTemplate（Spring Data Redis）还是 Redisson 取决于具体需求场景。以下是两者的对比和适用场景分析：\n1. RedisTemplate（Spring Data Redis） # 定位：Spring 生态提供的轻量级 Redis 操作工具，封装了 Jedis/Lettuce。 适用场景：\n简单的 CRUD 操作：读写字符串、Hash、List 等基础数据结构。 与 Spring 生态深度集成：需要无缝配合 @Cacheable、Spring Session 等功能。 无需复杂分布式特性：例如仅需缓存数据、计数器等基础功能。 特点：\n支持 JSON、JDK 序列化等多种序列化方式。 提供简单的发布/订阅、事务支持。 不支持分布式锁、信号量等高级功能（需自行基于 SETNX 实现）。 示例场景：\n// 存储字符串 redisTemplate.opsForValue().set(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); // 存储Hash redisTemplate.opsForHash().put(\u0026#34;user:1\u0026#34;, \u0026#34;name\u0026#34;, \u0026#34;Alice\u0026#34;); 2. Redisson # 定位：分布式服务框架，提供丰富的分布式数据结构和高阶功能。 适用场景：\n需要分布式协调：如分布式锁（RLock）、信号量（RSemaphore）、延迟队列（RDelayedQueue）。 复杂分布式业务：跨 JVM 共享对象、分布式任务调度（如 RExecutorService）。 高性能分布式缓存：支持本地缓存联动（RLocalCachedMap）。 特点：\n提供 java.util.concurrent 风格的 API（如 RMap、RList）。 内置看门狗机制避免锁死，支持锁自动续期。 支持 Redis 集群、哨兵、云托管等多种部署模式。 示例场景：\n// 分布式锁 RLock lock = redisson.getLock(\u0026#34;orderLock\u0026#34;); lock.lock(10, TimeUnit.SECONDS); // 自动释放避免死锁 try { // 处理订单 } finally { lock.unlock(); } // 分布式Map RMap\u0026lt;String, Object\u0026gt; map = redisson.getMap(\u0026#34;userMap\u0026#34;); map.put(\u0026#34;user1\u0026#34;, new User()); 3. 对比总结 # 需求 RedisTemplate Redisson 简单数据读写（String/Hash） ✅ 更轻量 ✅ 但稍重 分布式锁/信号量 ❌ 需手动实现 ✅ 内置完善支持 与 Spring Cache 集成 ✅ 原生支持 ✅ 需额外配置 跨 JVM 共享复杂对象 ❌ 序列化受限 ✅ 透明化操作 延迟队列、BloomFilter ❌ 不支持 ✅ 直接提供 4. 如何选择？ # 选 RedisTemplate 如果：\n项目已深度集成 Spring，仅需基础 Redis 操作。\n不想引入额外依赖，保持轻量级。\n选 Redisson 如果：\n需要分布式锁、限流等高级功能。\n业务涉及跨服务共享对象或复杂协调逻辑。\n追求更直观的分布式数据结构（如 RList 替代手动序列化）。\n5. 混合使用 # 两者可以共存，例如：\n用 RedisTemplate 处理简单缓存。 用 Redisson 实现分布式锁和队列。 需注意避免序列化冲突（建议统一配置序列化方式）。 "},{"id":91,"href":"/post/books/computer-science/redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","title":"Redis设计与实现","section":"Computer Science","content":" 第2章 简单动态字符串 # 第3章 链表 # 第4章 字典 # 第5章 跳跃表 # 第6章 整数集合 # 第7章 压缩列表 # 第8章 对象 # Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象） 对象的类型 字符串对象 REDIS_STRING 列表对象 REDIS_LIST 哈希对象 REDIS_HASH 集合对象 REDIS_SET 有序集合对象 REDIS_ZSET 对于Redis数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种 当我们称呼一个数据库键为“字符串键”时，我们指的是“这个数据库键所对应的值为字符串对象” 当我们称呼一个键为“列表键”时，我们指的是“这个数据库键所对应的值为列表对象” TYPE命令的实现方式也与此类似，当我们对一个数据库键执行TYPE命令时，命令返回的结果为数据库键对应的值对象的类型，而不是键对象的类型 因为键的类型始终为字符串 "},{"id":92,"href":"/post/books/computer-science/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E4%B8%8E%E8%BF%9B%E9%98%B6/","title":"Spring Cloud微服务：入门、实战与进阶","section":"Computer Science","content":" 1.3 什么是Spring Cloud # Eureka 服务注册中心，用于服务管理 Ribbon 基于客户端的负载均衡组件 Hystrix 容错框架，能够防止服务的雪崩效应 Feign Web服务客户端，能够简化HTTP接口的调用 Zuul API网关，提供路由转发、请求过滤等功能 Config 分布式配置管理 Sleuth 服务跟踪 Stream 构建消息驱动的微服务应用程序的框架 Bus 消息代理的集群消息总线。 第3章　Eureka注册中心 # Spring Cloud Eureka是一个基于REST的服务，并且提供了基于Java的客户端组件，能够非常方便地将服务注册到Spring Cloud Eureka中进行统一管理。 服务治理是微服务架构中必不可少的一部分，阿里开源的Dubbo框架就是针对服务治理的。服务治理必须要有一个注册中心，除了用Eureka作为注册中心外，我们还可以使用Consul、Etcd、Zookeeper等来作为服务的注册中心。 用过Dubbo的读者应该清楚，Dubbo中也有几种注册中心，比如基于Zookeeper、基于Redis等，不过用得最多的还是Zookeeper方式。至于使用哪种方式都是可以的，注册中心无非就是管理所有服务的信息和状态。 程序也是一样，当你需要调用某一个服务的时候，你会先去Eureka中去拉取服务列表，查看你调用的服务在不在其中，在的话就拿到服务地址、端口等信息，然后调用。 为什么Eureka比Zookeeper更适合作为注册中心呢？ 主要是因为Eureka是基于AP原则构建的，而ZooKeeper是基于CP原则构建的。在分布式系统领域有个著名的CAP定理，即C为数据一致性；A为服务可用性；P为服务对网络分区故障的容错性。这三个特性在任何分布式系统中都不能同时满足，最多同时满足两个。 Zookeeper有一个Leader，而且在这个Leader无法使用的时候通过Paxos(ZAB)算法选举出一个新的Leader。这个Leader的任务就是保证写数据的时候只向这个Leader写入，Leader会同步信息到其他节点。通过这个操作就可以保证数据的一致性。 总而言之，想要保证AP就要用Eureka，想要保证CP就要用Zookeeper。Dubbo中大部分都是基于Zookeeper作为注册中心的。Spring Cloud中当然首选Eureka。 第4章　客户端负载均衡Ribbon # 目前主流的负载方案分为两种：一种是集中式负载均衡，在消费者和服务提供方中间使用独立的代理方式进行负载，有硬件的（比如F5），也有软件的（比如Nginx）。另一种则是客户端自己做负载均衡，根据自己的请求情况做负载，Ribbon就属于客户端自己做负载。 Ribbon作为一款客户端负载均衡框架，默认的负载策略是轮询，同时也提供了很多其他的策略，能够让用户根据自身的业务需求进行选择。 第6章　Hystrix服务容错处理 # 在微服务架构中存在多个可直接调用的服务，这些服务若在调用时出现故障会导致连锁效应，也就是可能会让整个系统变得不可用，这种情况我们称之为服务雪崩效应。 Hystrix是Netflix针对微服务分布式系统采用的熔断保护中间件，相当于电路中的保险丝。 "},{"id":93,"href":"/post/computer-science/java/spring/spring-transaction/","title":"spring transaction","section":"Spring","content":" @Transactional详解（作用、失效场景与解决方法）| 事务注解实际原理（AOP）解析 Spring Boot + MyBatis-Plus 使用事务 # MyBatis-Plus 是基于 MyBatis 的增强工具，在 Spring Boot 中使用事务的方式与原生 MyBatis 类似。以下是详细的使用方法：\n1. 添加必要依赖 # 首先确保你的项目中包含以下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;最新版本\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 配置事务管理器 # Spring Boot 会自动配置事务管理器，但如果你想自定义，可以在配置类中添加：\nimport org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jdbc.datasource.DataSourceTransactionManager; import javax.sql.DataSource; @Configuration public class MyBatisPlusConfig { @Bean public DataSourceTransactionManager transactionManager(DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } } 3. 使用事务 # 3.1 声明式事务（推荐） # 在 Service 层方法上添加 @Transactional 注解：\nimport org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; @Service public class UserServiceImpl implements UserService { @Autowired private UserMapper userMapper; @Autowired private OrderMapper orderMapper; @Override @Transactional // 默认遇到RuntimeException时回滚 public void createUserWithOrder(User user, Order order) { // 插入用户 userMapper.insert(user); // 设置订单用户ID order.setUserId(user.getId()); // 插入订单 orderMapper.insert(order); // 如果此处抛出异常，上面两个操作都会回滚 } @Override @Transactional(rollbackFor = Exception.class) // 遇到所有异常都回滚 public void updateUserWithOrder(User user, Order order) throws Exception { userMapper.updateById(user); orderMapper.updateById(order); // 即使抛出非RuntimeException也会回滚 } } 3.2 编程式事务 # 如果需要更精细的控制，可以使用编程式事务：\nimport org.springframework.stereotype.Service; import org.springframework.transaction.support.TransactionTemplate; @Service public class OrderService { @Autowired private TransactionTemplate transactionTemplate; @Autowired private OrderMapper orderMapper; public void processOrder(Order order) { transactionTemplate.execute(status -\u0026gt; { try { // 业务逻辑 orderMapper.insert(order); // 其他数据库操作... return Boolean.TRUE; } catch (Exception e) { status.setRollbackOnly(); // 标记回滚 return Boolean.FALSE; } }); } } 4. 事务传播行为 # 可以指定事务的传播行为：\n@Transactional(propagation = Propagation.REQUIRED) // 默认值，如果当前没有事务，就新建一个事务 public void methodA(){ // ... } @Transactional(propagation = Propagation.REQUIRES_NEW) // 总是新建事务 public void methodB(){ // ... } 5. 事务隔离级别 # 可以设置事务隔离级别：\n@Transactional(isolation = Isolation.READ_COMMITTED) // 读已提交 public void updateData(){ // ... } 注意事项 # @Transactional 注解应该加在 Service 层，而不是 DAO/Mapper 层 默认只对 RuntimeException 回滚，检查异常不会触发回滚 确保调用的方法来自外部类（Spring 代理机制要求） 私有方法上的 @Transactional 注解无效 同一个类中方法调用带有 @Transactional 的方法时，事务不会生效 常见问题解决 # 如果事务不生效，检查以下方面：\n是否使用了 @EnableTransactionManagement（Spring Boot 默认已启用） 方法是否为 public 是否在同一个类中调用了带 @Transactional 的方法 异常是否被捕获而未抛出 通过以上配置和使用方式，你可以在 Spring Boot + MyBatis-Plus 项目中有效地使用事务管理。\n@Transaction的底层原理是什么？ # spring的事务管理机制，结合AOP和动态代理技术实现事务的控制和管理 事务管理核心组件 事务管理器 事务拦截器 事务属性源 事务代理对象 实现流程 代理对象的创建 事务拦截器的应用 TransactionInterceptor 事务的开启与提交 事务的传播行为 @Transactional 事务传播机制 # 事务传播机制：当一个事务方法调用另一个事务方法时，事务应该如何传递或处理 REQUIRED 如果当前存在事务，则加入该事务；如果不存在事务，则创建一个新事务 SUPPORTS 如果当前存在事务，则加入该事务；如果不存在事务，则以非事务方式执行 场景：适用于查询操作，是否在事务中执行均可 MANDATORY 如果当前存在事务，则加入该事务；如果不存在事务，则抛出异常 场景：强制要求调用方必须在事务中调用该方法 REQUIRES_NEW 重新创建一个新的事务，如果当前存在事务，暂停当前的事务。(当类A中的 a 方法用默认Propagation.REQUIRED模式，类B中的 b方法加上采用 Propagation.REQUIRES_NEW模式，然后在 a 方法中调用 b方法操作数据库，然而 a方法抛出异常后，b方法并没有进行回滚，因为Propagation.REQUIRES_NEW会暂停 a方法的事务) NOT_SUPPORTED NEVER NESTED @Transactional注解可以作用于哪些地方？ # 作用于类：当把@Transactional 注解放在类上时，表示所有该类的public方法都配置相同的事务属性信息。 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。 作用于接口：不推荐这种使用方法，因为一旦标注在Interface上并且配置了Spring AOP 使用CGLib动态代理，将会导致@Transactional注解失效 @Transactional失效场景与解决办法 # @Transactional 应用在非 public 修饰的方法上 @Transactional 注解属性 propagation 设置错误 这种失效是由于配置错误，若是错误的配置以下三种 propagation，事务将不会发生回滚。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 @Transactional 注解属性 rollbackFor 设置错误 rollbackFor 可以指定能够触发事务回滚的异常类型。Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定 rollbackFor属性。 一般使用 @Transactional(rollbackFor = Exception.class) 就可以了，但可以根据业务自定义异常类 同一个类中方法调用，导致@Transactional失效 开发中避免不了会对同一个类里面的方法调用，比如有一个类Test，它的一个方法A，A再调用本类的方法B（不论方法B是用public还是private修饰），但方法A没有声明注解事务，而B方法有。则外部调用方法A之后，方法B的事务是不会起作用的。这也是经常犯错误的一个地方。 那为啥会出现这种情况？其实这还是由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。 ((TestController) AopContext.currentProxy()).transactionalTest(); 异常被你的 catch“吃了”导致@Transactional失效 AOP 可以说是生成一个代理类(其实可以理解对这个类中的某个方法外面再包装了一层)，可以在这个方法的头和尾添加代码，比如代理类使用一个try、catch把这个方法给套起来了，只有这个方法抛出异常之后，调用了代理类中catch的事务回滚代码才能回滚，所以你没抛出异常的话，@Transactional认为你是正常运行的代码所以不回滚 数据库引擎不支持事务 这种情况出现的概率并不高，事务能否生效数据库引擎是否支持事务是关键。常用的MySQL数据库默认使用支持事务的innodb引擎。一旦数据库引擎切换成不支持事务的myisam，那事务就从根本上失效了 "},{"id":94,"href":"/post/computer-science/java/spring/unit-test/","title":"unit test","section":"Spring","content":" document "},{"id":95,"href":"/post/computer-science/vim/","title":"vim","section":"Computer Science","content":" vim # nvim # neovim.io 直接用brew安装就行 brew install neovim 第一步肯定是要把插件管理工具安装一下 junegunn/vim-plug 直接运行文档中linux的安装命令 indent # How can I make (Neo)Vim wrap lines in respect to indentation? 这个可以解决缩进换行的问题，很棒！ clipboard 剪贴板 # 直接在配置文件中添加这两行，就可以了\nvnoremap y \u0026#34;+y set clipboard+=unnamedplus quickfix # VIM学习笔记 QuickFix LazyVim # lazyvim org 用 neovim 写 markdown 是一种什么样的体验(含技巧) markdown # theCW 不影响听课的高效率记笔记方法：Vim + Markdown - 教学与配置 iamcco/markdown-preview.nvim My neovim markdown setup in 2024 tadmccorkle/markdown.nvim cnshsliu/smp.nvim MeanderingProgrammer/render-markdown.nvim 这个插件可以直接在 neovim 中直接 render markdown 文件 但是安装只提供了 lua 的安装方式 outline.nvim # hedyhli/outline.nvim 这个插件太优秀了！ 解决 outline 左箭头和下箭头乱码的问题\nsymbol_folding = { autofold_depth = false, markers = { \u0026#39;\u0026gt;\u0026#39;, \u0026#39;∨\u0026#39; }, } Vim Markdown Folding?\n直接在配置文件中加上下面这段\nfunction! MarkdownLevel() if getline(v:lnum) =~ \u0026#39;^# .*$\u0026#39; return \u0026#34;\u0026gt;1\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^## .*$\u0026#39; return \u0026#34;\u0026gt;2\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^### .*$\u0026#39; return \u0026#34;\u0026gt;3\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^#### .*$\u0026#39; return \u0026#34;\u0026gt;4\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^##### .*$\u0026#39; return \u0026#34;\u0026gt;5\u0026#34; endif if getline(v:lnum) =~ \u0026#39;^###### .*$\u0026#39; return \u0026#34;\u0026gt;6\u0026#34; endif return \u0026#34;=\u0026#34; endfunction au BufEnter *.md setlocal foldexpr=MarkdownLevel() au BufEnter *.md setlocal foldmethod=expr 搜索插件 # fzf # note 只能搜索文件，不能进行全文搜索 安装fzf brew install fzf 安装 fzf 的vim的插件 junegunn/fzf.vim Reference FZF：终端下的文件查找器【猛男必备233333】 telescope # nvim-telescope/telescope.nvim 支持全文搜索需要额外安装这个插件 BurntSushi/ripgrep 搜索结果换行的配置，vimscript 版本\nlua \u0026lt;\u0026lt;EOF require(\u0026#34;telescope\u0026#34;).setup { defaults = { wrap_results = true, }, pickers = { oldfiles = { initial_mode = \u0026#34;normal\u0026#34; } } } EOF 美化 # Looking for airline replacement famiu/feline.nvim buffer # akinsho/bufferline.nvim 需要安装一个字体，不然图标显示不出来很丑 ryanoasis/nerd-fonts brew install font-hack-nerd-font ap/vim-buftabline 这个 repository 里面讲了一些和 buffer 有关的只是和维护者对 buffer 的一些思考 dropbar.nvim # cellular.automation # vimscript # VimScript 五分钟入门（翻译） lua # theCW 用Lua重新配置Neovim，我一周就干了个这。｜ Neovim Vlog[0] Lua实战：加强Neovim｜Neovim Vlog[1] theCW的lua 配置 从 VimScipt 切换至 Lua "},{"id":96,"href":"/post/computer-science/operating-system/windows/","title":"windows","section":"Operating System","content":" AutoHotkey # AutoHotkey powershell # fleschutz/PowerShell Mega Collection of PowerShell Scripts 一句话完成繁琐操作：你可以试试的 8 个 Windows 命令行工具 systeminfo 列出当前电脑的ip Get-CimInstance -Class Win32_NetworkAdapterConfiguration -Filter IPEnabled=$true | Select-Object -ExpandProperty IPAddress others # 一日一技 | 重启试试不是长久之计，两条命令帮你排查意外关机成因 在 Windows 上用 WSL 开发的操作体验指北 "},{"id":97,"href":"/post/books/computer-science/%E4%B8%80%E6%9C%AC%E4%B9%A6%E8%AE%B2%E9%80%8F-elasticsearch%E5%8E%9F%E7%90%86%E8%BF%9B%E9%98%B6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/","title":"一本书讲透 ElasticSearch：原理、进阶与工程实践","section":"Computer Science","content":" 第1章 Elastic Stack全景 # 首先，Elasticsearch支持各类应用、网站等的全文搜索，包括淘宝、京东等电商平台的搜索，360手机助手、豌豆荚等应用市场平台的搜索，以及腾讯文档、石墨文档等平台的全文检索服务。 许多知名企业，如58集团、唯品会、日志易、国投瑞银等，都使用Elasticsearch来快速分析和处理大量的日志数据，从而对业务运行状况进行实时的监控和故障排查。 许多知名企业的商业智能系统，如睿思BI、百度数据可视化Sugar BI、永洪BI等，都借助Elasticsearch的高效、实时的数据分析和可视化能力，帮助企业更好地理解市场趋势、优化决策过程。 ClickHouse ClickHouse是一款由俄罗斯搜索引擎Yandex开发并开源的列式存储数据库，专为**OLAP（在线分析处理）**场景设计。ClickHouse具有高速查询分析的能力，支持实时添加数据和修改结构，并且能够实现高度数据压缩比，从而有效节省存储空间。此外，ClickHouse支持SQL查询，易于使用和集成。 第2章 Elasticsearch基础知识 # 倒排索引 一本C语言图书末页的索引结构。这种结构揭示了核心关键词与页码之间的对应关系。这种关系模式可以视为倒排索引的实际例证。在此结构中，我们可以根据关键词快速找到包含这个关键词的内容的页码。这与倒排索引在接收关键词输入后能够迅速定位包含该关键词的文档的性质是一致的。借由这种类比，我们可以更为直观地理解倒排索引在数据查询中的关键作用。 数据索引化 数据索引化指的是数据在写入搜索引擎（本书中主要指Elasticsearch）的过程中，扫描文档中的每一个词项，结合分词器和词典对必要的词项建立倒排索引，同时指明该词项在文章中出现的次数和位置。 全文检索的前提是待检索的数据已经索引化，当用户查询时能根据建立的倒排索引进行查找。 全文检索的特点如下 只处理文本，不处理语义。 结果列表有相关度排序。 支持高亮显示结果数据。 原始的文本被切分为单个单词、短语或特殊标记后进行存储。 给定词与它的变体（如近义词）会被折叠为一个词，如electrification和ectric、mice和mouse、“土豆”和“马铃薯”、“西红柿”和“番茄”等，每组词均被视为同一个词。 2.2 Elasticsearch的核心概念 # 集群 Elasticsearch集群常用于处理大规模数据集，目的是实现容错和高可用。Elasticsearch集群需要一个唯一标识的集群名称来防止不必要的节点加入。集群大小从单个节点到数千个节点不等，具体大小取决于实际业务场景。 节点 节点是指一个Elasticsearch实例，更确切地说，它是一个Elasticsearch进程。节点可以部署到物理机或者虚拟机上。每当Elasticsearch启动时，节点就会开始运行。每个节点都有唯一标识的名称，在部署多节点集群环境的时候我们要注意不要写错节点名称。 索引 索引可以看作数据库中的一个表，它包含了一组具有相似结构的文档 在Elasticsearch中，数据以JSON格式的文档存储在索引内。 每个索引具有唯一的名称，以便在执行搜索、更新和删除操作时进行引用。 索引的名称可以由用户自定义，但必须全部小写。 分片 在了解分片是什么之前，让我们谈谈为什么需要分片。假设你有一个包含超大规模文档的索引，有总计1TB的数据。当前集群中有两个节点，每个节点有512GB的空间可用于存储数据。显然，整个索引无法存储在任何一个节点上，因此有必要以某种方式拆分索引的数据，否则会导致数据存储不完整。在这种情况下，索引的大小超过了单个节点的硬件限制，分片就派上用场了。分片通过将索引分成更小的部分来解决这个问题。 当处理涉及多个数据分片的查询时，Elasticsearch会将查询请求分发到各个相关的分片，并将它们的结果集进行聚合。 副本 分片可以被复制，被复制的分片称为“主分片”，如图2-3中的主分片1～4；主分片的复制版本称为“副本分片”或简称为“副本”，如图2-3中的副本1～4 创建索引时需要指定主分片，且主分片数一经指定就不支持动态更新了。而副本同样需要在创建索引时指定，每个分片可以有0或多个副本，副本数支持动态更新。 当某主分片所在的数据节点不可用时，会导致主分片丢失现象，若短时间内不对此采取补救措施，集群会将该分片对应的副本提升为新的主分片。 文档 关系型数据库将数据以行或元组为单位存储在数据库表中，而Elasticsearch将数据以文档为单位存储在索引中。 作为Elasticsearch的基本存储单元，文档是指存储在Elasticsearch索引中的JSON对象。文档中的数据由键值对构成。键是字段的名称，值是不同数据类型的字段。不同的数据类型包含但不限于字符串类型、数字类型、布尔类型、对象类型等。 字段 字段是Elasticsearch中最小的单个数据单元，类似于关系型数据库表中的字段。一般实战项目前期的设计环节都是根据业务需求拆分、定义字段，并且敲定字段类型。在上面航空类索引的示例中，“FlightNum”是字段，其含义为“航班号”，字段类型为keyword。 与关系型数据库不同的是，Elasticsearch的一个字段可以设定两种或两种以上的数据类型，通过定义multi-field来灵活地满足复杂的业务需求。 映射 不少初学者对映射(Mapping)这个概念会感觉不好理解。映射类似于关系型数据库中的Schema，可以近似地理解为**“表结构”**。 我们拿到一个业务需求后，往往会将业务细分会几个索引。每个索引都需要一个相对固定的表结构，包含但不限于字段名称、字段类型、是否需要分词、是否需要索引、是否需要存储、是否需要多字段类型等。这些都是设计映射时要考虑的问题。 分词 在英文文本中，空格就是切分语句或短语的“屏障”。但中文文本中则没有了这道“屏障”，于是分词就变得就不那么简单，需要由专门的分词算法构建的分词器来实现。 第3章 Elasticsearch集群部署 # 什么是堆内存\nJava中的堆是JVM所管理的最大的一块内存空间，主要用于存放各种类的实例对象。在Java中，堆被划分成两个不同的区域：新生代(Young)和老年代(Old)。新生代又被划分为3个区域：Eden、From Survivor、To Survivor。 这样划分的目的是使JVM更好地管理堆内存中的对象，包括内存的分配以及回收。 堆内存的作用是什么\n堆内存的唯一目的就是创建对象实例，所有的对象实例和数组都要在堆上分配。 堆内存如何配置\n默认情况下，Elasticsearch JVM使用的堆内存最小和最大值均为4 GB（8.X版本以上） 在转移到生产环境时，配置足够容量的堆大小以确保Elasticsearch功能和性能是必要的。 Elasticsearch将通过对Xms（最小堆大小）和Xmx（最大堆大小）的设置来分配jvm.options中指定的整个堆。 堆内存的值取决于服务器上可用的内存大小。Elasticsearch堆内存设置对其性能表现来说十分关键。建议将堆大小配置为服务器可用内存的50%，上限为32GB，且预留足够的内存给操作系统以提升缓存效率。合理调整堆内存大小可减轻垃圾回收工作的压力，优化查询速度和索引效率。请务必进行监控并根据实际需求来调整堆内存大小。 为什么堆内存不能超过物理机内存的一半\n堆对Elasticsearch来说绝对重要，它用于许多内存数据结构的快速操作。但还有另外一个非常重要的内存使用者——Lucene。 Lucene旨在利用底层操作系统来缓存内存中的数据结构。Lucene段存储在单个文件中。因为段一旦形成就不会改变，所以它们非常容易进行缓存，并且，底层操作系统会将热段保留在内存中以便更快地进行访问。这些段包括倒排索引（用于全文搜索）和正排索引（用于聚合）。 Lucene的性能依赖于与操作系统的这种交互。如果把所有可用的内存都给Elasticsearch堆，那么Lucene就不会有任何剩余的内存，这会严重影响其性能。针对内存的分配，通常的建议是将可用内存的一半分配给Elasticsearch堆，而保留剩下的一半。这种操作的核心在于平衡Elasticsearch堆和Lucene。剩余的内存看起来空闲，但其实并非如此，因为Lucene会利用这些“空闲”内存来提高搜索和索引的性能。这种内存分配策略确保了Elasticsearch与Lucene之间的高效协作，进而能够提升整体系统性能。 如果实际业务不需要在字符串字段上做聚合操作（开启text类型的fielddata），则可以考虑进一步降低堆大小。堆较小，就可以从Elasticsearch（更快的GC）和Lucene（更多内存缓存）中获得更好的性能。 Elasticsearch集群节点角色划分\n节点类型 主节点：负责集群管理和元数据维护，确保集群正常运行。 数据节点：负责存储、检索和处理数据，提供搜索和聚合功能。 协调节点：处理客户端请求，协调数据节点工作，优化分布式搜索。 ingest节点：即预处理节点，负责数据预处理，如过滤、转换等，准备好数据再将其索引到数据节点。 在Elasticsearch 8.X版本中，节点类型升级为节点角色。节点角色分得很细，包括数据节点角色、主节点角色、ingest节点角色、热节点角色等。 在Elasticsearch集群中，每个启动的Elasticsearch进程都可以叫作一个节点。以Elasticsearch 8.X版本集群为例，如果我们不手动设置节点角色，则默认节点角色为cdfhilmrstw 主节点 专用候选主节点(dedicated master-eligible node) 仅投票主节点(voting-only master-eligible node) 关于集群主节点配置，要强调一点：高可用性集群需要至少3个符合主节点资格的节点，其中至少两个不是仅投票节点。这样即使其中一个节点发生故障，该集群也能够选举出一个主节点。 数据节点 内容数据节点 热数据节点 热数据节点的用途主要是保存最近、最常访问的热数据，即经常被访问和更新的数据 温数据节点 冷数据节点 冷冻数据节点 ingest节点 这类节点通常执行由预处理管道组成的预处理任务 仅协调节点 这类节点的作用类似于智能负载均衡器，负责路由分发请求、聚拢（或叫作收集，可理解为分发的反过程）搜索或聚合结果 远程节点 这类节点用于跨集群检索或跨集群复制 机器学习节点 机器学习节点是一类特殊类型的节点，它专门用于运行机器学习功能。它们负责运行数据分析任务，如异常检测、预测和回归等。这类节点的功能是收费的，Elasticsearch开源版本并不提供。 转换节点 转换节点是一个特殊类型的节点，负责执行数据转换任务。数据转换是指将数据从一种格式或结构转换为另一种格式或结构的过程。在Elasticsearch中，这通常涉及对原始数据创建新的索引，并对新索引中的数据进行汇总、分组或其他转换操作，以便更有效地进行分析和查询。 Nginx+Elasticsearch Coordinate+Elasticsearch Master+Elasticsearch Node应该如何安装配置呢？可以只安装一个节点，然后拷贝并更改其他节点角色吗？\n先划分节点角色。节点不多的话可以一个个手动部署（部署好一个以后，可以在其他部署中进行拷贝，再修改角色、IP等）；节点非常多的话可以借助Ansible等脚本工具快速部署。 在Elasticsearch部署上，节点角色分为m、d、i等多种，它们在部署上各有什么优势？更推荐哪种？\nm代表主节点master，d代表数据节点data，i代表数据预处理节点ingest。不同节点角色有不同的应用场景，建议根据集群规模进行综合考虑。 请问在写入海量数据时，应该连接什么角色的节点，是专用协调节点还是数据节点？\n这要看节点规模和节点角色划分。如果已经有了独立协调节点，则连接独立协调节点。如果没有，则连接硬件配置较高的节点。 在进行节点角色的配置时，data_hot、data_warm、data_cold等角色和早期版本中自定义的attr属性有区别吗？\n新版本具有新特性，所以有区别。新的方式配置更为简洁，并且可读性强、用户体验优。 Elasticsearch的角色data、data_content、data_hot、data_warm、data_cold之间有什么区别？\n这涉及冷热集群架构的数据节点的分层处理机制。对于早期版本冷热集群架构中手动配置节点属性的部分，Elasticsearch 8.X版本做了精细切分，使得数据的冷热集群管理更为高效。尤其在默认迁移自动实现机制之后，早期版本的分片分配策略手动配置（如下方代码所示）变得不再必要。 Elasticsearch 8.X的data_content角色是什么？它和协调节点有什么区别？\n它们是两种完全不同的节点。data_content属于数据节点，是永久存储数据的地方。而协调节点是用来请求路由分发、结果汇聚处理的。 Elasticsearch集群核心配置解读\n开发模式和生产模式 默认情况下，Elasticsearch工作在开发模式(development mode)下。在该模式下，如果配置错误，则警告信息会写入日志文件，但节点依然是能启动的。而在生产模式(production mode)下，一旦出现配置错误，节点就无法正常启动了。这本质上是一种保护机制。 开发模式和生产模式的界限在于：当修改network.host的默认值之后，默认的开发模式会升级为生产模式。通俗地讲，如果开发者个人搭建集群，则推荐使用开发模式；如果企业级开发环境，务必使用生产模式。 Linux前置配置 修改文件描述符数目 首先，Elasticsearch在节点和HTTP客户端之间进行通信使用了大量的套接字，而套接字需要足够的文件描述符支持。 其次，在许多Linux发行版本中，每个进程默认有1024个文件描述符，这对Elasticsearch节点来说实在是太低了，何况该节点要处理数以百计的索引，所以要调大这个默认值。 修改最大映射数量 Elasticsearch对各种文件混合使用了niofs（非阻塞文件系统）和mmapfs（内存映射文件系统），以实现对各种文件的优化处理。为了保证系统的顺畅运行，需要合理配置最大映射数量(MMP)，以便有足够的虚拟内存可用于内存映射的文件。 path.data配置注意事项：\n不要修改data路径下的任何文件，手动修改会有数据损坏或丢失的风险。 不要尝试对数据目录进行备份，因为Elasticsearch不支持文件备份后的恢复操作。 使用快照snapshot命令对集群进行备份，使用restore命令进行恢复。 不要对数据路径进行病毒扫描，病毒扫描可能会阻止Elasticsearch工作，甚至修改数据目录内容。 在Elasticsearch系统中，为了保证数据安全，不同节点间的通信和数据传输通常采用HTTPS的加密协议。这样的设计能有效防止数据在传输过程中被窃取或篡改。同样，Elasticsearch与Kibana之间的互动也使用了HTTPS，以确保数据在交互过程中的安全性。\n第4章 Elasticsearch索引 # 4.1 索引的定义 # 索引是具有相同结构的文档的集合，由唯一索引名称标定。\n实战场景1：将采集的不同业务类型的数据存储到不同的索引。\n微博业务对应的索引weibo_index 新闻业务对应的索引news_index 博客业务对应的索引blog_index 以上3个索引包含的字段个数、字段名称、字段类型可能不完全一致。 实战场景2：按日期切分存储日志索引\n2025年1月的日志对应logs_202501 2025年3月的日志对应logs_202503 索引设置\n静态设置(static index settings)，只允许在创建索引时或者针对已关闭的索引进行设置。 设置主分片大小的参数是index.number_of_shards，只在创建索引时生效，不支持动态修改。默认主分片大小为1，且每个索引的分片数量上限默认为1024。此限制是一个安全限制，可防止索引分片数过多导致集群不稳定。 动态设置(dynamic index settings)，可以借助更新设置(update settings)的方式进行动态更新，更新后立即生效。 设置副本数参数为index.number_of_replicas，可以动态修改。 设置刷新频率参数为index.refresh_interval，可以动态修改。默认刷新频率参数值为1s，即每秒刷新一次。这1s决定了Elasticsearch是近实时的搜索引擎，而非准实时搜索引擎。如果业务层面对实时性的要求不高，可以考虑将该值调大。因为如果采用1s，则每秒都会生成一个新的分段，会影响写入性能。 max_result_window是Elasticsearch中的一个设置参数，用于控制搜索结果的最大窗口的大小。默认情况下，max_result_window的值为10000。这意味着在分页搜索时最多可以返回10000条数据。如果每页可显示10条数据，那么最多可以翻到1000页。 增大max_result_window的值可能会对Elasticsearch集群的性能产生影响，尤其是在处理大量数据时。因此，在根据实际需求调整此参数时，要权衡性能和查询范围之间的关系。如果需要遍历大量数据，则建议使用scroll API或search_after参数，以更高效地进行处理。 4.3 索引别名 # 场景1：面对PB级别的增量数据，对外提供服务的是基于日期切分的n个不同索引，每次检索都要指定数十个甚至数百个索引，非常麻烦。 场景2：线上提供服务的某个索引设计不合理，比如某字段分词定义不准确，那么如何保证对外提供服务不停止，也就是在不更改业务代码的前提下更换索引？ "},{"id":98,"href":"/post/books/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E7%AC%AC%E4%B8%89%E7%89%88/","title":"宏观经济学 第三版","section":"Books","content":" 宏观经济学 第三版 # 第1章 经济学原理的实践 # 第2章 经济科学：运用数据和模型理解世界 # 第3章 优化：竭力做到最好 # 第4章 需求，供给与均衡 # 第5章 国家财富：定义和测算宏观经济总量 # 第6章 总收入 # 第7章 经济增长 # 第8章 为什么很多地区仍然不发达？ # 第9章 就业与失业 # 第10章 信贷市场 # 信贷：我们把包括企业家、购房者和学生在内的借款主体称为债务人，他们所借入的资金被称为信贷\n借款当然不是免费的，借款人需要支付利息。借款的初始金额被称为本金。利率是借款者在偿还本金之外，需要（在满一年时）为每1美元贷款支付的额外费用。也可以说，利率就是一笔1美元贷款的年度成本。\n如果你借了1年期利率为i的L美元，1年后你要偿还本金L美元加上i×L美元的利息。为了和实际利率区分开来，我们把利率i称为名义利率。\n实际利率=名义利率-通货膨胀率\n实际GDP=名义GDP-通货膨胀率 几乎所有的贷款都是以名义利率发放的 我现在理解了韩秀云说的贷款买房比全款买房更好，因为实际利率会随着通货膨胀越来越低，甚至可能低于越来的本金 通货膨胀率指的是整体经济中物价上涨的速度。\n其他条件不变时，通货膨胀率越高，企业销售的商品和服务价格就会越高，在给定的名义利率下偿还贷款就会越容易。 信贷需求曲线：信贷需求量与实际利率之间的关系\n政府所感知到的商业机会变化、家庭偏好或预期的变化、政府政策的变化，会使得信贷需求曲线左移或右移 实际利率：人们因存钱而得到的回报，因为今天存的1美元，在一年后的购买力是1+r美元，其中r是实际利率\n换句话说，实际利率是当前消费的机会成本，也就是你基于未来的购买力而放弃的东西。因此，较高的实际利率会增加当前消费的机会成本，鼓励更高水平的储蓄。 真实市场中，为了补偿出借人，具有不同违约风险的借款者需面对不同的实际利率。 信贷供给曲线：信贷供给量与实际利率之间的关系\n信贷供给曲线的移动则源于实际利率不变的情况下，追求优化的经济主体储蓄动机的变化（家庭储蓄动机的变化、企业储蓄动机的变化） 人们为什么要储蓄？\n为退休储蓄 为孩子存钱 为一些可预见的大额支出而存钱 投资个人事业而存钱 以备不时之需 信贷市场：借款者从储蓄者那里获取资金的市场，有时也被称为可贷资金市场\n信贷市场均衡：信贷供给曲线与信贷需求曲线的交点所对应的实际利率和信贷量 交点决定了市场中的信贷总量(Q*)和均衡实际利率(r*)。在均衡实际利率下，信贷需求量等于信贷供给量。实际利率高于均衡水平将导致超额的信贷供给，这通常会给实际利率带来下行压力。实际利率低于均衡水平将导致超额的信贷需求，给实际利率带来上行压力。 信贷市场的作用：通过使储蓄者把多余的钱出借给借款者，信贷市场改善了经济中的资源配置\n金融资本：金融资本存在多种不同的形式，包括信贷（也被称为债务）和股权。\n当一个储蓄者将其存款变成信贷时，他就把自己的储蓄借给了另一个人，换来的是连本带息偿还贷款的承诺。 当一个储蓄者把自己的存款变成股权时，他就利用其储蓄变成了一家公司的股东，这意味着他获得了公司的所有权和对公司未来利润的索取权。这些利润会以股息的形式支付给公司股东。 独角兽：越来越多科技初创公司的市值超过10亿美元。在向公众发行股票之前估值超过这一门槛的公司被称为独角兽。\n第11章 货币体系 # 第12章 短期波动 # 第13章 逆周期宏观经济政策 # 第14章 宏观经济学和国际贸易 # 第15章 开放经济的宏观经济学 # "},{"id":99,"href":"/post/blog/2025/2025-03-29-%E6%95%99%E8%82%B2%E5%88%B0%E5%BA%95%E6%80%8E%E4%B9%88%E4%BA%86/","title":"教育到底怎么了 2025-03-29","section":"Posts","content":" 教育到底怎么了 2025-03-29 # 我们的价值在哪里？\n刚刚走过来图书馆的时候，听了一个新的播客（无界有声）「毕业即失业，教育到底怎么了」。听完之后感触还是很深的，尤其是在现在工作不好找的情况下，真的是很有体会。\n首先是播客里面提到的一个老生常谈的话题，我们接受的教育学到的东西在我们进入职场时有用吗？或者说社会需要什么你知道吗？我一直都觉得理论知识是很重要的，这决定了你能实践的深度和广度，对我而言我接受的教育并不是完全没有用的。但是第二个问题，我确实没有思考过。即使是上一家公司在降本增效的时候，同事调侃说领导要让我们思考「我们的价值在哪里？」「我们能为公司带来什么价值？」的时候我觉得这只是在PUA。现在我觉得这个问题是很有意义的，如果我们是一个普通人，我们需要在这个社会上生存，我们就需要去思考这个问题，尤其是在现在竞争这么激烈的情况下。如果你所在的行业真的就已经卷到不能再待下去了，更需要思考这个问题。你需要调整你自己，去学习新的技能，以市场为指导。\n现在学历是真的越来越不值钱了，你要培养你自己全方面的能力，而不是去内卷。上一份工作关系好的同事X一直推荐我买一个咖啡机，我平时每天都喝咖啡自己买一个咖啡机既省钱，又有做咖啡的乐趣多好；还有我渐渐地不怎么骑车了。工作都把我蹂躏成什么样子了，我没有思考的时间，对其他事情也渐渐地没有了兴趣，对我的爱好（骑行、乒乓球）也越来越不上心了。最主要的，我作为一个程序员，在高强度的工作压力下也没有很多的积累，也造成了我这次找工作焦虑的主要原因（我想如果我入职的岗位是纯粹做技术的，我这次应该就没有那么焦虑了吧）\n我不应该抱着学习地心态来面对社会和职场，我要想我有什么价值。读到这句话我想到最直接的就是我学习计算机，我想着要有一个环境我才能去了解掌握到高并发的知识，才能学习到AI相关的知识。不，我要努力为自己创造这样的条件，培养这些能力，让培养出来的这些能力成为我的通行劵。应该要放弃学习心态来面对社会和职场。\n不要通过学校和分数来评判你的成功和失败，你要具体分析你每一次的表现，在你能承受的范围内，再进步一点。就像这次找工作面试一样，不要去那么在意是通过了还是没有通过，去总结每次面试你的收获是什么，你有什么可以改进的地方，这样的心态才是好的。好的心态真的很重要。\n"},{"id":100,"href":"/post/computer-science/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"系统设计","section":"Computer Science","content":" 系统设计 # 数据持久化 # 冷热分离 # 冷热分离之 OTS 表格存储实战 数据架构：数据冷热分离实践思考 数据架构：概念与冷热分离 查询分离 # 分表分库 # 服务发现 # 事务处理 # 本地事务 # 全局事务 # 共享事务 # 分布式事务 # 缓存 # 客户端缓存 # 系统是否真的需要缓存？ # 软件开发中引入缓存的负面作用要明显大于硬件缓存带来的负面作用 从开发角度来说 你要考虑缓存的失效、更新、一致性等问题（硬件缓存也有这些问题，只是不需要由你去考虑，主流的ISA也都没有提供任何直接操作缓存的指令） 从运维角度来说 缓存会掩盖一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上 从安全角度来说 缓存可能会泄漏某些保密数据，也是容易受到攻击的薄弱点 引入缓存的理由 为缓解CPU压力而引入缓存 譬如把方法运行结果存储起来、把原本要实时计算的内容提前算好、对一些公用的数据进行复用，这可以节省CPU算力，顺带提升响应性能 为缓解I/O压力而引入缓存 譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问， 将原本对单点部件（如数据库）的读写访问变为对可扩缩部件（如缓存中间件）的访问，顺带提升响应性能 服务端缓存 # 读缓存 # 写缓存 # 负载均衡 # 流量治理 # 服务容错 # 流量控制 # 可观测性 # 时间日志 # 链路追踪 # 聚合度量 # 架构安全性 # 认证 # 授权 # 凭证 # 保密 # 传输 # 分布式共识 # Reference # 凤凰架构 构建可靠的大型分布式系统 搞定系统设计 面试敲开大厂的门 "},{"id":101,"href":"/post/blog/2025/2025-03-16-%E8%83%BD%E6%89%BE%E5%88%B0%E5%B7%A5%E4%BD%9C%E5%90%97/","title":"能找到工作吗 2025-03-16","section":"Posts","content":" 能找到工作吗？ 2025-03-16 # 从星期一开始找工作已经第七天，今天还是怎么也不想起来，很累，心里很焦虑。这几天旺财总是抱怨我，出门前怎么呆呆地站在那里，也不把阳台的自行车推出来一下，这几天发愣的次数越来越多。今早也是这样，回过神来早上咖啡还没去做。出门前旺财问我今天天气还不错，要不骑车去图书馆吧，我说要不走路过去吧，节奏慢一点。心里不想那么快就到了图书馆开始学习准备面试找工作的事情，慢慢走过去心情会好一些。\n在离职上一家公司时，我没有做任何的犹豫只想要离开，这份工作越到后面越和我想象的不一样，我想要去寻找新机会，我充满了信心，我能力不算出众但也不算太差。我觉得不会太困难。在正式找工作之前，我没有怎么去思考和关注就业市场，gap休息了一个多月之后，我就开始中等强度的学习，学习算法，编程相关的知识。来到广州安顿下来之后，我和旺财就开始泡了两个星期的图书馆一直到上个周日。\n到现在为止已经在Boss直聘上找了很多岗位，大部分都是不回复的，有几家回复了我觉得不合适，现在只有1家约了面试在周二的时候（第一面已经通过了，下周二晚上是第二面）。昨天早上旺财说要再改一改自己的简历，我现在的行动也渐渐失去了方向，就和旺财说那我也看看改一下。我找大学同学Z要了他的简历，旺财帮我要了她朋友的简历。下午和晚上在图书馆就又包装了一下项目部分的内容。图书馆闭馆之前感觉自己又有希望了。\n从行动开始找工作到现在其实就过了6天，但我真的没有想到这对我的心理有那么大的影响，我会那么地担忧这件事情，我会对这种不确定的时期感觉到如此的焦虑。但我仔细想来这是我第一次经历这样的事情。高考的成绩再不理想，我的下一个阶段也是开始大学生活；大学的生活马马虎虎，但最后找工作的时候也是在好几份工作中挑一个（21年的就业环境真好。。哭了）。但这次不一样了，首先我遭遇到的是很低的招聘回复率；其次就是程序开发这个行业情况越来越不好, 竞争压力越来越大，还有越来越多的人挤进来。我在担心我现在的处境，也在担心我未来的处境。\n这一次我真正感觉到我只是一个普通人，之前三年多相对稳定的工作并不代表什么，这段工作结束之后，我也是一个被“我应该挺不错的，为什么没有公司联系我面试”，“我的工作经历有什么问题吗？为什么招聘的人觉得我不合适？”，“是我的项目太简单了吗？是我不会包装我的简历吗？”，“是我能力不行吗？”这些问题不断困扰的人。我一边必须在网上获取信息，一边又不得不看到哪些让人焦虑的网上讨论，再加上我现在的经历，真的感觉喘不过气来。\n这才找工作过了7天？是呀，才过了7天。我想我该停一下了，花一点时间写一段文字让自己平静一下，想一想我该怎么调整我的心态。\n首先，计算机这条路我和旺财都没有走死，即使找不到好的公司，也能去干外包的开发。在现在的就业环境下，这也是没有办法的；现在看来计算机干到35岁，你还怕什么影响职业规划。 "},{"id":102,"href":"/post/books/%E8%8B%B1%E4%BC%9F%E8%BE%BE-%E9%BB%84%E4%BB%81%E5%8B%8B%E4%B9%8B%E8%8A%AF/","title":"英伟达-黄仁勋之芯","section":"Books","content":" 黄仁勋-英伟达之芯 # 第1章 求学生涯 # 第2章 职涯早期 # 第3章 从餐厅起步的Nvidia # 第4章 英伟达遭遇绝境 # 第5章 咸鱼翻身 # 第6章 新机器时代曙光初现 # 第7章 死亡竞赛 # 第8章 游戏玩家拯救英伟达 # 第9章 光速之道 # 第10章 同频共振 # 第11章 范式转变的时刻 # 第12章 千载难逢的机会 # 第13章 由机器引领的时代 # 克里泽夫斯基：辛顿在多伦多大学时的学生 因为无法解释神经网络的计算过程，学术界不认可这种方法 辛顿给苏茨克弗和克里泽夫斯基布置了一项艰巨的任务：利用英伟达的GPU训练计算机学会图像识别 卡坦扎罗 2011年加入英伟达 cuDNN cuda deep neural network 矩阵乘法 优秀的神经网络软件应该注重速度而不是精度 马克思与黄仁勋的分歧 马斯克认为，先进的人工智能可能带来灭绝级威胁。这一观点得到了包括辛顿和苏茨克弗在内的大批技术专家的认同，他们还是最初那篇关于AlexNet的论文的合著者。然而黄仁勋完全不这么认为。他竟觉得人工智能毫无风险，真是令我吃惊。 第14章 AI行业的佼佼者 # 2016年，英伟达的股价飙升了224%，这让黄仁勋重获荣光，再度跻身亿万富翁行列。不过，在当年的标准普尔500指数中，表现最抢眼的股票并非英伟达，而是其长期竞争对手AMD，其股价涨幅高达309%。黄仁勋并不甘心位居次席。 Omniverse 第15章 AI工厂 # 乌斯科雷特把这套学习机制命名为“自注意力” 第16章 全球最具价值的半导体企业 # 在2018年的GTC大会上，黄仁勋指出，在短短5年内，英伟达的GPU处理速度提升了25倍，这一成绩远超摩尔定律的预测。接着，他展示了一张图，这张图显示在2012年的显卡上需要一周的时间才能训练出AlexNet，而在他推出的新款计算机DGX-2上则仅需18分钟就能完成训练。 2020年7月，英伟达的市值终于超越了英特尔。没过多久，英伟达的市值又超越了AMD。 第17章 这个时代最重要的科技公司 # 第18章 人类需要更多智慧 # 第19章 更多电力更大算力 # 第20章 地球上最重要的股票 # 第21章 向理性本身发起挑战 # 第22章 深不见底的恐惧 # 第23章 思考机器 # "},{"id":103,"href":"/post/computer-science/%E8%BF%90%E7%BB%B4/","title":"运维","section":"Computer Science","content":" 查询 # # 查找文件 find ./ -name \u0026#34;elastic\u0026#34; # 端口查询 ### 查询 sudo netstat -tulnp | grep :443 sudo lsof -i :443 ### 杀死 kill -9 内存 # # 服务器内存占用率 free -h 磁盘 # # 磁盘占用 df -h "}]